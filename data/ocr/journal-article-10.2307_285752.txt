<plain_text><page sequence="1">SSS ABSTRACT This is a study of a well-known controversy in computer science, between artificial intelligence and neural networks researchers. It examines claims made by participants in the field that the controversy was triggered, shaped and finally resolved in connection to activities of state research agencies, particularly the US Department of Defense Advanced Research Projects Agency (ARPA). In contrast to these claims, this account concludes that, although ARPA's relations to the controversy among researchers were important, they were indirect. This study thus brings the analytical resources of studies of scientific controversy to bear on a domain which has so far gone largely unexamined in studies of 20th-century controversies - namely, state research policy and management. The account is based on contemporary documents, historical literature, and interviews with researchers and ARPA officials. Controversy and the State: Lord ARPA and Intelligent Computing Jon Guice One of the most celebrated controversies in computer science took place between proponents of artificial intelligence (AI) and neural networks in the 1960s.1 By all accounts, the victor was AI. AI not only became an established specialty in computer research, but also a mainspring of ideas for other fields about the nature of mind, and the relationship between human beings and machines. This study examines the controversy in the context of competition between research groups for government sponsorship. According to some, the controversy's inception among researchers, the form it took, and its denouement, were all stimulated by activities of state organizations, particularly the US Advanced Research Projects Agency (ARPA). Some participants in the historical debate also link ARPA to a supposed outcome of the controversy, blaming the agency for the eventual demise of neural networks as a research specialty. In this account, I am not concerned with the later trajectory of specialties, but with the period of the controversy itself in relation to the agency. I argue that ARPA was an important but indirect party to skirmishes among researchers. By including the activities of state sponsors, this account runs counter to a tendency in studies of scientific controversy not to deal with issues of the state. There are surprisingly few studies of 20th-century scientific controversies which deal centrally with issues of state research policy and management. Moreover, while many studies in the history of computing acknowledge the massive financial underwriting of computer research by Social Studies of Science 28/1(February 1998) 103-38 :c SSS and SAGE Publications (London, Thousand Oaks CA, New Delhi) [0306-3127(199802)28:; 1 03-138;004584]</page><page sequence="2">Social Studies of Science 28/1 national security state organizations, few recognize that there may have been technical outcomes from this sponsorship.2 By examining contro- versy, this paper contributes to a growing body of literature which resists the tendency of historical studies of intelligent computing to focus on one research approach - AI - to the exclusion of other approaches.3 Controversy Studies: Bringing the State Back In4 There have been two main traditions of social studies of scientific con- troversy, both of which got their start in the 1970s. On the one hand are studies which examine public policy debates with an important element of technical content: some of Dorothy Nelkin's works are the most prominent examples of this tradition.5 On the other hand, there are studies of controversies about scientific research per se: historical and social accounts of conflict among experts over facts, theories, methods and programmes for research. Martin Rudwick's Great Devonian Controversy, and studies by H.M. Collins, are perhaps some of the better-known examples.6 Their concerns are generally epistemological. The common motivating argument is that controversies in the scientific community expose, in a particularly accessible form, the technical or rational indeterminacy of scientific activ- ity.7 Such accounts explain the cessation of dispute, or 'controversy clos- ure', by reference to various social contingencies, rather than the ration- ality or the technical effectiveness of the winners. This literature, which I will refer to simply as 'controversy studies', provides the analytical frame- work for this paper. Controversy studies succeed in displaying technical indeterminacy. There is now a wide range of examples of how a technical issue, which might be taken to be settled, factual, and so on, can be seen as open to question. The literature describes an almost equally large number of events, processes or circumstances through which disputants closed partic- ular controversies. However, controversy studies often have had a re- stricted scope. They have largely focused on what Collins calls the 'core set', or the supposedly primary disputants in a controversy.8 The core set is identified by examining a body of scientific discourse and (usually in an informal manner) spotting high frequencies of references between parties.9 The problem is that the core set is often composed almost entirely of scientists. The premise is that the determinative figures are to be found among technical professionals, and can be restricted more or less to technical debates in their own terms. This focus on technical specialists is not necessarily inaccurate, since the composition of the core set is arrived at more or less inductively in particular case studies. Still, there have been no prominent controversy studies which deal centrally with issues of state sponsorship. The best-known studies which discuss at some length relations beyond the narrow circle of technical specialists treat events before World War II.1 There are no conspicuous studies of post-World War II scientific controversies which focus, for example, on the role of state research policy and management.'1 This may 104</page><page sequence="3">Guice: Controversy and the State be surprising, considering the importance of the state in scientific research in the latter half of the 20th century. However, this situation is under- standable, considering the history of high-profile theoretical commitments of social studies of science. The loosely affiliated approaches which have defined social studies of science since the 1970s, while accomplishing a great deal epistemologically by foregrounding the local and contingent, have tended to bracket important distal social relations, such as state activities.12 Having made these general observations, it is necessary to add several qualifications. First, there has been a significant number of historical studies of science and of technical controversy which deal with state activities, notably in physics and weaponry.13 Also, in social studies of science, there are recent salutary trends. One is the extension of the general controversy studies approach to technology (that is, to techno- logical research, design, development and use). Such studies have broad- ened the cast of characters, prominently to include industrialists, members of the lay public and, increasingly, state agents and organizations.14 There has also been a renewed general interest, in social studies of science and technology, in relating technical change to politics and the state. Much of the discussion has taken the form of programmatic debate. In 1986, for instance, Susan Cozzens made the following assessment: The problem is not that we ignore science policy entirely, but rather that we do not take it systematically into account. Sociologists sometimes address their research to policy issues, but they have seldom taken the role of government agencies in scientific development as problematic in and of itself. 5 Since then, there have been other calls for widening the scope of science studies to include research policy and management, and a number of empirical studies along these lines - though none, to my knowledge, focusing on controversy.16 The challenge is to maintain controversy studies' core strength of displaying technical indeterminacy, while also expanding their scope. My aim in this paper is to demonstrate the relevance and possibility of widening the scope of controversy studies with a case study of interactions between researchers and state research managers. I argue that, in my case, it was in the midst of research decision-making (on the part of state agents) and strategizing for government sponsorship (on the part of researchers) that the indeterminacy of certain technical issues was brought to the fore, battled over and finally resolved. The Historical Argument The story of the rise and fall of 'perceptrons', told from a variety of perspectives, can be found throughout the technical literature of comput- ing, and has been passed from one generation to the next as professional folklore.'7 The controversy concerned a difference of general technical 105</page><page sequence="4">Social Studies of Science 28/1 approach, the roots of which can be seen in the earliest of World War II computer research: Once upon a time two daughter sciences were born to the new science of cybernetics. One sister was natural, with features inherited from the study of the brain.... The other sister was artificial, related from the beginning to the use of computers. Each of the sister sciences tried to build models of intelligence, but from very different materials. The natural sister built models (called neural networks) out of mathematically purified neurones. The artificial sister built her models out of computer programs.... In their first bloom of youth the two were equally successful and equally pursued by suitors from other fields of knowledge....18 However, the peaceable parity was not to continue. Representatives of AI, Marvin Minsky and Seymour Papert, criticized the work of the leading exponent of neural nets, Frank Rosenblatt. Minsky and Papert published their critique in a book called Perceptrons, appropriating the name Rosen- blatt invented for his neural models and devices.'9 Rosenblatt did not respond publicly to the book, and the field of brain-inspired computer science and engineering went into decline. The number of researchers and others in intelligent computing in the late 1950s and the 1960s was small, and the debate over perceptrons was confined largely to that community. But the controversy was recycled, and in some respects expanded, in the 1980s, as part of a resurgence of neural computing, in the limelight of advanced computing. During the 1980s, it was widely reported that the roots of the controversy had lain in competi- tion for state funding.20 In Perceptrons, Minsky and Papert themselves imply that their criticisms are motivated in part by concern over the allocation of resources for research.21 Later, Papert made the point even more bluntly: 'Money was at stake'.22 Many observers single out a funding source in the US Department of Defense (DoD). This was a critical point in the story among computer professionals, particularly among supporters of neural networks research. The two 'sisters' started to feel differently toward each other: ... when a new monarch appeared, one with the largest coffers ever seen in the kingdom of the sciences: Lord DARPA, the Defense Department's Advanced Research Projects Agency. The artificial sister grew jealous and was determined to keep for herself the access to Lord DARPA's research funds. The natural sister would have to be slain. The bloody work was attempted by two staunch followers of the artificial sister, Marvin Minsky and Seymour Papert, cast in the role of the huntsman sent to slay Snow White and bring back her heart as proof of the deed. Their weapon was not the dagger but the mightier pen, from which came a book - Perceptrons - purporting to prove that neural nets could never fill their promise of building models of the mind.... Victory seemed assured for the artificial sister. And indeed, for the next decade all of the rewards of the kingdom came to her progeny....23 Recent scholarly studies on the controversy by Mikel Olazaran argue for the technical indeterminacy of the perceptrons controversy.24 The central 106</page><page sequence="5">Guice: Controversy and the State concern of Olazaran's studies is that of other controversy studies: to show that some of the main technical claims made in the disputes were open to question on various grounds, and to describe the competitive mobilization of various resources and allies by the disputants. But, in addition, Olazaran calls for inquiry into the role of government agencies in the controversy. According to Olazaran, ARPA's sponsorship decisions did make important differences in the institutionalization of the two approaches: while AI became a well-known, thriving specialty, neural nets research was, at least for a time, consigned to the margins of the scientific mainstream. Re- searchers in both traditions attest to the fact that funding was crucial in their careers, either reinforcing their approach or directing them toward other approaches. However, because of constraints on information about the activities of Defense Department staff, details on the process of government decision-making have, in these earlier accounts, been limited. Olazaran's examination of the role of funding in the controversy thus stands as an example of the new interest in expanding the scope of controversy studies, and of the practical difficulties of investigating state research management, particularly in national security agencies. The wider historical literature on intelligent computing is crowded with semi-popular accounts which tend to characterize researchers as operating in a scientific and institutional vacuum: AI is equated with intelligent computing, or is regarded as the only credible approach; and relations with Defense Department sponsors are elided, or left unex- plored.25 In contrast, scholarly studies of the field, while also tending to focus on AI, have made an increasingly strong case for the significance of state sponsors in intelligent computing, particularly ARPA. Probably the best known assertion of government influence in AI was made by Kenneth Flamm, who suggested that the history of AI is a paradigm of massive and effective state intervention in science and technology.26 James Fleck has argued that AI was institutionalized in large part because it was successful in securing organizational backing, particularly from ARPA.27 Arthur Nor- berg and Judy O'Neill have argued not only that the agency's financial support for AI was substantial, but that agency staff supported a particular orientation to computing research.28 Paul Edwards, pursuing further still the epistemic implications, has argued that the field has had multiply ramified connections to ARPA and other national security agencies and, more broadly, to Cold War technologies, institutions and discourse.29 In the account that follows, I review points of technical indeterminacy within the research community, and underscore the argument that the controversy was animated by competition for funding. In order to explain the particular conditions of closure of the controversy, I describe the contemporary federal sponsorship system and ARPA research manage- ment practices. I show, first, that ARPA did provide high levels of funding to AI researchers, and that there were no other sponsors providing compa- rable levels of support for work in intelligent computing at that time. Then I attempt to unravel the many possible reasons that AI was chosen for support by ARPA, and research in neural nets was not. My reconstruction 107</page><page sequence="6">Social Studies of Science 28/1 of ARPA's decision-making process relies on a variety of historical materi- als which have not before been examined for their relevance to the perceptrons controversy. Sister Sciences The story of the controversy over perceptrons has been told in many different ways. In this section, I briefly present some of the highlights of the controversy among researchers, and the points of technical indeterminacy. While following the storyline of most previous accounts, this synopsis puts special emphasis on institutional and material stakes in a debate which featured both engineering problems and mathematical arguments. Artifice Artificial intelligence was becoming established as a research specialty in the late 1950s and early 1960s. AI was identified with a relatively small set of academic faculty members and their students, located mainly at the Massachusetts Institute of Technology (MIT), Stanford and Carnegie- Mellon. Among the key defining characteristics of the AI research pro- gramme was a logical or symbolist approach. This meant that AI took as its focus abstract structures of knowledge and representation. Intelligent behaviour is built up from word-like bases, using syntactical rules. This approach has generally been opposed to biologically-inspired approaches, in which intelligence is regarded as an emergent feature of machines which develop or behave like organic systems. To use a recent diplomatic expression, AI takes a 'top-down' ap- proach.30 AI researchers begin with the logic or outcomes of behaviour, and use the most expedient means available to translate the behaviour into a series of steps that can be taken by a computer - typically, a pro- grammable digital computer. Paradigmatically top-down approaches have resulted in rather intellectual applications like theorem-provers, but they have also been applied to such practical tasks as language processing and spatial manipulation of objects. 'Bottom-up' approaches, on the other hand, begin with a model of a biological system, such as the behaviour of a nervous system, and set up machines to act in a similar way. Such approaches have more often used analogue devices. Bottom-up approa- ches, particularly those which mimic the structure and function of brains, are also generally adopted for more sensory applications, such as machines which can distinguish between different sounds or sights. The lines between the two camps have never been clear-cut.31 Never- theless, a rift between symbolist and biologically-inspired computing had begun to develop among some researchers before the controversy that would later unfold about perceptrons. For example, as Fleck explains, a conference in 1952, organized by John McCarthy... ... was intended by him to attract proponents of the symbolic modeling approach. It failed in this aim, and attracted contributions more clearly in ... other... traditions. This determined McCarthy to 'nail the flag to the 108</page><page sequence="7">Guice: Controversy and the State mast the next time', which he did by using the term 'artificial intelligence' in a subsequent summer school held at Dartmouth College... in 1956.32 This 1956 meeting was later to be mythologized as 'The Dartmouth Conference', at which all of the future great men of AI, including Minsky, happened to be present.33 By 1960, important elements of the AI research programme had been put in place (notably, a focus on symbolic representation and the use of heuristic search techniques), but it was only after the perceptrons con- troversy and the decade of the 1960s that the symbolist emphasis became pronounced. Before 1970, one did not see definitions of AI which put quite as much stress on their logical or symbolic character. When the spectre of perceptrons had been laid to rest, this issue was a cornerstone of the AI conceptual edifice.34 Nature Around the time of the fabled Dartmouth conference, a challenger was gaining support. Starting in 1957, and working out of Cornell University and the Cornell Aeronautics Research Laboratory in Buffalo, NY, Frank Rosenblatt received considerable funding from the Office of Naval Re- search (ONR), then one of the primary federal sponsors of basic computer research. In 1959, Rosenblatt's research group was awarded a small grant ($10,000) by the Institute for Defense Analyses. From 1962 on, he received support matching ONR from the National Science Foundation. Joint funding by these two agencies continued through 1966, at a level of about $200,000 per year.35 Rosenblatt's original support at the ONR chiefly lay with a programme manager named Marshall Yovits. Yovits supported a number of conferences and other research activities on related lines of research, under the heading of'self-organizing systems'. Yovits acknowledged important advances in the use of computers which rely on the stored program. However, it appears that certain types of problems, mostly those involving inherently non-numerical types of information, can be solved efficiently only with the use of machines exhibiting a high degree of learning or self- organizing capability. Examples of problems of this type include auto- matic print reading, speech recognition, pattern recognition, automatic language translation, information retrieval, and control of large and complex systems.36 These examples suggest the wide range of practical interests and basic cognitive skills envisioned under the heading of 'self-organizing systems'. All these examples had considerable military interest. 'Pattern recogni- tion', for instance, meant the automation of tasks such as viewing satellite photographs for the identification of objects relevant to reconnaissance and command and control. 109</page><page sequence="8">Social Studies of Science 28/1 In addition to Rosenblatt, other prominent researchers also received large government grants under the broad heading of self-organizing sys- tems, beginning with the ONR and research wings of the US Army.37 In spite of efforts such as McCarthy's for symbolist approaches to command the lion's share of resources, other researchers were able, for a time, to persuade government sponsors that self-organizing systems held promise. Rosenblatt became an increasingly vociferous proponent of bottom-up approaches. In a 1958 report to the ONR, which was later used in other writings, he not only reasserted the bottom-up bias that he shared with other researchers, but squared off against the top-down AI community. The first section of this report is entitled 'Probabilistic Mathematics versus Symbolic Logic'. In it, Rosenblatt took his argument to the moral high ground of computer research: mathematics. While granting respect to practical achievements of the symbolic approach, he insisted that the ultimate instantiation of intelligence, the human brain, was founded on a different sort of mathematics: The mathematical field of symbolic logic, or Boolean algebra, has been eminently successful in producing our modern control systems and digital computing machines. Nevertheless, the attempts to account for the opera- tion of the human brain by similar principles have always broken down under close scrutiny... [I]n dealing with the brain, a different sort kind of mathematics, primarily statistical in nature, seems to be involved.38 In this paper, and in the rest of his works, Rosenblatt argues that probabi- listic models will yield greater insights into the working of the brain, and will also provide the basis for machines which can accomplish a wide range of intelligent tasks. At first, these tasks will be simple, and based on the classification of sensory inputs. His own work, for instance, focused on the classification (or recognition) of visual patterns and speech.39 The engineering approach of Rosenblatt and others in neural networks research was to feed a large number of small sensory inputs into a set of processing units ('neurons') - for example, eight picture elements per processing unit. These processing units would each be assigned a weight, or strength of response, with which they could then change the amplitude of the original sensory signal. These units were often called 'linear thresh- old elements', referring to their 'weighted' responses and, in analogy, to the threshold response firing of brain cells. The responses would then be combined for an overall output from the system. The key to such schemes was that the individual weights would change in response to 'training', strengthening weights that contributed to a correct answer, and weakening others. Rosenblatt published a flurry of specific findings using statistical approaches. He spoke at many conferences, and travelled to research groups throughout the USA and abroad. Rosenblatt's campaign was thus a highly visible part of a swell of interest among researchers. Starting with just a few groups at the beginning of the decade, neural computing grew to many more groups in the USA, and others in Japan and Europe. In 110</page><page sequence="9">Guice: Controversy and the State statements to the lay public, Rosenblatt waxed poetic about computers which would fall in love, write sonnets and accomplish other romantic, intuitive feats. His remarks to the popular press were full of hyperbolic fantasy about the potential capabilities of machines of intelligence. An ONR-supported press conference, unveiling one of the first working per- ceptron machines, resulted in news reports that the perceptron would, in the not-so-distant-future, 'be able to walk, talk, see, write, reproduce itself and be conscious of its existence'.40 Speaking to the scientific community, while avoiding the charged rhetoric that the mass media seized upon, 'Frank was very positive.... He was sure'.41 His scientific writings, begin- ning with contract reports to the ONR, had engaged in a sweeping, programmatic rhetoric. While careful to point out that the actual results of the new approach were as yet limited, he argued that its potential would be to open a royal road into the functioning of the human mind and the engineering of intelligent automata. Bloody Work The community of people who were involved in computer research in the late 1950s and the 1960s was small: [I]t was such that you could have an interest and keep track of what was going on in neural nets and what was going on by the AI people who had attended say, that 1956 Dartmouth conference. Some of these people went to all the same kind of workshops and would argue back in forth about what techniques were worthwhile.42 In fact, there were many occasions on which AI people, particularly Marvin Minsky, clashed with Rosenblatt and others from the neural network research community. With such a small circle of researchers, there were no doubt personal aspects to these disputes. Nevertheless, it appears that the high visibility and effectiveness of Rosenblatt's campaign fixed his work, in particular, as a political or institutional target in the minds of AI researchers. As Papert and Minsky explain in Perceptrons, the final and most public form of their critique: Rosenblatt's [1958] schemes quickly took root, and soon there were perhaps as many as a hundred groups, large and small, experimenting with the model either as a 'learning machine' or in the guise of 'adaptive' or 'self-organizing' networks or 'automatic control' systems.43 Minsky had himself worked on neural networks, as a graduate student in the mid-1950s. He even claimed priority in constructing a neural network computing device (the Snark) with a grant from the ONR.44 After gradua- tion, however, Minsky adopted a top-down approach, and became one of the leading exponents of AI. Papert was a psychologist who arrived at MIT in the late 1950s, just as Minsky was starting to assemble a research group from various funding sources at MIT.45 Minsky and Papert's criticisms, like Rosenblatt's, were pitched at the level of the eventual potential of large research programmes.46 On the one 111</page><page sequence="10">Social Studies of Science 28/1 hand, Minsky and Papert criticized the neural computing researchers for making unsupported, sweeping generalizations about the potential of their models and machines, and pledged to bring order to the domain with a rigorous investigation of the limits and possibilities of perceptrons.47 On the other hand, Minsky and Papert reserved for themselves the ability to make the judgement that, on the whole, neural computing research would be fruitless.48 Perceptrons broadcast a simple message to other members of the community interested in computers: neural computing is weak in its very foundations. By way of demonstrating the weakness of perceptrons, Minsky and Papert make a point of indicating that they use rigorous mathematical models. Like Rosenblatt, they move to moral high ground by invoking mathematics, but they do so even more pointedly. The principal thrust of their book is not to introduce a class of mathematics, but to use specific mathematical tools to set limits on the claims that neural-net researchers have made. Indeed, while the book does claim to initiate the use of certain branches of mathematics in the field of neural computing, these branches have not, by and large, been used in later work in the field of neural networks. It is rather the specific, limiting claim that neural nets are weak that was remembered by those party to the controversy. While, for Rosenblatt, 'perceptron' referred to a wide class of devices and models of brain functioning, Minsky and Papert defined their percep- tron as the simplest of such devices. According to them, the perceptrons represented the most extreme view of how simple networks of linear threshold elements could be used in computer engineering. Borrowing Rosenblatt's assertion that his and others' work in neural networks de- pends on a two-clause theorem, Minsky and Papert take issue with one of the clauses. The theorem states that (1) a perceptron can learn to recognize any pattern presented to it, (2) if (and only if) the machine can represent the pattern. The aim of their book is to show that the class of patterns which can be represented by a perceptron is so limited as to be of little practical value. One of Minsky and Papert's main examples, chosen because it high- lights a 'global' characteristic of a visual pattern, is called the 'problem of connectedness'. In this problem, a visual pattern represents a connected figure 'if it is not composed of two or more separate, non-touching, parts'.49 In the illustration that Minsky and Papert give, the problem is whether or not a line drawing that looks something like a labyrinth inscribes a single polygon. This problem cannot be solved by the percep- tron Minsky and Papert defined, and was one example of a class of problems that had been shown to be intractable, using current neural networks techniques, by researchers associated with Rosenblatt.50 Not surprisingly, Minsky and Papert had a handy solution for this problem which fitted with their research programme. They were able to write a brief, elegant program for a machine which scans the lines and constructs summary statements about its connected or non-connected structure.51 This sort of approach might be called 'logical' or 'symbolic', since it 112</page><page sequence="11">Guice: Controversy and the State translates the abstract character of the problem. More specifically, it would be called 'heuristic', since it uses a shortcut description of the specific problem at hand to produce a solution. In more positive terms, Minsky and Papert's overall argument was that what was needed were heuristics which can at least reduce the computa- tional work required for complex tasks, and also provide interpretive structure to a problem. Heuristics were an important element of Minsky's top-down research programme (and, indeed, of the research programme of most of the AI community), starting around 1960. 'Heuristic program- ming', as Minsky called it at the time, consists of translating a simplified, expedient task description into a program for a conventional digital computer. A large part of the research on heuristic programming by Minsky's group concerned visual patterns. As Minsky explained in a now-classic paper entitled 'Steps Toward Artificial Intelligence', pattern recognition methods should focus on 'heuristically significant' aspects of problems.52 For instance, in a contemporary publication discussing the processing of aerial photographs, Minsky argued that the central problem is to cope with representations which are 'somehow similar to, but not exactly the same' as representations that the computer system already has represented in its memory. Otherwise, a computer would quickly become overloaded with memorizing all possible patterns that are not exactly alike, and would be useless, since there is always in practice some kind of noise or distortion. 5 The Digital Heart of an Analogue Pig: Varieties of Indeterminacy Many recent writers, prompted by the professional folklore, have at- tempted to defend parties to this dispute, and have thereby re-examined the technical issues and terms of debate. I will describe the most common approaches to reconstruction of the controversy taken on each side of the AI/neural nets divide, which also do not simply reject the opposing research programme. These more charitable accounts describe some of the less extreme grounds of technical indeterminacy in the controversy. Both sides share a focus on the difficulties raised by 'combinatorial explosion': namely, that when dealing with large amounts of information, one can overwhelm a machine with so many possibilities of sorting data that one can never solve any problem in an affordable manner. The most common argument in defence of the 'natural sister' is that, as Papert mockingly puts it, he and Minsky never actually accomplished their goal: what they produced as evidence of the death of the natural sister was merely the heart of a pig. Specifically, Minsky and Papert's definition of a perceptron required that it be a 'single-layer' network.54 The much larger class of possible neural networks have multiple layers. That vital centre was unscathed by Minsky and Papert's attack. Rosenblatt (and other neural network researchers of the 1960s) had difficulty in getting multi-layer devices to perform correctly on specific 113</page><page sequence="12">Social Studies of Science 28/1 tasks. The neural-net research community openly acknowledged that train- ing multiple-layer nets was an engineering hurdle they had yet to sur- mount. They also acknowledged, on fundamental mathematical grounds, that it was impossible universally to define the limits of multiple-layer nets in the same fashion that Rosenblatt had defined them for single-layer machines.55 (It has no finite bounds for solution, and thus is prey to the problem of combinatorial explosion.) In other words, they granted the mathematical indeterminacy of the limits of their research, while continu- ing with their practical work.56 In defence of the 'artificial sister', it was argued that she was a more realistic and effective engineer: AI techniques were better suited to the digital computing machines of the 1960s than were neural networks.57 Many neural network models of the 1950s and 1960s were instantiated in simulations on digital computers.58 However, the genius of a neural network approach was often seen as stemming from the use of analogue devices, specially built to resemble the interconnected character of groups of brain cells.59 AI researchers pushed the limits of existing digital com- puters, but their methods were better adapted to the high costs of comput- ing power. AI researchers had to develop new languages for digital com- puters, so that the machines which had handled mainly numeric data could be used for non-numeric symbolic information. Moreover, as Minsky argued in 'Steps Toward Artificial Intelligence', heuristics promised to reduce the complexity of problems, so that the digital computers available would not become bogged down in combinatorial excess. The Richest Monarch As textbook accounts point out, beginning in the early 1960s, ARPA money was given to Minsky's group at MIT. No ARPA money was given to Rosenblatt. However, this does not mean that the agency had made any simple choice between AI and neural nets. For one thing, it is likely that ARPA recognized more than two research groups in intelligent computing, although debates among researchers may have frequently been simplified to two camps. It also appears that ARPA had a variety of criteria for choosing between lines of research. The conclusion of the perceptrons controversy remembered by most researchers was also the one remembered by ARPA personnel of the time: Minsky and Papert showed that perceptrons were highly limited. The question is how ARPA staff reached this conclusion, and what this meant to agency decision-makers in the context of the concerns of that agency. How did ARPA staff conceive of Defense Department problems and the technical promise of particular approaches to intelligent computing? This question has been difficult to answer because there are no direct sources of information. There are virtually no relevant contemporary agency documents, and the faulty memories and tact of living former government staff makes interrogation on this question only partly pro- ductive.60With a little detective work, though, other sources of information 114</page><page sequence="13">Guice: Controversy and the State can help to piece together a solution. The sleuthing begins with an account of ARPA's policies, management practices and financial commitments, especially towards AI. Then I consider various intellectual, personal and practical ties that the agency staff had to AI, and their more distant relationship to research on neural nets. I will be arguing that some of the most important considerations contributing to ARPA decisions in favour of AI were not matters of policy in the ordinary sense, but eminently practical issues: the credibility of particular research projects and individual researchers in professional networks associated with particular organizations, and practical com- plementarities between AI work and particular approaches to digital computing.61 Command and Control ARPA's institutional home was (and still is) the DoD-wide Office of the Director of Defense Research and Engineering (ODDR&amp;E). ARPA's gen- eral charge was to support 'high-payoff' research and development in universities, government labs and industry, which otherwise might not have a niche in other DoD research enterprises.62 A small number of managers distributed large budgets. Administration of ARPA contracts was handled by other military research sponsors. ARPA's spare internal struc- ture was also supported in technical matters by an extensive system of external contacts and consultants throughout the technical wings of the Pentagon, and by revolving, informal relationships with researchers and research managers in the private sector. From ARPA's founding after Sputnik until the mid-1960s, the major- ity of the agency's programmes were linked directly to Presidential and other high-profile Cold War policy concerns, including nuclear test detec- tion and space and missile technologies. Starting in the late 1960s, ARPA's programmes diversified. However, throughout this period computing re- search represented a relatively small part of the overall budget, and had little direct involvement from ARPA and ODDR&amp;E. In early 1960, ARPA requested that the closely-related Institute for Defense Analyses survey the information sciences for their implications for defence. The survey noted five critical DoD problems...: 1) pattern recognition and formation of concepts out of data, 2) decision-making, 3) commu- nications, 4) control, and 5) information storage and retrieval, data handling, and data processing. The report described some research activ- ities concerning information science already supported by agencies of the DoD. They ranged from main-line applications of psychology, the social sciences, and biology to specific projects in encoding of basic information, self-organizing systems, and heuristic and adaptive computers.63 This survey was one of several steps that led the ARPA director and executives in the ODDR&amp;E to the understanding that 'improved comput- ing technology was the way to control greater amounts of information and 115</page><page sequence="14">Social Studies of Science 28/1 to present it in more effective ways to aid decision making'.64 In 1962, ARPA established a Command and Control Program, initially to give an official home for a contract with the Systems Development Corporation.65 This programme was soon promoted to the rank of Information Processing Techniques Office (IPTO), and charged with funding basic and applied research which addressed problems in military information han- dling and decision-making. In particular, IPTO would apply computers to non-numeric data - a largely undeveloped area of research. The first IPTO director was a psychologist and computer specialist from the Boston area, J.C.R. Licklider. Licklider came to ARPA on leave from a computer firm called Bolt, Beranek and Newman (BBN), having earlier taught at Harvard. He presented a strong vision of the directions in which computing research should go, published in 1960 in a paper entitled 'Man-Computer Symbiosis'.66 According to Norberg and O'Neill, this paper reflected leading ideas in the computer research community at MIT and other institutions in Cambridge, MA, with whom Licklider was in close touch. The central idea was not to attempt to replicate human abilities with computers, but to draw on the strengths of computers to produce a more fruitful partnership between human decision-makers and computing machines. This conclusion had also been reached by the staff of the Lincoln Laboratory, a DoD-funded offshoot of MIT, then developing the SAGE computer-based system for air defence. SAGE researchers thought that 'command and control systems required both computers and people'.67 From Licklider's point of view, in close contact with defence-related computer research in the MIT area, this meant that computers, as well as improving on other fronts, had to become easier to use. People should be able to exchange information with machines in a natural manner, using, for instance, visual displays, ordinary speech and pointing. Computer systems should be powerful enough to provide up-to-the-second informa- tion with little lag time, and to process data at least as fast as human operators can use them. Computers should also be able to handle complex problems in a wide variety of situations, in an adaptive and flexible manner. Licklider called this vision 'interactive computing'. While this vision was extremely broad, Licklider did have specific preferences of approach and an agenda for research, which in turn defined the initial IPTO funding portfolio. IPTO's programmes began with an emphasis on time-sharing, computer languages, programming and, under various other budget categories, artificial intelligence. Licklider stepped down from his directorship two years after IPTO began, in 1964. It was this initial funding of AI research that represents the IPTO support for work relevant to the controversy among researchers over approaches to intelligent computing. As it happened, however, Licklider's immediate successors worked closely with him, shared many views on computing, and are good sources of information about the thinking in the community in which Licklider 116</page><page sequence="15">Guice: Controversy and the State played a unique role. Of Licklider's three successors through 1970, two hailed from the MIT computing research community: Ivan Sutherland (IPTO director, 1964-66) and Lawrence Roberts (1969-72). The other, Robert Taylor (1966-69), met Licklider as a computing research pro- gramme officer for NASA, and had other links to the MIT defence research community. They all subscribed to Licklider's vision of interactive computing, and continued most of the research directions originated by Licklider through the decade, including AI.68 (For illustration, see Chart 1, 'IPTO Programme Areas, Fiscal Year 1965'.) Chart 1 IPTO Programme Areas, Fiscal Year 196569 Command and control research, focusing on man-machine interaction Computer languages Advanced programming techniques Advanced computer systems design as related to defence problems Time-sharing Advanced software techniques For the most part, the decisions of IPTO were in the hands of its director, in consultation with a network of contacts in the DoD and the computing research community, centred, at least through the mid-1960s, on MIT and Lincoln Laboratory.70 During Licklider's tenure, ONR staff, especially a programme manager named Marvin Denicoff, offered particularly close contacts.71 Denicoff had managed research in computing and cognitive sciences for years before IPTO's founding, and not only administered many ARPA contracts with universities, but also served as a 'scout' for IPTO by virtue of his own sponsorship efforts in the field: A common phenomenon was for ONR to be an advance scout and find a person who wasn't funded and get him a small amount of money, like 50 thousand dollars or so. Then, if something came of it... I would go to [ARPA] and they would say 'Yes... Looks promising. Maybe we'll now come in with a larger sum. We'll begin funding that individual (or that group) and run the program through ONR so the Department of Defense and the Navy will still get full benefit'.72 It was not necessary for IPTO directors to show their Washington con- stituencies that the basic research they sponsored would have immediate use, but there had to be a clear connection to medium-term use in military systems. The view of IPTO managers was that there were no major differences in interests in computing between academics, corporate users, and the military. Their strategy, as Licklider explained in an interview, was to... ... look at the thing in terms of big block diagrams, because what the military needs is what the businessman needs is what the scientist needs. 117</page><page sequence="16">Social Studies of Science 28/1 But look more sharply - look ahead a block... [t]ake a project done around here: making a computer simulation of a Morse Code operator, so that you can hook the computer in the net with people. That's an artificial intelligence problem, and academics get tremendously interested in it.... Military people want something that will work, and not something that will advance the theory of how to do AI. But they will both be happy with exactly the same project if it has both facets... I did not feel much pressure to make a military case for anything. I tried to stay at the top level of the block diagram, and tried to convince people of the philosophy that in general the same thing is needed.73 While the promise of at least medium-term military applications was necessary for support, IPTO managers sought the development of generic computing abilities. One reason for this was that computing was not high on the list of priorities among Pentagon technical and strategic policy staff. While computing was recognized as important for command and control, nuclear and space technologies (among other examples) were more press- ing fronts at the time. More generally, the political climate at this time, before the public debates of the late 1960s and later, which required greater accountability for defence and non-defence categories, allowed for pockets of relatively loose fit between university research and warmaking. IPTO's Interest in AI While some accounts assume specific reasons for ARPA's endorsement of artificial intelligence research, AI was also, and probably in large part, supported because of a number of practical contingencies. As Licklider himself has explained: AI came into the picture primarily because several universities who had ARPA contracts also had early workers in AI. For example there was a contract with MIT which brought Marvin Minsky... and his AI group in.74 There were other AI research groups funded by IPTO through the 1960s, but Minsky's group at MIT was the first, and appears to have helped establish cooperative relations between the emerging IPTO community and the emerging AI community. During the 1960s, the Information Processing Techniques Office budget was a small percentage of the total ARPA budget, but IPTO was the single largest sponsor of computer research in the Department of Defense. It funded between half and two-thirds of all DoD support for computer research in the decade, which represented a major share of university computer research.75 In fiscal year 1965, for instance, the total was $14 million: through the 1960s, artificial intelligence funding repre- sented about a fifth of the total Office budget.76 IPTO provided high levels of consistent funding to a small group of researchers.77 Estimates of the American AI research supported by the agency during this period range between 75% and 95%.78 The singular presence of ARPA in the field has led some observers to say, in exaggeration, that AI was 'created' by ARPA.79 118</page><page sequence="17">Guice: Controversy and the State The concentration of IPTO funding was increased by limiting the number of institutions to which the office would grant support. There was an explicit policy of focusing on 'centres of excellence'. Licklider selected a small number of groups and individuals for sponsorship during his tenure, most of which he knew before his appointment at ARPA. Throughout the 1960s, the central justification for IPTO funding for AI research was that it would contribute to the construction of computer systems which would assist with data interpretation and decision-making in command and control - the vision articulated by Licklider in his paper on interactive computing: A capable machine assistant required the design and construction of a system that could understand data about a problem situation, frame hypotheses about the task to be performed..., select from among hypoth- eses, present a recommended or rank-ordered solution, and state the justifications for the recommendations.80 Specifically, for example, it was assumed that '.. AI techniques will make it possible to interpret satellite photographs automatically.. ..81 More generally, AI was justified as an approach which integrated the variety of tools and techniques then available to computer scientists - that is to say, as an approach which facilitated research and development through innovative and synthetic approaches to software. In other words, Licklider and his successors thought that AI had important value for systems research. As Taylor explained to me: I funded the AI work not because I believed that they were going to actually create computer organisms that manifested intelligent behaviour but because... the AI community in those days was a leading edge for the rest of computer science. They were a sort of avant garde, out-in-front group of people who were creating challenging problems for the rest of computing - problems having to do with building complicated subsystems that then had to work together to accomplish some objective. They formed the leading edge of systems research.82 In this manner of understanding AI research, anthropomorphic metaphors are downplayed in favour of a more practical, experimental and community- oriented view. IPTO's interests in AI were rooted in the Boston-area defence and research communities. At MIT, computer policy and research plans in the late 1950s were focused, not on AI, but on 'time-sharing' - ways of apportioning the work of a central computer so that multiple users could interact with the computer at apparently the same time, as with many terminals. An initial scheme for accomplishing this task was developed by a team including Marvin Minsky.83 Around the same time, Digital Equip- ment Corporation personnel located in the Boston area, having founded the company in 1957 to commercialize MIT computer design work, were working on a similar project. In 1961, Digital's new computer, the PDP-1, was presented to MIT, and another MIT spin-off company, BBN, was working on developing a time-sharing system for the PDP-1, which was 119</page><page sequence="18">Social Studies of Science 28/1 fully functioning in 1963.84 Until taking leave for service at IPTO in 1962, Licklider was the vice-president of BBN and a principal organizer of the time-sharing project, along with MIT staff, including Minsky and McCar- thy.85 Minsky had earlier been a student of Licklider's at Harvard.86 Minsky's ARPA contract for work later publicly identified as 'AI research' - which was IPTO's first AI contract - was part of a large, interdepartmental project intended to make use of the PDP-1 computer. Licklider asked a colleague from MIT, Robert Fano, to head the project and to bring a proposal, with other faculty members such as Minsky, to Licklider in his new post at ARPA.87 This effort was called 'Project MAC'. The acronym has been said to stand for several phrases, including 'multiple access computer', which noted the technical focus of the project, and 'machine-aided cognition', reflecting the vision of interactive computing. That vision motivated many involved, and formed the core of its initial proposal: The broad, long-term objective of the program is the evolutional develop- ment of a computer system easily and independently accessible to a large number of people and truly flexible and responsive to individual needs. An essential part of this objective is the development of improved input, output and display equipment, of programming aids, of public files and subroutines, and of the overall operational organization of the system. A second, concomitant objective is the fuller exploitation of computers as aids to research and education, through the promotion of closer man- machine interaction....88 Between 1963 and 1970, ARPA spent about $25 million on Project MAC for research not only in time-sharing, but also in interactive visual displays, programming languages and a number of programming tools. The first year's grant was for over $2.2 million, about a third of which went to Minsky's group for research on heuristic programming and 'natural language processing' (machine interpretation of English).89 Among other complementarities and practical dependencies among the various projects, the time-sharing system afforded the computer-power-hungry AI research greater memory and speed, and allowed for faster iterations of experiment. As John McCarthy later put it, he supported the time sharing system 'as something for artificial intelligence, for I'd designed [a programming language] LISP in such a way that working with it interactively - giving it a command, then seeing what happened, then giving it another command - was the best way to work with it'.90 Minsky's group continued to be supported through the 1960s, involv- ing all of the office directors named in the acknowledgments of Perceptrons: 'J.R. Licklider, I.E. Sutherland, R.W. Taylor, L.G. Roberts'.91 Starting in the mid-1960s, IPTO spread its support for AI research to groups at Stanford and Carnegie-Mellon, and smaller institutions, such as BBN. Stanford's principal investigator, John McCarthy, had moved from MIT, where Licklider knew him in several capacities, originally having audited one of his courses. Likewise, most of the other investigators in the wider IPTO-sponsored AI community, including such major figures as Allen 120</page><page sequence="19">Guice: Controversy and the State Newell and Herbert Simon, were known to ARPA staff before their sponsorship. Partly under the direction of IPTO managers, American AI research groups were in close communication, swapping knowledge, tech- niques and personnel over the years. IPTO's Stance on Neural Networks The relations between IPTO directors and neural network researchers was more distant at best. Like many members of the MIT-area computer community, Licklider had had an interest in 'self-organizing', 'adaptive' and other biologically-inspired approaches in the 1950s; but by the mid- 1960s he was openly critical of them. Norberg and O'Neill found that, during the late 1950s, while working with others on an air-defence project, Licklider's earlier concern with 'the status and promise of self-organizing automata' turned toward artificial intelligence, particularly ideas in the field 'that appear to have a bearing on systems problems' - that is to say, are relevant to the integration of complex assemblages of information- processing devices and procedures.92 In 1962, Licklider gave a conference paper which outlined his posi- tions on the fields in which he was responsible at ARPA, military in- telligence and command and control. He strongly favoured artificial in- telligence approaches, citing in particular the kind of work in heuristics done at MIT, and the work of Simon and Newell. At the same time, he suggested that other approaches to intelligent computing were based on an unrealistic vision of problems being 'made to unfold at the lifting of a finger'.93 In 1966, Licklider gave a keynote speech at a conference on 'self- organizing or learning information systems', in which he chastized partici- pants for their interest in this topic - a rather unusual approach to take in a keynote address, as he pointed out himself. A more promising approach, Licklider said, reviewing his vision of interactive computing, was to de- velop 'assistants' to humans. Rather than replacing people with machines, which was at best a long-range possibility, he said, it should be possible in the near and medium term to develop systems which complement human skills: Eventually, if we are successful in actually solving the problems of adaptive, self-organizing, and learning automata, it may be that the amount of man-computer interaction required in problem solving and decision making will decrease, but I am not very sanguine about seeing that conclusion proved at any early date.94 The facilities which Licklider cited as promising... ... are widely known through the experiences in on-line interactive computing at Bolt, Beranek and Newman, the Carnegie Institute of Technology, Dartmouth College, General Electric Company, IBM Cor- poration...the Lincoln Laboratory, Project Mac and the Research Laboratory of Electronics of Massachusetts Institute of Technology, the System Development Corporation... 121</page><page sequence="20">Social Studies of Science 28/1 ... in short, the MIT-related centres and spin-offs from which Licklider hailed.95 The ONR research manager Marvin Denicoff had given small grants to many researchers in intelligent computing, including Rosenblatt, and later worked with IPTO to administer much larger ARPA awards, includ- ing the award to Minsky. According to Denicoff in a 1989 interview, Rosenblatt's work was more appropriate for funding by ONR, rather than ARPA, because it was unlikely to produce technological results in the near or medium term: [T]he Office of Naval Research had funds at the level of $40K to $50K. ARPA was able to fund hundreds of thousands, or even millions. Rosen- blatt never attracted that kind of money, because he wasn't offering a large pay-off. By pay-off I mean not in the scientific sense, but in the applica- tion sense, world problem solving... [H]is work was much more, I would say, traditional science.96 Similarly, Robert Taylor said in a recent interview that during his tenure as director of IPTO, he never considered funding neural networks and 'other' linear threshold element devices. The main problem with work with neural networks research was that the devices were far too simplistic to result in the kinds of behaviours that their proponents envisioned: 'the models that these folks in the perceptron world had that led them to make the claims that they made were just unrealistic...'.97 Like many of his contemporaries, Roberts had some experience with neurobiology and neural-type computer engineering. His view, and that of other researchers, was that it was often much easier at the time to program a computer with some assumptions about a problem than to develop a working neural network for the same problem. In visual pattern recogni- tion, for instance, it was more productive to build in basic spatial assump- tions - such as that something which is partly blocked from view might be under something else. This sort of approach enormously reduced the amount of computation necessary for useful machines.98 Thus, Roberts supported a heuristic approach to such problems as image processing - at least for near- and medium-term results. In sum, IPTO controlled a large amount of money for basic research in intelligent computing - a larger, more concentrated sum than could be found anywhere else at the time; and IPTO practised an explicit policy of concentrating resources in relatively few centres of excellence. IPTO's funding decisions were determined by its directors, who were generally aware of a variety of approaches to intelligent computing. However, these directors, particularly the founding director, exhibited a leaning toward top-down and digital approaches. The view of computing which the early directors took was steeped in the perspective of the MIT-area computing research community, and professional links to this community were dense. In contrast, professional and other links to Rosenblatt and other neural networks researchers were more distant. 122</page><page sequence="21">Guice: Controversy and the State As James Fleck has argued in relation to the growth of the field through the 1970s, AI gained advantage from the fact that digital technol- ogy eventually became the dominant standard in computing. But, espe- cially in the early 1960s, what counted was the support for digital comput- ing among certain defence-related organizations, and the provision of digital computing in particular universities. Minsky's contract with ARPA, as I have argued, was associated with the large time-shared digital com- puter at the centre of Project MAC, which itself was partly an outgrowth of the military research in the MIT area. The Artificial Intelligentsia Some of these points are colourfully illustrated by a satiric paper presented at a conference in 1963. Entitled 'The Artificial Intelligentsia', this paper proposed a review of the field of intelligent computing, and included a mock US federal 'request for proposals' (RFP), along with responding proposals and an official evaluative report. The names of all of the organizations and their staff would be altered, but each of the imaginary documents would be written in 'the spirit and style of the genuine article'.99 The paper is based on first-hand knowledge of many of the individuals in the account, a well-rounded bibliography (citing actual papers in the technical literature), and guidance from young researchers (acknowledging them by name). The author, Louis Fein, was a financially independent computer consultant who was sometimes known as a 'cynic' and a 'gadfly' - and the text of his paper gives no impression that he has been taken in by any particular group within the field of intelligent computing, including the US government.'0? His earlier publications in- cluded a respected general review of the emerging field of computer research, with which Fein was among the first to bring into circulation the term 'computer sciences'.101 Fein parodies the concerns and claims of both researchers and inter- ested parties in the Defense Department. Along with a wide range of specific technical problems, his RFP characterizes the technical issues in the following manner: [I]f a method could be found which would provide intelligence, by- passing humans altogether, revolutionary improvements could be made in our domestic and international situation.'02 Several 'companies' respond to the RFP. The first (mock) proposal is presented by a rather vague and platitudinous group interested in 'self- organization'.103 The next is submitted by 'Dandylines Enterprises': their proposal claims that some, but not all, of the technical problems identified by the RFP can be solved using networks of simple computing elements running concurrently. These machines are intended to operate as object recognizers or classifiers, such that distinguishing features are put in correct categories. The networks of elements are arranged in 'layers', and 'trained' according to a variety of methods. The notation is statistical and algebraic.104 123</page><page sequence="22">Social Studies of Science 28/1 The third proposal is submitted by a company called 'Search Limited, formerly Search Unlimited', located in 'Carnage, Pennachusetts'. In a polite but conspiratorial remark on the experience of this research group with all of the specific problems identified in the RFP, the author states: I take it that this is not a coincidence.... We would be delighted to negotiate separately a contract covering some of the items on the list that we are certain our competitors will not bid on. For the others, we feel sure that our demonstrated competence and experience will influence your decision to award contracts in our favor.'05 The product line of Search Limited 'consists mostly of heuristic programs; some algorithms; a few formal languages and an occasional computer system design'.106 The final proposal is presented by a company called 'Calculated Risks, Inc.', located in 'Clusterville, N-Space'. This proposal observes that 'Cal- culated Risks... is probably the oldest and certainly the quietest of the organizations currently in the field'.107 They make a claim to seniority 'based on the fact that our founder Bayz N. Gouse generated the theoret- ical foundations' of their approach centuries before.108 The technical explanation uses a statistical notation similar to that of'Dandylines Enter- prises', and in fact points out that the most basic machine in their line 'is a threshold element'.'09 Also like Dandylines Enterprises, Calculated Risks focuses on 'recognition applications such as target recognition, voice recognition, handwriting recognition, medical diagnosis...'..1 The evaluation of the proposals was contracted to a company called 'Pessimyths, Inc.', whose president is 'J.R. "Bubbles" Piercer'. The evalu- ation begins by criticizing the RFP issuer for 'failing to ask certain companies to bid', and asserts that there is one 'firm' which, while not characterizing its research 'in exotic and anthropomorphic terms', does possess the practical skills necessary for advanced computing."' Then Piercer criticizes the RFP for overlooking the possibility of computer 'assistants', rather than machines which emulate, simulate or imitate human behaviours. Of the companies which did make a bid, the one focusing on 'self-organization' is dismissed as a serious enterprise. The remaining three are compared by size: the largest and most established by far is Search Limited, 'with hundreds of staff scientists'.112 The evaluation makes 'a strong recommendation to support research' by Search Limited, particularly for the Representative and the Scientific Bureau of Investiga- tion. It also supports research in the other two companies, focusing on 'proving training theorems and capacity theorems'.13 Of course, the satire should be taken with a grain of salt. The main point of the 'evaluation' is to deride the field of intelligent computing: it is short on praise for any of its schools. For whatever reasons, three of the schools, and not just one, were 'recommended for funding'. However, 'Search Limited' was singled out in the mock evaluation as the largest, most established, and most worthy of support. What is more, the areas 'recommended' for 'Search Limited' correspond to areas actually funded 124</page><page sequence="23">Guice: Controversy and the State by IPTO. The areas 'recommended for research' by the two schools which were never actually funded by IPTO correspond to major points of criticism of those schools at the time: the need for improved methods of training (which was an important point of contention), and proofs that linear threshold element networks have the capacity to represent the problems given to them (the central problem of Perceptrons). The basis of the evaluator's confidence in Search Limited, relative to other 'companies', was its size and well-established character. According to the report, this company, which imaginatively represents not only MIT researchers but AI researchers at other universities as well, employed hundreds of scientists, while the other 'companies' represented far fewer researchers and was, from the point of view of the evaluators, less well established. A hint of direct personal links between AI and ARPA is suggested by the conspiratorial tone of Search Limited's proposal. Fein's parody not only offers some suggestive evidence of ARPA's preference for AI because of organizational success and personal links to ARPA, but also humorously illustrates the multiplicity of approaches and research groups competing in the field of intelligent computing in the 1960s. The companies described (that is, research schools) were in fact recognized groups of researchers reflected in the technical literature. More than two sets of researchers were necessarily in some sense also recognized by ARPA staff, though the research groups taken seriously in the mock evaluation were grouped, by and large, into two camps: those which used perceptron-like devices (with linear threshold elements), and those which took AI's algorithmic approach. Conclusion Rosenblatt's campaign was at its peak in 1958 and 1959. Minsky began mounting his attack in meetings at that time, and presented critical papers in 1960 and 1961. In 1962, Minsky and his colleagues landed an ARPA contract for research, which continued each year after that for over a decade. Rosenblatt was not considered for funding by ARPA, and his support from the ONR and NSF, which had never been very large compared to ARPA grants, started petering out around 1964. Minsky and Papert refined and developed arguments against perceptrons throughout the decade. The controversy, which was most visible in a few documents and in small scientific meetings, never ended with a public spectacle. Rosenblatt and other neural networks researchers did not admit defeat. Individuals who had worked on neural nets either continued their work without the trappings and comforts of major institutional support, or moved into other areas of research. Major centres of research in the field, such as the SRI neural-nets group, withered and disbanded."4 By 1969, when Minsky and Papert's book was published, the controversy among academic and in- dustrial researchers had, for all practical purposes, been over for years. 125</page><page sequence="24">Social Studies of Science 28/1 Through the early 1970s, government funding for neural-net research groups in the USA did not grow. Minsky's group continued to get nearly 'a million dollars a year' from ARPA, as part of Project MAC.115 The published literature displayed a slow decline in references to 'perceptrons', and a rise in those to 'artificial intelligence'.16 AI had captured the limelight in conferences and publications, representing itself as a coherent and important field of research, while neural networks research receded to the background of the many various approaches taken by computer scientists and engineers. Minsky and Papert's Perceptrons stood as a memorial to a 'failed approach' until the early 1980s when, again with government sponsors (including ARPA) playing an important role, there was a resurgence of interest in neural computing and, some claim, a crisis of confidence in AI. The controversy of the late 1950s and early 1960s became relevant once again, and various re-enactments and defences have been performed, and may continue to be performed, as struggles in cognitive and computing research continue. Like other controversy studies, this story has an opening, a contest, and an end: a period of relative closure. Like all controversy studies, it identifies parties to the dispute and characterizes their arguments, tactics, and concerns. What is different about this account is that it includes government sponsors among the relevant groups, and discusses the com- petition of researchers for funding. Before reviewing the argument, however, I want to take pains to point out what I am not arguing. First, although I have quoted references to the strong claim that neural networks research fell into decline simply because of ARPA's actions, I do not make that claim myself. I would stress that, while ARPA's implicit decision not to fund neural networks among other approaches affected the practical, symbolic and other resources available to neural networks researchers, there were undoubtedly many other aspects and causes of the decline. Most importantly, however, this issue is of secondary importance to my argument, which is less concerned with controversy outcomes than with the role of ARPA as an audience to the controversy. Second, I do not want to suggest that the published book entitled Perceptrons had any historical relationship to decisions at ARPA. The most heated points in the controversy took place around 1960, and ARPA's initial decisions in the field of intelligent computing were made by 1962, while the book was published in 1969. Rather, I am arguing that the contents of the controversy which preceded the book bore some relation- ship to decisions among ARPA staff. Perceptrons used material first articu- lated by its authors in conference papers, seminars and informal conversa- tions in the late 1950s, and DoD executives made it their business to be aware of debates among researchers at that time. In fact, Licklider (who, along with Denicoff and other consulting members of the defence commu- nity, took part in the founding of ARPA's computer research agenda on the heels of the most heated period in the controversy) took an explicit 126</page><page sequence="25">Guice: Controversy and the State position on the debate in public. Licklider said that he was choosing AI over other approaches in intelligent computing. Finally, and more generally, I am not arguing that 'external factors' were the determinants of controversy closure, as distinct from technical merits of arguments and other 'internal' issues, such as the performance of computational devices. There is a common misunderstanding of con- troversy studies, and of social studies of science in general: namely, that a 'social analysis' means that 'technical issues' are written out of the account. In fact, the distinct contribution of studies of scientific controversy is that they show how technical issues are generated within frames of reference not normally seen as 'technical'. In this study, too, I have tried to show how so- called 'internal' (or scientific, rational, technically meritorious, and so on) phenomena are also situated in, and constituted through, a particular set of social and practical phenomena - thus collapsing the distinction between 'internal' and 'external' factors. These are important qualifications to make - in part, because the history of intelligent computing and ARPA are sensitive topics today. This is reflected in the professional folklore about the perceptrons controversy, with its tone of finger-pointing at ARPA, and at its supposed henchmen. A 1987 textbook on neural networks, for instance, seems to suggest that Minsky and Papert should be held personally culpable for having en- couraged the decline of a competing line of research.117 Not surprisingly, Minsky and Papert (and other supporters of AI) have denied such accusa- tions. In a direct rejoinder to the textbook, Dr Minsky told me: ... the idea that we had proved... true theorems for political reasons is ... terribly comical. I just wondered what [the author] understood about the nature of mathematics. Can you actually prove any theorem you want to if you're evil enough?18 In this paper, my concern has not been with these moral questions, but with what actually happened: how it was that politics, money, theorems and machines came to have certain relationships in the context of conflict and collaboration among researchers and research agency officials. So, in reviewing the substance of the argument, let me state at the outset: in my story, there are no bad guys, and there is no bloody dagger. There are numerous value-laden issues, but the story I tell lacks the charm of an open conflict amid a few distinct characters. Unlike the controversy among researchers, in which participants actively sought to make divisions clear and explicit, relations to government agencies were left undeveloped. I have argued that ARPA related to intelligent computing in a web of relationships, and that there were many indirect links between ARPA and the perceptrons controversy. It appears that the perceptrons controversy originated, at least in part, in competition for government sponsorship. Rosenblatt's arguments, and the responses of Minsky and Papert, could be enough to suggest that this 127</page><page sequence="26">Social Studies of Science 28/1 might be true. In addition, the strong rhetoric took place in an environ- ment of scarcity. Intelligent computing was distinguished from general computer research in that it required extraordinarily expensive computing facilities, almost by definition. ARPA was an important audience, because it had a great deal of money compared to other sponsors of the sort of exploratory research that intelligent computing then represented; and ARPA tended to concentrate this money in select research groups. The IPTO policy of establishing centres of excellence may have augmented the winner-take-all character of the perceptrons debate. The sweeping, pro- grammatic character of its arguments is consistent with the need for high levels of funding, and an environment dominated by large-scale programmes. There is little evidence in this account to suggest specific effects of DoD-wide military strategy that would distinguish greatly between the then-existing approaches to intelligent computing, and thus alter the conduct of the controversy. As references to applications of both AI and neural networks research suggest, both research programmes had already adapted to, and grown out of, military problems, to the extent that these developments were not shared by other constituencies for computing research. However, the prominence of visual pattern processing tasks in the debate - particularly the direct references to satellite imagery - may have been stimulated by the current technical infrastructure, and by the air defence interests of command and control facilities, then prominent. For IPTO in particular, there do appear to have been important differences among research groups and approaches. I have tried to suggest that, among the most important factors weighing in favour of the AI camp (and, in particular, Minsky's group at MIT), were not 'policies' in the usual sense, but practical issues: strong professional ties; the fit between AI techniques and particular computing installations; and the IPTO bias toward studies which took a pragmatic approach, and appeared to promise medium-term development. However, it is not possible, based on the information gathered here, to point to specific ways in which these issues affected the conduct of the controversy among researchers, aside from a general reinforcement of these tendencies in AI research. The closure of the controversy - the cessation of dispute, for a time, in a certain locale, 'for all practical purposes' - was, among other things, a matter of disinvestment by American research agencies in neural nets, and lavish investment by ARPA in AI. On this point, the professional folklore, making a commonsense inference in observing the history of the field, is on target. As Olazaran has argued in detail, the institutional support which went to Minsky's group was not only precisely that, but was also accom- panied by wider support for AI, and wider repudiation of perceptron-like (and other self-organizing) approaches.118 At least partly, this was because the US research agencies were the leading funders of intelligent comput- ing, and they communicated closely with each other. In this way, ARPA's decision to support AI was part, and possibly an especially influential part, of a larger institutional process affecting the closure of the controversy. 128</page><page sequence="27">Guice: Controversy and the State Fleck has shown that the AI research community exhibited, at least through 1970, remarkably dense ties between groups.'20 This is an ob- servation frequently made about the field - often as a complaint. For example, Edward Feigenbaum, an early leader of AI research at Stanford University, made the following remark on the contentious climate in which computer science management decisions were being made during the 1960s: Computer science not being a discipline of well established cultures and traditions, you would find wide dispersion of opinion, so that the average ranking of a computer science grant, let's say on a scale from one to five - would be around three, with some of the peer reviewers saying it was excellent and some saying it was terrible.... Now, people outside the ARPA community of investigators would say that that's an insider's view, that in fact it was highly political; it was just that there was an 'in' group and an 'out' group. If you were a student of Newell, or Simon, or Minsky, or Fano, you were in. That was very political. That was 'political' in the British sense of being a minister by virtue of where you went to school, and your accent.'12 My point is that ARPA was also a central figure in the AI community. Feigenbaum's reference to 'ministers' is (at least partly) not just an analogy: allowing for personnel and other exchanges between investigators and ARPA staff, it is (at least in part) a literal description of the situation. As I see it, the most troubling problem with the argument I have presented is the problem of all controversy studies: they are complicated, imprecise and hard to prove. Studies of scientific knowledge have the difficult task of showing complex relations between cultural contents (knowledge, argument, design decisions, research programmes, and the like) and other cultural, social, political and practical situations. Most importantly, as controversy studies have repeatedly shown, facts and apparent realities are always bound up with evaluations. Sifting through historical deposits of earlier activities, decisions and disputes, the archae- ologist of scientific knowledge will always find objects embued with the ineradicable, fundamentally 'valued' character of all knowledge. It is not possible for me to 'prove', in the sense that one can 'prove' through controlled experiment, that ARPA had a significant effect on the con- troversy. No studies of scientific controversies are able to make such a claim about those involved in a controversy, and most cases are limited to directly participating scientists. My suspicion, based on the background research required for this study, is that the difficulties of controversy studies will be compounded by the inclusion of activities of state organizations. Simply including one more set of voices on an issue introduces more divergences and more interpretive work for the analyst. Investigating activities of state organizations (partic- ularly those associated with national security), one also has to understand a social setting which in many ways is not represented by (and is only partly overlapping with) the world of researchers. One needs to learn how the 129</page><page sequence="28">Social Studies of Science 28/1 organizations function, and how their members make decisions - which is not the same as understanding the technical issues as understood among researchers. One may also have to do more footwork, ferreting out in- formation which might not be as easily accessible as the traces of con- troversies among scientists. Understanding technical and other relations in a research field can be difficult; investigating the likely divergent set of dynamics in state organizations can only make it more so. Understanding relations between research fields and state organization is thus, in a manner of speaking, doubly or triply challenging. Nevertheless, it is important to explore the roles of government organizations in scientific controversies. It is unlikely that this case is unusual, considering the extent to which research worldwide has been underwritten by ministers, policy makers and military planners. State powers have likely been party to many technical controversies, and con- tinue to be part of how science and technology gets done. Notes Research for this paper was sponsored by a fellowship from the Smithsonian Institution. I thank the several staff members there who contributed to the intellectual and material sustenance of this project, especially Jon Eklund and Paul Forman. I also thank the many members of the science studies community in California for their collegial support. Paul Edwards, Mikel Olazaran and Arthur Norberg offered comments which benefited the paper. Finally, I am grateful to the people associated with computing research and ARPA who shared with me their recollections, advice and documents. 1. The terms 'AI' and 'neural networks' (or 'neural nets') were standard terms during the period under study, although AI had been in use for a shorter time, and neural nets had many synonyms. 'Neural network' had roots in post-World War II neuropsychological models (see, for example, Warren S. McCulloch and Walter Pitts, 'A Logical Calculus of the Ideas Immanent in Nervous Activity', Bulletin of Mathematical Biophysics, Vol. 5 [1943], 115-33), and its use became more frequent through the decade. In 1969, it was admitted as a thesaurus term in the bibliographic index INSPEC. Related terms, and some of the history of the term 'artificial intelligence', are discussed below in passing. 'Intelligent computing' has not often been used in the technical literature, which has been deeply influenced by divisions such as those described in this paper. Rather, this phrase is my attempt at a bipartisan description of the field defining (and invoked by) the controversy. A similar approach is adopted in Kristin Luker, Abortion and the Politics of Motherhood (Berkeley, CA: University of California Press, 1984). 2. Michael S. Mahoney, 'The History of Computing in the History of Technology', Annals of the History of Computing, Vol. 10, No. 2 (1988), 113-25; Paul N. Edwards, The Closed World: Computers and the Politics of Discourse in Cold War America (Cambridge, MA: MIT Press, 1996), 43. 3. The clearest examples of the earlier tendency include the following: Daniel Crevier, AI: The Tumiultuous History of the Search for Artificial Inltelligence (New York: Basic Books, 1993); Grant Fjermedal, The Tomorrow Makers (NewYork: Macmillan, 1986); Pamela McCorduck, Machines Who Think: A Personal Inquiry into the History and Prospects of Artificial Intelligence (San Francisco, CA: W.H. Freeman, 1979). Other works on the history of artificial intelligence include the following: Thomas Bartee (ed.), Expert Systems and Artificial Intelligence (Indianapolis, IN: Howard Sams, 1988); James Fleck, 'Development and Establishment in Artificial Intelligence', in Norbert Elias, Herminio Martins and Richard Whitley (eds), Scientific Establishments and Hierarchies, Sociology of the Sciences Yearbook, No. 6 (Dordrecht, The Netherlands: 130</page><page sequence="29">Guice: Controversy and the State Reidel, 1982), 169-217; Philip J. Hilts, Scientific Temperaments: Three Lives in Contemporary Science (NewYork: Simon &amp; Schuster, 1982); Ray Kurzweil (ed.), The Age of Intelligent Machines (Cambridge, MA: MIT Press, 1988); Rene Moreau, trans. J. Howlett, The Computer Comes of Age: The People, the Hardware, and the Software (Cambridge, MA: MIT Press, 1984); George Johnson, Machinery of the Mind: Inside the New Science of Artificial Intelligence (New York: Random House, 1986); Allen Newell, 'Intellectual Issues in the History of Artifical Intelligence', in Fritz Machlup and Una Mansfield (eds), The Study of Information: Interdisciplinary Messages (New York: Wiley, 1983), 187-228; Harvey P. Newquist (ed.), The Brain Makers (Indianapolis, IN: Sams Publishing, 1st edn, 1994); ACM SIGPLAN, The Second ACM SIGPLAN History of Programming Languages Conference (HOPL-II) in Cambridge, MA (NewYork: Association for Computing Machinery, 1993); Howard Rheingold, Tools for Thought (New York: Simon &amp; Schuster, 1985); Frank Rose, Into the Heart of the Mind (New York: Harper &amp; Row, 1984); Geoffrey L. Simons, Evolution of the Intelligent Machine: A Popular History of AI (Manchester, UK: NCC Publication, 1988); Tom Stonier, Beyond Information: The Natural History of Intelligence (London: Springer-Verlag, 1992). Important exceptions to the earlier tendency, because they do map some of the differences and diversity of technical approaches in the fields, are the following: Howard Gardner, The Mind's New Science: A History of the Cognitive Revolution (NewYork: Basic Books, 1985); Mikel Olazaran, A Historical Sociology of Neural Network Research (unpublished PhD dissertation, University of Edinburgh, 1991); Olazaran, 'A Sociological History of the Neural Network Controversy', Advances in Computers, Vol. 37 (1993), 335-425; Olazaran, 'A Sociological Study of the Official History of the Perceptrons Controversy', Social Studies of Science, Vol. 26, No. 3 (August 1996), 611-59. 4. Theda Skocpol, 'Bringing the State Back In: Strategies of Analysis in Current Research', in Peter B. Evans, Dietrich Rueschemeyer and Skocpol (eds), Bringing the State Back In (Cambridge: Cambridge University Press, 1985), 3-37. Not to overstate the case, I should point out that there are many predecessors to the current concern with the state in social studies of science, including, perhaps most prominently, the small body of literature on science advice and the scientific elite in the 1960s. Examples include Donald Cox, Anmerica's New Policy Makers: The Scientific Elite and the Use of Power (New York: Chilton, 1964); Robert Gilpin, American Scientists and Nuclear Weapons Policy (Princeton, NJ: Princeton University Press, 1962); Gilpin and Christopher Wright (eds), Scientists and National Policy-Making (New York: Columbia University Press, 1964); Daniel S. Greenberg, 'The Myth of the Scientific Elite', The Public Interest, No. 1 (Fall 1965), 61-70; Lyle Groeneveld, Norman Koller and Nicholas C. Mullins, 'The Advisors of the United States National Science Foundation', Social Studies of Science, Vol. 5, No. 3 (August 1975), 343-54; Ralph Lapp, The Nezv Priesthood: The Scientific Elite and the Use of Power (New York: Harper &amp; Row, 1965); Avery Leiserson, 'Scientists and the Policy Process', American Political Science Reviezu, Vol. 59, No. 2 June 1965), 408-16; Bruce L.R. Smith, The RAND Corporation (Cambridge, MA: Harvard University Press, 1966). 5. Dorothy Nelkin (ed.), Controversy: Politics of Technical Decisions (Beverly Hills, CA &amp; London: Sage, 1979). The following is a synthetic work dealing with this tradition: H. Tristam Engelhardt, Jr, and Arthur L. Caplan (eds), Scientific Controversies: Case Studies In The Resolution and Closure of Disputes in Science and Technology (Cambridge: Cambridge University Press, 1987). 6. Martin J.S. Rudwick, The Great Devonian Controversy: The Shaping of Scientific Knowledge amnong Gentlemanly Specialists (Chicago, IL: The University of Chicago Press, 1985); H.M. Collins, 'The TEA Set: Tacit Knowledge and Scientific Networks', Science Studies, Vol. 4 (1974), 165-86; Collins, Changing Order: Replication and Induction in Scientific Practice (London: Sage, 1985). Other examples include: Barry Barnes and Steven Shapin (eds), Natural Order (Beverly Hills, CA: Sage, 1979); Adele Clarke, 'Controversy and the Development of American Reproductive Sciences', Social Problems, Vol. 37, No. 1 (February 1990), 18-37; H.M. Collins (ed.), 'Special Issue: 131</page><page sequence="30">Social Studies of Science 28/1 Knowledge and Controversy: Studies of Modern Natural Science', Social Studies of Science, Vol. 11, No. 1 (February 1981), 1-158; Jonathan Harwood, 'The Race- Intelligence Controversy: A Sociological Approach; 1: Professional Factors', Social Studies of Science, Vol. 6, Nos 3 &amp; 4 (October 1976), 369-94, and '2: "External" Factors', ibid., Vol. 7, No. 1 (February 1977), 1-30; Shapin and Simon Shaffer, Leviathan and the Air Pump: Hobbes, Boyle and the Experimental Life (Princeton, NJ: Princeton University Press, 1985). There are also a number of studies which combine the two traditions in various ways: for example, David W. Chambers, A Wornm in the Bud: Case Study of the Pesticide Controversy (Waurn Pond, Victoria: Deakin University, 1979); Brian Martin, Scientific Knowledge in Controversy: The Social Dynamics of the Fluoridation Debate (Albany, NY: State University of New York Press, 1991). 7. In addition to works cited above, see Karin D. Knorr-Cetina and Michael J. Mulkay (eds), Science Observed: Perspectives on the Social Study of Science (London &amp; Beverly Hills, CA: Sage, 1983); Steven Shapin, 'History of Science and its Sociological Reconstructions', History of Science, Vol. 20 (1982), 157-211. 8. H.M. Collins, 'The Place of the "Core-Set" in Modern Science: Social Contingency with Methodological Propriety in Science', History of Science, Vol. 19 (1981), 6-19. 9. Ibid., 9. Students of scientific controversy typically interrogate both archives and people. One eventually settles on a cast of characters for one's re-enactment of the controversy, with a number of iterations and some informed judgement about the issues at play. As Collins points out, this sort of description puts the process in somewhat unrealistically formal terms for many studies, but accurately represents the logic of the inquiry. 10. Examples include: S. Leigh Star, Regions of the Mind: Brain Research and the Quest for Scientific Certainty (Stanford, CA: Stanford University Press, 1989); Donald MacKenzie, 'Statistical Theory and Social Interests: A Case Study', Social Studies of Science, Vol. 8, No. 1 (February 1978), 35-83. 11. Bibliographic search was limited to English-language studies. 12. Some similar issues are raised by the following: S. Shapin, 'Discipline and Bounding: The History and Sociology of Science as Seen through the Externalism-Internalism Debate', History of Science, Vol. 30 (1992), 333-69; K.D. Knorr-Cetina, 'Scientific Communities or Transepistemic Arenas of Research? A Critique of Quasi-Economic Models of Science', Social Studies of Science, Vol. 12, No. 1 (February 1982), 101-30. 13. Some of the better-known studies include the following: Finn Aaserud, Redirecting Science: Niels Bohr, Philanthropy and the Rise of Nuclear Physics (Cambridge: Cambridge University Press, 1990); Paul Forman, 'Weimar Culture, Causality, and Quantum Theory, 1918-1927: Adaptation by German Physicists and Mathematicians to a Hostile Intellectual Environment', Historical Studies in the Physical Sciences, Vol. 3 (1971), 1-115; Forman, 'Behind Quantum Electronics: National Security as a Basis for Physical Research in the United States, 1940-1960', ibid., Vol. 18 (1987), 149-229; Daniel J. Kevles, The Physicists: The History of a Scientific Community in Modern Anierica (Cambridge, MA: Harvard University Press, 1987 [1971]); Arnold Thackray (ed.), 'Science after '40', Osiris (second series), Vol. 7 (1992). There is also a body of historical studies of research sponsorship by foundations: see, for example, Robert E. Kohler, Partners in Science: Foundations and Scientists, 1900-1945 (Chicago, IL: The University of Chicago Press, 1991); Pnina Abir-Am, 'The Discourse of Physical Power and Biological Knowledge in the 1930s: A Reappraisal of the Rockefeller Foundation's "Policy" in Molecular Biology', Social Studies of Science, Vol. 12, No. 3 (August 1982), 341-82. In the wider literature on science, technology and the state, there have also been some important accounts of technical controversy: for example, Michael H. Armacost, The Politics of Weapons Innovation: The Thor-Jupiter Controversy (New York: Columbia University Press, 1969). 14. Donald MacKenzie and JudyWajcman (eds), The Social Shaping of Technology: How the Refrigerator Got Its Hum (Milton Keynes, Bucks. &amp; Philadelphia, PA: Open University Press, 1985); Wiebe E. Bijker and John Law (eds), Shaping Technology/Building Society: Studies in Sociotechnical Change (Cambridge, MA: MIT Press, 1992); Alberto 132</page><page sequence="31">Guice: Controversy and the State Cambrosio and Camille Limoges, 'Controversies as Governing Processes in Technology Assessment', Technology Analysis and Strategic Management, Vol. 3, No. 4 (December 1991), 377-96; Brian Elliott (ed.), Technology and Social Process (Edinburgh: Edinburgh University Press, 1988). 15. Susan E. Cozzens, 'Editor's Introduction' to Theme Section on 'Funding and Knowledge Growth', Social Studies of Science, Vol. 16, No. 1 (February 1986), 9-21, at 10. 16. Other programmatic works include the following: Alberto Cambrosio, Camille Limoges and Denyse Pronovost, 'Representing Biotechnology: An Ethnography of Quebec Science Policy', Social Studies of Science, Vol. 20, No. 2 (May 1990), 195-227; Thomas Brante, Steve Fuller and William Lynch (eds), Controversial Science: From Content to Contention (Albany, NY: State University of NewYork Press, 1993). Among empirical studies the following are particularly relevant to this study: C. Stewart Gillmor, 'Federal Funding and Knowledge Growth in Ionospheric Physics, 1945-81', Social Studies of Science, Vol. 16, No. 1 (February 1986), 105-33; Donald MacKenzie, Inventing Accuracy: A Historical Sociology of Nuclear Missile Guidance (Cambridge, MA: MIT Press, 1990). It is also important to note that there have been many studies of regulatory and science-based government policy, motivated by concerns similar to those expressed by recent programmatic works, among which the following are perhaps the best known: Sheila Jasanoff, Risk Management and Political Culture: A Comparative Study of Science in the Policy Context (New York: Russell Sage Foundation, 1986); Jasanoff, The Fifth Branch: Science Advisers as Policymakers (Cambridge, MA: Harvard University Press, 1990); Susan Wright, Molecular Politics: Developing American and British Regulatory Policy for Genetic Engineering, 1972-1982 (Chicago, IL: The University of Chicago Press, 1994). 17. These accounts are echoed in print. Examples of publications reproducing such hearsay include: Crevier, op. cit. note 3, 105-07; McCorduck, op. cit. note 3, passim; DARPA Neural Network Study (US), DARPA Neural Network Study: October 1987-February 1988 (Fairfax, VA: AFCEA International Press, 1988); R. Colin Johnson and Chappell Brown, Cognizers: Neural Networks and Machines That Think (New York: Wiley, 1988); Philip D. Wasserman, Neural Computing: Theory and Practice (New York: Van Nostrand Reinhold, 1989); Hubert L. Dreyfus and Stuart E. Dreyfus, 'Making a Mind Versus Modelling the Brain: Artificial Intelligence Back at the Branchpoint', Daedalus, Vol. 117, No. 1 (Winter 1988), 15-43, reprinted (with the same pagination) in Stephen R. Graubard (ed.), The Artificial Intelligence Debate (Cambridge, MA: MIT Press, 1988), and also republished in Massimo Negrotti (ed.), Understanding the Artificial: On the Future Shape of Artificial Intelligence (London: Springer-Verlag, 1991), 33-54; Robert Hecht-Nielsen, Neurocomputing (Reading, MA: Addison-Wesley, 1990). 18. Seymour A. Papert, 'One AI or Many?', in Graubard (ed.), op. cit. note 17, 1-14, at 3. 19. Marvin L. Minsky and Seymour A. Papert, Perceptrons: An Introduction to Computational Geometry (Cambridge, MA: MIT Press, 1988 [1969]). 20. Among works cited in note 18, those especially salient on the point of funding are by Dreyfus &amp; Dreyfus, DARPA Neural Network Study, and Hecht-Neilsen. 21. Minsky &amp; Papert, op. cit. note 19, passinm. 22. Papert, op. cit. note 18, 7. 23. Papert, op. cit. note 18, 3-4. Papert writes 'Lord DARPA', using the agency's acronym from 1972 to 1993, when its name was the 'Defense Advanced Research Projects Agency'. The name of the agency, from its inception in 1958 until 1972, which includes the period of this paper, did not include the word 'Defense', and thus it is historically accurate for this account to refer to the agency as 'ARPA'. 24. Olazaran, op. cit. note 3. 25. See note 3. 26. Kenneth Flamm, Creating the Computer: Government, Industry, and High Technology (Washington, DC: Brookings Institution, 1988). 133</page><page sequence="32">Social Studies of Science 28/1 27. Fleck, op.cit. note 3, 169-217. 28. Arthur L. Norberg and Judy E. O'Neill, with Kerry J. Freedman, A History of the Information Processing Techniques Office of the Defense Advanced Research Projects Agency (Minneapolis, MN: Charles Babbage Insitute, University of Minnesota, 1992). 29. Edwards, op. cit. note 2. Other works with related concerns include the following: Donna Haraway, 'The High Cost of Information in Post-World War II Evolutionary Biology', Philosophical Forum, Vol. 13, Nos 2/3 (1981-82), 244-78; P.N. Edwards, 'A History of Computers and Weapons Systems', in David Bellin and Gary Chapman (eds), Computers in Battle, Will They Work? (Boston, MA: Harcourt Brace Jovanovich, 1987), 45-60; Chris H. Gray, Computers as Weapons and Metaphors: The US Military 1940-1990 and Postmodern War (unpublished PhD dissertation, University of California, Santa Cruz, 1991). 30. See, for example, Marvin Minsky, 'Logical vs Analogical or Symbolic vs Connectionist or Neat vs Scruffy', in Patrick Henry Winston (ed.), with Sara Alexandra Shellard, Artificial Intelligence at MIT: Expanding Frontiers (Cambridge, MA: MIT Press, 1990), 219-69. 31. There are many admixtures and ironies in the history of computing before 1960, such as the fact that John von Neumann, the putative father of the architecture of the standard programmable digital computer, had an active interest in brain models of information processing: see J. von Neumann, The Computer and the Brain (New Haven, CT: Yale University Press, 1958); William Aspray, John von Neumann and the Origins of Modern Computing (Cambridge, MA: MIT Press, 1990). Von Neumann's lectures on computing and the brain were later cited by Rosenblatt: Frank Rosenblatt, Two Theorems of Statistical Separability in the Perceptron (Buffalo, NY: Cornell Aeronautical Laboratory, Inc., VG-1 196-G-2, 1958) . For an in-depth discussion relevant to the perceptrons controversy, see Olazaran (1991), op. cit. note 3. 32. Fleck, op. cit. note 3, 178. 33. Ibid. 34. See, for example, John Haugeland, Artificial Intelligence: The Very Idea (Cambridge, MA: MIT Press, 1985). 35. Unless otherwise noted, cost figures are presented in current dollars. Grant information is extracted from the following: F. Rosenblatt, unpublished documents: 'Proposal to the Office of Naval Research for Continuation of the Cognitive Systems Research Program, 1961-1962' (Cornell University, 1960 [n.d.]); 'Proposal to the Office of Naval Research for Continuation of the Cognitive Systems Research Program, 1963-1964' (Cornell University, 1962 [n.d.]); 'Proposal to the Office of Naval Research for Continuation of the Cognitive Systems Research Program, 1966-1967' (Cornell University, 1965 [n.d.]). Copies of these documents granted to the author by Dr George Nagy. On ONR's role in funding early neural net research, see: Olazaran (1991), op. cit. note 3; Thomas McKenna, 'A Brief History of Neural Nets at ONR' (unpublished report, US Office of Naval Research, 1993). The following are relevant general sources: Mina Rees, 'The Computing Program of the Office of Naval Research, 1946-1953', Annals of the History of Computing, Vol. 4, No. 2 (1982), 102-20; David K. Allison, 'US Navy Research and Development Since World War II', in Merritt Roe Smith (ed.), Military Enterprise and Technological Change: Perspectives on the American Experience (Cambridge, MA: MIT Press, 1985), 289-328; James W. Cortada, 'Office of Naval Research (ONR)', in Cortada (ed.), Historical Dictionary of Data Processing - Organizations (New York: Greenwood Press, 1987), 215-17; Harvey M. Sapolsky, Science and the Navy: The History of the Office of Naval Research (Princeton, NJ: Princeton University Press, 1990). 36. Marshall C.Yovits, 'Preface', inYovits and Scott Cameron (eds), Self-Organizing Systems: Proceedings of an Interdisciplinary Conference, 5 and 6 May, 1959 (London: Pergamon Press, 1960), v-viii, at v. 'All of the papers presented at the Conference are included in these Proceedings in the order presented... with the exception of the paper entitled "Progress on the Advice Taker" by Dr Marvin Minsky...' (ibid., vii). 37. Olazaran (1991), op. cit. note 3, 73-85. 134</page><page sequence="33">Guice: Controversy and the State 38. Rosenblatt, op. cit. note 31, 2. 39. George Nagy, 'Neural Networks -Then and Now', IEEE Transactions on Neural Networks, Vol. 2, No. 2 (March 1991), 316-18; F. Rosenblatt, Principles of Neurodynamics (Washington, DC: Spartan Books, 1961). 40. This was the Perceptron Mark I: New York Times (8 July 1958), 25:2, quoted in Olazaran (1996), op. cit. note 3, 621. 41. Charles Rosen (telephone interview with author, 6 August 1993). 42. Nils Nilsson (telephone interview with author, 14 September 1993). 43. Minsky &amp; Papert, op. cit. note 19, 19. 44. Jeremy Bernstein, 'Profiles: AI (Interview with Marvin Minsky)', New Yorker (14 December 1981), 50-126. 45. The criticisms made by Minsky and Papert took a number of forms: see Minsky &amp; Papert, op. cit. note 19, 239. For instance, there were many conference paper versions of parts of the book (see, for example, ibid., 242), and Minsky taught graduate courses on the subject (M. Minsky, interview with author, 23 August 1993). 46. Papert explains this sort of rhetoric by arguing that there has been a culture in AI and cognitive science of seeking universal mechanisms of cognition, and that this culture is in turn partly a strategic response to an institutional environment, particularly in government sponsorship, which seeks general solutions: Papert, op. cit. note 18. 47. See, for example, Jack D. Cowan, 'Neural Networks: The Early Days', in David S. Touretzky (ed.), Advances in Neural Information Processing Systems, Vol. 2 (San Mateo, CA: Morgan Kaufmann, 1990), 143-68. 48. Minsky &amp; Papert, op. cit. note 19, 4. In other words, one of the key characteristics of Minsky and Papert's critique was its tactical deployment of specificity and generality. 49. Ibid., 73. 50. Olazaran (1991), op. cit. note 3, 158-60. 51. Minsky &amp; Papert, op. cit. note 19, 136-39. 52. Marvin L. Minsky, 'Steps Toward Artificial Intelligence', Proceedings of the IRE, Vol. 49 (1961), 8-30, at 8. 53. My interpretation of Minsky's work has been greatly helped by personal exchanges with Robert H. Baran, and by access to Baran's 'Artificial Intelligence and Rosenblatt's Idea' (unpublished manuscript in electronic format, 1993). 54. Specifically, a single-layer, feedforward network with important constraints. Minsky and Papert note that their investigation, while pointing out that training is an important problem in such networks, stops short of a full discussion. Nevertheless, Minsky and Papert put the burden of proof on neural-net researchers to upset their strong doubts about the potential of multilayer nets (centring on the problem of training): 'we consider it an important research problem to elucidate (or reject) our intuitive judgement that the extension [to multiple layers] is sterile': Minsky &amp; Papert, op. cit. note 19, 232. 55. Nagy, op. cit. note 39. 56. Olazaran (1991), op. cit. note 3, 160-65. 57. See, for example: Terrence J. Sejnowski and Halbert White, 'Introduction', in Sejnowski and White (eds), The Mathematical Foundations of Learning Machines (San Mateo, CA: Morgan Kaufmann, 1990), vii-xxi; Cowan, op. cit. note 47; Papert, op. cit. note 18. 58. For instance, Rosenblatt's research group ran simulations of neural network models on IBM 7090/94 systems: see Nagy, op. cit note 39, 317. 59. The Mark I Perceptron was the largest example of this sort of design, which featured an array of photosensitive cells for visual input connected by a tangle of plug boards wired 'at random' by hand to over 500 stepping motors governing potentiometers: see John C. Hay and Albert E. Murray, Mark I Perceptron Operator's Manual (Project PARA) (Buffalo, NY: Cornell Aeronautical Laboratory, Inc., Report VG-1196-G-5, 1960); Hay and Charles W. Wightman, 'The Mark I Perceptron', Research Trends (Buffalo, NY: Cornell Aeronautical Laboratory, Inc., Spring 1960), 1-5. 135</page><page sequence="34">Social Studies of Science 28/1 60. Record-keeping and archive maintenance in the relevant office was spotty at best during the period under examination: see Norberg &amp; O'Neill, op. cit. note 28, 11. For the following account, the transcripts of interviews conducted by the staff of the Charles Babbage Institute for the study by Norberg and O'Neill were consulted, and archives at Carnegie-Mellon and Cornell Universities, the Cornell Aeronautics Laboratory and MIT were explored. In addition, consultations with many experts were helpful in identifying unproductive avenues of research, as well as sources of information reflected in the references cited. Important consultations which are not reflected in the works and interviews cited below were held with the following individuals: John Holland, George Nagy, Arthur L. Norberg, Richard D. O'Brien and Severo Ornstein. 61. An argument for practical complementarities between AI work and particular approaches to computing is made in a similar way by Edwards, op. cit. note 2, Chapter 8. 62. Richard H. van Atta, Seymour J. Deitchman and Sidney G. Reed, DARPA Technical Accomplishments, Volume III: An Overall Perspective and Assessment of the Technical Accomplishments of the Defense Advanced Research Projects Agency: 1958-1990 (Washington, DC: Institute for Defense Analyses, IDA Paper P-2538, 1991), 1; Barber Associates, The Advanced Research Projects Agency, 1958-1974 (Washington, DC: Richard J. Barber Associates, Inc., AD-A154 363, Defense Technical Information Center, 1975). 63. Norberg &amp; O'Neill, op. cit. note 28, 35. The report citation is as follows: 'F.H. Tyaack, "Progress Report: Survey of the Information Sciences", IDA-IM-198, 23 May 1960, contract No. SD-50, RG 330-74-107, Box 1, Folder: unspecified, NARA [National Archives and Records Administration]'. 64. Norberg &amp; O'Neill, op. cit. note 28, 5. 65. J.C.R. Licklider, in a series of interviews compiled and edited by Robert S. Engelmore, 'AI Development: DARPA and ONR Viewpoints', in Bartee (ed.), op. cit. note 3, 213-90, at 220. 66. Norberg &amp; O'Neill, op. cit. note 28, 24; J.C.R. Licklider, 'Man-Computer Symbiosis', IRE Transactions on Human Factors in Electronics, HFE-1, Vol. 1 (March 1960), 4-11. Licklider's paper was widely cited in the years following its publication: see Edwards, op. cit. note 2, 283. 67. Norberg &amp; O'Neill, op. cit. note 28, 24. An overview of the MIT research complex is presented in: Henry Etzkowitz, 'The Making of an Entrepreneurial University: The Traffic Among MIT, Industry and the Military, 1860-1960', in Everett Mendelsohn, Merritt R. Smith and Peter Weingart (eds), Science, Technology and the Military, Sociology of the Sciences Yearbook, No. 13 (Dordrecht: Kluwer, 1988), 515-40. 68. Norberg &amp; O'Neill, op. cit. note 28, 105-14; Robert W. Taylor, An Interview with Robert W Taylor, interview conducted by W. Aspray, 28 February 1989, transcript in electronic format (Minneapolis, MN: Charles Babbage Institute, University of Minnesota, 1989). 69. Based on a chart, 'IPTO Program Areas and Specific Emphases', Norberg &amp; O'Neill, op. cit. note 28, 49. 70. The IPTO office staff consisted mainly of the director, a secretary and a military officer assistant. Each director also had the assistance of his successor a few months before the official transfer of power. In 1967, Taylor began to assign the supervision of some programmes to programme managers. 71. Licklider, interviewed in Engelmore, op. cit. note 65, 216. 72. Marvin Denicoff, interviewed in Engelmore, op. cit. note 65, 276-77. 73. J.C.R. Licklider, An Interview with J.C.R. Licklider, interview conducted byW. Aspray and A.L. Norberg, 28 October 1988, transcript in electronic format (Minneapolis, MN: Charles Babbage Insitute, University of Minnesota, 1988). 74. Licklider, interviewed in Engelmore, op. cit. note 65, 220. 136</page><page sequence="35">Guice: Controversy and the State 75. Joel S. Yudken and Barbara Simons, A Field in Transition: Current Trends and Issues in Academic Computer Science (Stanford, CA: Project on Funding Policy in Computer Science, Final Report, 1989), 9. 76. Norberg &amp; O'Neill, op. cit. note 28, 93. 77. However, AI did not appear as a line item on budgets until 1968. Instead, AI work was officially supported in conjunction with basic and applied research under other categories: see R.H. van Atta, S.G. Reed and S.J. Deitchman, DARPA Technical Accomplishments: An Historical Review of Selected DARPA Projects (Washington, DC: Institute for Defense Analyses, IDA Paper P-2192, 1990), 21-4 and 21-5. 78. The lower and upper bounds of this range are represented respectively by Fleck, op. cit. note 3, 180, and Norberg &amp; O'Neill, op. cit. note 28, 303. 79. This expression is used figuratively by Flamm in the title of his book, op. cit. note 26. It is used literally, to all appearances, in some newspaper articles, and in Manuel De Landa, War in the Age of Intelligent Machines (New York: Zone Books, 1991), passim. 80. Norberg &amp; O'Neill, op. cit. note 28, 299. 81. J.C.R. Licklider, quoted in Norberg &amp; O'Neill, op. cit. note 28, 102. 82. Robert W. Taylor, interview with the author (5 October 1993). 83. Karl Wildes, A Century of Electrical Engineering and Computer Science at MIT, 1882-1982 (Cambridge, MA: MIT, 1985), 344. 84. Ibid., 345. 85. Licklider, interviewed by Engelman, op. cit. note 65, 220. 86. Crevier, op. cit. note 3, 65. 87. Wildes, op. cit. note 83, 347. In 1968, Licklider succeeded Fano as director of the centre: ibid., 351. 88. Ibid., 348. See also Jan Hurst, Michael S. Mahoney, John T. Gilmore, Lawrence G. Roberts and Robin Forrest, 'The Early Years in Computer Graphics at MIT, Lincoln Lab and Harvard', Computer Graphics, Vol. 23, No. 4 (December 1989), 39-73. 89. Norberg &amp; O'Neill, op. cit. note 28, 44-47; McCorduck, op. cit. note 3, 247. Funding was for student salaries and for computing time: Crevier, op. cit. note 3, 65. 90. John McCarthy, quoted in Edwards, op. cit. note 2, Chapter 8, 258. 91. Minsky &amp; Papert, op. cit. note 19, 246. 92. Norberg &amp; O'Neill, op. cit. note 28, 111. 93. J.C.R. Licklider, 'Artificial Intelligence, Military Intelligence, and Command and Control', in Edward Bennett, James Degan and Joseph Spiegel (eds), Military Information Systems: The Design of Computer-Aided Systems for Command (New York: Praeger, for the MITRE Corporation, 1964), 118-22, at 120. 94. J.C.R. Licklider, 'Interactive Information Processing', in Julius T. Tou (ed.), Computer and Information Sciences, Vol. 2 (New York: Academic Press, 1967), 1-14, at 4. 95. Exemplary projects represent many of the IPTO-sponsored researchers, including John McCarthy and Marvin Minsky for graphic display and typewriter text input programs: ibid., 10. 96. Marvin Denicoff, quoted in Olazaran (1991), op. cit. note 3, 171. This is corroborated by several sources, particularly: Edward Feigenbaum, An Interview with Edward Feigenbaum, interview conducted by W. Aspray, 3 March 1989, transcript in electronic format (Minneapolis, MN: Charles Babbage Institute, University of Minnesota, 1989). 97. Taylor, interview, loc. cit. note 82. 98. Lawrence G. Roberts, consultation with author (2 October 1993). See, for example, L.G. Roberts, Machine Perception of Three-Dimensional Solids (Cambridge, MA: Lincoln Laboratory, Technical Report 315, 1963). 99. Louis Fein, 'The Artificial Intelligentsia', Wescon Technical Papers, Vol. 7 (11.1, Part 7, 1963), 1-17, at 2. 100. Charles Rosen, telephone interview with author (10 March 1994). 101. Louis Fein, 'The Role of the University in Computers, Data Processing, and Related Fields', Communications of the ACM, Vol. 2, No. 9 (September 1959), 7-14; Paul 137</page><page sequence="36">Social Studies of Science 28/1 Ceruzzi, 'Electronics Technology and Computer Science, 1945-1975: A Coevolution', Annals of the History of Computing, Vol. 10, No. 4 (1989), 257-75. 102. Fein, op. cit. note 99, 2. 103. Ibid. 104. Ibid., 7. 105. Ibid., 9. 106. Ibid. 107. Ibid., 12. 108. Ibid. 109. Ibid., 13. 110. Ibid. 111. Ibid., 15. 112. Ibid. 113. Ibid., 16. 114. Olazaran (1991), op. cit. note 3, 116. 115. Minsky, interview, loc. cit. note 45. 116. This information was gleaned from searches of the INSPEC bibliographic database, years 1969-79. 117. Hecht-Nielsen, op. cit. note 17, 17. 118. Minsky, interview, loc. cit. note 45. 119. Olazaran (1991), op. cit. note 3, 166-86. 120. Fleck, op. cit. note 3. 121. Feigenbaum, interview, loc. cit. note 96. Jon Guice is a researcher and project manager in a distance learning research programme between Stanford University and Sweden's Royal Institute of Technology. As well as consulting and publishing in the field of human-computer interaction, he is currently revising his doctoral dissertation on management practices of the US Defense Advanced Research projects Agency (Sociology Department and Science Studies Program, University of California at San Diego) for publication. Address: Electrum 204, S-164 40 Kista, Sweden; email: jguice@concentric.net 138</page></plain_text>
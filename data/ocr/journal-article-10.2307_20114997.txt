<plain_text><page sequence="1">TED BASTIN PROBABILITY IN A DISCRETE MODEL OF PARTICLES AND OBSERVATIONS* I. PROBABILITY AND EPISTEMOLOGY In this article I shall sketch a model of the elementary particle in the observation situation which has been developed to avoid the paradoxes in the foundations of current quantum theory (for a general commentary see Bastin, 1971). In this model aspects of quantum theory which are usually associated with the observer or with the measuring process are kept entirely separate from discussion of the basic principles of probabili ty. The reason why many writers have felt themselves tempted to link these aspects of quantum theory with the place of probability in the theory is because such a link looked like a way of keeping elementary particles that had fairly traditional, common-sense properties. In the model I am proposing, extremely counterintuitive characteristics are postulated for the particles, but the paradoxes which still exist whatever use is made of probability, are avoided. Rosenfeld (1965) introduced the terms 'objectivist' and 'subjectivist' into the philosophy of quantum theory. Interpretations in which the person who performs the experiment must be explicitly incorporated into the description of what happens are called subjectivist by him. An objectivist interpretation, by contrast, is one where the descrip tion can be given from the outside without any essential reference to an agent or subject. In this article, I reject Rosenfeld's attempt to specify objectivism on the grounds that it postulates complementarity, and that in the complementarity approach the question of the place of the observer or of the profound role of the measuring process still remains to be under stood. The complementarity approach has been the central philosophy of those who have tried to avoid subjectivism, while insisting on the pro found place played by measurement, and in this approach, measurement and probability are closely linked. It was by relating the postulates which prescribe the form of the probability mathematics used in quantum theory Synthese 29 (1974) 203-227. All Rights Reserved Copyright ? 1974 by D. Reidel Publishing Company, Dordrecht-Holland</page><page sequence="2">204 TED BASTIN to the postulates which specify the part played in the theory by the observation process that Bohr and his associates were able to ensure that any actual description of any quantum object was in classical terms. (Even though there could only be complementary descriptions, each of those descriptions had to be in classical terms.) To justify this assertion in detail is not easy. It is notoriously difficult to get a presentation of the view of Bohr, or of his real impact, which a majority of the Bohr commentators will subscribe to. However, in a recent article von Weizs?cker (1973) makes very much my case about Bohr. Moreover von Weizs?cker is undeniably writing from the position of a follower of Bohr, since the quantum logic which he advocates is designed to incorporate the possibility of incompatible descriptions - the kernel of Bohr's position. With regard to the place of probability in this scheme, von Weisz?cker says, "I think quantum theory is as universally valid as it is because it formulates nothing but general laws of probability, including laws for the change of probabilities with time." Another remark shows how profoundly von Weizs?cker is proposing to take the notion of probability itself as one of the set of concepts upon which the quantum theoretical formalism is to be based. "One of the traditional difficulties in the empirical interpretation of probability stems from the idea that experience can be treated as a given concept and probability as a concept to be applied to experience. This is what I call a mistaken epistemological hierarchy. I shall try to point out that, on the contrary, experience and probability interlink in a manner which will preclude us from under standing experience without already using some concept of probability." Rosenfeld's use of the term 'subjectivist' would have to be extended to apply to the complementarity theorists, though in the case of von Weizs?cker the subjectivist's approach is a consequence of a particular sort of attitude to probability. A possible confusion in terminology must be forestalled here. In probability theory one distinguishes between 'subjective' and 'frequency' approaches. This usage is different from mine. Indeed, where, in my treatment, that which is unknown forces us to limit ourselves to proba bilistic descriptions, the situation is reminiscent of subjectivism in the sense of the probability theorists, but has nothing in common with Rosenfeld's use of the term.</page><page sequence="3">PROBABILITY IN A DISCRETE MODEL 205 II. THE OPERATIONAL PRIMACY OF PARTICLES My account of the place of probability theory in the quantum domain will, in one way, offer little of interest to probability theorists since it requires nothing that was not familiar from classical physics so far as probability is concerned. However, my approach is novel in that hitherto no one has been able to propose a view of the place of probability in quantum physics that follows the principles for the use of probability familiar in the rest of physics and in the rest of science generally, except those who propose a return to more or less classical thinking (Lande, 1955, and similar writers, and - in a different way - Popper, 1967). The essential feature of this view is that probabilities are not irreducible. They can be 'reduced', in the same way as in classical physics, to an influence of an unknown background on any particular experimental situation. In most theories of quantum phenomena it is supposed that the proba bilistic character of the laws governing the phenomena is connected with the fact that in order to make an observation one has to use a quantum particle (taking that term for the moment to include photons). The accounts vary, however, in the way in which they establish the connection. I shall take the position that it is of the essence of the quantum situation that one has no privileged access to any reality behind the appearance of particles which could short-circuit the stage of using the particles to get information. Now one could characterize current quantum theory, so far as its logical and epistemological foundations are concerned, as a theory which attempts to give this primacy to the operational place of the par ticles, while retaining the essentials of the classical background, namely, concepts which derive their meaning from situations in which indefinite refinability of observation is presupposed. There is an obvious incompa tibility here, which in quantum theory is bridged (in ways too well known to need repetition) by the idea of a participating observer. In effect, quantum theory says we can have an indefinitely refinable background as well as an operational primacy of the particles because whenever the consequences of these principles result in conflict, we can postulate that the effect of the observation process justifies us in neglecting the causal consequences that we would otherwise deduce from the existence of the background. Hence I wish at once to say that the notion of'participation' in current quantum theory is the most profound discovery of that theory,</page><page sequence="4">206 TED BASTIN and that in its usual forms of expression it is so misleading as to be wrong. It is profound because it recognizes the operational primacy of the parti cles. It is wrong because it does so only at the expense of importing one inappropriate philosophy (the subjectivist observer) to cancel out another equally inappropriate (that of the background which is inde pendent of our ways of discovering it). A writer whose thinking has brought him within range of my position is Wheeler. Wheeler (1968) had, in the last few years, come to the conclu sion that the structure of space-time must be regarded as just the last of a chain of cherished preconceptions of physics which have had to be abandoned as we get knowledge of unfamiliar and extreme conditions which obtain in the universe (for example, in black holes). If space-time had to be abandoned, then, Wheeler argued, the hunt would be on for combinatorial conditions which gave rise to space-time topology and, derivatively, to space-time geometry under the normal circumstance, but which, being more fundamental, could give rise to other topologies and geometries in other more extreme circumstances. Just recently, Wheeler (1974) has moved further to say that of the basic principles upon which people have seen quantum theory to be based (uncertainty, exclusion, complementarity, and so on) the principle that alone really is inescapable is that of 'participation' (and I have taken this term from Wheeler). Wheeler seems to want to separate the participation idea from that of an all too anthropomorphic observer, because he then argues that his structural or combinatorial relations had - in virtue of the need for econo my in basic hypotheses - to exhibit that very participatory character which he had argued to be the essential basis of quantum physics. His own hunch about how to achieve this reconciliation was to look at G?delian situations in mathematical logic on the combined grounds that (a) the binary choices in logic are compatible with the discreteness of quantum theory, and (b) that the participatory idea is exemplified. I cannot myself see that the G?delian analogy can be useful, because it depends on the actions and decisions of a mathematician and gets us back to the subjectivist philosophy, but it is interesting that analysis of the participation notion has led Wheeler to postulate the existence of a class of combinatorial structures which depend upon a binary algebra and upon which physics should be based. The mathematical model used in this article will have this character.</page><page sequence="5">PROBABILITY IN A DISCRETE MODEL 207 III. A SPECIFIC MATHEMATICAL MODEL USING OBJECTIVIST PROBABILITY The approach presented in this article has its experimental reference in the macroscopic observation of the elementary particles. That is to say that I depart from the classical view according to which the properties of space time are determined by macroscopic measurement independently of observation and according to which we treat the particles as individuals in isolation from each other and from their surroundings. For us, the 'observation' or 'measurement' situation is of a particle and its environ ment as a unity. I shall introduce this approach using as an example a combinatorial mathematical structure generated from a finite set of initial elements which I shall expound separately from its interpretation. The initial elements are not interpreted as particles of any sort, nor, indeed, as any other physical entity. According to this approach, each interpretable element can only be interpreted given the existence of the whole structure, but at the present time, only a small part of what needs interpretation has received it. Even though the individual mathematical quantities in the structure do not correspond directly to observables, we still have to insist that they and their relationships must correspond to something in the universe because some properties of the structure are given an inter pretation and because they are of the same kind as the rest (Bastin, 1966, 1971). The environment in which a particle has to appear (and therefore the characteristics of the particle) is specified by a particular configuration of the mathematical structure at each given stage of its development, and it would be incorrect to make independent provision for interpreting the behavior and the characteristics of the particles. Rather, what we do is to impose or specify a particular mathematical configuration upon the mathematical structure, and this corresponds in the physical interpreta tion to the way in which one 'prepares' a particle in a particular state in current quantum theory.1 The idea of the imposition of a particular configuration or constraint upon the mathematical structure will be described later. This approach provides an interpretation of certain combinatorial relations within the structure. Thus, for example, the selection of particles to those which (as we should normally say) travel in</page><page sequence="6">208 TED BASTIN one plane as a result of the particular kind of field and particular arrange ment of slits will correspond to a particular constraint on the mathemati cal structure. Any model of the sort I have described must have a technique de scribing increasingly complex structure, since the device open to ordinary physics in which we simply imagine a multiplicity of systems of the sort we have constructed spread out in a space is not available to us. In fact the method for extending the system is extremely important and depends upon extending further the idea of a constraint which has just been described. We construct a new system out of the constraints which have already been imposed. The simple combinatorial structures that I have so far introduced are to be identified - using the notion of constraints - with the operational specification of particles. This specification uses classical dynamical concepts, though in a way that allows for the fact that our knowledge is in terms of discrete interactions. The aspects of the structure available for interpretation in terms of particle processes are constraints imposed upon the random generation of the finite set. In any application of the model to the world it will be possible to attribute causes to appar ently random processes by imagining the investigation pushed further: but however far it is pushed, a practical limit must come at which we treat the process as random. Randomness, therefore, always expresses a practi cal limit on the extent of our knowledge, and within that limit, knowledge is expressed by constraints upon the field over which the randomness operates. The following points about the relation of our structure to physics as we normally understand it may be noted. 1. The mathematical structure with generating rules for creating new elements has a finite character. Hence there is never a representation of the physical continuum. The continuum is viewed rather as a possibility of further construction. 2. The existence of a background continuum, while it may be anything from a theoretical convenience to a theoretical necessity, must only be assumed insofar as it has been justified. Particles do display attributes (like a high degree of coherence in describing a path) in particular kinds of situation (such as when a particle has enough energy to ionize particles and</page><page sequence="7">PROBABILITY IN A DISCRETE MODEL 209 describe a path with some semblance of smoothness. Instead of taking up the idea of the continuum at an intuitive level as happens in current quantum theory these situations have to be described theoretically and set up mathematically. This process of setting up the mathematical background corre sponds to the experimental setting up of the particle experi ment and the preparation of the state of the particle. Since however the quantum world provides knowledge in discrete steps, there is no reason to expect that a rigorously opera tional mathematical development would incorporate the idea of the continuum, except as an ideal limit. 3. In order to set up the mathematical background, we impose constraints and these represent the particular experimental conditions in question. 4. It may seem surprising that if our macroscopic experience is part of the same universe as that which is continually being created by these sequential processes, it should exhibit so much stability. Certainly a great task remains in propounding any account of classical physics in terms of our structure, but we should remember how specialized an environment is provided for us by (a) the conditions of that part of the universe in which we happen to live, (b) the evolution of our sensory mechanisms including that aspect of them which gives great prominence to a uniform spatio-temporal back ground, and (c) our own efforts in setting up experiments. To illustrate the concept of 'constraint' and the way in which it can relate to spatial specification, let us consider the idealized steps one takes in a typical experimental situation. (1) We observe (or have records of) individual particle processes for which 'collision' or 'interaction' is perhaps the correct metaphor with its discrete connotations. (We should not be misled by the tracks in bubble chambers or cloud chambers into giving operational centrality to the path with its classical continuum overtones, for these 'paths' are collec tions of individual events and are only a special case as becomes clear from the high energy situation.)</page><page sequence="8">210 TED BASTIN (2) We infer successively motions and changes of motion (accelera tions) from these observations. (3) We apply the Newtonian insight in a non-metrical form and ascribe the accelerations to forces. (4) We introduce a new form of words in which the forces are described in terms of fields of different sorts depending on the nature of our knowl edge of the accelerations; at this stage of complexity of description a field has no existence independently of a particle. To represent constraints we used ordered sets of the symbols 0, 1. Such a set will be referred to as a 'column'. The constraints act in such away as to restrict the generation of columns to some d.c. subspace,2 smaller than the entire space of all possible col umns of the given order j, say. The simplest way to represent this genera tion process is by the successive operation on the set of columns of a j xj matrix over Z2 having the desired d.c. subspace as an invariant sub space. This generation process thus acts in parallel, as it were, to the discrimination process. The matrix which thus represents the constraint and its operation is it self one of a new and more complex set of entities. Since these new entities are themselves in the universe and subject to the same conditions as have already been discussed, we expect them to generate subsets. In this way, we introduce a notion of inducing subsets at a new level. I shall consider cases where a disturbance of the system, represented by an element at the new level produces something new, the essential idea being that if it falls within the d.c. subset already determined by the initial constraints then it is not new. The simplicity and weakness of this basis evidently allows very many different mathematical developments. This is due, first, to the fact that much work remains to be done both in tightening the physical thought and in investigating the mathematics, which, as one might expect with such a basis, remains conceptually simple but becomes, combinatorially, extremely complex; and second, to our intention that, in accordance with page 204, paragraph 2, certain apparently conventional choices in the mathematics should correspond to features of a particular physical situa tion to which the mathematical structure is applied. We can extend our structure by considering mappings defined on the mappings and so on: that is, we can extend it by writing the n x n matrices</page><page sequence="9">PROBABILITY IN A DISCRETE MODEL 211 as n2 columns, over the set of which we consider mappings which preserve d.c. sets. This gives rise to a hierarchy, the levels of which contain columns of ever greater order - the order rising by the square. The foregoing mathematical steps are intended to provide a model for the operational specification of the properties of particles in terms of progressive knowledge of their behavior, and it is convenient to think of the mathematical steps in this construction in a hierarchical system as being performed in a computer program. If one considers actual models involving hidden variables as I shall do, rather than constructing existence theorems about them, then the choice is immediately impossibly wide. This is probably why people do not work that way. In the search for principles which restrict the freedom to what is manageable, the principle of the hierarchy in which the simple entities of the quantum world have a background of progressively more complex interactions is given a central place. The purpose of the following model is to represent a set of interacting processes which underly the quantum processes as an operating unit and this, for want of a better word, I shall call the engine. More than one such unit can then be used together to represent states of partial correlation. In the present article the correlations between different states of the engine will be associated with particular states of spin. A particular state of spin is a constraint upon the transformations that take place in a set of discrete processes which are caused by similar larger sets in a hierarchy. The causation is represented by mathematical operation. The Model 1. There exists a set I=I(A, B,... to n terms) of binary strings (strings consisting of the binary units 0,1) of equal length /, in store at a given time. 2. There exists a set of names assigned to the strings in (1). These are equal strings a, b,... to n terms of length /, and the name a will be given to string A, and so on. 3. A generating process a is defined for constructing elements of J. If P and Q(P and Q in /) are called, then a new string R is constructed such that for all P, Q there exists a unique R, and such that: 4. Various nonzero strings P, Q are called and combined by the</page><page sequence="10">212 TED BASTIN discrimination Operation (p. 206) to produce further strings which are added to the set /. The strings are selected by an algorithm whose initiation is again outside the model, the strings being referenced by their names. 5. Further algorithms generate matrices corresponding to con straints so as to establish the next hierarchical level, as described above (this part). 6. Strings Pu P2,..., Pt(t ^ n) are called and a matrix J(PU..., Pt) constructed having the discriminate closure of the set {Pl5..., Pt} together with the zero string as an invariant sub space. J(PU..., Pt) is regarded as a string of I2 elements. 7. Concurrently with (6), a name?(P1, ...,Pt)is constructed from the names pl9..., pt (where pt is the name of P?) and forms the name of J(Pt,..., Pt) at the next hierarchical level. 8. After the generation of each matrix J, an element P is selected from I and used to generate the strings JP, J2P, J3P,..., ?P=P. If any of these elements are not in I, then one changes to one lower level, and repeats from (6); or if one is already at the lowest level, stops. If the elements JT are all in J then a new P is selected and the process repeated. If J1 Pel for all Pel, then a new matrix is to be generated as in (6). 9. If the process has not terminated after a preassigned number N of operators, terminate it. This 'engine' is arbitrarily restricted at the two ends: at the level of mini mum complexity where the elements are given an interpretation in terms of a discrete analogue of spin vectors, and at some level of greater com plexity. The first of these cut-offs is utilized to define a termination to a sequence. The second, which is a practical limit to what can be pro grammed, requires a random input at each instruction which would normally require appeal to a more complex level. IV. HIDDEN VARIABLE THEORIES The foregoing model resembles a hidden variable theory in its approach to probability, but it differs from the usual idea of a hidden variable theory in that the background is not a totally analyzed, abstract mathe</page><page sequence="11">PROBABILITY IN A DISCRETE MODEL 213 matical structure. Indeed my aim is to begin to construct a testable mechanism for the background. This program requires that the back ground should not be totally hidden. Although the state of the back ground is, in any given experiment, essentially inaccessible to observa tion, the nature of the background must be capable of progressive in vestigation. Any theory in which probability is of the hidden variable type (as is mine) must meet the formal mathematical difficulties which the hidden variable theories encounter. I shall try to show that the difficulties are due to the assumption that if a mechanism is capable of forming a background then it is a classical mechanism. By contrast, I insist that one should be entirely open as to the nature of such mechanisms - not even presupposing that mechanisms are classical until the contrary is proven. The difficulties of hidden variable theories are : (1) It is of the essence of a hidden variable theory that it should be possible to specify the hidden variables, so as to give in a deterministic form the complete state of a particle. However, we know that this is impossible. (2) Any hidden variable theory of the familiar kind will localize the hidden variables, and so, by Bell's argument, will produce a result different from quantum-mechanical prediction. These difficulties are avoided in the present model as follows. (1) I do not attach hidden variables to a single particle in isolation from the rest of the universe and from the apparatus. (Nor for that matter are they attached merely to the apparatus which would pose other diffi culties.) I accept the quantum-mechanical insight that particle and appa ratus must be viewed as a single complex system. (2) The interactions within this whole system are not to be thought of as bound, a priori, by space and time. Space and time are particular aspects of the experimental situation, to be defined operationally, and approximated to in the model, in each case. I shall now apply the general point of view on the place of probability in quantum physics which has been presented in this article to the particu lar experimental situation that is used to present the Einstein-Podolsky Rosen paradox (henceforward EPR paradox). In particular, I shall use a discussion of this experimental arrangement given by Bell (1964) in the context of the idea of hidden variables, as well as a commentary by</page><page sequence="12">214 TED BASTIN Wigner (1969) on Bell's argument to bring my point of view as near to current thinking as possible. The usefulness of the EPR experiment is that in the standard quantum theoretical description of the phenomenon that is used to state the paradox, probabilities appear as an essential feature and in a fairly simple mathematical context. The EPR experiment can be considered as a combination of the Stern-Gerlach-type analyses in each of which the probability of transmission of a particle is a function of the macroscopi cally measured angle made between the preparing and the detecting polarimeters. Thus, In this idealization a spin4 particle is considered and there is no need to consider the nature of the preparation of the particle or of the polarizer so long as they represent the essential conceptual elements of the process we are taking as a paradigm of the connection between the microsystem and the classical background or embedding system of macroscopic apparatus. The basic relation connecting the probability of particle detection with the macroscopically measured angle is p = cos20/2 and here the squared function derives from the quantum-theoretical relation between probabilities and wave functions and the factor \ in the argument of the function derives from the half integral spin. It will be necessary to examine the derivation of this relationship in detail later, but for the present purpose it is only necessary to stress that a spin state given in terms of the first polarizer, ||&gt; say, has to be represented via the states defined for the second polarizer (|f&gt; and |J/&gt;) as a function of 9 (in fact of 6/2). For example in a treatment by Wigner I?&gt; = cos0/2|?'&gt; + /sin0/2|i,&gt;.</page><page sequence="13">PROBABILITY IN A DISCRETE MODEL 215 The essential point to stress in this treatment is that from an operational point of view quantities like cos?/2|t&gt; are unanalyzable, even though conceptually they separate into a part (the operator) which specifies the macroscopic setting for the experiment and a part (the Ket vector) which specifies the object system. The operational unanalyzability of this quantity also carries with it the probabilistic behavior of the object system, which therefore must play the part in standard quantum theory ascribed to it by von Weizs?cker, and whose account was described earlier. The spin treatment is thus a clear case of the irreducible inherence of probability in the initial quantum-theoretical concepts. The classical view of the place of probability in physics, whose retention - as I have explained earlier - it is the purpose of this article to make possible, has been a major motivation for discussion of'hidden variables'. There is an ideal and general impetus behind the desire to find hidden variables. One would like to have a background of interactions of some imaginable sort which by some collaborative process reproduces the appearance of discreteness which characterizes the quantum-theoretical formalism and causes us to understand why that formalism works. I am here taking the position, for which there is now some backing in the literature (see, for example, Bastin, 1971), that the quantum formalism is more a successful algorithm than a fully comprehensible theory since no one has any idea of how the elementary 'observation' or 'measurement' process works unless they are prepared to relegate the whole of the diffi culty into some portmanteau expression like 'collapse of the wave func tion' or unless they embrace a philosophy which makes a virtue of the apparent necessity of an incomprehensible step, as does complementarity. I shall refer to hidden variable approaches which undertake to find a mechanism3 which underlies the quantum-mechanical algorithms as 'full-blooded' hidden variable theories. Bell considers the decomposition of a spin-0 system to produce two spin-^ systems which, on conventional quantum theory, must still have total spin 0. The two spin-^ systems pass through two analyzing polarizers which can be set to measure spin in various directions. Bell looks at those hidden variable theories where the probability of the first polarizer responding when set in the direction of a unit vector a is A (a, X), where X is the value of the set of hidden variables in the theory. It is supposed in the mathematics that a and k are independent, presupposing that there is a</page><page sequence="14">216 TED BASTIN dichotomy between the macroscopic level (a) and the microscopic level (k). Likewise, the probability of the second polarizer responding is B(a, 4 The preselection of the role of the hidden variables k to be compatible with the quantum algorithm is built in by Bell who writes: A(a,k), B(b,k)=?l. However, out of all the enormous variety of conditions that k might prescribe, only one condition is specified; namely, that the result B for particle 2 shall not depend on the setting a of the magnet for particle 1, nor A on b. Hence what Bell is doing is establishing a paradigm for the representation of the classical background to the particle process in just one particular respect, on the assumption that a similar treatment could be applied to progressively more and more of the detail which constitutes the classical background. Of course this is a step on from the current quantum algorithm which assumes the dichotomy between macroscopic and microscopic bridged, and helps towards establishing comprehension of the bridge. Bell's argument is developed using a correlation function P which varies from +1 to ? 1, the latter value being reached at a = b only if (1) A(a,k)=-B(a,k) and the correlation function can be written (2) P(a, b) = -?dkpkA(a, k) A(b, k). Bell then introduces a third unit vector c and his proof requires this. He gets (3) l+P(b,c)^|P(a,b)-P(a,c)|. At this point Bell's argument becomes vague, but he demonstrates that, even allowing for experimental error, the inequality (3) is incompatible with the quantum-mechanical value (4) P(a,b) = &lt;&lt;va|&lt;y2-b&gt;=-a-b. From my point of view, the vital thing to notice in this proof of Bell's is that although the argument is presented in such a way that the inter pretation of the quantities a, b, c in terms of unit vectors representing the</page><page sequence="15">PROBABILITY IN A DISCRETE MODEL 217 position of the macroscopic measuring apparatus is strongly suggested, yet actually the proof is independent of this interpretation. The unit vectors can therefore be broken up into parts in the following way: Component 1. Discrete dichotomic variables. Component 2. A relationship between the variables, which under special circumstances can be regarded as the expression of angular relationships representing the measuring apparatus. The strategy of this article is to present a model in which a particular form is given to these special cir cumstances, starting from a position in which nothing is assumed to be known about them, and in which it is by no means assumed, but rather has to be demonstrated, that one gets to a representation of the macroscopic end of the dichotomy. In my model, the correlation of two spin4 particles is represented as a condition of homeostasis in the interaction between two similar sequen tial, hierarchically organized discrete systems, and the correlation is defined as a correlation of two sequences of completely correlated or completely anticorrelated discrete states. V. HOMEOSTATIC MODEL FOR PARTIAL CORRELATION I shall suppose that the correlation of \ spin directions is a homeostatic phenomenon in the sense of Ashby (1952) in which a condition of stability is established to a certain degree by providing a random input when the agreed stability disappears and withholding it when the stability obtains. Homeostasis is a crude notion in a way, but on the other hand, the concatenation of hidden variables that produces the stability of the quantized state must be capable of overriding a great variety of particular conditions, and must in the same sense be rather crude. Two engines will be said to be in the same state when they have the same value for whichever of their parameters represent the spin state. For example, if the combinatorial scheme for representing spin suggested by Bastin (1971, Ch. 10) is used, then the two spin states are achieved in the engine by obliterating one or other of the elements (?), (J) from the store at the 2-component level. The instructions for representing the correlation state by homeostasis then conclude: (1) If the two engines are in the same state at the randomization point (i.e., where appeal is made to a nonexistent higher level) then the state</page><page sequence="16">218 TED BASTIN ofthat engine reverts to the state from which it started when the previous termination took place. (2) If the engines are in a different state, then the input is randomized. The program outline just given, represents an idealization of the way the rest of the universe acts as a 'random input' when we cut out a particular part for examination. We treat it as random when we know nothing about it as yet. This article could be seen as an answer to the question, Tf there are no preconditions upon the nature of the background mech anism, and if it cannot be isolated from the rest of the universe, how can we know anything about it ?' I suggest that the only way is by progressively extending the system which we are able to discuss, attempting with each step to establish as much as possible by rigorously operational means. Probably the com plexity of the world is such that it is only in very special circumstances that one attains a complete description up to the classical level. For example, one would require a quite different use of the 'engine' with quite different conditions upon it to approximate to a particle moving in a classical path and this is only surprising because we are in the habit of lumping all our models together because they all go on 'in the world', Actually, the operational requirements to get a classical path out of an experiment like the Einstein-Rosen-Podolsky experiment would make it something entirely different when the combinatorial structure of spin has been decided. In other words, a satisfactory relationship between spin and the 3-symmetry must be included in the 'engine' which generates particle properties. This relationship was outlined in Bastin (1971) in a form suitable for incorporation in such an engine. Further specification of macroscopic concepts has to be provided by increasing the number of interacting particles and therefore by estab lishing further correlations between 'engines' or computing units, along the lines described above for spin correlation. Table I gives a guide as to how the progressive identification of macroscopic concepts might proceed. A natural criticism of such a program might be that in such experimen tal operations as polarizing particle beams, one is already using magnetic fields, and therefore any progressive operational specification can only be circular. This objection has a plausibility derived from our normal ways</page><page sequence="17">PROBABILITY IN A DISCRETE MODEL 219 TABLE I Number of Number of interactions Description interacting providing constraints on particles what properties the particles can have A particle is conventionally assumed to exist. Velocity assumed constant till more is known. Velocity known, acceleration conventionally assumed constant in direction and magnitude and spoken of as in one plane until known to be otherwise. No field need be postulated. Acceleration known to be not in one line, i.e., requiring a plane (or known to be in one line as a special case). Necessary to postulate unipolar field only. Acceleration known to be not in one plane (except as a special case). Necessary to postulate bipolar field. (Electro-magnetic descriptions.) No consistent field description yet in existence for describing behavior of this or greater complexity. of thinking, but it has no real force. It is quite easy to imagine that our experimental operations with particles could be pursued using quite different sets of terms, yet getting the same results. VI. PLANCK'S CONSTANT In the last parts of this article, I shall discuss the place of Planck's constant in the physics of the quantum domain seen in the light of the approach of the preceding parts. The constant h is specially closely connected in the popular mind with the place of probability in quantum theory. One feels</page><page sequence="18">220 TED BASTIN that h is a numerical measure of the irreducibly statistical character of the world as one approaches the very small, but this idea is actually not very clearly defined, and it is necessary to spend some space clarifying it. In the early quantum theory following Planck, h appeared in physics as a unit of action, which imposed discreteness on the units of energy if a given wave length were selected. This intrusion of discreteness was felt at the time to indicate an explanatory failure in physics, because of the in escapable dependence of physical theory upon a space-and-time con tinuum as a conceptual framework. It is possible to see subsequent developments in the quantum theory as attempts to remedy this basic defect, and, indeed, I think this is a reasonable view to take if one is prepared, as I advocate in Part I, to discuss the quantum domain without identifying our whole knowledge of it with the current formalism in all its ramifications. The strength and the weakness at once of the thinking of the physicist is his power to identify a formal structure with physical reality, but the uncriticalness which results from this kind of thinking in the case of the quantum-theoretical formalism constitutes, in my opinion, a grave danger in view of the now familiar formal obscurities and paradoxes of that formalism. We need to be able to separate out the strands in our basic physical picture of the quantum domain and to estimate their importance separately. The uncertainty principle of Heisenberg is usually thought to specify the relation of h to probability, but it may be clearer to link the main conceptual change with Born's probabilistic interpretation of the wave function. Given the latter conceptual change Heisenberg's uncertainty principle is directly deducible from the original specification of action units and resulting energy quanta of Planck. What was Born's innovation? According to Jammer (1966), it was to place primary emphasis on the particles as the observational entities in terms of which the wave function had to be interpreted. If one has decided to follow this course, and if one's background of colloquial thinking is still classically realistic, then one needs no further strands of thinking to see that an irreducibly probabilistic picture of the particle behavior is an automatic consequence. The experimental detail which led to Born's treatment is of importance for my later conclusions, and I shall quote Jammer's (1966, p. 284) account.</page><page sequence="19">PROBABILITY IN A DISCRETE MODEL 221 Born's method was essentially an application of the perturbation theory to the scattering of plane waves, the initial and final wave-functions being both approximately plane waves far from the scattering centre. To the system of an electron of energy E = h2?mk2 coming from the -I- z direction and approaching an atom whose unperturbed eigenfunctions are i/^ (q) he ascribed the eigenfunction \?/?E(q, x) = \l/&lt;??(q) sin27i(z/A). Taking V(x, y, z, q) as the potential energy of interaction between the electron and the atom and applying the theory of perturba tions, he obtained for the scattered wave at great distance from the scattering centre the expression ?A&lt; y (x, v, z, q) = ? J dc#&lt;3 (a, /?, y) sin knm (ax + ?y + yz + ?) $?&gt; where dca is an element of the solid angle in the direction of the unit vector whose com ponents are a, ?, y and where i/^J (a, ?, y) is a wave function which determines what was subsequently called the differential cross section for the direction (a, ?, y). If this formula, said Born, allows for a corpuscular interpretation, there is only one possibility: i/^S or rather |^?|2 measures the probability that the electron which approached the scattering centre in the direction of the z-axis is found scattered in the direction defined by a, ?, y. At the time, it was generally assumed that this argument for a proba bilistic particle interpretation should be incorporated into a general dynamical scheme with equations of motion comparable with those of classical mechanics. Born himself assumed this. It was this assumption that made it necessary to postulate a field which was responsible for prescribing the values of the probability at each point in space. Indeed, one can see on quite general grounds that if one insists on this line of thought, then one is on an essentially circular path and the same argu ments concerning the operational specification of the Gespensterfeld which specifies the probability come up, that it was the purpose of Born's argument to avoid. In fact, a new possibility is open. One may treat Born's argument as a way of padding out a statistical particle argument with conventional dynamical trappings while restricting the operational reality to the scattering process itself. I am not, of course, suggesting that Born thought of doing this ; only that it is a logical possibility. I shall now exploit this logical possibility. The first consequence is that the status of h is left completely obscure. One cannot regard it as part of the, now separate, dynamical trappings, because it is essential to the operational reality expressed in the scattering situation. On the view taken at the time, it was possible to see h (the fixity of whose numerical value is vital to any theory) as a parameter which appears along with other parameters in a system of equations which express physical laws. Al though I do not think this feeling (it was never more than a feeling) about the status of h was ever capable of sustaining exact scrutiny, it did play</page><page sequence="20">222 TED BASTIN a part in guiding the conceptual development of the quantum theory. An alternative to thinking of h as an empirical parameter in a classical type dynamics is to locate its origin at a more fundamental place than the dynamical equations of motion so that it is imposed, as it were, from out side, upon all particular dynamical schemes. The possibility of such an origin was postulated first by Eddington for all of the fundamental dimensionless constants of physics. His idea was that there were algebraic calculations of some sort which could be made, which would specify the values of enough of the dimensionless ratios of the fundamental physical constants to give unique values to their dimensional constituents. I shall call this idea Eddington's conjecture. In practice an unsatisfactory compromise is usually adopted in which h is fundamental and universally applicable to any dynamical scheme, but at the same time unanalyzed and unexplained. If, as I am arguing here, the probabilistic character of quantum theory is not something brought in a priori (in which case one usually finds oneself insisting that the probabilities are irreducible as in the argument just quoted from Born), but is founded on an objective mechanism, then h (the measure of the extent of probability) must also be grounded in the mechanism which requires that one deduce its value in the way Eddington speculated. Eddington had a scheme for calculating the dimensionless constants which derived a numerical value of h from the 3 and 4 dimension numbers of the space and space-time structures. No one has been prepared to support Eddington's detailed argument which underlies his calculation and, as its premises are entirely different from those on which this article is based, I shall not discuss it now. However, the question of what calcula tion, if any, is correct is separate from the general position upon which Eddington's conjecture is based, and I accept his argument for the con jecture in its general form. Even in its general form, however, Eddington's conjecture has remained an object of curiosity rather than a center of active and creative controversy. (For a good account of the various arguments on this subject see Bondi, 1952, especially the chapter on the possible connection of microphysical and large-scale constants). One has to do more to gain acceptance in physics than establish logical force for an argument: one has to provide a way in which the new position or principle can be actively imagined, in its operation, by the physicist, so that lines of thought</page><page sequence="21">PROBABILITY IN A DISCRETE MODEL 223 which are started off by the new idea can be consistently developed. Twenty years ago, at the time when Eddington's conjecture failed to make the changeover into an actively generative idea, one frequently heard the idea dismissed with the remark 'I don't believe in these a priori theories myself. The objection was that the only considerations capable of im posing particular values on the dimensionless constants (and therefore, derivatively, on h) must lie outside physics and must therefore be derived 'a priori' from pure thought, in flat contradiction with the experimental basis of physics. There is much that could be said about this old controversy (see, for example, Kilmister, 1955, 1962). What should have been said at the time was that for Eddington's conjecture to be taken seriously and incorpo rated into the canon of physical theory the principles upon which the deduction of the dimensionless constants is made must be part and parcel of the dynamical scheme, whatever that is, that is used to describe the quantum particles, and in particular the dynamical scheme that describes the interaction processes by which we get our knowledge of the quantum particles. It is at this point that the model of particle interactions of Part IV has a contribution to make in providing a combinatorial scheme which makes contact with measurable physical quantities beginning with the dimensionless constants as a bare framework or skeleton, and then filling in other measurable quantities step by step. A preliminary account of the identification of these constants was given (Bastin, 1966) using work by Parker-Rhodes, Kilmister, and Amson, and at that time there was a strong element of numerology about the work precisely because the hierarchical algebra, though based on an abstract notion of interaction by discrimination, did not provide an interpretation of particle processes. This defect has been remedied here to the extent of proposing a model of the particle process which is consistent with the hierarchical algebra. The position I maintain is that these constants must have a vital place in any scheme of the type we are attempting to set up. VII. CAN A MODEL OF DISCRETE PROCESSES BE INCORPORATED INTO CURRENT PHYSICS? So far I have discussed the logical possibility of a model based, in the way described above, on discrete processes. The question the physicist must</page><page sequence="22">224 TED BASTIN ask is, 'Can any such model be taken seriously given what we know of the experimental successes of the current theory, which seem to most people to require that the formalism be taken over basically unchanged, what ever interpretation be given to that formalism at the simplest stages?' What has happened in this article has been the introduction of ana logues of physical concepts which have the properties of the conventional concepts just so far as the discrete mathematics is able to define those properties. In other words (a) the two sets of concepts should agree completely so far as they are comparable, and (b) all the properties in each of the discrete concepts should be represented in the corresponding conventional concept. However, there will be properties in the latter which will not appear in the former. One could say that each discrete concept is embedded in the corresponding conventional one. This relation ship of embedding seems appropriate in a theory in which the continuum is an ideal to be thought of as the result of indefinitely prolonged inter polation of points. The main example of the construction of a physical concept in a discrete model in the case of spin correlation is a good example of embedding. The idea seems obvious really, but I do not know of any history of it elsewhere. We have another question to face, however, even if we allow the tech nique of embedding. It may be doubted whether by starting with particle processes we can ever get those results that need the concept o? a field or other independent starting point that described objects being spread out in space. To show that a possibility does exist of carrying out this pro gram, I refer to work of Noyes (1974). Noyes's argument aims at a con struction of a large part of physics, and is therefore long and complex, but again I shall only be concerned to follow him just so far as to establish possibility as a logical matter. Noyes requires two results from a combinatorial theory: (1) A sequence of numbers interpretable as the inverses of coupling constants of the main fields of physics (i.e., he takes over what I have called Eddington's Conjecture). (2) A background of interactions which take place in a sequence and which are such that the elementary particle events can be attributed to particular configurations of them. Ideally Noyes would require (3) that (1) and (2) be part of the same consistent scheme.</page><page sequence="23">PROBABILITY IN A DISCRETE MODEL 225 Noyes's demands are in fact not stringent because he feels sufficiently confident of his approach to go ahead and merely postulate (1) and (2), though he was in fact stimulated by the combinatorial program described in this article. As we have seen, it is too early to present (3) as more than a plausible conjecture. If the basis of (3) in our program were to be properly estab lished this would strengthen Noyes's case. The kernel of Noyes's argument is traced back by him, so far as any combinatorial approach goes, (1) to the original Yukawa (1935) inter pretation of exchange energy and quantum fluctuations, (2) to a reinter pretation of Yukawa due to Wick (1938), and (3) to an argument of Dyson (1952) explaining how a coupling constant can arise because a particular number of particle interactions are required to establish a balance between positive and negative contributions to the energy of the assembly as more are added. The limit arises when the increase in total energy due to the addition of a particle to the system is sufficient to create another new particle. This balance (which is defined in terms of the number of constituent particles) gives rise to the concept of a field. Noyes is really saying that these strands of argument combine to give a picture of a sort that we have already met once in this article, namely, in investigating the argument that led Born from a study of the scattering situation to a probabilistic scheme of particle interactions. In Born's case, one could see with some effort that what had been achieved was the possibility of running the conventional deductive argument in reverse and giving operational primacy to the particle process (in which case, the conven tional dynamical background could be left a bit shadowy). Noyes is much more explicit than Born. He is consciously rejecting all physical reality except that of the particle and he finishes up with quan tization of action. Anyway, the essential point is that the quantum fluctuations in particle number must exist for Noyes, but they must also have a very different ontological status from what they have in current physics. They are capable of a good deal of flexibility in the way we actually represent them, since, at once, they are the absolutely fundamen tal physical reality, and they are what the underlying model, whatever it is, has to provide for the edifice of later theorizing. Of course, so far as the model of this article has validity they are described by the operations existing within that model, and what we know of the appearance of</page><page sequence="24">226 TED BASTIN probability in the quantum fluctuations (and therefore in the universe) is what we have had to postulate to make the model work. Cambridge Language Research Unit NOTES * I am extremely grateful to Dr. C. J. S. Clarke for a very great deal of help with this paper, at all levels from sorting out of ideas to construction of detailed mathematical arguments. 1 I am assuming the view which is given central importance by some writers on the quan tum theory that a 'particle' includes in its own proper specification the preparation of its state. 2 A d.c. subspace (discriminately closed subspace) is a subspace closed under elementwise addition mod 2 between columns from which the null column is excluded. The use of this concept is explained in Bastin (1966): for the present purpose one may read 'closed under addition mod 2' for 'd.c.', but I retain the latter usage here. 3 I might save the reader unnecessary perplexity if I mention here that I by no means identify 'mechanism' with classical mechanics. I use the term to cover any system the interaction of whose parts could in principle be specified completely. In fact, the model I shall use will contain nonlocal relationships, and, far from its being classical, that which appears in current quantum theory as observer participation will be fully incorporated. REFERENCES Ashby, W. R., Design for a Brain, Chapman and Hall, London, 1952. Bastin, E. W., 'On the Origin of the Scale Constants of Physics', Studia Philosophica Gandensia 4 (1966), 77-101. Bastin, E. W. (ed.), Quantum Theory and Beyond, Cambridge University Press, Cambridge, 1971. Bell, J. S., 'On the Einstein Podolsky Rosen Paradox', Physics 1 (1964), 195-200. Bondi, H., Cosmology, Cambridge University Press, Cambridge, 1952. Dyson, F. J., 'Divergence of Perturbation Theory in Quantum Electrodynamics', Physical Review 85 (1952), 631-632. Jammer, M., The Conceptual Development of Quantum Mechanics, McGraw-Hill, New York, 1966. Kilmister, C. W., 'The Analysis of Observations (II)', Quarterly Journal of Mathematics (Oxford Second Series) 6 (1955), 161-172. Kilmister, C. W. and Tupper, B. O. J., Eddington's Statistical Theory, Oxford University Press, Oxford, 1962. Lande, A., Foundations of Quantum Theory, Yale University Press, New Haven, 1955. Noyes, P., 'Non Locality in Particle Physics', in R. Sheldrake and M. Masterman (eds.), Revision in Metaphysics and Science, Macmillan, London, 1974, in press. Popper, K., 'Quantum Mechanics Without "The Observer" ', in M. Bunge (ed.), Quantum Theory and Reality, Springer, Berlin, 1967. Rosenfeld, L., 'The Measuring Process in Quantum Mechanics', Progress of Theoretical Physics (Supplement to) Extra number (1965), 222-231.</page><page sequence="25">PROBABILITY IN A DISCRETE MODEL 227 von Weizs?cker, C. F., 'Probability and Quantum Mechanics', British Journal for the Philosophy of Science 24 (1973), 321-337. Wheeler, J. A., 'Superspace and Quantum Geometrodynamics', in C. M. De Witt and J. A. Wheeler (eds.), Battelle Rencontres: 1967 Lectures in Mathematics and Physics, Benjamin, New York, 1968. Wheeler, J. A., Lecture at King's College London, April 1974. Wick, G. C, 'Range of Nuclear Forces in Yukawa's Theory', Nature 142 (1938), 993-994. Wigner, E. P., 'On Hidden Variables and Quantum Mechanical Probabilities', American Journal of Physics 38 (1969), 1005-1009. Yukawa, H., 'Interaction of Elementary Particles. Part I.', Proceedings of the Physico Mathematical Society of Japan 17 (1935), 48-57.</page></plain_text>
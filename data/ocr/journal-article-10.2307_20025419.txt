<plain_text><page sequence="1">James Bailey First We Reshape Our Computers, Then Our Computers Reshape Us: The Broader Intellectual Impact of Parallelism TODAY WE MARVEL AT THE INGENUITY OF ENGINEERS who, in the 1930s and 1940s, created a new and seemingly unprece dented wonder: the computer. In the decades which followed, new versions of these computers have become ever faster and less expensive. Amidst the marveling, however, we often overlook a curious point; the fact that it took no time at all for these supposedly unprecedented marvels to be filled up with useful work. Immediately as the first electronic computers were put together, trusted algorithms were waiting to be fed into them. It was almost as if computers had existed and been used all along. They had, and they were, although prior to 1940 all computers were people. A creative partnership between scientist and computer had already existed for centuries. The role of these human computers is relevant today precisely because of the ease with which they were annihilated by their electronic substitutes. The first electronic com puters of the 1940s succeeded so quickly because they copied the sequential architecture of human computers. In so doing, they inherited all the sequential ways of expressing and formulating science that had developed over twenty-five hundred years, a period in which computers shaped science far more than science shaped computers. In effect, the architects of the 1940s packaged their wonderfully speedy electronic circuits in anthropomorphic forms to meet an existing market. They left essentially unchanged the compu tational partnership that scientists were, in the words of John von Neumann, "uniformly used to since the days of Gauss." James Bailey is Director of Marketing at Thinking Machines Corporation. 67</page><page sequence="2">68 James Bailey It is only today, for the first time in history, that we are genuinely reshaping our computers. We are making them parallel. A parallel computer operates on thousands of pieces of data at once and can keep track of extremely complex interactions among them all. Parallel computers are organized much more directly around what electronic circuits are good at than they are around what people are good at. As such, they are adept at carrying out computations that no human computer in their right mind would ever attempt. Viewed in this light, the stakes are wonderfully high this time around. Parallel computers threaten to reshape thinking that has gone unchallenged since the time of Newton, Descartes, and even Aristotle. What shape will this new thinking take? The first step in answering this question is to become more familiar with the old world of sequential computing, and to see what is now open to change. The second step is to look at some new forms of computa tion, ones that are just emerging today. With their emphasis on "changing all of the data all the time" these algorithms are very different from anything that has come before. It is a very exciting time. As we finish reshaping our computers, they are already begin ning to reshape us. Since the influence of computation on thought is considerable, anyone interested in the overall history of ideas should be paying attention to computing right now. COMPUTER SCIENCE AS ARCHAEOLOGY Looking back into the human computing era is not easy. The formal field of study called computer science and its vocabulary originated in the 1950s when the human computer era was on its way to oblivion. As a result, no sixteenth-century text describes computers as "having about seven scratch pad registers" or a book of sines and cosines as "storing a little over a megabyte." In fact, sixteenth-century texts rarely mention computers at all. Computers found no audience for their memoirs; they are not buried in Westminster Abbey. When they pretended to the status of scientists or mathematicians, they were rudely put down. As John Napier's biographer notes scornfully, "Many a man passes for a great mathematician [just] because he is a huge computer."1 The partnership between science and computation</page><page sequence="3">The Broader Intellectual Impact of Parallelism 69 was real, but it was not a partnership of equals. Then, as now, a computer was something a scientist wanted to employ, not be. In this sense, an Elizabethan computer is analogous to an Elizabe than actor: individually obscure but collectively very influential on what a play could or could not be. Only occasionally does a Shakespeare stop to note that he was writing his plays so as to be performed by human actors?but he was. And his success was absolutely dependent on writing plays that took into account the strengths and weaknesses of these actors. We can see the tradeoffs at work whenever a playwright strains against them, as in the use of soliloquy or deus ex machina, or even the use of a professional gymnast in a contemporary production of Peter Pan. Consider the analogous dilemma of the Renaissance scientist: His [Flamsted, the Royal Astronomer at the time of Newton] salary was only ?100 a year, and he was allowed nothing from Government, either to provide or repair instruments, or to pay the expenses of a computer for reducing his observations. He was, therefore, obliged to purchase, or to construct with his own hands, the instruments which he used, and to pay the expenses of a servant capable of making the calculations which he required.2 What kind of science would he choose to do, knowing that the ensuing computations would have to be carried out by himself, or someone just like himself architecturally? What kind of algorithmic mind-set would he bring to his job? And what fruitful avenues of scientific investigation would he never pursue at all, for want of the appropriate computational resource? In short, how much would his computer shape him? Both sides of the scientist-computer partnership offer clues to the answer. On the computer's side, there are a few rare cases where one actually wrote about his craft.3 Also helpful are the cases where scientists explicitly reflected on their computational resource. From these sources emerges a model of what a human computer actually was. On the scientist's side, there are the main currents of the science itself, and whether they closely and explicitly mirror the strengths and weaknesses of those computers. A final source of insight is provided by cases where scientists proposed algorithms incomputable by</page><page sequence="4">70 James Bailey humans. Did good ideas get lost simply because they were not sequential? FOR THE "RELIEF OF MEMORY" Given the comparative speediness of today's computers, it is natural to assume that computation rate was the controlling architectural issue in the human computing era. Such was not necessarily the case. Memory architecture was the most-noted frustration. For example, Pierre Duhem, writing at the turn of the century, comments on the way human memory weakness affects the expression of science. "He [the physicist] will choose a certain formula because it is simpler than the others; the weakness of our minds constrains us to attach great importance to considerations of this sort."4 Formulae are programs. A memorable formula is in fact preferable to an efficient one. A computer that reckons slowly will still get the answer eventually, but a computer that forgets its program is doomed. John Napier is just one example of those who put Duhem's premise into action. Those versant in spherical trigonometry know that sixteen cases in spherical rectangular triangles may be proposed, and of these there are ten or twelve so difficult that authors who have written on the subject have been oblidged [sic] to construct a table to consult for the relief of memory; Napier's rule reduces all these cases to a single rule, composed of two parts, whose elegant form is particularly apt to impress itself profoundly on the memory.5 The memory being referred to by both Duhem and Napier is long-term, or program memory. It has been realized for at least a hundred years that computing involves two kinds of memory. The second, which registers intermediate results, is even more limited. As regards the second direction in which memory is active, it may be noted that, according to Bidder, the key to mental calculation lies in registering only one fact at a time, the strain in calculation being due to this work of registration. Thus, in a complex multiplication he goes through a series of operations, the last result in each operation being alone registered by the memory, all the previous results being consec utively obliterated until a total product is obtained.6 None of this is true any more. Current computer memories are both capacious and cheap. If an algorithm is twice as bulky but gets</page><page sequence="5">The Broader Intellectual Impact of Parallelism 71 the answer twice as fast, that is a wonderfully good trade-off. The essential characteristic of a parallel computer is that it keeps thou sands of intermediate results active at once. So the approaches of Duhem, Napier, and Bidder no longer have computational advan tage. In particular, algorithms that operate on all the data values at once are now very plausible. Aristotle, in his analysis of human memory, focuses on an aspect of memory architecture that goes even deeper. Using the term change to refer to a piece of data stored in memory, he observes that human memory is designed to read out data sequentially, not randomly. And thus whenever someone wishes to recollect, he will do the following. He will seek to get a starting-point for a change after which will be the change in question. And this is why recollections occur quickest and best from a starting point. For as the things are related to each other in succession, so also are the changes. And whatever has some order, as things in mathematics do, is easily remembered. Other things are remembered badly and with difficulty.7 Indeed. How awkward it would have been if human memory architecture were not aligned with the structure of scientific and mathematical algorithms. But Aristotle's observation raises a far more unsettling question. Why exactly is it that mathematics "has some order?" How much of the reason is independent of the historical accident that mathematics was invented at a time when all the computers available to carry it out were sequential? Perhaps whole new forms of reckoning exist, forms that only make sense in parallel. If they do, and our reshaped parallel computers lead us to discover them, will we even call them mathematics? PRESUPPOSING AN ORDER AMONG OBJECTS WHICH DO NOT FOLLOW ONE ANOTHER NATURALLY The assertion that mathematics "has some order" embeds a telling ambiguity. Order is as much a synonym for comprehensibility as it is for sequentiality. Putting information in order implies making an improvement to it, not just a rearrangement. In his Discourse On Method, Ren? Descartes elevates this sequentialism to be one of his four laws of correct thinking: Conducting one's thoughts in order, by beginning with the simplest objects, easiest to know, in order to rise gradually, step by step, so to</page><page sequence="6">72 James Bailey speak, to the knowledge of the more composite ones, and even presupposing an order among those objects which do not follow one another naturally.8 The interaction between thought pattern and world view could not be clearer. Descartes felt that his own mental processes were more efficient when he put them into order. So, he did. But then, and this is the decisive step?or misstep?he goes on to impose the notion of sequentiality on objects in the physical world, whether they are inherently sequential or not. Aristotle introduces the same potential distortion when he suggests that "we think of the stars as mere bodies and as units with a serial order indeed but entirely inanimate."9 In both cases, of course, the imposition of sequentiality made good practical sense. It allowed scientific investigation to get started. As Kuhn notes, "Seen on a clear night, the skies speak first to the poetic, not to the scientific imagination," and that "systematic study requires the ability to select stars for repeated study wherever in the heavens they appear."10 Without ordering, there is no opportunity for selec tion, or even for enumeration. One way to achieve order is to limit one's scientific focus to phenomena which already exhibit it intrinsically. Newton's celestial mechanics, the most celebrated science of the human computing era, is a prime example. The movement of a planet through space is inherently sequential. In Newton's case, it is known that he kept the limitations of human computers explicitly in mind. As de Gemaches noted in 1740, "His work did not bear on any subjects except those that could be treated by means of the calculations he knew how to make."11 Planetary orbits were among the grand challenges of seventeenth century computation. It is also the case that these methods had major impact on the design of the first electronic computers in the 1940s. A planet's position at any moment in time is integrated from its previous position and momentum. Because a planet has only one position, the equations of its motion around the sun keep only a few intermediate results active at each step in the computation. The formulae themselves are brief and easily impressed upon the memory. Generations of computers found both their training and their careers in these computations and the related ones of navigation. Newton's laws and human computers were made for each other, perhaps literally.</page><page sequence="7">The Broader Intellectual Impact of Parallelism 73 It was via the science of ballistics that Newton's work came to impact the design of the electronic computers in the 1940s. Ballistics, like celestial mechanics, epitomizes sequential computing. The goal is to compute the trajectory of an artillery shell, given its initial velocity. Many of the great minds of western science, including Galileo, Lagrange, Laplace, and Euler, worked on the subject; it has always enjoyed lavish government funding. Significant progress was made in the twentieth century when astronomical techniques were employed. As Bliss notes, "The method adopted in this country [America] was one of approximate numerical integration which was remodeled for ballistics from earlier uses in astronomy by Professor F. R. Moulton and his associates."12 The methods of Moulton provide a charming glimpse of what computing was like sixty years ago. The first few steps in the computation of a trajectory should be made with relatively short time intervals, since there are so few differences to guide the estimates at that stage. The sizes of the intervals should be adjusted at all stages so that improved values of the variables are not too far from estimated ones. A typical example is a trajectory which has been used as a model by Jackson. The computation has intervals of 1/4 second each from t = 0 to t = 1,1/2 second each from t = 1 to t = 2, 1 second each from t = 2 to t = 12, and 2 seconds each from t = 12 to t = 48. The time of flight is very close to 48 seconds_ A novice at computing will possibly find the computation of a trajectory confusing at first. But it is interesting to see how rapidly the work proceeds after some practice, and especially when two or three computers collaborate in using the tables or a computing machine, and in recording the results.13 It is important to underscore the practical nature of ballistics calculations. These are not abstract descriptions of theoretical calcu lations. Ballistics computations were actually carried out and carried out in volume. For example, America's Aberdeen Ballistics Research Laboratory employed almost two hundred computers during World War II. They computed the range tables without which artillery officers could not level their guns. The same point applies to celestial mechanics. Planetary orbit computations were actually performed, to the point where the existence of Neptune was worked out computa tionally before it was seen telescopically. Thus the authority of the field of mechanics was doubly established: first by the reputation of its scientists all the way back to Newton, and second by the practical</page><page sequence="8">74 James Bailey success of its computational algorithms. The artillery shells landed and the eclipses happened where the computers said they would. BUT IMAGINE . . . Obviously, celestial mechanics and ballistics both align strongly with Descartes's desire to "conduct one's thoughts in order." The compu tations involved are an ideal fit to the strengths and weaknesses of human computers. The programs are short and easy to remember, and the number of active data elements remains small throughout the computation. The tightness of the fit can be seen even more clearly when it is contrasted to some examples of science that did not follow the sequentialist mold. Galileo's Two New Sciences, published in the same decade as the Discourse, provides a counterpoint to Descartes's sequentialist pre scription. Written in the form of a dialogue, it deals with both principles of motion and also the resistance of solid bodies to fracture. Most of it is given over to theorems of a geometric form. There is a particularly clever theorem among the proofs about the relationship in time of two balls descending different inclined planes.14 Theorem 6.6. If from the highest or lowest point in a vertical circle there be drawn any inclined planes meeting the circumference the times of descent along these chords are equal to each other. At this point in the dialogue, the speaker asks, apologetically, for his companion to "Please allow me to interrupt the lecture for a moment in order that I may clear up an idea which just occurs to me." He then goes on to imagine (but not prove) the parallel implications of Theorem 6.6.15</page><page sequence="9">The Broader Intellectual Impact of Parallelism 75 But imagine a vertical plane from the highest point of which are drawn lines inclined at every angle and extending indefinitely; imagine also that heavy particles descend along these lines with a naturally accelerated motion and each with a speed appropriate to the inclination of its line.If these moving particles are always visible, what will be the locus of their position at any instant? The answer, of course, is an ever-expanding circle, the same shape that is obtained by sending the balls outward from a central point. But this answer is a parallel answer, not a sequential one. It depends upon all of the objects being changed at once. If one rolls, or computes, the balls sequentially, "in order," the circular shape never emerges at all. The answer is also an inherently visual answer, as Galileo makes clear when he says, "If these moving balls are always visible." No single number can really capture or communicate it. For whatever reason, Galileo does not actually supply pictures. The visual representations above do not appear in the original. The fruitfulness of this parallel way of thinking becomes patent when Galileo takes it to three dimensions and notes that "an infinite number of spheres are produced about a single point, or rather a single sphere which expands in size without limit." He then con cludes:16 The fact that one can take the origin of motion either at the inmost center or at the very top of the sphere leads one to think that there may be some great mystery hidden in these true and wonderful results, a mystery related to the cre ation of the universe (which is said to be spher ical in shape), and related also to the seat of the first cause [prima causa]. This is as far as he sees fit to take it. A very early and very beautiful theory of an expanding universe ("a single sphere which expands in</page><page sequence="10">76 James Bailey size") and a first cause is left to die undeveloped. There is no attempt to compute rates of expansion or the size of the initial mass or anything along those lines. Galileo's brief foray into cosmology?and parallel science?achieved none of the visibility and influence that Newton's subsequent work on single planet behavior enjoyed. Joseph Fourier provides a nineteenth-century example of parallel science that is somewhat more sophisticated. His Analytical Theory of Heat focuses on the flow of heat in solid objects. Most of the analysis deals with the objects as single blocks and analyzes heat flux between pairs of points in the continuum of matter. But he, like Galileo, pauses at one point for a side excursion into a parallel view of the problem. He notes that the flow of heat through a bar may also be analyzed successfully by breaking the bar into a number of discrete pieces and thinking of heat as being "communicated" between the pieces. He chooses to put these pieces into a ring, because that simplifies the problem.17 Suppose n equal pris matic masses to be placed at equal dis tances on the circumfer ence of a circle. All these bodies, enjoying perfect conductibility, have known tempera tures, different for each of them; they do not permit any part of the heat which they contain to escape at their surface; an infinitely thin layer is separated from the first mass to be united to the second, which is situated towards the right; at the same time a parallel layer is separated from the second mass, carried from left to right, and joined to the third; the same is the case with all the other masses, from each of which an infinitely thin layer is separated at the same instant, and joined to the following mass. Lasdy, the same layers return immediately afterwards, and are united to the bodies from which they had been detached. Fourier's basic methodology is the one still used today to model physical behavior inside a computer. Known as finite element anal ysis, it depends on dicing an object into myriad small discrete pieces, called elements. Elements are linked to their neighbors, two in the case above but as many as eight or ten in the complex topologies of modern grids. And each element has a boundary condition, a rule specifying how it interacts with the outside world. Fourier specifies</page><page sequence="11">The Broader Intellectual Impact of Parallelism 77 "Dirichlet conditions," meaning that no heat escapes. Heat only moves between elements, via the communications links. By substituting a different geometry, this same methodology is appropriate, for example, for predicting whether the nose cone of a space shuttle will burn up on reentry. Heat is applied to the elements that constitute the cone itself. As they heat up, they communicate some of that heat to their cooler neighbor elements further back along the fuselage. These in turn communicate it to their neighbors, or to the air around them. If the heat is dissipated quickly enough, the temperature of the nose elements stabilizes; if not, they burn up. Equations of heat transfer, together with knowledge of the heat dissipation characteristics of the materials involved, determine how much heat moves from element to element at each unit of time. As with Galileo, Fourier uses parallelism as a critical simplifying assumption: "From each of which an infinitely thin layer is separated . at the same instant." But, also like Galileo, he treats the whole enterprise almost as an aside, and goes back to more conventional forms of analysis for the rest of his book. He never translates his parallel science into any form of parallel computation. Lewis Rich ardson, working in the 1920s, does make such a translation into parallel computation. Compared to Galileo's and Fourier's treatises, his Weather Prediction by Numerical Process is obscure, but it was well known to subsequent computer architects, such as von Neu mann. In his book, Richardson boldly proposes to predict the global weather by a process of parallel computation. His algorithm was inspired by the fact that the weather stations of Europe could be fitted roughly into a checkerboard pattern. He established a computational equivalent of this checkerboard for which he borrowed the term lattice from crystallography. He then developed discrete versions of the fluid flow equations to be applied at each lattice point. His first attempt required six weeks of computing to advance the weather at one lattice point by three hours, but that did not deter him. By optimizing his computing sheets, Richardson brought the time down below a hundred hours, so that thirty-two human computers could keep up the pace at an individual lattice point. He calculated that he would need two thousand lattice points worldwide. With all this in mind, he architected his parallel computer.18</page><page sequence="12">78 James Bailey Sixty-four thousand computers would be needed to race the weather for the whole globe- Imagine a large hall like a theatre, except that the circles and galleries go right round through the space usually occupied by the stage. The walls of this chamber are painted to form a map of the globe. The ceiling represents the north po lar regions, England is in the gallery, the trop ics in the upper circle, Australia on the dress circle and the Antarctic in the pit. A myriad computers are at work upon the weather of the part of the map where each sits, but each computer attends only to one equation or part of an equation. The work of each region is coordinated by an official of higher rank. Numerous little "night signs" display the instantaneous values so that neighbouring computers can read them. Each number is thus displayed in three adjacent zones so as to maintain communication to North and South on the map. From the floor of the pit a tall pillar rises to half the height of the hall. It carries a large pulpit on its top. In this sits the man in charge of the whole theatre. WHAT WE WERE "UNIFORMLY USED TO SINCE THE DAYS OF GAUSS" Although these early examples of parallel science are exhilarating, they were outside the mainstream. So it should come as no surprise that, when the transition to electronic computing occurred in the 1940s, it was the tradition that we associate with Descartes, Newton, and Moulton that held sway. To be more accurate, it was the tradition of generations of anonymous computers which held the sway?it was precisely the carrying out of Moulton's algorithms that motivated the construction of von Neumann computers. H. H. Goldstine, von Neumann's collaborator in systems design both during and after World War II, states: The reason why we wish to discuss this recondite and perhaps uninteresting branch of mechanics [that is, ballistics] is because it was to have a vital impact on our subject. We shall see how the ballistical needs of the United States were to be a primary incentive for the development of the modem computer.19</page><page sequence="13">The Broader Intellectual Impact of Parallelism 79 As I have said, one of the main functions of the [Aberdeen] Ballistic Research Laboratory was the production of firing and bombing tables and related gun control data. It is worth saying a few words about such tables so that the reader will have some conception of what was being undertaken. The automation of this process was to be the raison d'?tre for the first electronic digital computer.20 This linkage cannot be emphasized too strongly. The raison d'?tre of the first electronic digital computer was the computation of algorithms that had been refined for centuries around the strengths and weaknesses of human computers. Goldstine personally managed Aberdeen's staff of 176 computers, whose job it was to compute range tables. They were not able to do the job quickly enough. [A] typical firing table required perhaps 2,000-4,000 trajectories? assume 3,000. Thus, for example, the differential analyzer required perhaps 750 hours?30 days to do the trajectory calculations for the table. The estimates reveal a situation that was unsupportable both because the volume of work was too large and perhaps more importantly, because the work had to be done very promptly to avoid delays in putting weapons into the hands of the troops in the field.21 Ballistics computations were not the only calculations being con templated in that period. Von Neumann was very familiar with Richardson's work, and returned to it in later years. During the war he split his time between Aberdeen and Los Alamos; at Los Alamos he worked on hydrodynamics calculations. In an unpublished paper written during the war, von Neumann and Goldstine list continuum dynamics, classical electrodynamics, and hydrodynamics as other important influences. But it was ballistics that held people's attention, because ballistics calculations were already being carried out. Von Neumann and Goldstine were ?o? inventing the computer. They already knew what a computer was, what a computer did, and how long it took a computer to do it. In fact, they used ballistics trajectory calculations as the standard benchmark of electronic computer performance partly because it was so easy to compare to what had come before. Such a typical problem is the determination of an average ballistic trajectory. A good analyzer will usually require 10 to 20 minutes to handle this to a precision of about five parts in 10,000. Trajectories</page><page sequence="14">80 James Bailey have been run on the ENIAC and require 0.5 min. for complete solution including printing of needed data. The computation of a ballistic trajectory considered above is a reasonably typical instance of a simple system of non-linear, total differential equations. As we saw, it involves about 750 multiplica tions.22 A final factor driving the architects to an inherently human computer architecture was the electronic memory technology of the period. The first von Neumann computers used mercury delay lines which could only read out data in a fixed "order," exactly as Aristotle describes the human memory as doing. When contrasted with the parallel computational approaches of Galileo, Richardson, and Fourier, it is clear how little the von Neumann computers deviated from the uniform human computing tradition stretching back to Gauss and before. Even when they had become standard, von Neumann computers were still being described in anthropomorphic terms. And now we come to the concept of a stored program_Suppose you wished to give your assistant a large number of instructions for manual computations all in advance. You could do this by supplying him with a prepared set of instructions, or you could dictate the instructions and have him write them down, perhaps at the top of the same sheet of paper on which he is later to perform the computations. Two different situations are here involved_The second is becoming quite common in the newer machines and is the case usually meant when the term "stored program" is used.23 The third or "high speed" store is quite small and holds only that information needed in the course of a calculation?the sort of thing that a clerk would hold in his head while working out the answer.24 THE SKIES SPEAK FIRST TO THE POETIC, NOT THE SCIENTIFIC IMAGINATION At one level, the difference between the sequential and parallel algorithms is mechanical. Any computation that can be carried out by a parallel computer can also be carried out by a sequential computer?and, in fact, they are. It is one of the great ironies of</page><page sequence="15">The Broader Intellectual Impact of Parallelism 81 computational history that the primary use of sequential (von Neu mann) supercomputers in the 1980s was to carry out the inherently parallel ?-body algorithms of Galileo, the finite element algorithms of Fourier, and the finite difference algorithms of Richardson. Now that parallel processors are available, they are allowing these algorithms to be carried out on much larger, more detailed data sets. For this reason alone, they are likely to become predominant in the market place. But the opportunities for exploiting parallel computation are already moving beyond mere mechanical improvements. Today at least three new threads of development are becoming visible. The first is the shift from presenting results as numbers to presenting results as pictures. Known as scientific visualization and already underway in the sequential computing era, this shift is actually implicit in Galileo, Fourier, and Richardson. They all introduce their ideas by saying "Imagine ..." since imagination was the medium of visual commu nications most available to them. The shift to visual forms of answers is both important and inherently tied to parallelism. It is important because the mode in which something is communicated affects the contents of that communication. The influence of communication on the structure of science itself was one of the important contributions of Ernst Mach. It was his view that "the first real beginnings of science appear in society ... when the necessity for the communication of experience arises."25 How would a shift from a number-based form of commu nication to an image-based form of communication affect the content of that communication? The philosopher Suzanne Langer, writing in the 1930s, makes an instructive distinction, one which emphasizes the parallel nature of visual communication. She calls her first type of communication discursive, and typifies it by language, although the same points hold for numbers.26 But words have a linear, discrete, successive order; they are strung one after another like beads in a rosary; beyond the very limited meanings of in flections, which can indeed be incorporated in the words themselves, we cannot talk in simultaneous bunches of names.</page><page sequence="16">82 James Bailey The second she calls presentational, which she typifies by pictures.27 Visual forms?lines, colors, proportions, etc.? are just as capable of articulation, i.e., of complex combination, as words. But the laws that govern this sort of articulation are altogether different from the laws of syntax that govern language. The most radical difference is that visual forms are not discursive. They do not present their constituents successively, but simultaneously, so the relations determining a visual structure are grasped in one act of vision.... An idea mat contains too many minute yet closely related parts, too many rela tions within relations, cannot be "projected" into discursive form. In short, there are things one can say in the presentational (parallel) form that simply cannot be said in the discursive (sequential) form: "Too many relations within relations cannot be projected into discursive form." A modern computational fluid dynamicist, study ing the flow of air over the wing of a supersonic airplane, would say, "Too many vortices within vortices cannot be comprehended simply from a printout of numbers." Where the relevant science lies in the relations among elements, as it did in Galileo's multiple moving objects, words fail, and so do individual numbers. In Galileo's time, artists communicated one set of truths in the parallel (presentational) mode; scientists communicated a different set of truths in the sequential (discursive) mode. When the skies spoke to the poetic imagination of Galileo, he had no computational place to go with his insights. Today's Galileos do, and that is becoming one of the significant impacts of parallelism. It is no accident that the fields of scientific visualization and parallel processing have emerged in the same decade. They are, in a sense, two sides of the same coin. A number is akin to a single pixel on a computer screen. Its expressive power is limited. Scientific visualization renders whole fields of data onto a computer screen at once, so relations within relations can be "grasped in one act of vision." Parallel processing is the most natural and logical way to generate and manipulate those fields of data. Numerical algorithms have traditionally had a great advantage: they produce numerical results. But if results are no longer desired in numerical form, then the ability to produce numbers is no longer an advantage. In fact, the first generation of scientific visualization</page><page sequence="17">The Broader Intellectual Impact of Parallelism 83 programs is made up of hybrids. The first part of the algorithm computes numerically; at the very end, a "graphics postprocessor" takes the numbers and translates them into the pixels that make up an image. A radically new form of parallel computation is now growing up around the realization that numbers are not necessarily the best medium for building pictures. These new forms, generally called lattice gas or cellular automata algorithms, are the second of the three principal new developments. A cellular automata algorithm uses no numbers at all. Instead, it allows millions of simple-minded objects to interact on a playing field akin to a checkerboard. At every step in the computation, all the objects move to an adjacent cell. When two collide, they bounce off. Depending on the rules of movement used, one of a variety of patterns of behavior emerge. These patterns are directly projectable onto a computer screen since the field of objects is directly analogous to a field of pixels. Such algorithms exist, and the first of them are now functioning on parallel computers. They have been used to solve heat flow problems similar to Fourier's and to model fluid behavior. In the latter case they treat a fluid as millions of tiny independent particles each bumping and jostling each other in simple ways. Traditional methods view the same fluid as marching numerically to the beat of the Navier-Stokes equations. Particle-based fluid simulation methods are quite natural, because a brook is in fact made up of myriad jostling water molecules. They are also an excellent match to what electronic circuits do best. Real numbers are quite ungainly from the point of view of an electronic circuit; blacks and whites, or zeros and ones are much more simp?tico with the way an electronic circuit operates. But the method is totally inhuman. Efficient for circuits, it is incomputable by humans, who prefer numbers. Hence it is hard to build up trust on the part of those who work with these systems. Impressionistic forms of validation ("Looks like a fluid. Swirls like a fluid. Must be ... ") are not satisfying. So these methods are slow to find acceptance. But these methods are coming nevertheless. Some of the most advanced work in this area is described in "Parallel Billiards and Monster Systems" by Brosl Hasslacher in this issue. The third line of parallel development takes its inspiration from Darwin. If evolution may be thought of as computing a range of selected species, then the computation is clearly a parallel one. A</page><page sequence="18">84 James Bailey parallel computer can be set up to allow the same kind of evolution to occur. Instead of a single all-knowing program, the computer is given myriad flawed programs called agents. Initially, all agents have equal voice in the way the overall computation proceeds. Results are then compared to what the answer should have been. When the computed results are close to the desired one, those agents who helped the most are rewarded with a larger voice next time. They become more dominant while the more feckless agents wither away. Over time this porridge of competing agents can improve its behavior. The pot is continually stirred by mutating agents sponta neously and allowing them to mate. For example, the first half of one agent program might be mated to the last half of another, and a new agent is created. A description of a somewhat similar kind of system may be found in "Complex Adaptive Systems" by John Holland in this issue. The internal mechanics of these systems are complicated, but their potential uses are very straightforward. They hold great promise for modeling the behavior of systems that have defied analysis by traditional numerical techniques. The behavior of an economy is one such example. More radically, these techniques might some day make parallel computers self-programming. Rather than specify a program, the user would specify what they want the computer to do, and it would evolve its way there.28 FIRST WE RESHAPE OUR COMPUTERS, THEN OUR COMPUTERS RESHAPE US Scientific visualization, lattice gas algorithms, and genetic algorithms: all are genuinely new ways of thinking about problem solving and computation. They underscore the difference between the current revolution in computing and the transition that occurred in the 1940s. As mentioned already, there was no delay in using the results that the first electronic computers produced. There was no anxiety about their validity, because the answers could be checked directly. The results from the electronic computer were compared to the results of the same calculation, using the same algorithm, from a human computer. The results of lattice gas and genetic computations enjoy no such cultural preacceptance, but their potential to change the way we think about the world is all the greater for their unorthodoxy. They are clearly a better, more efficient fit to the</page><page sequence="19">The Broader Intellectual Impact of Parallelism 85 parallel electronic circuitry itself. Thus, fifty years after the first electronic computers were fabricated, their potential to reshape us may be taking hold at last. It is not uncommon for the true impact of a new technology to remain veiled for a generation or two. Such was the case with the steam engine.29 Early steam engines were often relegated to a downstream role by mill owners. Their job was simply to pump water back up into the mill pond after it had passed over the water wheel. It was a role dictated not by what they were inherently good at, but rather by a seasonal bug in the way mill streams work. Only decades later did this age-old culture recognize and reorganize itself around the unique capabilities of the engines themselves. Only then did the Industrial Revolution truly take hold. The partnership between human scientist and human computer is even more ancient than the partnership between miller and mill stream. It is reasonable to assume that there will be a lag between the time when we reshape our computers and the time when they reshape us. Or maybe it is not reasonable at all. Maybe it only sounds reasonable because we are all still trained to believe that orderly, sequential processes (first this happens, then that happens) are more likely to be true. Maybe it will turn out to be more accurate to have said that "As we were reshaping our computers, so simultaneously were they reshaping us."30 Maybe when things happen in this world, they actually happen in parallel. ENDNOTES !Mark Napier, Memoirs of John Napier of Merchiston (Edinburgh: William Blackwood, 1834), 501. 2Sir David Brewster, Memoirs of the Life, Writings, and Discoveries of Isaac Newton (Edinburgh: Thomas Constable, 1855), 162. 3In early times, computers were males. By World War II, computing had become a predominandy female profession. 4Pierre Duhem, The Aim and Structure of Physical Theory (New York: Athenaeum, 1962), 171. 5Napier, 505. 6W. G. Smith, "Notes on the Special Developments of the Computing Ability," in E. M. Harsburgh, Modern Instruments and Methods of Calculation (London: G. Bell and Sons, 1915), 63.</page><page sequence="20">86 James Bailey 7Richard Sorabji, Aristotle on Memory (Providence: Brown University Press, 1972), 55. 8Duhem, 65. 9Aristotle, On the Heavens II, 11.292a 1-19. 10T. Kuhn, The Copernican Revolution (Cambridge: Harvard University Press, 1957), 87. "Dunem, 49. 12Gilbert Bliss, Mathematics for Exterior Ballistics (New York: John Wiley and Sons, 1944), 42. 13Ibid., 51-52. 14G. Galileo, Dialogues Concerning Two New Sciences (New York: Macmillan, 1914), 188-89. 15Ibid., 192. i*Ibid., 193. 17J. Fourier, The Analytical Theory of Heat (New York: Dover, 1962), 238. 18Lewis F. Richardson, Weather Prediction by Numerical Process (New York: Dover, 1965), 219. Illustration by Alf Lannerbaeck. 19H. H. Goldstine, The Computer from Pascal to von Neumann (Princeton: Princeton University Press, 1974), 72. 2&lt;&gt;Ibid., 136. 21H. H. Goldstine and J. von Neumann, "On the Principles of Large Scale Computing Machines," in Collected Works of John von Neumann, vol. 5 (New York: Pergamon, 1961-1963) 6. 22Ibid., 9. 23Samual, "Computing Bit by Bit," Proceedings of the I.R.E. (October 1953): 127. 24J. W. Cox, "Britain's First Municipal Computer," The New Scientist, 4 April 1957, 30. 25E. Mach, Popular Scientific Lectures, Chicago, Open Court, 1898, 191. 26S. Langer, Philosophy in a New Key (New York: New American Library, 1951), 76. 27Ibid., 86. 28M. Browne, "Lively Computer Creation Blurs Definition of Life," New York Times, 27 August 1991. 29R. J. Forbes, The Conquest of Nature (New York: Mentor, 1968), 46. 30M. Bailey, personal communication.</page></plain_text>
<plain_text><page sequence="1">Lang Resources &amp; Evaluation (2007) 41:341-365 DOI 10.1007/s 10579-007-9051-7 A case study of gesture expressivity breaks Nicolas Ech Chafai Catherine Pelachaud Danielle Pele Published online: 22 February 2008 a Springer Science+Business Media B.V. 2008 Abstract In this paper we propose a study of co-verbal gesture expressivity during a conversational interaction. The work is based on the analysis of gesture expres- sivity over time, that we have conducted on two clips of 2D animations. The first results point out two types of modulations in gesture expressivity that we relate to the rhetorical functions of the discourse. These results extend the knowledge about gesture expressivity from emotion and personality issues to pragmatical ones. An evaluation study is proposed to measure the effects of the modulations. Keywords Gesture expressivity a Cartoon animation a Annotation schema for gestures 1 Introduction Since the 1990s a new type of Human-Computer interaction has grown through the emergence of a new medium between a user and her machine: Embodied Conversational Agents (ECAs). Several ECAs have been developed (Pelachaud 2005; Kopp et al. 2002; Cassell et al. 1999) aiming at giving autonomy and interactivity when a user converses with these agents. N. E. Chafai (nc) a C. Pelachaud Universit6 of Paris 8, Montreuil, France e-mail: n.chafai @iut.univ-paris8.fr C. Pelachaud e-mail: pelachaud@iut.univ-paris8.fr N. E. Chafai a D. Pele France Tel~com R&amp;D, Paris, France D. Pele e-mail: danielle.pele@francetelecom.com Springer</page><page sequence="2">342 N. E. Chafai et al. Since Alice (see http://www.alicebot.org/), computer systems have been able to talk with human beings through a textual mode. Chatterbot systems are often implemented as pattern matching models. Recently, language processing models have evolved yielding other models for natural language processing, and at the same time, the degree of realism of conversational interfaces has risen to exhibit agents endowed with a body. The latter ones are able to maintain a "natural" conversa- tional interaction with a user using the same modalities that people use when conversing with humans. These ECAs allow a high degree of presence of the conversational partner, suggesting that a user may interact with them in a natural way. This sensation of presence requires the endowment of embodied agents with the same capabilities of human beings, especially the communicative features. People communicate with each other through a verbal channel (speech), non-verbal channels (voice, facial expressions, head movements, gaze, gestures, posture) and through the interaction of each of these modalities. Agents, therefore, should communicate with us using these same capabilities. During a conversational interaction, the communication is multimodal: the whole body is used for communicating the speaker's intention. Some of the ways we behave and communicate information is linked to the syntactic structure of the discourse; to the semantic content of the signs we send to the interlocutor; to our personality; to the social relations we share between participants of the conversa- tional interactions; to the emotions we feel during an interaction turn; etc. Raising the eyebrows may be a cue to show surprise. More generally, facial expressions are a good are good indicators of emotional content. We may describe the shape of an object using appropriate gestures able to represent, but not limited to, the physical properties through iconic links between such an object and its representation: the gaze is efficient to regulate speaking turns during conversational interaction and so on. Going further to synthesize an anthropomorphic agent, the question that arises is to whether we have to endow this agent with perfectly realistic behavior in the same way that a human would produce if she replaces the agent? Or, do we endow this agent with a specific behavior that might not be realistic but is highly expressive? Since the agents have a head, a face, a gaze, two arms, etc., a user expects the agent to behave like a human, but since the agents are computer objects and are artificially animated, they might use the full potential of computer systems to produce an attractive and efficient communicative behavior indepen- dent of realism. The agents we developed do not aim at a prefect imitation of realistic humans, but aim at the representation of the ways they behave, to animate communicative and expressive agents (Hartman et al. 2005; Poggi and Pelachaud 2000). The methodology we propose in this paper is part of such objectives, looking for the definition of efficient principles to render a communicative and expressive agent, with no consideration about whether these principles are realistic or not. This methodology is based on two clips of traditional 2D animations, trying to take into account the animators' abilities to render communicative and attractive characters through the way they animate them. Springer</page><page sequence="3">A case study of gesture expressivity breaks 343 2 Background In this section, we first present what the history of the animation teaches us in the context of our study, that is, the animation of (virtual) characters. This area encompasses the 3D animation, since our agents evolves in a 3D environment, but also the cartoon-like animation since the principles of traditional animation the animators have established are still a great source of knowledge in both areas. Second, we present which are the main topics in the study of communicative gestures, trying to endow our agents with gestures that would be expressive and communicative during a conversation interaction. 2.1 Animation techniques We can state that the world of the animation has begin in the 1920s right after the first decades of creating "moving drawings", with the production of cartoons that would be attractive and appealing. A cartoon is made of successive drawings projected at the rate of 24 fps, we cannot summarize the art of animation to the ability of producing attractive and appealing drawings. As many teachers say to their new students in animation: "You know how to draw. Now, you can learn how to animate." The reality is that if at the beginning of the 20th century people did know how to draw, they still had not found how to animate (or they did not realize that they were not animating but giving movement to static drawings). One of the first to really look for producing animations as such was certainly Walt Disney and his scientific process of experimentations, building a necessary background to establish the basis and the rules of animation. In 1981, Thomas and Johnston-two formers animators of Disney-have published all their experiences in a book that expose their fundamental principles of animation: timing (the speed at which something moves), slow in or slow out (the dynamic between two key positions), anticipation (the action of an object is decomposed into three phases: the setup for the motion, the actual action, and the follow through of the action), exaggeration (the exaggeration of motions, poses, proportions, etc., gives more life if used carefully), squash and stretch (the way an object is deformed due to its movement, see Illustration 1), staging (an action should be presented so that it is easily understood), and some others (Thomas and Johnston 1981). Being more interested in the end result than in being a perfect replica of human body movement, some of the rules are not biologically realistic. But when applied to animations, they create a given effect to be perceived by the spectator. This effect can be achieved by emphasizing the emotional feature of a character, the body deformation due to a movement, etc., (see Illustration 1) provided these animations be coherent (e.g. the whole mass of a character is conserved even when this character is deformed to the extreme). We can summarize the needs required by a cartoon as: the art of cinematography (to give the cartoon a story, exposed as a succession of plans organized in a specific way, etc.); the art of drawings (which aspect the cartoon looks like); and the art of Springer</page><page sequence="4">344 N. E. Chafai et al. Illustration 1 Squash and stretch, John Lemmon Films S I C animation (that is, how to give life to animated characters). Without one of these, we would still have a cartoon, but a cartoon that does not reach its full potential. Some previous works have already tried to produce 3D animations based on traditional animation. Several fundamental principles of traditional animation (Thomas and Johnston 1981) have been applied to 3D animation. Choi et al. (2004) proposed a system able to computationally apply the principle of anticipation on a 3D animation. When humans produce a movement, they usually prepare it by performing a little retraction in a direction opposite to the move they want to produce. For instance when they throw a ball far away, humans retract their arm as far as they need to reach a certain target. As Choi et al. (2004) notice: "most humans actions involve anticipation, since most people think of an action before doing it, and they get the energy for the action from the anticipation. In general, the bigger the motion, the bigger anticipation". The animators use the principle of anticipation for a third reason: since it attracts the gaze of the spectator, this principle ensures the animator that the spectators will always follow the main action of a cartoon at a certain instant of time. Indeed, one of the rules of animation is that an animation should suggest the action to the spectator in a way that is inevitably clear. The principle of anticipation follows this principle. Lance et al. (2004) studied animators' abilities to express emotion and empathy in cartoon characters and build up a system able to generate expressive gazes for virtual characters. Rather than studying human beings in interaction, they explicitly made the choice of (3D) animations since in animations the behavior of a character is intended to be communicative and to elicit empathy. In another area of application, Bregler et al. (2002) captured the animations of 2D objects (deformable or not) by following some feature points. This result allows one to animate different kinds of 2D or even 3D objects in the same way. Not only the movement is produced identically, but it also preserves the same expressivity. But these works do not resolve the question of whether imitating 2D animations in a 3D animation is perceptually acceptable or not by a spectator. Lasseter (1987) pointed out how the principles from 2D animation could be applied successfully to 3D animation; however, the perception that the spectator has can change if we limit 3D animation to 2D imitation and if we do not look at finding the extent to which the 2D animation principles can be interpreted. In our work, we try to find some new rules of 2D animation that could be applied in a gestural animation of 3D characters, and evaluate the results on a conversational agent to test whether Springer</page><page sequence="5">A case study of gesture expressivity breaks 345 this result coming from 2D animation is consistent with the 3D ('realistic') animation of an ECA. In the domain of the ECAs, the agents do not follow free deformation as cartoon characters usually do. We aim at studying if the application of cartoon-like animation techniques can be used for the animation of an ECA. That is, we are more interested in the effect of the animation than in the realistic reproduction of human movement. 2.2 Communicative gestures While communicating humans gesture a lot with their hands and arms. These movements can be categorized based on their relation they have with the discourse (Mcneill 1992): - Iconic: they are gestures that describe a property of a spoken object, or an aspect of an action or event the speaker is talking on. For instance, the circle we draw in space when we speak about a ball. - Metaphoric: they are close to iconic gestures, except that metaphorics depict an abstract idea. For instance, we balance our two hands slowly up and down when we hesitate "Oh, I don't know ... " with a metaphoric link with a balance. - Cohesive: they are gestures that provide continuity and cohesion in the speech. We connect different parts of a discourse with the repetition of a same gesture form, that build a cohesion in the discourse. - Deictic: they are gestures that point to an object or a person of the environment (concrete deictics), or that locate in the space a concept, an object or a person that is not present (abstract deictics). - Beats: they are gestures that accompany the flow of the speech with a repetitive movement. As Cassell and McNeill (1991) say: "The typical beat is a simple flick of the hand or fingers up and down or back and forth; the movement is short and quick", and punctuates the discourse. Gestures can also be differentiated depending on the speaker's mental state (Poggi 2001): - whether they are co-verbal or autonomous (relationship to other signals); - whether they are ideative or codified (cognitive construction); - whether we can infer an iconic link between the gesture's meaning and its representation (gesture-meaning relationship); - whether the gestures refer to information in the world, on the speaker's mind, or the speaker's identity (semantic content); - whether the goal of the gestures is individual, biological or social; - whether the gestures are conscious, unconscious or tacit (level of awareness- Poggi 2001). These classifications highlight the variety of gesture types, considering their relation to speech or their relation to the speaker's state of mind, etc. Several studies have been conducted to determine the most communicative or relevant parameters Springer</page><page sequence="6">346 N. E. Chafai et al. of gestures. Eye tracking techniques allow researchers to follow where and when a listener gazes and in particular on which gestures he gazes. This type of disposition was adopted by Gullberg and Holmqvist (1999) to study which elements lead to look at a particular gesture. They found that gestures are more often fixated if they are performed in the vertical periphery rather than centrally performed: the gestures that are produced with a large extent attracts more the attention than gestures produced in front of the speaker's body, and especially if they are also concrete deictic gestures (the speaker points to an object of her environment). They also found that the listeners tend to fixate the gestures that the speaker fixates: if the speaker fixates her gesture, she communicates to the listener that her gesture is relevant and that the listener should look at it. With the same kind of disposal, Barrier et al. (2005) have determined that through the use of deictic signals, a speaker is able to redirect the listener's focal attention toward her gestures or toward a virtual space built by her gesture (abstract deictic). This result confirms the potential of deictic gestures to attract and direct the listener's attention, and complements it by specifying the active role of abstract deictic gestures. In cartoons (Thomas and Johnston op. cit.) noticed the efficiency of an animation that could be understood from its silhouette. This observation complements results from Gullberg and Holmqvist by adding the notion of point of view: the same body gesture can change silhouette type depending on from where we are looking at it. Thus, a same gesture might not have the same ability to attract the attention. Figure 5 shows two identical gestures seen from different points of views. Only the first one makes explicit the spatial expansion of the gesture, and thus has more capacity to attract the attention. On the other hand, if gesture type, gesture position or the speaker's behavior have an impact on the listener's fixation on gestures, we are interested in the role of gesture expressivity to elicit the listener's attention and interest, that is, which are the gestures the speaker aims to be communicative. Indeed, gestures can be produced with different expressivity: with more strength (power), with more smoothness (fluidity), larger in space (spatial expansion), etc. Our work aims at determining new criteria that could attract spectator's gaze attention and increase her interest through gesture expressivity properties and at implementing these criteria in an ECA. 3 Methodology Being interested in gesture expressivity, we looked at how traditional cartoons used it in the animation of characters. We aim to enhance the animation of an ECA by taking into account the capabilities of traditional 2D animators to attract and maintain the attention of the spectators and to enhance the communicative value of a character through the way it is animated. As a first step, we have selected a small number of traditional 2D animations (Sect. 4). Having defined an annotation schema (Sect. 5), we have segmented these videos at the gesture phrase level and have annotated the gesture expressivity at this level of segmentation. A case analysis of the annotated videos have led us to identifying some patterns of gesture expressivity modulations (Sect. 6) that could constitute some rules to enhance the pragmatic value of a discourse (Sect. 7). To run Springer</page><page sequence="7">A case study of gesture expressivity breaks 347 Arnotation scherna 2 corpis E Annotation Rules , Evaluations gesitfes ~.4th gestures modulateans o extpressivty C) 'a~7 ECsj animaions Fig. 1 Methodology of the study an evaluation study of these rules (Sect. 9), an animation is rendered from a representation language (APML-de Carolis et al. 2004) that allows the synchro- nization of speech and gestures in an ECA system called Greta (Pelachaud 2005). Finally, the results of the evaluation serve as basis for better understanding of the rules we describe and of their pragmatic value. The general view of our methodology is given (Fig. 1). 4 Data of the study Our data consists of two videos from Tex Avery cartoons (MGM). These cartoons fit particularly well with our objectives since their representation of behaviors are highly expressive, sometimes through a highly exaggerated animation of the characters. This fits our aim as we are looking for principles of ECA animation that are expressive and communicative without regard to its realism, provided that it is coherent with the context of the animation. In other words, we are looking for efficiency or relevancy of the behavior. Each of these videos lasts about 10 s. Our choice of low level analysis (as described later, we segment the gestures at the level of gesture phrases) leads to a corpus with few videos. With regard to our aim to animate conversational agents, we choose sequences showing a conversational interaction between characters. The first one serves as a basis for our analysis. The second has been used to verify the results from the first one. One of these videos comes from the cartoon Blitz Wolf (1942) (Fig. 2). It displays a pig character trying to convince two other pigs to protect themselves against a wolf's threat.' The other video comes from Henpecked 1 Produced in the middle of World War II, this cartoon is a short propaganda film. The animators are displaying the Big Bad Wolf with A. Hitler's features and are warning how dangerous he is. The main pig represents the judgment value of the American state. Animators are using this pig to display to the American people what kind of behavior they have to adopt towards WWII. That is, they have to support the war effort. The title of Blitz Wolf directly refers to the "Blitz Krieg" practiced by Hitler. Springer</page><page sequence="8">348 N.E. Chafai et al. Fig. 2 Blitz Wolf (1942) Fig. 3 Henpecked Hoboes (1946) Hoboes (1946) (Fig. 3). In this cartoon, the two main characters are George and Junior2 who are trying to catch a hen to feed themselves. In the sequence that we are using, George explains to Junior the set of actions they will have to perform to reach their goal. These two sequences exhibit two different discourse goals. In the first one the pig aims to incite and advise. In the second one, George aims to communicate 2 Refers to George and Lennie, characters from J. Steinbeck's novel "Of Mice and Men" (1937). Springer</page><page sequence="9">A case study of gesture expressivity breaks 349 information. We chose two different discourse strategies because we are looking for rules that could be applied to any type of such strategies. In these animation sequences, the characters produce a high number of gestures in a small amount of time: 27 gesture strokes are produced (15 in the first video, 12 in the other one, thus an amount of 106 gesture strokes per second) organized in nine gesture units, and that represent a total amount of 127 gesture phases (74 for the first video, 53 for the other one, a mean of five phases per second). Thus, the data we collect is sufficient to allow a case analysis. 5 Annotation schema We now describe the general notions that define the annotation schema we use. The first section describes the low-level segmentation of gestures. The second section defines the different gesture expressivity parameters we annotate using the three- degree scaling justified in the last section. Finally, we give an example of our general annotation schema (Fig. 4) using the Anvil tool (Kipp 2004). 5.1 Gesture phases To get precise data on the modulations of gesture expressivity, we annotate expressivity at the gesture phase level. Kendon defines gesture unit, gesture phrase and gesture phrase as three different levels in gesture production (2004, chap. 7). - A gesture unit refers to "the entire excursion, from the moment the articulators begin to depart from a position of relaxation until the moment when they finally return to one". Power control U C, 0S, 0, m 0: Nr 32 5 30 27 a5 25 22.5 20 17 5 22 5 75 5 2.5 SPwsra%1 Frame Fig. 4 Overshoot of a movement (blue), and high tension in a hand movement (red) (Hartmann et al. op. cit.) Springer</page><page sequence="10">350 N.E. Chafai et al. - A gesture phrase is usually what we intend to mean when we use the term gesture: the production of one consistent movement of the hand and/or the arm that is meaningful. - Within a gesture phrase, we distinguish some gesture phases that comprise the whole gesture. To produce a gesture, we usually prepare it, then we produce the meaningful part of it (the stroke), and then we may hold the stroke before retracting it or beginning a new one. We describe these phases in more detail. Thus, there are different kinds of gesture phase. Kendon organizes them around the phase of stroke recognized as the expressive part of the gesture: preparation, stroke, post-stroke-hold and recovery. Kita et al. (19)97) refine these phases and distinguish: preparation, stroke, hold and independent hold, retraction and partial retraction. In our analysis, we are using most of the phases described by Kita et al. For sake of simplicity we consider 'independent hold' as having the same function as 'hold' and no distinction in both terminologies is made. We add the phase of anticipation: it refers directly to one of the fundamental principles of animation as described in Thomas and Johnston (1981). From our point of view, it seems necessary to add this phase in the analysis. Thus we consider the following set of gesture phases (Kita et al. op. cit.; Kendon op. cit.; Kipp 2004): - Anticipation: preceding a gesture phase, the arm may produce a backward movement. This happens due to motor constraints, but also to get spectator's attention to focus on the following movement. - Preparation: the arm moves to the location where the speaker wants to produce his stroke. - Stroke: expressive phase of gesture. It is produced synchronously or anticipates the verbal referent. - Hold: the stroke may be held for a while. - Recoil: following the stroke, the arm may recoil to emphasize this stroke. - Retraction: the arm moves to a rest position. - Partial retraction: before the arm finishes moving to a rest position, another gesture starts and thus ends up the retraction. 5.2 Gesture expressivity The expressivity parameters we chose for our annotation are those implemented by Hartmann et al. (2005) in their conversational agent, Greta. These correspond to: fluidity, the smoothness and continuity of the overall movement (e.g., smooth, graceful versus sudden, jerky); power, the dynamic properties of the movement (e.g., weak/relaxed vs. strong/tense); spatial extend, the amplitude of movements (e.g., the amount of space taken up by the body); repetitivity, the tendency to rhythmic repeats of specific movements along specific modalities. To enhance the coherence in the annotation process, we define these parameters with a set of criteria from Hartmann et al. (2005): Springer</page><page sequence="11">A case study of gesture expressivity breaks 351 - Fluidity: a gesture is fluid when the trajectory of the movement is smooth; the consistency with the preceding gesture is ensured and when there is no retraction phase between gestures. We adapt this definition in our annotation of gesture phases. The notion of smooth trajectory is preserved. We evaluate the consistency of keeping, between succeeding phases, the same velocity and direction of movement. This latter definition allows a low level kinematical evaluation of the fluidity parameter following the continuity parameters described in Kochanek and Bartels (1984). The last part of the gesture definition for fluidity is set to a high value if the annotated phase is produced following an anticipation of this phase. In the two videos, we collect 39 phases produced with a high fluidity, 12 produced with a medium fluidity, and 25 produced with a low fluidity (four phases are not determined).3 - Power: stands for the acceleration of the arm; or even the continuity in tension at the end of the movement. Power is also annotated when the gesture phase is produced with a fist hand which suggests tension in the arm. There is power, also, when the phase ends with high velocity. This definition does not differentiate the velocity or acceleration to the extent that the little segmentation we perform does now permit their distinction. Power exists when the gesture phase ends strongly while there is low power if the hand overshoots at the end of the movement. The overshoot phenomena is when the hand runs over the position of stroke when the character does not maintain tension during the end of her movement. Figure 4 shows a view of such an overshoot. In the two videos, we collect 20 phases produced with a high power, 26 produced with a medium power, and 33 produced with a low power (one phase is not determined). - Spatial expansion: Hartmann et al. (op. cit.) have distinguished two criteria to define the spatial expansion parameter we use in our annotation. The first corresponds to the gesture space defined in Mcneill (1992) and the second corresponds to the angle of the swivel that reflects the opening of the arms. If these two criteria match the absolute spatial expansion of a particular gesture, they are not sufficient to describe its relative value, considering the way it is perceived by the user (or spectator in our case). If an animated character produces a gesture using a large gesture space and is seen from the side, the feeling of a large spatial expansion would be highly reduced. Thus we add the notion of point of view to the criteria we use during the annotation process. This notion considers the angle from which the user sees an animated character (front view or side view) and combines with other criteria (gesture space, swivel angle) to define the higher notion of silhouette (Thomas and Johnston op. cit.). During our study, the spatial expansion and the silhouette represent the same notion. We give a view of silhouette in Fig. 5. In the two videos, we collect 26 phases produced with a high spatial expansion, 27 produced with a medium one, and 27 produced with a low one. 3 Thus, 80 gesture phases are annotated. This total differs from the previous amount of gesture phases we have segmented (127, see previous section): since there is no movement in the "hold" phases, we glue the hold phases with their preceding phase. For instance, if a stroke is produced with a high power and this stroke is followed by an hold, we annotate this "stroke + hold" with a high power. Springer</page><page sequence="12">352 N.E. Chafai et al. Fig. 5 Greta, an ECA seen from different points of view, showing different silhouettes with a same gesture - Repetitivity: the repetition rate of the gesture stroke. Usually it corresponds to beats; thus this parameter is annotated at a phrase level. In the two videos, we collect six gestures produced with a repetitive stroke. Both analyzed videos are annotated using the Anvil tool (Kipp op. cit.) which allows us to precisely assign values of the expressivity parameters for each of the gestural phases. Then, we observe and analyze the modulations in gesture expressivity. That is, we analyze the variation over time for each expressivity parameter. We are not interested in finding out which particular parameter varies. Rather, we concentrate on the variation itself of the parameters. We try to find some correlations between these modulations and the production of the corresponding gesture. In parallel, we try to find some correlation between these modulations and the structure of the verbal utterance in order to observe if there is any regularity. 5.3 Gesture quality These gesture expressivity parameters are annotated using three degrees of values (Low, Medium, High), whether a particular phase is produced with an expressivity consistent with the rest of the behavior or with more or less expressivity. We Springer</page><page sequence="13">A case study of gesture expressivity breaks 353 r9~~~~e. Fig. 6 Annotation of gesture expressivity with the Anvil tool (Kipp 2004) decided to not evaluate how much a gesture phase is produced with such expressivity to the extent that we are not running a quantitative analysis, but rather a qualitative one. We give an example of the general annotation in Fig. 6. 6 Analysis We have annotated each gesture of the two videos with the value of each expressivity parameter. When we analyze the data we do not consider the annotated value of each parameter as such, but we look at the variations over time of these values. On the one hand we try to find some kinds of correlation between these modulations and the production of the corresponding gesture. On the other hand we try to find some correlation between these modulations and the structure of the verbal utterance in order to observe if there is any regularity in the modulations. This analysis is based on one of the two annotated videos. The second is used to verify the results we obtain. Interested in the potential of the speaker's behavior to attract, regulate or maintain the listener's/spectator's attention and interest, we are studying whether the gesture expressivity is related to these capabilities in the cartoons. Our hypothesis is that a sudden variation in the expressive behavior of the character may resolve such pragmatic issues. We name these sudden variations "breaks" that we define more precisely in the following sections. 6.1 Two types of gesture expressivity breaks We found two types of modulations for each expressivity parameter: - Irregularities: They correspond to a brief period of time (a single gesture phase) in which the annotated modality has a sudden change of value from the Springer</page><page sequence="14">354 N. E. Chafai et al, 09 0. x Irregularities: in a given sequence wth a constant expressivity (one track), only one gesture phase has a different value. (a) PElfttPe Discontinuities: two successives sequences are produced with a different value of expressivity There is a discontinuity between the two sequences. (b) Fig. 7 (a and b) Breaks of irregularity and of discontinuity surrounding gesture phases, and then comes back to the original one just after this phase. For example, it happens when a character produces a powerful sequence of movements, except for a single phase that is produced with low power (Fig. 7a). Let a be one extreme value of an expressivity parameter (low or high), and / the other one. Each sequence upa admits f as an irregularity. - Discontinuities: They correspond to a sudden change in the annotated modality. For example, it happens when a character in the animation produces a sequence of movements with low power, preceding a sequence with powerful movements (Fig. 7b). That is, each time a sudden variation in gesture expressivity occurs, it is defined as a discontinuity. If this variation directly precedes another sudden variation, we will speak in terms of irregularities. Figure 7 illustrates these concepts graphically. With the same notation as for irregularities, each sequence afPP admits // as a discontinuity. Each occurrence of these two modulation types has been noticed. We find 4 irregularities and 10 discontinuities in one annotated video and 8 irregularities and 6 discontinuities in the other one. We report this data as: (4, 8) for irregularities (to be read as "4 irregularities in the first video and 8 in the second one") and (10, 6) for discontinuities. There are differences in the result quantities of the two videos. This is partly due to a difference in the quantity of gesture repetitions for each video and the structure of their utterances. Some invariance appears to inform their role in a conversational interaction in a cartoon, as described in the next sections. 6.2 A case analysis We propose a case analysis of one of the two annotated videos. The speech of the character is given as follows: Springer</page><page sequence="15">A case study of gesture expressivity breaks 355 Illustration 2 Do you [remember] # Lennie, do you remember our points? I go up to their hands, and we tri-cross this soar, and we reduce her attention. She passes me over here, and through this lock. Note it! When she comes out, you bump her. # Each sentence of the character's speech is analyzed separately. We give a picture of one gesture produced in each of these sentences. # Lennie, do you [remember] our points? # This sentence corresponds to a performative of type &lt;ask&gt;. However it also corresponds to an incitative rhetorical formulation that announces the speaker's intent to introduce some knowledge that it shares with its interlocutor. We interpret this formulation as a call for attention, for the sharing of a common discourse background. These two observations were also seen by Bouvet (2001) in another context, that of enunciation. When Bouvet analyzed the tale of a storyteller, she observed that at the beginning of the enunciation, the holding of eyebrows up highlights a consensual deixis for sharing a common discourse background while gaze direction toward the interlocutor, related to deixis, calls for attention from the listeners (p. 142) (Illustration 2). In synchrony with this sentence the character performs a repetitive gesture that provides rhythm for the enunciation (Mcneill 1992). This repetition is produced with low power and high fluidity. We observe that the anticipation phase of a new occurrence of a stroke repetition is produced with high power and low fluidity, leading to an irregularity break on these two parameters. While there are two gesture repetitions in this video, we observed that in the other video, the three occurrences of a gesture repetition are produced using irregularity breaks. We believe that these breaks help the spectator segment the beats of the repetition and thus they strengthen the rhythm of these repetitions. # I [go up] to their hands, and we [tri-cross] this soar, and [we reduce her attention]. # During this sentence and the following, the character produces fluid gestures with low power. It was already the case during the preceding sentence, and it suggests that the character aims to maintain the same relation as constructs as previously. However, some discontinuities appear in the fluidity of its gestures: the character Springer</page><page sequence="16">356 N.E. Chafai et al. Illustration 3 I [go up] produces a fluid gesture in the first gesture phrase, then a low-fluidity gesture in the second and finally a high fluidity one in the third gesture phrase. Corresponding to each new gesture phrase, these discontinuities occur at each new proposition of the sentence. At the end of the sentence, an irregularity appears. As explained in the next sentence analysis, the character produces again a fluid sequence of gestures (Illustration 3). # She passes me [over here], and [through] this lock. # If the character produces fluid gestures during this sentence and the preceding one, we observe an irregularity in the fluidity parameter between these two sentences as the character produces a partial retraction with a low fluidity. This irregularity links two sentences of the same type (to inform) and the presence of an irregularity suggests these sentences are sequentialized (Illustration 4). # [Note it ]. # In this proposition we can observe a discontinuity break in the fluidity of the gesture: the movements that compose the gesture with a high fluidity follow a sequence of movements produced with low fluidity. The character also produces this gesture with a high spatial expansion, enhanced with an appropriate perspective that creates a gesture with a high silhouette. Illustration 4 And [through] this lock Springer</page><page sequence="17">A case study of gesture expressivity breaks 357 Illustration 5 [Note it] These two observations lead to performing a gesture that has high visibility by a gesture that contrasts with the preceding movements on the fluidity parameter and with a high spatial expansion value that is able to attract the attention of the speaker on this particular gesture (Barrier et al. 2005). We believe that the visibility of this gesture serves to identify for the spectator that the speaking character has a communicative intent towards its interlocutor. Once the spectator's attention is attracted and once she has recognized this communicative intent, the animated character is ready to deliver the important information of its speech as we describe in the following sentence (Illustration 5). # When she [comes out], you [bump] her! # This sentence corresponds to what we have identified as the most important information the character is delivering. It informs the interlocutor about an action it will have to perform later on in the cartoon: to catch a hen (this sequence has comic value, since we do know that the interlocutor is simple-minded and will inevitably fail in doing so). The attention of the spectator has been elicited in the preceding sentence [Note it] through the identification of the communicative act of the speaking character. In this sentence, the latter has to ensure that its information will be correctly delivered. The first impression of the gesture produced in relation with [you bump her] is that it is produced with high energy. As for the sentence [Note it], we observe a discontinuity break in the sequence of movements. It appears on the power and expansion Illustration 6 You [bump] her! Springer</page><page sequence="18">358 N.E. Chafai et al. parameters: the character performs a gesture with high power and expansion that flows into a proposition produced with low power and low expansion. If the gesture unit is produced with high fluidity (except for [Note it] as described previously), the preparation phase of the gesture corresponding to [you bump her] has low fluidity and introduces irregularity. Thus, the two types of breaks occur on three different expressivity parameters. On the one hand, it emphasizes the segmentation of the propositions. On the other hand it contrasts with the preceding sequence of gestures to highlight the important information the speaker is delivering (Illustration 6). Although we can observe (even though it is not about the expressivity parameters but about the analysis of speech/gesture synchrony) that the gesture in relation to [you bump her] entirely precedes the corresponding speech pronunciation. Our view is that it reinforces the spectator's attention on the iconic value of the gesture: the spectator has to keep in mind the gesture since, in the following of the story, it is the expectation of this gesture that will contain the comic value. 7 Results From the analysis above, we found consistency in the functions performed by the two types of gesture expressivity breaks. These functions are described in the following several subsections. 7.1 The functions of the irregularity breaks From the annotation, we observe that irregularities seem to play a role of anticipation by linking similar elements of the enunciative structure. The elements can be the occurrences of gesture repetitions (2, 7, namely 2 gesture repetitions in the fist video and 7 gesture repetitions in the second one), performatives of the same general class (Poggi and Pelachaud 2000) (1, 1), gesture phrase (1, 1). By linking similar structures, irregularities are able to perform the role of an AND connector that allows the spectator to anticipate the behavior the character will display. Following the principle of anticipation (Thomas and Johnston 1981), this property should enhance the visibility of gesture, i.e., to increase our propensity to gaze at this particular gesture. 7.2 The functions of the discontinuity breaks We also observe that discontinuities may perform a relation of contrast. This relation may take diverse forms. It can enhance the emphasis on a specific gesture by contrasting it with other gestures (6; 1). Over a whole sequence produced with low fluidity, only a single gesture phrase (and not gesture phase since that would have led to an irregularity) has been produced with high fluidity. This results in an isolation effect of this gesture phrase. It can also contrast with the action verbs of the utterance when they are gesturally illustrated (3; 2). Each occurrence of these Springer</page><page sequence="19">A case study of gesture expressivity breaks 359 gestures is produced with a specific expressivity. Another form of discontinuity can also be noticed when the speaker enunciates a new type of general class of performative (1; 2): he changes his expressivity. These different functions of discontinuities seem to be closely linked to a relation of contrast between each of the levels they are referring to. This relation is defined as the speaker's intention that the addressee recognizes the similarities and differences of the enunciative structure (Mann and Thompson 1988). 7.3 The functions of the breaks To summarize, the functions performed by the two kinds of modulations in gesture expressivity act at different levels of the enunciative structure. They do not depend on the performative act the speaker enunciates. Modulations appear as a pragmatic tool. Irregularities can affect the spectator's attention through their anticipation properties while discontinuities perform a relation of contrast that suggests another attentional effect: as Feyereisen (1997) noticed: "communication supposes to perform contrasts. A signal is perceived with more clarity if it is distinguishable from noise or other signals" (p. 39). 8 Interpretations of the results Our study highlighted the functions of the two gesture expressivity breaks. Usually, the expressivity values are related to the emotional content of the speaker or her personality. In our work, we link expressivity modulations to the pragmatic strategy of the speaker. Looking closer at these modulations, we noticed that the irregularity breaks enhance the rhetorical relation of similarity, whereas the discontinuity breaks enhance the rhetorical relation of contrast. The generality of these assumptions leads us to a cross-study over the expressivity of the other modalities, looking to see if the two types of breaks we considered are consistent with their respective functions. In the speech domain, the paralinguistic parameters are usually related to culture, to the specifics of the language, to the emotions or to the personality. If we look at the intonational breaks, some results point to the same types of phenomena that we have introduced in our study in the domain of gesture expressivity. Some researchers observed that the ToBI breaks of type 2, which correspond to a disparity between the pitch and a sensation of disjunction in the perception of two successive words, may be perceived as a rhetorical effect of a conscientious deliberation (Beckman and Elam 1997) through the reinforcement of discourse segmentation. This observation is consistent with the enhancement of the discourse rhythm we observed, performed by the irregularity breaks in the domain of gesture expressivity. In his study, Gussenhoven (2002) describes three types of biological codes that can explain the variation of the pitch: the Frequency Code, the Effort Code and the Production Code. The Effort Code corresponds to a modulation in the energy of the signal. It derives from the speaker's intent to signal relevant information in her discourse and is usually interpreted as surprise, as a call for attention or even to Springer</page><page sequence="20">360 N. E. Chafai et al. contrast the information of the discourse (Gussenhoven op. cit.) through this variation in the signal. This observation is consistent with the function of contrast performed by the discontinuity breaks, adding a notion of the speaker's effort to signal her intent. To summarize this cross-study, we first observe a consistency in the functions of the expressivity breaks. In both domains, each type of expressivity break is related to the same function: a function of similarity for the irregularities, and a function of contrast for the discontinuities. Second, the research in the domain of paralinguistic parameters enhance our knowledge on these breaks as long as the similarity function of the irregularities serves the discourse segmentation, and the contrast function of the discontinuities derives form the speaker's effort to signal her intent. 9 Evaluation The work presented in the previous sections lead us to consider some new factors of gesture expressivity. That is, the modulations of gesture expressivity over time that define breaks. Through their synchronization properties with the different levels of discourse, these modulations could enhance a conversational animation with communicative considerations as developed previously. The results we describe have some limitations due to: - The number of annotators: two case analyses have been annotated by a single annotator. - The interpretative process of the annotations: we perform a (two) case analysis on the annotation. The amount of data is not sufficient to have a strong statistical justification. - The nature of the data used: considering the analysis is based on cartoons, and we want to animate 3D characters, we have to justify the rules we obtain will fit in the domain of 3D characters. The results have been observed in the two annotated videos and are consistent with the nature of the phenomena we analyzed: a cross-study of the phenomenon of irregularity breaks reveals their segmentation function, whereas the phenomenon of discontinuity breaks is a result of the speaker's effort to signal her intent, through a contrast function. Nevertheless, we need an evaluation step to validate the hypothesis in a 3D environment and the communicative performances of the breaks we have defined. This evaluation is processed on an ECA system (Pelachaud 2005), able to display a 3D animation of an agent from a high-level description of the multimodal behavior. In the following, we present the general procedure of the evaluation and the participants. We describe the results of the evaluation. Only the discontinuity breaks are evaluated. 9.1 Evaluation procedure For the evaluation we produce a demo lasting about 50 s of an ECA having a general presentation discourse on a network application. In this video we chose Springer</page><page sequence="21">A case study of gesture expressivity breaks 361 three gestures on which we apply a discontinuity or not. We call these gestures "key gestures" (KG) which we refer to as: KG A, KG B, KG C. The length of the video has been selected due to the type of phenomena we want to evaluate (that is, contrasting some part of a discourse) and the user task we want to perform, as presented below. In this demo, some discontinuity breaks have been added in the animation of the ECA. Sperber and Wilson (1986) define the communication as the interlocutor's ability to recognize the speaker's intention to share/convey information. That is, during the perception of an enunciative discourse, the interlocutor not only records this discourse as a sequence of information, but he recognizes this information as the speaker's willingness to express her intentions. In our experiment, we deal with two types of tests. In the first one called the intention test, the user task is to identify which utterance from the enunciative discourse represents the main intention of the speaker. For each user test, we "enhance" one proposition of the textual discourse with some discontinuity breaks. That is, we add discontinuity breaks in one of the expressivity parameters values (here, spatial extend). After viewing the application, participants were asked what was the message the agent was trying to convey, to test whether users identified the main intention of the speaker as the proposition on which we applied the discontinuity breaks. A list of possible answers is proposed to the user to overcome memorization bias. Five videos are used: in three videos a discontinuity break appears on one of three key gestures of the interaction, on another video two discontinuity breaks for these three ones are used and on the fifth video there is no discontinuity break at all. Our hypothesis is that the presence of a discontinuity break attracts the attention of the subjects on the part of the discourse the break enhances or contrasts. We expect users to better remember the information of the sentences told with a gesture expressivity discontinuity. The pragmatic value of the discontinuity break is measured from this test. We conducted, also a more general test called the preference test. In this test, we want to measure whether the participants prefer a demo with or without discontinuity breaks. That is, if we want these breaks to help our animation system for an ECA to be communicative, these breaks should not decrease the appealing of the animation. In this test, the user's task is to evaluate her preference between a demo with or without discontinuity. Thus, two videos are presented to users. These videos last about 15 s. The same demos, as used previously, have been cut out for this task to reduce the amount of contextual effects. Half of the participants run this task once; the other half runs this task three times to test the consistency of their choices. They were asked to answer which was their preferred video between the two that were presented to them. 9.2 Participants The evaluation has been run on a panel of subjects. Twenty-eight students from a French university have performed the evaluation. They are between 18- and Springer</page><page sequence="22">362 N. E. Chafai et al. 20-year-old and have some knowledge of computer science, but no clue about the evaluation subject. They were told that they have to evaluate an interface. 9.3 Results We presented one of the five videos to the participants to measure the pragmatic value of the discontinuity breaks during the test called Intention. The videos, which last about 50 s, are the following: - Without any discontinuity: there is no modulation of the gesture expressivity in the videos. - With two discontinuities: there is a discontinuity on the key gesture A and on the key gesture C. - Discontinuity KG A: there is one discontinuity on the key gesture A. - Discontinuity KG B: there is one discontinuity on the key gesture B. - Discontinuity KG C: there is one discontinuity on the key gesture C. Table 1 shows the distribution of the participants' choices for the Intention test. We presented a video with discontinuity and one without a discontinuity during the preference test. The video we used during the Intention test has been divided in three parts: A, B, and C that correspond to the three key gestures A, B and C. Table 2 gives the partition of the participants' preferences for the Preference test. As we can notice from Table 1: users mainly selected choice A, except for the videos with a discontinuity break on KG B or on KG C, in which the selection is partly choice B, and choice C. Results from Table 2 show that users equally selected the videos with a discontinuity and without a discontinuity break. These results are discussed in the next section. 9.4 Evaluation discussion On the intention task, we observe that an answer (choice A) is the most chosen; this choice is made independently of the presence of discontinuity or not. This answer corresponds to the proposition of the discourse that contains the most precise information when compared to the propositions of choices B and C. At the same Table 1 The Intention test # participants Choice A Choice B Choice C Without any discontinuity 6 5 0 1 With two discontinuities 6 5 1 0 Discontinuity KG A 2 2 0 0 Discontinuity KG B 9 4 5 0 Discontinuity KG C 5 3 0 2 Total 28 19 6 3 Springer</page><page sequence="23">A case study of gesture expressivity breaks 363 Table 2 The Preference test # participants With discontinuity Without discontinuity No choice Preference Step A 28 11 11 6 Step B 14 7 5 2 Step C 14 5 6 3 time, these last two choices have been re-phrased for the need of the communicative task whereas the choice A is a copy of a proposition told in the evaluated video. Thus, the choice A only needs to be recognized, and requires little cognitive load; whereas the participants need to interpret the discourse in the evaluated video before they choose B or C. This interpretation requires more cognitive load than for the choice A. This choice A tends to be naturally preferred (68%), independently of the presence or not of the breaks. Nevertheless, if choice A is widely chosen, the choices of the participants are more contrasted if they evaluate a demo with a discontinuity on the key gestures B or C (50% of the participants answered B or C when the key gesture was B or C): if a discontinuity occurs on KG B or KG C, the participants tend to identify the communicative intent resp. as choice B or C (56%; the other 44% are due to the fact that the choice A is the most chosen, as explained previously). Thus, the choice of the participants is influenced by the location of the discontinuity: this result suggests that the participants tend to identify a discourse proposition as the main intention of the agent on the basis of whether a discontinuity break occurs on the gesture produced synchronously with this proposition. On the preference task, we observe that half of the participants prefers a demo with a discontinuity break, and the other half prefers a demo without such a break. Few participants did not make any choice for the test preference. Thus, the participants answered equally that they prefer a video with or without some discontinuity breaks. Two explanations are possible: either the discontinuity breaks have a non-consistent effect on the participants or these breaks are not detected by them. Nevertheless, in a free discussion after the evaluation test, some participants reported that they had remembered the discontinuity breaks. On the other hand, the participants did not make a consistent choice in their answers for the preference task on the three videos: they have answered with or without discontinuity indifferently on the three videos. These results suggest that the discontinuity breaks have a non-consistent effect or no effect on the participants preferences, whether they detect or not these breaks. To summarize the results of the evaluation studies, we observe that the discontinuity breaks have a slight effect on the communicative potential of a discourse: the participants tend to identify the main intention of an agent partially on the basis of the presence of a discontinuity break. We also observe that these breaks have a non-consistent effect or no effect on the participants' preferences for the animation quality of the agent. Since the discontinuity breaks are a result of a study based on their communicative potential, the attractiveness of these breaks is not essential to our purpose, provided that they do not decrease this attractiveness of an animation; the results verify this point. Springer</page><page sequence="24">364 N. E. Chafai et al. We may suggest two limitations of this evaluation. First, the animations we produced for this evaluation are shaky at times since the co-articulation between gestures is not totally natural and have a synthetic look. That could disturb the participants. Second, if the choice of a rather long demo for the communicative task (50 s) is motivated by the type of phenomena we want to measure and the type of task the participants have to perform, this length might also introduce the effects of contextual variables (as the co-articulation disturbance) that we have to avoid. 10 Conclusion In this paper, we have presented a schema for the annotation of gesture expressivity at a low-level of segmentation. We annotated two videos of 2D cartoons we have analyzed at the gesture phase level. Interested in the communicative value of gestures, we looked at the modulations of gesture expressivity over time rather than at their values. This led us to introduce two notions of expressivity breaks: irregularities and discontinuities. These types of gesture expressivity breaks suggest that they act as a relation of similarity with a function of segmentation, for the irregularities, and as a relation of contrast that derives from the speaker's effort to communicate her intention, for the discontinuities. The discontinuity breaks have been evaluated on their pragmatic value, measuring the communicative intent of the ECA, suggesting that these breaks have a slight effect on this value. We have also evaluated the effect of these breaks on the preference of users. The results suggest that these breaks do not disturb the user's preference. We can conclude that the modulations act as a pragmatic resource that could profit in the animation of ECA and that could act on the interest that a spectator bears on a gesture. In the future, we plan to integrate the gesture expressivity breaks we define in an ECA to automatically apply the discontinuity but also irregularity breaks into an ECA animation. Acknowledgement This research is partially supported by the FP6 Network of Excellence HUMAINE (IST-2002-2.3.1.6). References Barrier, G., Caelen, J., &amp; Meillon, B. (2005). La visibilitd des gestes: Paramitres directionnels, intentionnalit6 du signe et attribution de pertinence. In Workshop Francophone sur les Agents Conversationnels Animeas. Grenoble, France, pp. 113-123. Beckman, M. E., &amp; Elam, G. A. (1997). Guidelines for ToBI labelling, version 3.0. The Ohio State University Research Foundation. Bouvet, D. (2001). La dimension corporelle de la parole. Paris: Peeters. Bregler, C., Loeb, L., Chuang, E., &amp; Desphande, H. (2002). Turning to masters: Motion capturing cartoons. SIGGRAPH 2002. Cassell, J. (1999). Embodied conversation: Integrating face and gesture into automatic spoken dialogue systems. In S. Luperfoy (Ed.), Spoken dialogue systems. Cambridge, MA: MIT Press. Cassell, J., &amp; McNeill, D. (1991). Gesture and the poetics of prose. Poetics Today, 12(3), 375-404. Choi, J., Kim, D., &amp; Lee, I. (2004). Anticipation for facial animation. CASA'04. Geneva, Switzerland: CGS. Springer</page><page sequence="25">A case study of gesture expressivity breaks 365 de Carolis, B., Pelachaud, C., Poggi, I., &amp; Steedman, M. (2004). APML, a mark-up language for believable behavior generation. In H. Prendinger (Ed.), Life-like characters. Tools, affective functions and applications. Springer. Feyereisen, P. (1997). La comprehension des gestes rif6rentiels. Geste, cognition et communication, PULIM, 20-48. Gullberg, M., &amp; Holmqvist, K. (1999). Keeping an eye on gestures: Visual perception of gestures in face- to-face communication. Pragmatics and Cognition, 7, 35-63. Gussenhoven, C. (2002). Intonation and interpretation: Phonetics and phonology. In Speech Prosody 2002: Proceedings of the First International Conference on Speech Prosody. Aix-en-Provence, France, pp. 47-57. Hartmann, B., Mancini, M., &amp; Pelachaud, C. (2005). Implementing expressive gesture synthesis for embodied conversational agents. In Gesture Workshop. Kendon, A. (2004). Gesture: Visible action as utterance. Cambridge University Press. Kipp, M. (2004). Gesture generation by imitation: From human behaviour to computer character animation. Boca Raton, Florida: Faculties of Natural Sciences and Technology. Kita, S., Van Gijn, I., &amp; Van der Hulst, H. (1997). Movement phases in signs and co-speech gestures, and their transcription by human coders. Gesture Workshop. Bielefeld, Germany: Springer-Verlag. Kochanek, D. H. U., &amp; Bartels, R. H. (1984). Interpolating splines with local tension, continuity, and bias control. Computer Graphics of SIGGRAPH'84, ACM. Kopp, S., &amp; Wachsmuth, I. (2002). Model-based animation of coverbal gesture. In Proceedings of Computer Animation 2002. Los Alamitos, CA: IEEE Press, pp. 252-257. Lance, B., Marsella, S., &amp; Koizumi, D. (2004). Towards expressive gaze manner in embodied virtual agents. New York: AAMAS Workshop on Empathic Agents. Lasseter, J. (1987). Principles of traditional animation applied to 3D computer animation. ACM Computer Graphics, 21, 4. Mann, W., &amp; Thompson, S. (1988). Rhetorical structure theory. Toward a functional theory of text organization. Text, 8(3), 243-281. Mcneill, M. (1992). Hand and mind: What gestures reveal about thought. Chicago and London: University of Chicago Press. Pelachaud, C. (2005). Multimodal expressive embodied conversational agent. Singapore: ACM Multimedia, Brave New Topics Session. Poggi, I. (2001). From a typology of gestures to a procedure for gesture production. In Gesture Workshop (pp. 158-168). Springer Verlag. Poggi, I., &amp; Pelachaud, C. (2000). Performative facial expressions in animated faces. In J. Cassell, S. Prevost, &amp; E. Churchill (Eds.), Embodied conversational agents (pp. 155-188). Cambridge, Mass: MIT Press. Sperber, D. &amp; Wilson, D. (1986, trad: 1989). La pertinence, Communication et cognition. Paris: Editions de Minuit. Thomas, F., &amp; Johnston, O. (1981). Disney animation, the illusion of life. New York, USA: Abbeville Press. Springer</page></plain_text>
<plain_text> <page sequence="1"> DEFENSE DOSSIER ROBOTS, WAR, AND SOCIETY  CAMILLE FRANCOIS  Since 2007, the discipline of military robotics has A CHANGING DISCOURSE gained sustained and significant attention in the “Robotic warfare” is quickly becoming a politicized  public debate. There is today a growing body of term and these debates have spawned new coalitions  scholarly work devoted to the ethical implications of and civil society organizations. Coalitions of scholars  autonomy, remote warfare, and its compliance with and human rights activists, such as the International  the requirements of international humanitarian law. Committee for Robot Arms Control (ICRAC), have  formed to argue in favor of an international ban on  Roboticists such as Ronald Arkin have argued that autonomous lethal weapons.4  The Campaign to Stop  military robotics could yield new forms of conflict, more Killer Robots is a successful example of the migration  moral and more observant of international law. “[R] of this originally academic and theoretical debate in  obots not only can be better than soldiers in conducting the political sphere.5  In May 2014, for instance, the  warfare in certain circumstances, but they can also United Nations Convention on Certain Conventional  be more humane in the battlefield than humans,” he Weapons held a Geneva meeting on “Lethal Autonomous  wrote in a piece describing current research underway Weapons Systems,” bringing killer robots into an  to explore the implementation of “ethical governors” in international humanitarian concern that historically  robotic technologies.1  Other scholars have responded has addressed issues like landmines and blinding lasers. 6 that autonomous lethal weapons will never have  the agency and morality needed to comply with the It will be hard, however, to separate either the strategic  complexities of constraints on the use of force, notably or human rights considerations of robotic warfare  as far as the principles of distinction, proportionality from the popular perception of “killer robots.” Years  and the need for accountability are concerned.2 of mainstream media have popularized a dystopian  future in which robotic soldiers mow down human  To date, there are no “fully autonomous” weapons targets with brutal efficiency, commanded by a rogue  (i.e., weapons that can select and engage targets artificial intelligence (AI). Perhaps the most prominent  without human intervention) currently deployed of these is the Terminator movie franchise, the plot of  on any battlefield. But advances in engineering and which is predicated on a military defense network  software are bringing these weapons closer to reality— (“Skynet”) becoming self-aware and turning on its  and of course, the use of “semi-autonomous” and creators. That is a far-fetched scenario, yet business  remotely operated weapons is steadily increasing. and science leaders have lent credence to these fears  Works such as P.W. Singer’s Wired for War3  have in recent years. Take rocket- and electric car investor  reached a wide audience and helped popularize Elon Musk, who has tweeted, with the casual brevity  these issues, which are also entwined in the public that befits that medium, that “We need to be super  debate with unmanned aerial vehicles (UAV, careful with AI. Potentially more dangerous than  or drones) and the legality of targeted killings. nukes.”7  Fears of rogue or malevolent AIs were later  seconded by the famed physicist Stephen Hawking,  Camille François is a fellow at the Harvard Law School Berkman Center for Internet &amp; Society. She is a researcher,  consultant and lecturer on cybersecurity policy, cyberwar and robotics issues. February 2015, ISSUE 13 11 </page> <page sequence="2"> DEFENSE DOSSIER who warned in a BBC interview that developments announced its acquisition of Boston Dynamics,  in AI “could spell the end of the human race.”8 its eighth robotics company in a string of related  acquisitions. Boston Dynamics is an engineering  These statements illustrate a new turn in the wider and robotics military contractor, best known for the  debate over robotic warfare. The topic matured BigDog—a quadruped robot designed for the U.S.  politically on the international scene, and fears of military with funding from the Defense Advanced  the impact of military robotics development are Research Projects Agency and the U.S. Army. In the  now spreading to the public in a more structured months preceding this move, Google had already  and articulate way than previously observed. When started this trend by hiring several key figures out of  reality catches up with our science fiction dreams DARPA, including former Director Regina Dugan  and nightmares, the evolution of military robotics and hacker/innovator Peiter “Mudge” Zatko. Then,  technology—and the legal and ethical framework in January 2014, Google announced a $650 million  within which it takes place—gains renewed interest. acquisition of DeepMind, a company specializing in  This is the ideal time to engage stakeholders across strong Artificial General Intelligence (AGI). As part  society to difficult, ambiguous questions surrounding of the acquisition, DeepMind set a condition that  the very real developments in robotic warfare. Google form an AI ethics committee to determine  how its technology may and may not be used. A QUICKENING PACE As new technologies such as robotics come to challenge  our legal, policy and ethical frameworks, a strong  dialogue between the military and other institutions If Google and the broader private sector  will be essential. Norms and rules created in one domain now drives a significant part of the robotics  will inevitably come to affect the others, especially search — including military components  when it comes to new technologies, which themselves — we can expect robots to deploy faster  circulate between military and civilian use to create in society, both in markets and on the  a “feedback loop.” Many modern technologies have battlefield. stemmed from military research; the most common  examples include the Internet, GPS and microwaves.  Civilian technology also serves military purposes,  and in the robotics industry it is very much the case Google certainly won’t turn into “Skynet” and soon  that civilian innovation feeds into the military realm. begin building Terminator robots. But these moves  aren’t without consequences either. One should, for  Take iRobot, a company founded in 1990 by instance, expect that when leading military robotics  three M.I.T. computer scientists. It produces research is transferred from military research agencies  both the popular plate-shaped vacuum cleaning such as DARPA to Silicon Valley tech giants such  “Roomba” robot and the military PackBot multi- as Google, the timeline in which research translates  mission robot notably used in Iraq and Afghanistan into deployment in markets will shorten. Google has  for improvised explosive device identification a history and reputation of moving forward quickly  and disposal. On iRobot’s website, products are in testing and deploying its innovations (such as self  showcased in different tables entitled “for the home,” driving cars), whereas military research agencies tend  “for business” and “for defense and security.”9 to be more careful and circumspect, or at least to target  deployment on the battlefield rather than in all realms  Civilian robotics companies have often walked this of society (circulation of technology to law enforcement  line, but many were stunned in late 2013 when Google forces being a noted and controversial exception  12 February 2015,  ISSUE 13 </page> <page sequence="3"> DEFENSE DOSSIER here). DARPA’s mission, since its establishment in debate has mainly concerned itself with autonomous  1958 after the “surprise” launch of Sputnik, revolves systems. Yet autonomy, too, is a complicated concept  around preventing technological surprises to the U.S. to define. Going back to Bekey’s definition: “Fully  But as robotics research moves into the private sector, remote or teleoperated machines would not count  the incentives are different. In short, if Google and as autonomous, since they fully depend on external  the broader private sector now drives a significant part control; they cannot ‘think’ and, therefore, cannot act  of the robotics research—including in its military for themselves.”11  Should our moral and legal norms,  components—we can expect robots to deploy faster then, focus on certain characteristics of a robot that  in society, both in markets and on the battlefield. would make it undesirable and dangerous in and of  itself (akin to weapons prohibited by international  DEFINITIONS AND PARADOXES law that are considered malum in se)? Or should  As the space between civilian and military robotics they instead rest on specific uses of said robots?  shrinks, some of the common issues will be discussed  in their broader societal context, which will surely In more mainstream terms: what makes a good robot,  make for a more productive and comprehensive and a bad robot? Is any robot equipped with high  conversation on key legal and ethical topics. Some autonomy and strong AI a bad robot? Are autonomous  elements, though, are likely to hamper productive robots bad if used in offense and good if used for defensive  conversations both within each realm (civilian and purposes? Much of the drone debate, for example,  military) and across them both. One of note is the focuses on the lethal autonomous uses of the robots.  lack of clear definition for “robots” or “robotics.” Military robotics also has plenty of non-lethal (and  “Robotic warfare” evokes the entangled concerns of therefore more popular) robots assigned to protecting  cyber warfare, automation and human rights (to name and “caring” for troops, such as the Battlefield- just a few).  In fact, we may say that “robot” is actually Extraction-Assist Robot (BEAR), tasked with  a helpful abstraction—and that “robotic warfare” extracting wounded soldiers from the battlefield with  is a convenient amalgamation of several different no risk to human life, or the BigDog robot which  technologies and trends compressed into a single concept. can walk alongside service members and serve as a  robotic pack mule when terrain is too difficult for  This begins with a lack of consistent terms of conventional vehicles. Such robots are often assigned  reference. Roboticists themselves are still struggling to “3D jobs” (i.e, Dull, Dirty &amp; Dangerous jobs).  to set a definition. George Bekey’s work on defining  the contours of a robot provides a good foundation Besides defining which robots we are talking about,  in this regard. He writes: “In its most basic sense, we there are concerns about how we talk about robots.  define ‘robot’ as a machine, situated in the world, that Specifically, roboticists have noted that the trend of  senses, thinks and act.”10  The rapid pace of robotics anthropomorphizing robots (which is truly a trend  innovation and the evolution of robotics forms in both language and design) is counter-productive  (from biomimicry to human enhancements) make and even dangerous for thinking through legal, moral  the definitional exercise quite a challenging one. As and policy issues in military robotics. Noel Sharkey,  such, definitions continue to rest on unsatisfactory, Professor of Artificial Intelligence at Sheffield University,  essential descriptions of “machines of our creation.” explains that “[t]he myth of AI makes it acceptable,  and even customary, to describe robots with an  Beyond “what’s a robot,” there also questions on anthropomorphic narrative.”12  Sharkey refers to Drew  “which robots are we concerned with” and “how do we McDermott’s influential essay Artificial Intelligence  talk about robots and robotics”? As mentioned, public Meets Natural Stupidity13 and to the use of “wishful  mnemonics” in the field of artificial intelligence, such  February 2015, ISSUE 13 13 </page> <page sequence="4"> DEFENSE DOSSIER as researching using words like understand to describe  aspects of their programs. This leads us to mistakenly  evaluate what robots can and cannot truly do. Simply put,  if you call your robot “John Trooper” rather than “BBK- Military robotics will certainly not be  85,” you will surely be more inclined to think robots contained on the battlefield, both because  could eventually act in a moral, legal and responsible way. robotic warfare is likely to extend the very  idea of a ‘battlefield’ and because of technology  Another factor that will take more importance as the transfers with society. military robotics debate goes mainstream is the strategic  paradox of the unintended consequences of robotic  warfare. Robotic warfare’s appeal is to distance troops  from their target, making America’s service members safer. These questions will need to be placed within the larger context  Yet concerns have arisen that robotic warfare’s unintended of the evolving nature of battlefield in the age of asymmetric  result is to bring the battlefield closer to, or even into, warfare and terrorism, and how new technologies force  the homeland. U.S. Army Lieutenant Colonel Douglas A. us to re-think the role of the military in securing society. Pryer’s article in the Military Review on “why increasingly  ‘perfect’ weapons help perpetuate our wars and endanger Military robotics, as a technology, will also easily find  our nations” develops some key psychological and strategic its way into society, both via dual-use technologies and  reasons about why the rise of robotics doesn’t necessarily through the use of the military robots for domestic security  contribute to a safer homeland.14  His piece insists on missions (such as immigration control and border patrols,  for instance). In short, military robotics will certainly not  be contained on the battlefield, both because robotic  Robotic warfare’s appeal is to distance troops warfare is likely to extend the very idea of a ‘battlefield’  from their target making America’s service and because of technology transfers with society. 16  member’s safer. Yet concerns ahve arisen  that robotic warfare’s unintended result is to HARD QUESTIONS In the meantime, at home, parallel questions of robot  bring the battlefield closer to, or even into, the ethics, accountability and liability take on great urgency  homeland. as automation progresses and as robots spread into all  areas of society. The year 2014 ended with a quite odd  event, when Swiss artists deployed a bot programmed to  randomly spend units of the virtual currency Bitcoin which  robotic warfare yielding strong moral reprobation within returned with ecstasy pills and a fake Hungarian passport.  civilian populations abroad, dangerously fueling anti- In response, Ryan Calo, an expert in robotics-and-the-law  American sentiment and raising domestic threat levels. issues, penned an opinion piece for Forbes smartly titled:  Others, such as Arizona State University’s Braden Allenby, “A Robot Just Committed a Crime. Now What?”17  That is  have worried that robotic warfare could expand the range a question that the military has had on its desk for a little  of legitimate military targets out of the battlefield and into while now. But it only just arrived in Swiss art galleries.  the homeland—to include, for instance, drone operators   in Nevada, outside their hours of operation and into their With the acceleration of both the development of  homes. “With Napoleonic-era combat, you knew where military robotics and of the pace at which it will  the battlefield was, right? With modern warfare, modern impact all fields in society, the urgency of finding  conflict, you really don’t know, where the battlefield is,” ways to engage in a productive debate about its legal  Allenby explained to reporter Manoush Zomorodi.15 and ethical impacts is great. Mapping how these  14 February 2015,  ISSUE 13 </page> <page sequence="5"> DEFENSE DOSSIER technologies will spread, understanding how they will  change society, breaking silos separating civilian and   military thinkers along with addressing the lack of clear  vocabulary to articulate these issues should be priorities. ENDNOTES 1  Ronald C. Arkin, “Ethical Robots in Warfare,” IEEE Technology  and Society Magazine, 2009. 2   Noel E. Sharkey, “The Evitability of Autonomous Robot Warfare,”  International Review of the Red Cross 94, no. 886, Summer 2012,  https://www.icrc.org/eng/assets/files/review/2012/irrc-886-sharkey. pdf.  3   Peter W. Singer, Wired for War: The Robotics Revolution and  Conflict in the 21st Century (Penguin Books, 2009).  4   International Committee for Robot Arms Control (icrac.net)  5   “2014 : A Year of Progress” Campaign to Stop Killer Robots, n.d.,  http://www.stopkillerrobots.org/2014/12/yearofprogress/.  6   CCW Expert Meeting, “Lethal Autonomous Weapon Systems:  Provisional Agenda,” n.d., 7 h t t p : / / u n o g . c h / 8 0 2 5 6 E D D 0 0 6 B 8 9 5 4 / (httpAssets)/58F0B0F7009B4407C1257CC4003382F2/$file/ ProvisionalAgenda_LAWSMX_22April.pdf.  8   Elon Musk, tweet on August 2, 2014, https://twitter.com/ elonmusk.  9   As cited in Rory Cellan-Jones, “Stephen Hawking Warns Artificial  Intelligence Could End Mankind,” BBC, December 2, 2014, http:// www.bbc.com/news/technology-30290540.  10   iRobot Corporation, www.irobot.com.  11   George A. Bekey, “Current Trends in Robotics: Technology and  Ethics,” in Patrick Lin, Keith Abney and George A. Bekey, Robot  Ethics: The Ethical and Social Implications of Robotics (Boston, MA:  MIT Press, 2011).  12   Ibid. 13   Noel Sharkey and Lucy Suchman, “Wishful Mnemonics and  Autonomous Killing Machines,” AISB Quarterly no. 136, May 2013,  14-20, http://eprints.lancs.ac.uk/65657/1/Sharkey_Suchman_ AISBQ_136.pdf.   14   Drew McDermott, “Artificial Intelligence Meets Natural  Stupidity,” in John Haugeland, ed. Mind Design: Philosophy,  Psychology, Artificial Intelligence (Cambridge, MA: MIT Press,  1981).  15   Lieutenant Colonel Douglas A. Pryer, “The Rise of the Machines,”  Military Review, March-April 2013, 14-24.  16   “New Tech City,” WNYC podcast, October 1, 2014, http://www. wnyc.org/story/killer-robots-ancient-rules-war-trouble/.  17   On this, see Patrick Lin, “Military 2.0.: Ethical Blowback from  Emerging Technologies,” Robots, Ethics &amp; War blog, December 15,  2010, https://cyberlaw.stanford.edu/blog/2010/12/robots-ethics- war.  18   Ryan Calo, “A Robot Really Committed A Crime: Now  What?” Forbes, December 23, 2014, http://www.forbes.com/sites/ ryancalo/2014/12/23/a-robot-really-committed-a-crime-now-what/.  February 2015, ISSUE 13 15 </page> </plain_text> 
<plain_text><page sequence="1">COMPUTERS, EDUCATION, AND ISSUES OF GENDER Suzanne K. Damarin The Ohio State University The presence of sex/gender differences in the attitudes, inclinations, and accomplishments of students using com puters in educational settings has been documented fre quently in both quantitative and qualitative studies. Gen erally speaking, females have been found to feel less posi tive about computers, less sure of their ability to work with computers, and more anxious about computers than their male counterparts (Cambre and Cook, 1985; Smith, 1987). Even when girls and women feel that, as groups, females are as capable as males in relation to the operation and control of computer technology, they tend not to see themselves as equally competent with males; "we can, but I can't" seems to be the attitude of many young women (Collis, 1985). Educators who study attitudes toward computing tend to see the sex differences uncovered as evidence of a need for affective education. That is, the attitudes of females are generally interpreted as indicative of a problem of females and one in need of "fixing" if women are to attain educa tional equality with males. However, a different interpretation of the findings of sex differences in attitudes toward computers is possible, es pecially as the items which typify attitude scales are de liberately broad. Items such as "Computers make me feel uncomfortable" and "I do not enjoy talking with others about computers" might be endorsed for a number of rea 81</page><page sequence="2">82 Computers, Education, and Issues of Gender sons which make very good sense in relation to the lives of women. This is particularly true in educational settings where computers are often most prominent in subjects such as mathematics where females are frequently uncomfort able, or in lessons delivered by CAI which supports the gendering of instruction (Damarin, 1990a). Perhaps com puters are more threatening to women as a group than they are to males. Perhaps females, more than male students, are perceptive of the intrusion of computers into their lives. Perhaps females are more resistant to complicity in these threats and intrusions. Resistance on the part of female students to certain as pects of computer technology has been documented in the work of Sherry Turkle; often this resistance goes hand in-hand with the tendency to anthropomorphize the com puter. For example, Mary, a young adolescent learning to program in Logo, resists top-down structured programming in order to accomodate the perceived personality of her ma chine (Turkle, 1984, pp. 112-113). Paradoxically, women who learn to program computers tend (more than males), not only to anthropomorphize computers, but also to resist this anthropomorphizing. The female graduate students in Turkle's studies establish personal relations with their computers and then reject those personal relationships, of ten expressing disbelief at their own tendencies and abili ties to establish caring relationships with machine person alities (Turkle and Papert, 1990). Generally, the women in Turkle's studies construct relationships with computers which are more "personal," more complex, and more trou blesome than the typical relationship of a tool-user to a tool.</page><page sequence="3">Suzanne K. Damarin 83 Relationships Between Computers and Persons Many of the social myths surrounding computers have as their function the preservation of the idea of separate ness of persons and machines. School children are taught that computers can do only what they are programmed to do and that the programmer (or user) is not only dis tinct from the machine, but in control of it. The myth of the household robot, assigned primarily to tasks which are currently performed by women, conveys the idea of a ma chine which is not only separate from its owner, but totally obedient to him (her?). Moreover, this robot need not be thought of as terribly intelligent in order to do the mun dane tasks of cooking, cleaning, ironing, and feeding the dog; the mythical household robot does not pre-empt the rights and responsibilities of male family members. Robots, such as TOPO, which are used in schools for computer pro gramming instruction, like the images of mythical house hold robots are anthropomorphized as cute, useful, and tractable; created in the image of R2D2, these robots would make nice multi-purpose household or classroom pets. The myth of computers as friendly, user-friendly, help ful, and obedient, as well as knowledgeable (in some cases omniscient), accurate, speedy, resourceful, and efficient is a part of the basic content of the computer literacy curricula of schools. Moreover, instructional software is advocated and advertized on the basis of similar myths: the computer as teacher is described as patient, even-tempered, and al ways attentive to the needs of individuals, as well as obe dient to the complex hierarchy of instructional objectives. Ironically, the attribution of human characteristics to com puters functions to preserve the myth of separateness of computers and persons. Most of the human characteris</page><page sequence="4">84 Computers, Education, and Issues of Gender tics attributed to the computer are commonly associated with the female or feminine; computers are not described as macho, aggressive, or virile. In this very real sense the construction of the computer as other to human reflects the construction of female as other to male. Developments in computer science and robotics, how ever, run counter to some of the popular myths. Machines which program themselves, and computer programs which perform cognitive tasks well beyond the conceptualization of their creators directly challenge the idea that the ma chine does nothing but follow rules which are supplied by a human. Moreover, the majority of robots being designed and manufactured today are neither cute nor at the ser vice of individuals. According to robotocists Aleksanderoff and Burnett (1983), robotics is developing in two direc tions; (1) the development of anthropomorphic machines that are interchangeable with skilled craftsmen (sic), and (2) the reconceptualization of work environments with pri mary concern for the robotic workers which perform pre viously human work, but on a different scale or schedule. Together, these developments deny not only the dualistic separation of person as essentially different from machine, but also the notion that individuals are served by the work of machines under their direct control. The question arises, then, of how humans and programmed and/or programmable machines are (and are to be) related to each other, not only in the perceptions of the users, but also in the minds of machine developers and in the analy ses of social scientists. There are currently at least three distinct conceptions which guide "scientific" development of answers to this question (Damarin, 1990b). Some robot scientists and some sociobiologists view the development of the computer as an exo-skeletal stage in the evolution</page><page sequence="5">Suzanne K. Damarin 85 of "mankind" and foresee the robot as replacing the hu man being as we know it, perhaps within the next century (Morawec, 1988; Stonier, 1988). In this view, machines en dowed with masculine rationality are becoming a superior non-biological form of humanity. The second view of the human-computer future is that of the cyborg, a single entity incorporating electronic hard ware and software into the biological "wetware" of human type bodies. This conception is consistent with develop ments in medical as well as computer technologies; it is the vision or view taken in primatologist Donna Haraway's (1985) radical feminist construction of the future and is also the conception which underlies futurist work ranging from the Human Genome Project to current "cyberpunk" science fiction (e.g., Gibson, 1984; Rucker, 1982, 1988). In the third view, machines retain their mechanical and electronic forms and humans retain their biological identi ties, but human-computer dyads, or larger groups of hu mans and computers, become increasingly mutually inter dependent for their continued operation. This view (to be examined more fully below) is currently dominant in the conceptualization of computer applications to business and industry and of the uses of computers for purposes of edu cation. Each of these conceptions of the unity of humans and machines has its own conceptual roots, its own impli cations for the viability or demise of ideas and concepts common to modern thought, and its own relations to fem inist and educational thought and to the future lives of all students (Damarin, 1990b). The remainder of this paper examines the third construct, that of the human-machine dyad, from the perspective of a feminist educator.</page><page sequence="6">86 Computers, Education, and Issues of Gender Women and Machines in Symbiotic Relation In the vision of the high tech future characterized by person-machine symbiosis, increasingly powerful comput ers are used by individuals and institutions; in theory, the computer and the computer-user each does "what it does best," as they work together in a powerful dyad. Of the three arrangements outlined above, this is the most com monly implemented in business today, and is prevalent in discussions of the optimal uses of computers in classrooms. This vision is also highly romanticized by those who ar gue that the computer will liberate workers from dull and mundane tasks and by those educators (the present author sometimes included) who argue that the classroom com puter can be used to provide disempowered children with a more liberatory education. These romantic visions are precluded from becoming reality by the unequal access of individuals both to computer power and to power over com puter use. Instead, as computers are being used in accor dance with this model the power of computers accrues to the politically powerful, and computers multiply social and economic inequity. The effects of computer implementation in offices, in manufacture, in businesses ranging from McDonalds to bro kerage houses, and in social service agencies have been documented by a number of social scientists (Cockburn, 1988; Garson, 1988; Howard, 1985; Zuboff, 1988). In all cases, the functions of the majority of workers are changed to accomodate the efficiency of computer operations; work becomes increasingly fragmented, meaningless, and repeti tive, and a large number of jobs, especially women's jobs, become nothing more than the preparation and entry of data for computer manipulation. In the hierarchy of U. S. jobs, black women are found most frequently in the low</page><page sequence="7">Suzanne K. Damarin 87 est paid and most tedious jobs for which they are crammed into back rooms where they work with and among outdated VDTs, inappropriate furniture, and poor lighting condi tions. Increasingly telecommunication is used to transport data to third world countries for data entry by women paid even less than these U. S. workers. The effects of this prac tice and of the export of microchip manufacture on Malayan women are graphically described by Aihwa Ong (1987), as follows: Electronics technology has exerted control over workers both materially and symbolically. First, the extreme decomposition of tasks requires work ers to perform repetitive and minute jobs, Sec ond, management seeks to control the women's self-perception by talking about the "natural" abil ity of "oriental" women's fingers, eyes, and pas sivity to withstand this low-skilled, mind-deadening work. The reduction of the social person to an or ganism subordinated to technological instrumen tality is no mere mystification. It constitutes ev eryday reality for the perception and treatment of workers gender has been disassembled. (pp. 622-623). These oriental women, and in this country many black women entering data in office back rooms, are defined as "wetware," biological material essential for the operation of the machines. In some conceptualizations of computers, the fully operational machine consists of hardware, software, wetware, and orgware, the latter being the (technology based) organizational system which schedules work, mon itors progress, and oversees the operation. In this frame work, the woman worker is, not complementary to, but an</page><page sequence="8">88 Computers, Education, and Issues of Gender integral part of the machine. A similar phenomenon occurs with "higher level" em ployees in fields such as sales, social service, and consul tation of various sorts, who are increasingly "assisted" in their work by computer-based artificially intelligent expert systems. Knowledge which was once a personal asset of the worker is encoded in a data base in the machine. The worker, no longer permitted to speak or act from her or his own expertise (Garson, 1988), becomes an "input/output device" comparable to a printer or other "computer periph eral." The design of the human- machine interface deliber ately limits the scope of interaction between the computer and its human user (Fischer and Lemke, 1988). Menu driven software puts the computer in control of communi cation, forcing the articulate and imaginative human user to limit communication and restructure inquiry to accomo date the multiple choice directives of the computer. As many jobs which previously required human expertize are limited to serving as a computer interface, these jobs are re defined and made less lucrative. New classifications of em ployment as "data workers" are identified, and these jobs become feminized, that is, low paid "women's work." Thus, as the computer-human dyad approach to the workplace integration of humans and computers matures, increasingly women are absorbed into computer systems; race and class distinctions are preserved as women of color and lower class women become wetware while middle class white women become more highly paid computer periph erals. In both cases electronic supervision of workers, in creasing pressure for productivity, and poor working condi tions prevail. In both cases the women who fill these jobs are reduced to machine components whose claim upon an essential personhood is reduced to their sexuality; that is,</page><page sequence="9">Suzanne K. Damarin 89 their otherness to the electronic machine lies in their sexual functioning. Student-Computer Dyads in Education The use of computers in education, particularly for the education of those students who are not expected to excel in mathematics and science, is increasingly such as to pre pare them for the world of the human-computer dyad (see Apple, 1986). The "at-risk" student, very often a person of color, is increasingly provided with (that is, subjected to) "computer-managed-instruction" on so-called "minimal competencies." In these procedures, the computer directs the multiple choice work of the would-be learner as she or he practices the input of responses to questions and prob lems which have already been solved (or at least could be solved) by the computer itself. Indeed, the decontextual ized "minimal competencies" which span the whole of some children's educational experience, have, in a large num ber of cases, been rendered obsolete in the marketplace; in the workplaces alluded to above, arithmetic, categoriza tion, and the like are no longer "people skills" performed by entry level employees, but computer operations, no longer entrusted to the human worker. Nor are these "skills" the stuff from which an education is made; removed from the contexts which provide them with meaning, the "minimal competencies" can be mastered only (if at all) as facts in themselves to be stored in the human brain against the day when "the batteries wear out" and a human might be called upon to determine some fact or number. For the av erage citizen, the social utility of these skills decreases daily as the computer-generated and computer-implemented bu reaucratic formulae for all facts and statistics become in comprehensible. Numbers increase their power as they sac</page><page sequence="10">90 Computers, Education, and Issues of Gender rifice their meaning ... only on minimal competency tests is long division appropriate. While the "education" of the "at-risk" student uses the power of the computer to direct student practice on de contextualized skills, educational researchers and knowl edge engineers are investigating a broad range of issues and techniques related to a variety of ways in which students' learning can be shaped by the computer rather than by experience with material objects, by textual reference to the accumulated wisdom of the past, or by inter-personal communications with teachers and peers. Computer mod els of systems of thought, language, behavior, and belief are constructed by cognitive and computer scientists, often in the form of expert systems. Such systems "emulate the reasoning and problem solving abilities of human experts" and serve "as powerful tools for the extension and redefi nition of human intellectual efforts (Pea, 1987, p. 128)." Through intelligent computer assisted instruction (ICAI) systems, these computer models are used to guide and shape the learning of young students. As Streibel (1986) points out, computer models are restricted to those ways of knowing which admit a procedural representation (that is, a representation in terms of "if ... then" pairs); artistic, methaphorical, historical and other ways of knowing which do not lend themselves to this model are thus eliminated from the base of education, and students are schooled in machine-like thought. Underlying much of this work is the idea of the "co-evolution" of machine and human thought, that is , the notion that education should reflect and sup port the symbiotic development of "cognitive abilities" of machines and humans. As machines develop new capacities for "cognition" these will drop out of human education and the repertoire of human abilities, thus creating further de</page><page sequence="11">Suzanne K. Damarin 91 pendence of the human upon the machine. As the balance of cognitive control shifts from human to machines, the human becomes absorbed into the machine architecture, becoming primarily a source of data for the data-hungry intelligent machine. Thus, at least in some visions, school ing will reduce students to data input and output devices, peripherals to the machine. Projecting the Future of Student-Computer Dyads Just as the machine depends upon data from the stu dent, the student comes to depend upon inputs from the machine. In their provocative description of "Kelly's Ed ucation," Belland and Taylor (1984) project, in the indefi nite future, a world in which Kelly's every cognitive and affective need is met; questions are answered and emo tions and attitudes are modified by machine response to the data generated by Kelly through brainwaves and the firing of neurons. It is misleading to say that Kelly is (con sciously) communicating with the machine or using it as a tool, for the interface between Kelly and machine is so transparent as to be invisible even (or, perhaps, especially) to Kelly. Moreover, while the process(es) of Kelly's "edu cation" world are described, it is not clear what it might mean to be an "educated person" in Kelly's world. And, then, there is Kelly who is described without reference to sex or gender; according to the authors Kelly might be ei ther male or female (Taylor, 1985) If so, with respect to education, Kelly is neither male nor female, and the educa tion of Kelly's world is unrelated to the social construction of gender. For educational purposes, Kelly and the machine are asexual extensions of each other. If Kelly is other to the machine, this separation is not based upon cognition or mentality. As with the workers in the machine-person</page><page sequence="12">92 Computers, Education, and Issues of Gender dyads of business and industry, Kelly's sexuality might de fine her/his otherness to the machine. If Belland and Taylor share a nightmarish vision of the human-computer dyad in education, other educators claim to have sweet dreams of the human-computer future. J. Aaron Hoko (1989), for example, asks us to: Imagine a small boy lying in bed with fists in eyes trying to rub away the last remnants of sleep. From the kitchen he hears his mother's famil iar call, "Ryan, Ryyyan! Breakfast will be ready soon. Get dressed quickly." A smile comes across the child's face as he crawls out of bed and makes his way to a desk in the far corner of the room. As he sits down a slightly older feminine voice reminds him, "Ryan, it's breakfast time." Rising from his chair the boy responds, "OK Sis, I'm hurrying. Quickly the boy dresses, (p. 136). Sis or SIS stands for "Smart Instructional Systems" and, as Hoko continues his story, SIS is with Ryan throughout the day, both at home and at school. SIS is (or simulates behavior which is) kind, patient, and nurturing of Ryan as it leads him through his arithmetic and his wordlists, provides graphic and game "rewards" for work well done, schedules and monitors his reading group, and so on. Al though Hoko's paper title claims that SIS provides a way in which computers enhance teacher's pedagogical power, the only function of the morning and afternoon proctors (who are, presumably, the teachers in Ryan's classroom) is to make announcements. As Ryan ends his day SIS tells him a dinosaur story, and As the story is being told, Ryan's father slowly and quietly enters the small boy's room. Ryan,</page><page sequence="13">Suzanne K. Damarin 93 sitting at his desk, hardly notices that his father is now standing behind him. The father listens and looks thankfully toward the animated desk surface. Fingers of his left hand gently massage the boy's small neck; fingers of his right hand gently caress the inscription on the corner of the desktop. It reads "Smart Instructional System (SIS)." (p. 138). The vision of SIS and its environment is an eerie mix of doctrinaire behaviorism, post-modern technology and pre feminist mentality. Manipulating data gathered by scan ning Ryan's retina, by monitoring events in his home and classroom, and by consulting the built-in course of very traditional school study, SIS is clearly the salient actor in Ryan's life. With its "slightly older feminine voice" and more patient (big SISterly) messages, SIS displaces Ryan's mother, as well as his teacher, as guide and au thority. Moreover, it is SIS, and not Ryan's mother, which receives the thankful look and the gentle caress from Ryan's father as the story ends with SIS receiving the seal of mas culine approval. In short, in the vision of Ryan and SIS the human-computer dyad is composed of a young (white?) male human and a machine which has usurped the tradi tionally feminine virtues and privileges. Simulating, and thus essentially replacing the female, SIS creates an envi ronment which is a nostalgic simulacrum of the mythical life of the white middle class nuclear family of the 1950's. In Hoko's copy of the nuclear family, however, the traditional mother has been disassmbled, divided into two; the com puter serves as nurturer, while the female is present, pre sumably as an agent of biological reproduction, and more pointedly, as a nagging scold who should be ignored.</page><page sequence="14">94 Computers, Education, and Issues of Gender In the human-computer dyads of the workplace and those of which Kelly and Ryan are parts, the computer exercizes direct control of the human. Kelly is totally controlled and without choice, indeed without knowledge, as to the direc tion of her/his behavior. It is unclear whether Ryan can resist the directives of SIS; in Hoko's portrayal he doesn't choose to defy SIS in any way. The computers in each of these myths have clearly been programmed in accordance with a theory of learning (neuropsychology for Kelly and behaviorism for Ryan), a theory (unarticulated) of the pur pose of education, and a theory of instructional design. The question arises, then, as to whether it is these theories that are responsible for the horrors of these visions, or whether the very idea of a human-computer dyad leads inescapably to such visions. It has been argued that one purpose for having students learn to program computers is that students learn that they control the machine, and not vice versa. Nonethe less, student programmers are not unaffected by their com puter use. Adolescents observed and interviewed by Turkle (1984) use their experiences with computer programming to construct new ways of thinking about themselves and of modifying their own behavior. About one troubled young woman Turkle writes: Before she met the computer Deborah didn't think about her problems in terms of control. ... She needed a world apart in which to build a new set of distinctions that she could then transfer to her way of thinking about herself and others. The computer provided this world. It gave her cate gories more useful than good or bad: things could be in or out of control. With the new distinction</page><page sequence="15">Suzanne K. Damarin 95 came a new way to think about her problems: I am in trouble because I have no rules. I am not in control. And I should be. I can be (pp. 144-145). Other students whom Turkle interviewed spoke of "de bugging" their own thinking and behavior. From their work with computers these students have learned to ana lyze themselves and to think of themselves as programmed, perhaps just as programmed as Ryan and Kelly. Hierar chy, control, and bug-free rules determine (or should de termine) their behavior. This is a different view of behav ior than that provided by Skinnerian conditioning theories and, indeed, Turkle (1988) argues that the existence of the computer relegitimates the idea of memory and is, thus, responsible for the demise of behaviorism. However, the construction of behavior as determined by rules and princi ples, hierarchy, and control is no less focussed on the values which characterize patriarchal systems. The Non-Neutrality of the Human-Computer Dyad Thus, the human-computer dyad takes many forms in educational settings, both real and projected. In each of these forms, the behavior of the human is constrained by or constructed in relation to the operations of the computer. In turn, these operations are derived, in part, from the de signers sense of what are important features and variables. Sex/gender of students does not seem to be included among the variables which are theorized; instead the common tacit assumption is made that the male student is representative of all students. With these observations, we return to the issue with which this paper began, female student's attitudes toward computers. The business and educational uses of comput ers cited in this paper and its sources are clearly gendered.</page><page sequence="16">96 Computers, Education, and Issues of Gender They constitute sufficient reason for females to be wary of computers and resistant to them. Female wariness and re sistance, however, contribute to the continued domination of the computer field by males who (naturally or necessar ily) construct computer applications from a male perspec tive. As computers become more multi-faceted and power ful, so too does the influence of thermale perspective. This influence is nowhere more apparent than in the design of artificially intelligent approaches to education. Extending her analysis of computers, Turkle (1988) asks us to consider artificial intelligence as a "sustaining myth" which is comparable to psychoanalysis in its discursive power: We are afraid of the sexual and aggressive sides of our natures, but we want to be in touch with them as well. Psychoanalytic ideas give us a way to play with what is forbidden. Similarly, we are afraid to think of ourselves as machines, yet we want to find a way to acknowledge this very real, if disturbing part of our experience. Playing with AI, with the idea of the mind as computer, makes this possible (p. 266). With this sugggestion, Turkle asks us, not only accept as analogous the constructions of ourselves as sexual and as mechanistic, but just as importantly to reverse the di rection of the original metaphor linking human and com puter intelligence. No longer should we view our human selves as the primary agency by reference to which we con struct, understand, and interpret the actions of "intelli gent " machines. Instead we should view the man-made machine as the principal and principles through which we construct, understand, and interpret ourselves. These are indeed provocative demands.</page><page sequence="17">Suzanne K. Damarin 97 Turkle's analogy highlights the common roots of psy choanalysis and artificial intelligence in patriarchal world views and masculine notions of the normal and normative. The response to psychoanalysis of females in general and feminists in particular has been varied, ranging from to tal rejection to appropriation and revision of its theories (Ramazanoglu, 1989). The mixed and negative attitudes of females to computers may reflect the beginnings of a comparable ambivalence. It is my fond hope that this am bivalence will lead, not to new and more effective programs of affective education, but rather to a rethinking and recon struction of human-computer relations, especially in edu cational settings. References Aleksander, I. k Burnett, P. (1983) Reinventing man: The robot be comes reality New York: Holt, Rinehart, and Winston, 56-58. Apple, M. W. (1986) Teachers and texts. New York: Routledge. Bell and, J. C. k Taylor, W. D. (1984) Kelly's education. Columbus, OH: mimeograph. Cambre, M. A. k Cook, D. L. (1985) Computer Anxiety: Definition, measurement, and correlates. Journal of Educational Computing Research 1 (1), 37-54. Cockburn, C. (1988) Machinery of dominance: Women, men, and technical know-how. Boston: Northeastern University Press. Collis, B.(1985) Psychological implications of sex in attitudes toward computers: Results of a survey. International Journal of Women's Studies 8, 207-213. Damarin, S. K. (1990a) Unthinking Educational Technology. In M. R. Simonson, ed. Proceedings of Selected Research Paper Presentations, Washington, DC: AECT, 179-188. Damarin, S. K. (1990b) The discourses of artificial intelligence: Robots as patriarchy. Presented at National Women's Studies Association, Akron, OH., June 1990. Fischer, G. k Lemke, A. C. (1988) Construction kits and design envi ronments: Steps toward human problem-domain communication. Human Computer Interaction 5(3), 179-222. Garson, B. (1988) The electronic sweatshop: How computers are trans forming the office of the future into the factory of the past. New York: Simon and Schuster. Gibson, W. (1984) Neuromancer. New York: Berkley (Ace).</page><page sequence="18">98 Computers, Education, and Issues of Gender Haraway, D. (1985) A manifesto for cyborgs: Science, technology, and socialist feminism in the 1980's. Socialist Review 80. Hoko, J. A. (1989) SIS: A futuristic look at how computers and class rooms can enhance rather than diminish teachers' pedagogical power. Com puters in the Schools 6 (1/2), 135-143. Howard, R. (1985) Brave new workplace. New York:Viking. Morawec, H. (1988) Mind children: The future of robot and human intelligence. Cambridge, MA: Harvard University Press. Ong, A. (1987) Disassembling gender in the electronics age. Feminist Studies 13, 3, pp. 609-626. Pea, R. D. Integrating human and computer intelligence. Mirrors of Minds: Patterns of Excellence in Educational Computing Roy D. Pea and Karen Sheingold, eds, New York: Ablex, 1987,128-146. Ramazanoglu, C. (1989) Feminism and the contradictions of oppression. New York: Routledge. Rucker, R. (1982) Software. New York: Avon Books Rucker, R. (1988) Wetware. New York: Avon Books Smith, S. D. (1987) Computer attitudes of teachers and students in relationship to gender and grade level. Journal of Educational Computing Research 5(4), 479-494. Stonier, T. (1988) Machine intelligence and the long-term future of the human species. AI and Society 2(2), 133-140. Streibel, M. J.(1986) A critical analysis of the use of computers in education. Educational Communications and Technology Journal 34(3), 137-161. Taylor, W. D. (1985) personal communication. Turkle, S. (1984) The second self: Computers and the human spirit. New York: Simon and Schuster. Turkle, S. (1988) Artificial intelligence and psychoanalysis: A new al liance. In S. R. Graubard, ed. The artificial intelligence debate: False starts, real foundations. Cambridge: MIT Press, 251-268. Turkle, S. L Papert, S. (1990) Epistemological pluralism: Styles and voices within the computer culture. Signs 16 (1), forthcoming. Zuboff, S. (1988) In the age of the smart machine: The future of work and power. New York: Basic Books.</page></plain_text>
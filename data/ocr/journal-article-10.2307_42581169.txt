<plain_text><page sequence="1">TECHNOLOGICAL MODELS OF THE NERVOUS SYSTEM ANATOL RAPOPORT * IT ishing is NOT up-to-date-ness. often that a book This written does in happen another when age suddenly some prophecy acquires an suddenly aston- ishing up-to-date-ness. This does happen when some prophecy suddenly passes from the realm of the fantastic to the realm of the imminent. Such a prophecy was contained in the book Er e w hon by Samuel Butler, written in 1872. The prophecy has to do with the evolution of machines, particularly machines endowed with a property which has seldom been attributed to machines - in- telligence. As stated by Butler in rather poetic terms, the prophecy envisages a world in which the machine becomes the dominant system of organization (in the way living things are systems of organization). Like living things, the machines of the future metabolize, reproduce, maintain themselves, and in general seem to have an aim in life. The one frightening thing about the genus machina is its parasitic dependence on the genus homo. The mechanism of natural selection is supposed to function in such a way on that form of "life" as to select those variations which are especially capable of catering to the compul- sions of human beings - namely, their compulsions of caring for machines. Gradually, what had started as a symbiosis between man and machine passes into parasitism, so that finally man becomes domesticated by the machine. Almost the same prophecy is stated in more realistic terms by N. Wiener in his Cybernetics (New York, 1948). Wiener envisages the Second Industrial Revolution ushered in by machines able to perform tasks requiring an average in- telligence with the resulting dislocations and crises similar to those which fol- lowed the First Industrial Revolution, when the "stupid" machines first appeared on the scene of history. Our purpose here is not to discuss the merits or the limitations of these prophecies, but rather to point out that the sudden dramatic revival of the "in- telligent machine" idea (be it a metaphor or a myth or a profound insight) is indicative of a really significant historical event - a major intellectual revolution. Like the Second Industrial Revolution, of which Wiener writes, this intel- lectual revolution is also the second in recent times. The first one occurred in the 17th century with the creation of mathematical physics. Perhaps I should make clear what I mean by an intellectual revolution. I think of such revolutions * Presented at the regional research conference of the American Psychiatric Associa- tion held at the National University of Mexico, Mexico City, March 10-12, 1954. 272</page><page sequence="2">summer 1954 TECHNOLOGICAL MODELS OF THE NERVOUS SYSTEM metaphorically as crystallizations of thinking around new, powerful concepts. In the 17th century these central concepts were those of mechanics - force, momentum, particularly energy. They became the central concepts of classical physics and of technology which came into being during the First Industrial Revolution. The second intellectual revolution, now occurring, brought forward another powerful new concept, that of "quantity of organization," a concept of high degree of sophistication and bearing within it the seeds of extremely far-reaching consequences. It is this concept, also called negative entropy and "amount of information," which makes the anthropomorphic conception of the machine especially intriguing, particularly because through it the common features of "intelligent" or "purposeful" behavior of the higher animals and "automatic" behavior of "higher machines" are made apparent. Now the personification of machines and "mechanization" of organisms are not new. The former has mythological roots in the medieval legends of the Golem and the Homunculus. The latter appears, for example, in the writings of Descartes. The question "Are living beings machines?" has long been treated as a metaphysical question, presumably answerable on metaphysical grounds. Since metaphysics is more or less a lost art, we must learn to look at that question somewhat more critically, that is, with semantic awareness. We must translate it into other questions, such as, "To what shall the name living thing' be ap- plied?" and "To what shall the name machine' be applied?" "Is there an over- lap among the referents of the two terms?" Putting the question this way, we see that the answers to the first are relatively clear, while the answers to the second are not nearly so clear. Barring certain borderline cases (viruses, etc.) we have no difficulty recognizing the class of objects to which the name "living thing" can be unambiguously applied. Not so with machines. This is so because living things are "given." They have re- mained about the same for as long as we can remember. But machines have evolved rapidly within the span of human history. We realize keenly that there are machines today which our grandfathers could not have dreamed of, and, by extrapolation, we feel that we can't really say what the limits of the world of machines may be. If we think about the matter a little more, we realize that machines in their evolution undergo "mutations" of tremendous magnitudes. Where it takes eons for a new biological species to develop, a new technological "phylum" has on occasion come into being within a generation. T3y a technological phylum I mean something similar to a biological -D phylum. If the latter is defined by a very general plan of organization in a wide class of living things, the latter is defined in terms of a principle of opera- tion . We can, if we wish, distinguish four technological "phyla," which came into being successively. 273</page><page sequence="3">ETC.: A REVIEW OF GENERAL SEMANTICS vol. XI, NO. 4 The first phylum we could call Tools. Tools appear functionally as extensions of our limbs and they serve primarily for transmitting forces which originate in our own muscles. In the transmission of force, sometimes a mechanical ad- vantage is gained, as in the crowbar, a screw, or a pulley. However, the work done by a machine of this sort is actually work done by our own muscles. There- fore a machine of this kind, a tool, does not give the impression of "inde- pendent' ' action, and so it did not occur to any one to compare tools to living things.1 With the second phylum it is a somewhat different story. This second phylum of machines we could call Clockworks. In a clockwork a new principle of opera- tion is at work, namely, the storing of mechanical energy. A typical clockwork is wound up, that is, potential mechanical energy is stored in it, which may be re- leased at an arbitrary later time and/or over a prolonged period to time. A clock- work does give the impression of autonomous activity, and doubtless this crude resemblance of a clockwork to a living thing (residing in its quasi-autonomous activity) gave the craftsmen of the late Middle Ages and of the Renaissance ideas of constructing mechanical dolls and animals. Perhaps the first ideas of automata sprang from the same sources. Characteristically, Descartes speculated on the possibility that animals were elaborate clockworks and, equally character- istically of his age, excluded humans from this class, as possessors of "souls." We may observe in passing that the bow and the catapult are also clockworks by our definition, since mechanical energy is stored in these machines to be re- leased later (in the case of the crossbow, it may be released much later). How- ever, the "autonomous" action of these machines is so brief that they do not give even the appearance of being "alive." The first comparison of living things to machines, therefore, was made with regard to clockworks. It is not surprising that this metaphor was not particularly fruitful for the understanding of the living process. We know now, of course, that energy is stored in living things, but this energy is not stored in the form in which it is stored in clockworks (mechanical stress) and so was not recognized as such. Living things are not wound up to keep going, and this absence of the most essential characteristic of a clockwork in living things made the early mechanical interpretation of life a sterile one. This comparison got a new lease on life with the appearance of the third phylum of machines. This phylum includes primarily the Heat Engines. Again an entirely new principle enters into their operation. As with tools and clock- works, the output of the heat engine is an output of energy which had been put into it. But whereas the energy put into the earlier classes of machines was in the form of mechanical stress, which is obviously associated with our own muscular effort, the energy put into a heat engine is contained in a fuel. however, personification of weapons does occur. Note also the legend of the Sorcerer's Apprentice. 274</page><page sequence="4">summer 1954 TECHNOLOGICAL MODELS OF THE NERVOUS SYSTEM Consider the vital difference between the two situations. It is obvious even to a child that the tool is not autonomous, because the tool is geared at all times to muscular effort. A child or a very primitive person may believe that a clock- work is autonomous, but it is still easy to convince him that it is not, because the winding up is still a result of some one else's muscular effort. No such effort is apparent in the fuel. Fuel is "fed" to the heat engine. The analogy to living things (which also need to be fed in order to operate) becomes ever stronger. The comparison between heat engines and organisms passed beyond the metaphorical stage and bore real scientific fruits. It became apparent that fuel is in a very real sense the food of the engine and equally apparent that food eaten by organisms likewise functions as "fuel." The principle of energy con- servation was shown to hold in living things - a serious blow to the contentions of the vitalists, which sent them on their long and tortuous retreat. Biochemistry was born. More and more processes characteristic of life were shown to be instances of processes reproducible in a chemical laboratory. An analogous revolution was occurring in technology. In fact, it would be not inaccurate to say that the First Industrial Revolution occurred when it became apparent that machines could be constructed which did not need to be "pushed" but only "fed" in order to do the work. Driven out of physiology, the vitalists took refuge in psychology. Here, in the realm of thought and purpose, of emotion and insight, they felt they would remain safe from the onslaught of the mechanists, materialists, determinists, and reductionists. The label "nothing-but-ism" was derisively pinned on the philosophical outlook of those who believed that even the most complex mani- festations of the living process, including the intricacies of men's psyche could somehow be described in terms of analyzable behavioral components which, in turn, could be related to observable events in space and time. And so the focus of the battle between the vitalists and the physicalists shifted to psychology, where it remains at this time. The line between the two camps is, of course, not sharply drawn. Like the political spectrum ranging from extreme left to extreme right, the range of convictions concerning the naturç of mental processes stretches from extreme behaviorism to vitalism or mysticism. The gestaltists can, perhaps, be assigned intermediate positions. I am offensive sure was you undertaken all know the by main the behaviorists, outlines of the the controversy. of what The opening in offensive was undertaken by the behaviorists, the champions of what in some circles bears the unattractive name of S - R psychology. The method has a strong physiological bias. Technological analogies are frequently invoked. The earliest of these was the "telephone switchboard" model of the central nervous system. The environment was supposed to act on the organism by a series of stimulus configurations, which activated combinations of receptors, which ini- tiated impulses, which traveled along nerve fibers, passed through the central 275</page><page sequence="5">ETC.: A REVIEW OF GENERAL SEMANTICS vol. XI, NO. 4 nervous system to other nerve fibers and into the effectors, whose activity ac- counted for the overt behavior of the organism, which was proclaimed to be a sole legitimate object of study in psychology. Behavior was viewed as a grand collection of units called reflexes. The model was seen to be inadequate from the start. If to every configura- tion of stimuli there corresponded a definite set of responses, how was learning (the acquisition of new responses to the same stimuli) possible? However, this seemingly embarassing question proved a blessing in disguise, for the discovery of the conditioned stimulus by physiological means strengthened the reflex theory of behavior. It was shown that the paths of the impulses could be systematically changed. The switchboard model was shown to be still useful. Learning was accounted for by the "switchings" of the connections. Hot serious on the critique, heels called of the gestaltism. behaviorists' Gestaltism successes, deserves however, serious came attention, a more serious critique, called gestaltism. Gestaltism deserves serious attention, because its ideas were the direct precursors of a new approach to the theory of the nervous system, which is the subject of the present discussion. The gestaltist critique was not simply a reiteration of the vitalist faith and did not confine itself to derisive labels like "nothing-but-ism" directed against behaviorism. It was much more specific and constructive and was based on at least two clearly identi- fiable characteristics of behavior, which did not seem to fit into the behaviorist scheme, namely, the recognition of "universais" and the equi-finality of response. The recognition of universais means the following. Suppose an organism learns to respond to the sight of a particular square in a certain way and to a particular circle in a different way (say open a box marked with a square but not with a circle) . The phenomenon is clearly an instance of conditioning. A strict behaviorist (telephone switchboard) explanation would have to rest on the assumption that the stimuli originating from the receptors activated by the sight of the square are "switched" by the conditioning process to paths leading to the proper effectors for opening the box. However, it is known that the conditioned stimulus can be varied considerably after the conditioning has been established and still elicit the response. For example, if the original conditioning was to a white square on a black background, it can be subsequently changed to a black square on a white background, which, at least in the retina, excites the comple- mentary receptors, i.e., precisely those which were not involved in the condi- tioning process. Roughly speaking, the organism responds to the square as a "square," regardless of the receptors involved. Hence the emphasis on the term gest alt (the configuration perceived as a whole, rather than a complex of ele- mentary stimuli). The gestaltists maintained that the behaviorists' emphasis on the stimulus response pathways detracted from the importance of "universais" or abstractions in the act of perception. (If a counter-argument is offered to the effect that in the perception of a 27 6</page><page sequence="6">summer 1954 TECHNOLOGICAL MODELS OF THE NERVOUS SYSTEM geometric figure only the receptors affected by the edges of the figure are in- volved, it can be countered by other interesting evidence, such as the well-known phenomenon where familiar maps are not recognized if the continents appear in blue and oceans in yellow, or the still more baffling phenomenon that the shapes of objects can be recognized regardless of position, size, or orientation.) The equi-finality of response argument is even more powerful. It has been observed that once an animal has learned to perform a task (say to run a maze to a reward) it will perform that task with whatever means are available to it. If its legs are amputated, it will roll through the maze. Clearly, such behavior cannot be explained in terms of a series of reflexes, each setting off the next, since the performance may involve totally different effectors each time. This equi-finality of response naturally leads one to talk of purposeful be- havior, in which only the goal is relevant and not the particular configuration of neural events which come into play. This seeming inevitability of invoking teleological notions opens the door to more vitalist arguments. The notion of "purpose" seems to resurrect the ancient classification of causes into "efficient" and "final" and to give new life to the ailing idea that the behavior of living and non-living things cannot possibly be governed by the same set of laws. It chines is at this become point exceedingly that the concepts important. associated We recall with that the the fourth first phylum phylum (tools) of ma- chines become exceedingly important. We recall that the first phylum (tools) operated primarily as force transmitters; the second phylum (clockworks) as storages of energy resulting from mechanical stress; the third phylum (heat engines) as transformers of different forms of energy into mechanical energy. Now the fourth phylum of machines operates on the principle of storing and transmitting something called inj or mati on. Already the telephone switchboard model of the nervous system employs a technological analogy with a communication device rather than a conventional engine. The primary concern of psychology is not so much with "what makes the organism active?" as "how does it know what to do?" Not the source, the transformation, or the utilization of energy by the organism is of prime sig- nificance but its organized disposition. What the psychologist actually studies is not how much activity has been performed but the sequence of specifically di- rected acts, which when organized one way may give one set of results and organized in another way (or randomly performed) may give an entirely dif- ferent set, even though the amount of energy expended remains the same. To give a homely example, consider the difference between closing the door and then turning the key and turning the key and then closing the door. The ma- chines of our fourth phylum are primarily concerned with systematizing opera- tions in which utilization of energy is involved. The amount of energy used is not important. The "power" of these machines is not "muscular" power but "mental." The giants among them are capable of receiving, transmitting, and 277</page><page sequence="7">ETC.: A REVIEW OF GENERAL SEMANTICS vol. XI, NO. 4 storing complex sets of directions, i.e., large amounts of "information." This is why technological analogies with these machines are of particular interest in psychology. These machines simulate not muscular effort (like their ancestors did) but human intelligence. Just as the concept of energy and its transformations was able to explain the "activeness" of organisms, which could not be explained on the basis of ex- ternally applied stress (as tools are activated) or by internally applied stress (as clockworks are activated), so the concept of "information" promises to do the same for a much larger area of the living process, namely, the "intelligent" and "purposeful" aspects of living behavior. What is this thing called information? There is now a wealth of literature on the subject and it is not within the scope of this presentation to develop the ideas of this literature. I think, however, that a reasonably good idea of the nature of "information" can be given by a few examples. I will not attempt to make these ideas precise. I will try to appeal to intuitive understanding, even at the risk of being vague. Information bears a similar relation to energy as organization to effort. One can best see this in an example where the inadequacy of a theory based on energetic considerations alone is obvious. Consider the automobile traffic in a large city. Suppose the proverbial man from Mars decided to study this traffic. He might measure the rate of flow of cars along the city's arteries. He would correctly relate that flow to the speed with which the cars traveled and, being a good physicist, he would relate the speed to the power of the engines. And so he would be satisfied, perhaps, in explaining the rate of flow by energetic con- siderations. Next suppose that all the traffic lights failed. Certainly the speed of the cars and thus the rate of flow of traffic would be reduced. Suppose our Martian stuck to his conceptualization in terms of energetics. He would then have to ascribe the reduced flow (or speed) to some failure of the automobile engines, and he would be wrong. The failure is not of the engines but of the traffic lights. True, it takes energy to activate the traffic lights, but it is negligible compared with the energy it takes to move the cars. Energy has therefore little to do with the traffic problem under consideration. The key concept is not that energy but of directions for the utilization of energy (commands "stop" and "go" properly patterned), i.e., a matter of information. If the traffic lights are not functioning, the driver of a car does not know what to expect at each inter- section and, playing safe, he slows down. The accumulated slow-downs of all cars at all intersections turn out to have a greater effect on the over-all slowing of traffic than the occasional full stops at the red lights. In the case of regulated traffic lights, set for certain speeds, the flow of traffic is most efficient. The cars are, in effect, "organized" or bunched up along the roads in such a way that the bunches on one system mesh with the empty spaces on the system perpen- dicular to it, and the flow is continuous without stops. 278</page><page sequence="8">summer 1954 TECHNOLOGICAL MODELS OF THE NERVOUS SYSTEM Examples can be multiplied at will. Children well-trained in fire drills leave a burning building in a surprisingly short time, while a disorganized mob may never leave it. The success of a military action depends both on fire power and on proper coordination of the units. Fire power is measurable in terms of energy units, but coordination is measurable in terms of something else: the rate of flow of information and the precision of timing in carrying out the sequence of necessary steps. Productivity of an industry depends on the amount of power available (energetics) but to no less extent on the skill of the workers (coordina- tion of activity within the individual) and the skill of management (coordina- tion of activity of the several workers) . While it was traditionally assumed that these coordinating functions must be performed by "reasoning beings," i.e., men, it became gradually apparent that a great many of them could be per- formed automatically (by traffic lights instead of policemen, IBM machines in- stead of filing clerks, automatic steering mechanisms instead of helmsmen, electronic computers instead of human calculators). There arose then the in- triguing idea that there may be a general "psychology" applicable both to the behavior of these devices and at least to certain aspects of human behavior. Now Historically let us pause the technological for a moment analogies and take purporting stock of to explain what we the have behavior said. Historically the technological analogies purporting to explain the behavior of living things have been geared to prevailing technological concepts. As technology became more involved, the analogies could be extended to more facets of behavior. We are now entering a new technological era - the era of "intelligent machines," called automata and servo-mechanisms. The under- standing of the principles on which these machines are constructed and operate promises to extend our understanding of the living process still further. We must, however, if we are to say something significant, indicate more specifically where that promise lies. We have two pieces of evidence in support of our rather optimistic view. The first is the tremendous stride forward in the understanding of the living process, which resulted from the previous discovery of just one far-reaching principle - that of transformation of energy. The second is the progress being currently made in the analysis of the vague teleological and vitalistic notions of "purpose" and "intelligence." Let us recall, at the risk of becoming repetitious, why the understanding of the living process presents difficulties. Living things seem to differ from non- living in three fundamental respects (immediately apparent to the naive ob- server) . 1. They seem to be "autonomously" active (i.e., the motive power seems to come from the inside rather than be impressed from the outside as in the case of moving inanimate objects). 2. They seem to be guided by purpose and intelligence. 3. They maintain their integrity, grow, and reproduce. 279</page><page sequence="9">ETC.: A REVIEW OF GENERAL SEMANTICS VOL. xi, NO. 4 The first technological analogy (with the clockwork) attempted to explain only the first of these characteristics and it did so very poorly. A clockwork is, to be sure, activated from the "inside" for a while, but there is no question about what the source of this activation is. The clockwork simply gives a de- layed response to a stress (a push ) impressed on it. It is different with a heat engine. There is no obvious push there. The engine is fed in a very real sense and is activated by the food it "eats." The analogy to a living organism is in the case of a heat engine far from superficial. But the "muscular effort" of the engine is still externally directed. The locomo- tive is guided by the rails; the boat by the rudder. A simple engine is "told what to do" at every step of the process. Here the analogy with the living organism fails. Now it is clear why the development of automata and servos naturally ex- tends the analogy. The mechanisms of control are now built into the machine. We now want machines to behave "purposefully" and intelligently and since we have to design the machines, we have to analyze the notions of purposefulness and intelligence into component parts. Really no sharp distinction can be drawn between intelligence and purpose- fulness. Any definition of one is sure to involve the other. Let me therefore describe very roughly the present status of "intelligence" and/or "purposeful- ness" in our machines which will then naturally lead me to the concluding re- marks on the modern ideas of the nervous system. I view "intelligent" machines as consisting of two kinds, automata and servo-mechanisms. The only distinction I make between them is that the automaton is guided by a program of discrete steps or directions fed into it, while the servo-mechanism is guided by observ- ing the effects of its action on the outside world. Thus a juke box which plays a number of selections in the order selected by the customer (in response to the buttons pushed) is an automaton, and so is an electronic computer. A target- seeking torpedo, on the other hand, or a gyroscope, I would call a servo-me- chanism. Both exhibit "purposefulness" and "intelligence," although if we ad- here to the intuitive popular meanings of these terms, the servo-mechanism seems to specialize in purposefulness and the automaton in intelligence. This seems so, because the automaton seems to be able to follow explicit directions, "When so and so, then so, unless so or so, in which case so . . ." (the program), while the servo seems to be guided by a goal. This difference is only apparent. To an outsider, the automaton may well seem to be guided by a "goal" ("Find the solution of this equation") while some one intimately familiar with the operation of a servo can describe its operation in terms of a program. This modern equivalence theories of of the "program" nervous system. and "goal" One is point the must principal be kept idea in of mind, the modern theories of the nervous system. One point must be kept in mind, however. Program and goal may be logically equivalent, but it does not by any 280</page><page sequence="10">Summer 1954 TECHNOLOGICAL MODELS OF THE NERVOUS SYSTEM means mean that a description of an operation of an organism or a machine is equally convenient in terms of one or the other. Let us take a trivial example. We wish a ball in a cup to "seek" to come to rest at a particular point. Here the desired behavior of the ball is described in terms of a "goal/' and nothing is simpler than to design a device which will exhibit just such behavior. Take a cup of any convex shape and place it so that the desired point is the lowest. To describe the same kind of behavior in terms of a "program" would necessitate an infinite number of statements, each of which tells which way the ball is supposed to move if it finds itself in a particular position. Such a description in terms of discrete statements (an explicit pro- gram) is, of course, out of the question. A description of "intermediate com- plexity," however, can be given, namely, as a set of differential equations of motion which imply a stable equilibrium at the desired point. Of the three descriptions clearly the first "stating the goal" of the ball is the simplest. What enables us to realize this "goal" by a mechanical device is our ability to see the problem as a whole. Similar considerations apply, I believe, to the theory of the nervous system. The first attempt to account for gestalt phenomena in strictly behaviorist terms was made by McCulloch and Pitts in 1943. They showed that any pattern of behavior which could be described by a program was realizable in an auto- maton of a specified construction and (herein lies the importance of their idea) they gave an "algorithm" for the construction of the automaton based on the program. Automata, of course, operate on the same principle. The limitations of this approach, however, are immediately evident. The whole difficulty is to describe the action of the nervous system in terms of a program of discrete ele- mentary steps. The task looks more hopeful if "goal seeking" steps are allowed in the de- scription of the program. If, for example, the construction of a mechanism for keeping a certain muscle tone constant is known, one of the directions in the program may read, "Plug in that mechanism." Thus with one stroke an immense number of elementary steps is "described." The value of information theory in this approach to the nervous system is now apparent. The McCulloch-Pitts picture represents behavior in terms of firing patterns of individual neurons. With IO10 neurons in the human body, there are 2 1010 such possible patterns at each instant of quantized time. This number is utterly unthinkable. Nothing whatsoever can be said of a system with that many distinguishable states where nothing is known about how the states are to be classified. To put it in another way, the amount of information per unit time needed to describe such a system is 1010 bits (the amount of information coming over an ordinary telegraph wire is considerably less than 5 bits per unit time) . It is quite another matter, however, when sub-systems are "organized" to work in pre- 281</page><page sequence="11">ETC.: A REVIEW OF GENERAL SEMANTICS vol. XI, NO. 4 scribed ways, when touched off by proper signals. The amount of organization of such subassemblies reduces the amount of information necessary to transmit over the channels. This havior consideration in organisms leads requires to two smaller complementary capacities conclusions. of channels Rigidity over which of be- in- havior in organisms requires smaller capacities of channels over which in- formation flows. Contrariwise, greater channel capacities allow for greater flexibility of behavior. We are thus led to ideas of the nervous system which involve not minute blueprint structures (a hopeless approach because of the tremendous com- plexity of the nervous system) but which involve over-all statistical concepts such as channel capacity, storage capacity, and other parameters familiar to the modern communication engineer, such as redundancy, signal-to-noise ratios, etc. They are concepts analogous to the over-all concepts in terms of which the operation of the "muscle engines" is understood: power, efficiency, compres- sion ratios, etc. It is the development of the corresponding over-all concepts of communica- tion and complexity which made intelligent machines possible and which gives us promise of future understanding of living behavior, particularly of the func- tions of the nervous system. I need not, I hope, emphasize that none of these considerations are relevant to the question of whether thinking machines "really think." I admit I do not understand the question. The really pertinent question is whether similar abstractions can be utilized in both the theory of intelligent machines and in the theory of living behavior, particularly that governed by the nervous system. We know that both organisms and machines receive, transmit, store, and utilize information. The question of how information is "utilized" is particularly interesting. We now know what food is used for: three things, namely, as a source of heat, a source of locomotive and chemical energy, and a source of materials for growth and restoring worn-out tissues. All these elements are being constantly dissipated by the organism: heat by conduction and radiation, energy by motion, materials through break down and excretion. Can it be that besides energy in the form of food and sunlight, organisms also feed on something called "information," which serves to restore the order, which is constantly being dissipated in accordance with the Second Law of Thermodynamics ? The formal mathematical equivalence between entropy (the measure of dis- order in a physical system) and information (as defined mathematically) was commented on by Shannon, Wiener, MacKay, and others. Can it be that this is no mere formal mathematical equivalence, such as obtains between an oscil- lating mechanical system and the analogous electrical one, but a more funda- 282</page><page sequence="12">Summer 1954 TECHNOLOGICAL MODELS OF THE NERVOUS SYSTEM mental equivalence such as that between heat and energy or between energy and matter? Can it be that 1.98 calories per degree mole (the difference in entropy between two moles of two separated perfect gases and two moles of their mix- ture in equilibrium) is actually equivalent to 6.06 x 1023 bits of information - the amount it would take to separate the mixture into the constituent parts in terms of yes-no decisions? If there is such a conversion factor, how do the information-receiving, in- formation-transmitting, and information-storing organs operate to convert in- formation into negative entropy or its concomitant "free energy" and, perhaps, vice versa? The take intriguing the study of nature communication of these questions nets from has the stimulated in formation- some theoretical of us to under- point take the study of communication nets from the in formation- theoretical point of view. This approach necessitates the description of such nets not in terms of detailed structure but rather in terms of gross statistical parameters. The flexi- bility and far-reaching adaptability of the behavior of higher organisms almost demands this sort of approach. Perhaps the most fundamental characteristic of living behavior as distinguished from that of man-designed machines is in the sacrifice of precision for safety. It is not important that a response be precise but rather that an equivalent response be given under a great variety of condi- tions or handicaps. It is more important to be "roughly" correct in practically every case than be "precisely" correct in every case but one and altogether wrong in that one. It is necessary to relate totally new situations approximately to situ- ations already experienced, and it is necessary to leave certain portions of the nervous system "uncommitted," so that new behavior patterns to meet new situations can be organized. When machines are built possessing these character- istics, we may expect an even closer analogy to the workings of actual nervous systems. That the day is not far off can be inferred from the fact that mathe- maticians like von Neumann already do not shirk from theoretical investiga- tions aimed at throwing light on the most typical of life processes - reproduction. I am referring to his recent calculations on the number of elements required in an automaton which can not only perform specific tasks assigned to it but also is able to reproduce itself, given a mixed-up aggregate of its elementary con- stituents. An actual materialization of such a machine would, of course, give startling reality to the prophecy in Butler's Erewhon. Such is the state of the present studies, which are extensions of the techno- logical analogies of the living process, particularly of the integrating functions of the nervous system. It is hoped that these studies are now approaching a level sufficiently sophisticated to yield enlightening and lasting results. 283</page></plain_text>
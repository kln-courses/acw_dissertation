<plain_text><page sequence="1">Learning Disability Quarterly 2011, Vol. 34, No. 1, 17-33 Â© 2011 Council for Learning Disabilities WINNER OF CLD'S 2008 AWARD FOR OUTSTANDING RESEARCH The following article was selected by CLD's Research Committee as the winner of the 2008 Award for Outstanding Research. Presented annually, this award is designed to promote and recognize doctoral or master's level research conducted within the last five years. Winners receive a certificate and a cash award during the J. Lee Wiederholt Distinguished Lecture at the International Conference on Learning Disabilities sponsored by the Council for Learning Disabilities. THE EFFECTS OF STRATEGIC MORPHOLOGICAL ANALYSIS INSTRUCTION ON THE VOCABULARY PERFORMANCE OF SECONDARY STUDENTS WITH AND WITHOUT DISABILITIES Monica L. Harris, Jean B. Schumaker, and Donald D. Deshler Abstract. This study tested the effects of teaching high school students with learning disabilities (LD) and other students enrolled in general education classes a morphemic analysis strat egy for analyzing and predicting the meaning of words. A com parison-group design was used with random assignment of three intact classes to each of two conditions: (a) the Word Mapping condition, where students learned the morphological analysis strategy; and (b) the Vocabulary LINCing condition, where stu dents learned a mnemonic strategy. Three other classes were used to establish a norm for knowledge of targeted words. Students in both strategy groups and students with and without disabilities learned their respective strategy and the meaning of taught words. Word Mapping students with and without disabilities earned higher scores on a test of morphological analysis than students in the other groups. Thus, students were able to learn generative and non-generative vocabulary strategies and could apply a generative strategy to analyze and create meaning for unknown words, an important skill while reading assignments and taking reading tests. MONICA L. HARRIS, Ph.D., Grand Valley State University, Grand Rapids, Michigan. JEAN B. SCHUMAKER, Ph.D., University of Kansas, Lawrence, Kansas. DONALD D. DESHLER, Ph.D., University of Kansas, Lawrence, Kansas. 17</page><page sequence="2">HARRIS ET AL. In the last couple of decades, notable progress has been made in improving the reading performance of young students in the United States (e.g., McCardle &amp; Chhabra, 2004), especially in the areas of phonemic awareness and decoding skills. However, the same kind of progress has not been made with adolescents (Deshler &amp; Hock, 2007). Currently, over eight million adolescents have not mastered the reading skills neces sary for responding to demanding secondary school requirements or competing for meaningful jobs in the workplace (Kamil, 2003). According to the National Assessment of Educational Progress (2005) results, 26% of eighth-grade students cannot read material essential for daily living, such as road signs, newspapers, and bus schedules. Overall, 68% of secondary students score below the proficient level in reading. Many of these stu dents are students with disabilities. One reason for the low reading scores of so many stu dents is that they have significant deficits in vocabulary knowledge (i.e., they score at least one standard devia tion below the mean). Students with disabilities earn even lower vocabulary scores than other struggling readers (Hock et al., 2009). The importance of vocabu lary knowledge to overall academic success, especially in the area of reading and oral comprehension, is well doc umented (e.g., Catts &amp; Kamhi, 1999; Nagy &amp; Scott, 2000; Snow, Porche, Tabors, &amp; Harris, 2007; Stahl, 1999). Recent reading reports (e.g., National Reading Panel, 2000; RAND Reading Study Group, 2002) have emphasized the central role of vocabulary in student achievement as well as the paucity of research on pro moting vocabulary acquisition (e.g., Stahl &amp; Nagy, 2006). Fortunately, a body of literature is emerging on vari ous instructional approaches to teaching vocabulary to students with high-incidence disabilities. For example, in their review, Bryant, Goodwin, Bryant, and Higgins (2003) organized studies on vocabulary instruction into the following categories: computer-assisted instruction, fluency-building vocabulary-practice activities, mne monic strategy instruction, and concept enhancement instruction. Similarly, Jitendra, Edwards, Sacks, and Jacobson (2004) organized vocabulary instruction under six headings: mnemonic strategy instruction, cognitive strategies instruction, direct instruction, constant time delay instruction, activity-based methods, and com puter-assisted instruction. For the purposes of this article, and for the sake of simplicity, instructional approaches for teaching vocab ulary will be characterized as either "generative" or "non-generative" (Fillmer, 1977; Harris, 2007; Nagy, 2005). Non-generative approaches are defined here as those designed for teaching students the meaning of a targeted word with the aid of a strategy and/or a device. While the specific strategy or device may be effective for learning the meaning of the targeted vocabulary word (and the strategy may be generalizable by the student to other specifically targeted words), through this instruc tional technique, students do not learn the meaning of several words as a result of learning the meaning of that one word. For example, teaching a student a mnemonic (memory) device for remembering the meaning of a tar geted word (e.g., dictate - to tell or say something for another person to write down) may enable the student to form associations between the new word and famil iar people, objects, or events in the student's life related to the meaning of that word (e.g., "I told Judy Tate, the school secretary, what to write"). This association helps the student to remember the meaning of the word. However, teaching such a mnemonic device does not teach a student the meaning of several new words. In contrast, a generative approach to vocabulary learning is defined as one that not only teaches students the meaning of a given word, but also allows them to unlock the meaning of new words that are related to the word. For example, teaching students the meaning of the word dictate ("along with the meaning of the root word diet (i.e., "to say or talk") might allow a student to unlock or predict the meaning of many words in the word family that contains the root word diet (e.g., dicta tion, dictator, dictaphone, prediction). Even though non-generative approaches have been shown to be effective (e.g., Bryant et al., 2003; Jitendra et al., 2004), they may not be the most practical approaches to use with adolescents who have large vocabulary deficits. Vocabulary research indicates that students can learn approximately 10 new words per week using the non-generative methods described above (Stahl &amp; Fairbanks, 1986). Assuming 36 weeks in a school year and strict adherence to a schedule of 10 words per week, students might learn approximately 360 new words per year. This is a relatively small num ber compared to the number of words they need to learn to keep pace with peers. For example, Anglin, Miller, and Wakefield (1993) projected that a normative group of students learned about 20,000 words between third and fifth grade. Given the limited vocabulary of most struggling learners and the thousands of words that they need to learn to close the gap between their performance and that of their normally achieving peers, strategies that teach students only one word at a time (and only a few words per week) lack the power to build their vocabulary at a sufficiently fast rate (Nagy &amp; Anderson, 1984; Nagy &amp; Herman, 1987). One generative approach that could potentially be used to provide the kind of vocabulary instruction stu dents with learning disabilities (LD) need in order to learn the meaning of thousands of words is called mor</page><page sequence="3">MORPHOLOGICAL ANALYSIS INSTRUCTION phemic analysis instruction (Blachowicz &amp; Fisher, 2000; Ebbers &amp; Denton, 2008; Graves, 1986; Nagy &amp; Scott, 2000). Morphemic analysis involves deriving the mean ing of a word by combining the meaning of the parts of the word (or morphemes) (Spencer, 2001). The word parts with meaning include (a) prefixes, (b) suffixes, and (c) roots. According to Nation (1990), morphemic analysis involves three skills: (a) breaking a new word into its morphological parts, (b) connecting a meaning to each of those parts, and (c) combining the meanings of the parts to determine the word's definition. Morphemic analysis is thought to be a useful vocabu lary-learning tool because, as Nagy and Scott (2000) esti mated, "about 60 percent of the new words a student encounters in reading are analyzable into parts that give substantial help in figuring out their meanings" (p. 275). Some authors (Nation, 1990; Sirles, 1997) have suggested that learning the meaning of Greek and Latin roots is critical because estimates regarding the number of words that are derived from Greek and Latin roots range from approximately 50% (Moore &amp; Moore, 1997) to as much as 65% of what is termed our academic vocabulary (Sirles). Thus, teaching one word part, like a root (e.g., port), has the potential to enable students to unlock the meaning of many words since word families comprised of as many as 20 to 30 words tend to be organized around a given root (Baumann &amp; Kame'enui; 2004; Graves, 2006; Marzano, 2004; Nagy &amp; Anderson, 1984; Nation; Stahl &amp; Nagy, 2006; White, Power, &amp; White, 1989). Some descriptive studies have shown that students generally develop morphological analysis skills as they get older (e.g., Biemiller &amp; Slonim, 2001; Reed, 2008; White, Power, &amp; White, 1989). For example, Anglin et al. (1993) conducted a study with 96 students in grades one, three, and five and asked each student a series of questions about the meaning of words. They found that student knowledge of root words, inflected words, derived words, and literal compounds significantly increased across the age groups as the students got older. Nagy, Diakidoy, and Anderson (1993) conducted a similar study with 630 fourth, seventh, and tenth graders on their knowledge of derivational suffixes. Nagy et al. reported a significant main effect for grade, with older students performing significantly better than younger students. More recently, Nagy, Berninger, and Abbott (2006) investigated the contribution of morpho logical awareness along with other components of read ing (e.g., phonological memory, decoding, reading vocabulary) to literacy outcomes of 607 students in grades four through nine. They found that morpholog ical awareness was a significant contributor to literacy outcomes, specifically reading comprehension. Addi tionally, the researchers showed that student knowl edge of morphology was greater in students enrolled in grade four than in younger students and continued to improve across the grades. Unfortunately, none of the above studies disaggregated the results for students with disabilities from other students' results, so there is no information on how knowledge of these types of words or word parts develops in students with disabilities. A few intervention studies conducted with students in grades three through eight have shown that students can be taught to identify some morphemic elements (e.g., prefixes and roots) (Otterman, 1955) and to derive the meaning of words using morphemic elements (Jenkins, Matlock, &amp; Slocum, 1989; White, Power, &amp; White, 1989; White, Sowell, &amp; Yanagihara, 1989). In only one study, students were taught a set of steps to follow for morphological analysis. Baumann, Edwards, Boland, Olejnik, and Kame'enui (2003) conducted this study with 157 students in 8 fifth-grade social studies classes. Experimental-group students received instruc tion related to a total of eight prefixes and suffixes, along with example words to which those word parts may be added. Students were also taught four steps for analyzing the meaning of a word using word-part clues: (a) look for the root word and remember its meaning, (b) look for a prefix and remember its meaning, (c) look for a suffix and remember its meaning, and (d) combine the meanings to build the meaning of the whole word. The control group was taught a different set of words derived from their textbook. They used a dictionary to find word meanings and completed a variety of activi ties (e.g., semantic mapping and comparing and contrasting words). Measures included (a) a textbook vocabulary test, (b) a morphemic transfer-word and word-part test, and (c) a vocabulary and context test requiring morphemic analysis of word-part meanings in sentences. Students in the experimental group earned statisti cally higher scores than students in the control group on the morphemic transfer-word and word-part test. There was no statistically significant difference between the groups with regard to inferring the meaning of words presented in sentences. On a delayed administra tion of the latter test, the experimental group earned significantly higher scores than the control group, but their mean score was only 1.8 points higher than the mean score of students in the control group. Since the two groups of students received instruction in two dif ferent sets of words, it is not possible to project whether the morphological analysis or the word sets produced the differences. Most of the intervention studies conducted in this area have employed multiple-choice measures. No studies have (a) focused on morphological analysis</page><page sequence="4">HARRIS ET AL. Table 1 Demographic Data on Students With Disabilities (SWD) Category Total Number of Participants (N = 24) Gender Male Female Ethnicity Caucasian African Am. Hispanic Multi-ethnic Am. Indian Asian Disability Category11 LD ED MR OH AU WMa N % 10 42 6 60.0 4 40.0 3 30.0 5 50.0 1 10.0 0 0.0 1 10.0 0 0.0 6 60.0 1 10.0 1 10.0 2 22.0 0 0.0 VLb N % 6 25 3 50.0 3 50.0 2 33.3 3 50.0 1 16.7 0 0.0 0. 0.0 0 0.0 4 67.0 0 0.0 0 0.0 2 33.0 0 0.0 TO0 N % 8 33.0 7 87.5 1 12.5 3 37.5 3 37.5 2 25.0 0 0.0 0 0.0 0 0.0 6 74.0 1 13.0 0 0.0 0 0.0 1 13.0 Achievement Scores (SAT-10) Vocabulary Reading Comp. Total Reading Mean Mean SS (SD) Percentile 657 (21) 25th 652 (40) 36th 653 (27) 30th Mean Mean SS (SD) Percentile 654 (44) 25th 624 (13) 13th 633 (20) 15th Mean Mean SS (SD) Percentile 692 (46) 51st 658 (40) 39th 669 (39) 42nd # of Mean # of Mean # of Mean Students SS (SD) Students SS (SD) Students SS (SD) Ability Scores (WISC-II1) V 7 81 (18) 6 87 (14) 4 112 (17) P 7 91 (19) 6 88 (19) 4 100 (18) FS 7 85 (19) 6 90 (13) 4 106 (18) Note. aWM = Word Mapping Group; bVL = Vocabulary LINCing Group; "TO = Test-Only Group. dLD = Learning Disability; ED = Emotional Disability; MR = Mental Retardation; OH = Other Health Impairment; AU = Autism Spectrum Disorder. Table 1 Demographic Data on Students With Disabilities (SWD)</page><page sequence="5">MORPHOLOGICAL ANALYSIS INSTRUCTION instruction within general education classes with heterogeneous groups of students (including students with disabilities), (b) disaggregated the data for stu dents with disabilities from other students' data, (c) assessed student prediction of word meanings using an open-ended measure, and (d) compared the effects of generative versus non-generative vocabulary inter ventions. The purpose of this investigation was to develop and test the effects of an intervention for teaching high school students with disabilities and other students enrolled in heterogeneous general education English classes a morphemic analysis strategy for analyzing and predicting the meaning of words. The effects of instruc tion in this generative strategy were tested against the effects of teaching students a non-generative vocabu lary-learning strategy. Targeted open-ended measures were student strategy use, knowledge of taught words, knowledge of word parts, as well as student ability to predict the meaning of untaught words. Method Participants Participants included 230 public-school students whose parents had given consent for them to partici pate in the study and who were enrolled in nine ninth grade English classes. Two subgroups of students participated: students with disabilities (SWDs) and stu dents without disabilities (NSWDs). SWDs were stu dents who had active IEPs; NSWDs were students who did not have IEPs. Stanford Achievement Test (SAT-10) data, including vocabulary scores and reading compre hension scores, plus demographic information were collected from school records for all participating stu dents (see Tables 1 and 2). In addition, IQ data were collected for the SWDs, where available (see Table 2). The nine classes were taught by three teachers. Two teachers agreed to allow the first author to come into their six classes to teach their students and to set aside class time for their students to participate in the exper imental interventions. These six intact classes were ran domly assigned to one of two groups: the Word Mapping (WM) group (the generative vocabulary inter vention) and the Vocabulary LINCS Strategy (VL) group (the non-generative vocabulary intervention). The third teacher did not want her students to miss any part of the regular curriculum and, therefore, did not participate in the experimental intervention, but she did agree to allow her three classes to participate in the study as a normative comparison group. Her decision was supported by the principal. Thus, her three classes served as the Test-Only (TO) group. There were 10 SWDs in the WM group, 6 in the VL group, and 8 in the TO group (see Table 1 for their dis ability categories, demographic data, and test data). The majority of these students had LD, for a total of 69 NSWDs in the WM group, 73 in the VL group, and 64 in the TO group. To determine any differences between the three groups with regard to the data in Tables 1 and 2, chi-square tests and one-way ANOVAs were con ducted. The Pearson's chi-square results showed that there were no significant differences between the groups with respect to gender, /2(2) = 3.39, p = .184, or ethnicity, %2(10) = 4.33, p = .931. Similarly, the one-way ANOVAs revealed no significant differences among the groups on the vocabulary achievement standard scores on the SAT-10 (SWDs, F(2,21) = 2.584, p = .099; NSWDs, F(2,203) = 2.329, p = .100) and full-scale scores from the WISC-III (SWDs only, F(2,14) = 1.950, p = .179). Setting The participating school district is located in an urban midwestern community with a population of approxi mately 124,000. The participating high school serves 1,687 students, 46.1% of whom receive free or reduced price lunches. The study took place in the students' regularly assigned general education "inclusive" class rooms for their ninth-grade English course. These were typical classrooms furnished with rows of desks that accommodated between 28 and 32 students in each class. To aid instruction, the instructor used an over head projector and a screen at the front of the room in addition to chalkboards. The Vocabulary Strategies The Word Mapping Strategy. The Word Mapping Strategy (WMS), the generative morphemic analysis strategy taught to students in the WM group, is a set of cognitive and behavioral steps students can use to pre dict the meanings of unknown words. The mnemonic device MAPS helps students learn and remember the names of the steps. The strategy involves (a) Step 1 - breaking words into their morphemic parts (i.e., prefix, suffix, root); (b) Step 2 - attaching meaning to each word part; (c) Step 3 - making a prediction about the meaning of the unknown word based upon the mean ing of each part; and (d) Step 4 - checking the diction ary for the definition. The Word Map (Figure 1) is a graphic device used to prompt students through the steps of the strategy. Specifically, for the first step, students write the new word to be analyzed in the top box. In the next level of boxes, they write the word parts (i.e., prefix, root, suf fix). In the third level of boxes is space for writing the meaning of each word part during the second strategy step. The final box provides a place to predict the mean ing of the word during the third strategy step by blend ing the meanings of all parts together. Students can adjust the meaning of the word in this final box after</page><page sequence="6">HARRIS ET AL. Table 2 Demographic Data on Students Without Disabilities (NSWD) Category WMa N VLb N TOc N Total Number of Participants (N = 206) 69 33 73 35 64 32 Gender Male Female 37 32 53.6 46.4 31 42 42.5 57.5 34 30 53.1 46.9 Ethnicity Caucasian African Am. Hispanic Multi-ethnic Am. Indian Asian 29 23 12 2 2 1 42.0 33.3 17.4 2.9 2.9 1.4 25 23 19 5 1 0 34.2 31.5 26.0 6.8 1.4 0 19 26 14 2 1 2 29.7 40.6 21.9 3.1 1.6 3.1 Achievement Scores (SAT-10) Vocabulary Reading Comp. Total Reading Mean SS (SD) 694 (44) 679 (36) 683 (34) Mean Percentile 53rd 56th 55th Mean SS (SD) 689 (43) 672 (37) 677 (36) Mean Percentile 47th 49th 48th Note. aWM = Word Mapping Group; Â°VL = Vocabulary LINCing Group; TO = Test-Only Group. Mean SS (SD) 679 (33) 670 (34) 673 (31) Mean Percentile 42nd 47 th 45th Table 2 Demographic Data on Students Without Disabilities (NSWD) they check its meaning in the dictionary. This final part of the strategy allows students to check their predictions against a source and gather feedback for themselves about the accuracy of their predictions. Vocabulary Strategy. The Vocabulary (LINCS) Strat egy (Ellis, 1992), the non-generative vocabulary strat egy taught in this study, is a set of cognitive and behavioral steps that students can use to help memo rize and recall the meanings of vocabulary words. This process involves the use of a set of mnemonic strategies that include (a) a keyword strategy, (b) a visual imagery strategy, (c) a story strategy to link known words and information to new vocabulary words and their defini tions, and (d) a self-testing method used while practic ing recalling the meaning of the word. The mnemonic device LINCS helps students remember the steps. In the first step of the strategy, students write the word and its definition. Second, students identify a Reminding Word that sounds or looks like the new word. Third, students create a LINCing Story, a state ment or phrase that includes both the Reminding Word and the definition. Next, students draw a picture that includes the important parts of the story. Finally, they self-test using a procedure that helps them recall both the word and its meaning. During this self-test proce dure, the students say the word to themselves, think of the Reminding Word, think of the LINCing Story, think of the picture, and then remember the definition.</page><page sequence="7">MORPHOLOGICAL ANALYSIS INSTRUCTION Alternatively, they do the self-test process in reverse by saying the definition to themselves and then thinking of the picture, the story, the Reminding Word, and then the original word. As students follow the LINCS Steps, they fill in a graphic device called the LINCS Table (Ellis, 2001) (see Figure 2). In the top half of the far-left box is a space for students to write the vocabulary word to be learned. Directly below that is a place for students to write a Reminding Word; that is, a word that sounds or looks like all or part of the new word. To the right of the above-mentioned boxes is a place for students to write a brief story. Directly to the right of this box is a place for the student to draw a picture of the story. Finally, in the box farthest to the right is a space for writing the defi nition of the word. Students can fold the device for use during the self-test process so that they can see only the word or the definition, depending on which self-test process they are using. Measurement Instruments1 Fidelity of Treatment Checklists. A fidelity checklist was used to assess the quality of teacher performance in implementing the instruction for each of the two strate gies described above. Each checklist consisted of 10 items, representing all the instructional practices associ ated with a given strategy. Each of the items specified a teacher behavior, such as cueing students to fill in the device or modeling each sequential step of the strategy. One point was given for each item correctly performed. An observer used the checklist during randomly chosen class sessions. All observed sessions were also video taped for reliability purposes. A percentage score was calculated for each type of instruction by dividing the number of points earned across all the checklists for that instruction by the number of points available and multiplying by 100. Strategy-Use Tests. A Strategy-Use Test was used to measure student knowledge and use of the two strate gies before and after instruction to determine whether students learned what they had been taught. Students who learned the WMS took the Word Mapping test; stu dents who learned the Vocabulary Strategy took the Vocabulary LINCS test. Each test was comprised of two forms (A and B), containing different words matched across the forms by the number of syllables per word.2 A counterbalanced approach was used to control for dif ficulty of the forms. For the pretest for each test, Form A was administered to half of the students, whereas Form B was given to the other half of the students. For the posttest, Form B was administered to students who completed Form A during the pretest; Form A was administered to the other half of the students. The words that appeared on the two tests were not the same, nor were the words that appeared on different forms of each test. (The tests were designed to measure student use of the strategy that they learned, not their knowl edge of the meaning of words.) The words were chosen because their characteristics fit the strategies used. For example, all the words on the Word Mapping Test had prefixes and roots. Some had suffixes. The words on the LINCS Test had word parts for which students would be able to think of Reminding Words. All the words were words found in textbooks related to vocabulary learning that had been specified as difficult words. The Word Mapping Test measured student ability to use the WMS. It consisted of 10 questions. The first six items provided an unknown word and required stu dents to fill in a Word Map to (a) identify the mor phemes in the word, (b) specify the meaning of each morpheme, and (c) make a prediction of each word's meaning. The last four items required students to write the types of morphemes, rules for morphemes, the rules for identifying roots, and the steps of the WMS. The number of points awarded for first six items varied (range = 5 to 7 points for each), depending upon the number of word parts in each word; a total of 10 points was available for the last four items. A total of 48 points was possible for the whole test. Each Vocabulary LINCS Test also included 10 ques tions. The first six items provided LINCS Tables, each containing a word and its definition. Students had to record a Reminding Word, create a brief LINCing Story, and draw a picture for each word. The last four items required students to provide rules for creating good Reminding Words, LINCing Stories, and pictures, and to write the steps of the Vocabulary LINCing Strategy. The first six items on this test were each worth 6 points (2 pts. for each part of the LINCS Table). The last four items were awarded a total of 11 points, for a total of 47 points for the entire test. An answer key was used to score each of the Strategy-Use Tests. The Strategy-Use score was the percentage of points earned on a given test. Word Knowledge Test. The Word Knowledge Test measured student knowledge of the 20 target words that were taught to both the WM and VL groups.3 All 20 words contained word parts that were targeted for instruction. They each had at least one high-frequency Greek or Latin root and a prefix and/or a suffix. Half of the words had a Greek or Latin root with both a prefix and a suffix. For instructional purposes, the words were divided into two matched lists of 10 words each (Word List #1 and #2), based on the number of word parts they contained. Each of 20 items on the Word Knowledge Test con tained one of the target words and three prompts that required students to (a) write any information they con nected with the word, (b) use it in a sentence, and/or (c)</page><page sequence="8">HARRIS ET AL. Figure 1. The Word Map used in conjunction with the Word Mapping Strategy Steps. S ee if you are right! Figure 1. The Word Map used in conjunction with the Word Mapping Strategy Steps.</page><page sequence="9">MORPHOLOGICAL ANALYSIS INSTRUCTION Figure 2. Example LINCS Table. (T") Term palisades (^T^Reminding Word pal LINCing Story My pal, Joe, dove from the cliff into the LINCing Picture ) Definition A line of steep cliffs a long a river or ocean. Figure 2. Example LINCS Table. define it (Stahl, 1999). The same test served as pretest and posttest. The posttest was administered a week after instruction had ended. One point was given if students wrote correct definitional information about the word in response to any of the three prompts according to an answer key, for a total of 20 points. A percentage score was calculated. Morphological Analysis Test. The Morphological Analysis Test assessed students' ability to identify word parts within untaught words, specify the meaning of the word parts, and predict the meaning of the words. This single test was administered twice to all students, once before and once after instruction. It consisted of 14 items, each containing a word and an accompanying table with columns and rows on which students could write their responses. The words4 were not taught at any time during either intervention. The table was struc turally different from the Word Map and the LINCS Table and was not used during either intervention. It included three parts: spaces for identification of word parts, spaces for recording the meaning of word parts, and a space for predicting the unknown word's mean ing. A range of 2-7 points could be awarded for each item, depending on the number of word parts in the entire word. The 14 untaught words contained word parts that were directly taught to the students in the WM group. These same word parts were included in the words taught to both groups, but the word parts were not directly taught to students in the VL group. A total of 88 points was possible. An answer key was used to score the tests. A percentage score was calculated. Satisfaction Questionnaires. Two satisfaction ques tionnaires were administered to determine if the WM and VL students were satisfied with the instruction and the strategy they had learned. Each question naire included seven items to be rated on a 7-point Likert scale ranging from "Completely Satisfied" (7) to "Completely Dissatisfied" (1). Example questions for the WM group asked students how satisfied they were with their ability to identify words' parts and their ability to predict word meaning. Example questions for the VL group asked students to indicate how satisfied they were with their ability to create Reminding Words and to use the strategy to learn the meaning of new words. A mean rating was calculated for each group on each item. Interscorer Reliability. Interscorer reliability was determined by having two trained independent scorers score a randomly selected sample (20%) of each of the tests and each of the videotape records of the observed lessons. Both the primary scorer and the reliability scor ers were blind to the purpose of the study, the assign ment of the students to groups, and the time of testing (pretest vs. posttest). A side-by-side item analysis was used to determine agreements for each instrument. On the Fidelity Checklists, scorers agreed on 111 out of 120 opportunities to agree for 93% agreement (range = 80% to 100% on individual lessons). For the Strategy-Use Tests taken by the WM group, including Forms A and B, scorers agreed on 2,120 out of 2,208 total opportunities to agree, for a 96 percentage of agreement (range = 88% to 100% for Form A; range = 94% to 100% for Form B). For the Strategy-Use Tests taken by the VL group, scor ers agreed on 2,153 out of 2,208 total opportunities to agree for a percentage of agreement of 97.5 (range = 94% to 100% for Form A; range = 96% to 100% for Form B). On the Word Knowledge Tests, scorers agreed on 846 out of 920 opportunities to agree for 94% agreement</page><page sequence="10">HARRIS ET AL. (range = 86% to 100% on individual tests). On the Morphological Analysis Tests, scorers agreed on 3,809 out of 4,140 opportunities to agree for 92% agreement (range = 84% to 100% on individual tests). Procedures Pretest Procedures. For the WM and VL groups, pretests were group administered during two class peri ods (90 minutes each) in which all participants were given as much time as they needed to complete the tests. The tests were administered in the following order: (a) Word Knowledge Test, (b) Morphological Analysis Test, and (c) Strategy-Use Test. For the Test Only control group, only two tests were administered during a 90-minute class period: the Word Knowledge Test and the Morphological Analysis Test. The Strategy Use Test, which was designed to determine whether stu dents learned the strategy they were taught, was not given to the TO group since these students did not receive instruction in either strategy. Common Instructional Procedures. The instruction for the WM and VL groups was carried out by the first author, a certified general and special education teacher with 10 years of teaching experience at the secondary level. Instruction for each group took place over 10 les sons; each lesson was 45 minutes long, for a total of 450 minutes or 7.5 hours. The lessons for each group occurred in three phases: (a) Phase I - Orientation, (b) Phase II - Instruction of Vocabulary Word List #1, and (c) Phase III - Instruction of Vocabulary Word List #2. Word Mapping Instruction. During Phase I instruc tion for the Word Mapping Strategy (Orientation), the instructor (the first author) conducted four lessons that focused on the following: prefixes, suffixes, roots, and the Word Mapping Strategy Steps. Cue cards were used to convey information about each topic visually. In addition, the instructor presented the information orally, and students were asked to fill in the blanks on note-taking sheets. Each of the lessons included activi ties that involved identifying morphemes and practic ing looking up morpheme meanings. The instructor described and modeled the process, enlisted student help in the process, and provided opportunities for group and individual practice using worksheets created specifically for each lesson's focus (e.g., finding prefixes in words in Lesson #1, finding suffixes in words in Lesson #2, finding root words in Lesson #3).5 The last lesson of this phase focused on the specific steps of the Word Mapping Strategy. The instructor used the Word Map in this lesson to introduce the sequential process for analyzing and predicting the meaning of unknown words and modeled what to do for each step, using an example word. During Phase II instruction, which lasted for three les sons, the steps of the Word Mapping Strategy were reviewed, and students practiced using the strategy with the target words on Vocabulary Word List #1. During guided practice, the instructor displayed a blank Word Map, wrote the first word at the top of the map, and prompted students to "Map out the parts" by entering the prefix, suffix, and root in the appropriate boxes on their own blank forms of the Word Map. Students were called upon to contribute the word parts. After the parts of the unknown word had been mapped by the class, students were prompted to "Attack the word part mean ings" by looking up the meaning of each part using lists of the meanings of prefixes, suffixes, and roots. As each meaning was found and contributed by a student, the instructor wrote it into the appropriate box on the Word Map for students to copy. Students were then prompted to use the meanings of all the mapped word parts to "Predict the word's meaning" by starting with the root and adding the meanings of the prefix and then the suffix. The students were prompted to figure out how the meanings might fit together and to make a prediction for the definition of the whole word. Students contributed predictions and decided which was best; they wrote their own prediction (or the one they liked best) on their Word Map. Finally, after they had made a prediction, students were prompted to "See if you're right!" by checking with a friend or the teacher, or by looking the word up in the dictionary. After the four strategy steps were completed, the process was started over with the next target word on the list. Phase III instruction was carried out like the instruc tion during the three Phase II lessons, but now students applied the strategy to target words on Vocabulary Word List #2 with a partner. Typically, three to four words could be "mapped" during each lesson, includ ing student practice in completing each Word Map, students working together to identify the word parts and fill in the meanings of each word part, and collab orating in pairs to make an educated guess or predic tion, based upon the morphological meanings derived. The class then came back together as a whole group to share the meanings of the word parts and students' pre dictions of the meaning of each target word, to check the word's meaning, and to adjust their predictions, as needed, to align with the word's actual definition. Vocabulary Strategy Instruction. Instruction for the Vocabulary Strategy took place in three phases. Again, the instruction was provided by the first author. During the Phase I instruction (Orientation), which lasted for four lessons, the instructor used cue cards to describe the steps of the strategy. She also modeled all the strat egy steps, enlisting student help in the process, and provided opportunities for individual and group prac tice using LINCS Tables and a few example words.</page><page sequence="11">MORPHOLOGICAL ANALYSIS INSTRUCTION During Phase II, which lasted for three lessons, the steps of the Vocabulary Strategy were reviewed, and LINCS Tables were made for three to four words per lesson from Vocabulary List #1 through a whole-group guided-practice activity. The instructor displayed the LINCS Table (see Figure 2) and wrote the new word and its definition in the appropriate boxes. Students filled in their own LINCS Tables at their desks. Next, stu dents, as a group, "Identified a Reminding Word" by thinking of a word that sounded and/or looked like the new word and writing it in the proper space. Then, stu dents "Noted a LINCing Story" by using the Reminding Word and the definition of the new word to create a brief sentence or two to help them remember the mean ing of the new word. Next, they each "Created a LINCing Picture" by drawing a picture of the story they had just created. Finally, students quizzed themselves over the words using the "self-test" process. After completing the five steps, the process was repeated for the next target word. After LINCS Tables were created for the words scheduled for a given day, students quizzed each other on the words learned thus far using the self-test procedure in two directions: self testing forward and self-testing backward. "Self-testing forward" consisted of the following steps: say the new word, think of the Reminding Word, think of the LINCing Story, think of an image, think of the mean ing of the new word, and check if you are correct. "Self testing backward" consisted of saying the definition of the new word, then thinking of the image, the LINCing Story, the Reminding Word, and the new word, respectively. Phase III procedures were carried out in the same manner as during Phase II but using the words on Vocabulary Word List #2 and with students working with partners. Typically, three to four words could be covered during each lesson, including student practice in completing each LINCS Table. Students collaborated in pairs to create Reminding Words, LINCing Stories, and images for each word. Then the class came back together as a whole, and student volunteers shared their creations. Students readjusted their LINCS Tables, as needed, based on the discussion. Test-Only Group Procedures. The TO group received instruction in the traditional ninth-grade English cur riculum without any specific instruction in vocabulary strategies. The students' regularly assigned teacher pro vided the instruction. The teacher emphasized vocabu lary words pertinent to what she was teaching at the time. No specific strategy or instruction was given to help students learn the definitions of the words. Posttest Procedures. Posttesting occurred in the same manner as pretesting. Students did not have access to any word-part lists during the tests. Research Design and Data Analysis A pretest-posttest comparison-group design with ran dom assignment of three intact classes to each of two conditions (Word Mapping Strategy or Vocabulary Strategy) was employed to determine the effects of instruction on students' strategy use and vocabulary knowledge. A third group of three classrooms was des ignated as a "test-only" group in order to establish a norm for knowledge of targeted words and growth over the course of the study. For the Strategy-Use Test, where students in the WM and VL groups took different tests, a separate repeated measures ANOVA with one between-subjects factor (subgroup: SWDs and NSWDs) was conducted for each strategy group (WM and VL) to examine changes from pretest to posttest. If a two-way interaction (Subgroup x Time) was revealed at the .05 level, a separate paired sample t-test was performed within each subgroup to determine whether gains made by the subgroup were significant. For the other measures (the Word Knowledge Test and the Morphological Analysis Test), where students in the WM, VL, and TO groups took the same test, a series of repeated-measures ANOVAs with two between-subjects factors (group [WM, VL, and TO] and subgroup [SWDs and non-SWDs]) was conducted to examine changes from pretest to posttest. If the three-way (Time x Subgroup x Group) interac tion was revealed for a given test at the .05 level, a series of follow-up tests was conducted. First, the file was split on "subgroup," and two repeated-measures analyses were conducted (i.e., one for SWDs and one for NSWDs). If the Time x Group interaction was signifi cant at the .025 level, a paired-sample f-test was con ducted for each subgroup. The level of significance was set at the .006 level. If the three-way interaction was not significant at the .05 level, 2, two-way interactions (Time x Subgroup, and Time x Group) were examined. If a two-way interaction was found to be significant at the .25 level, further follow-up tests were conducted by splitting the file on subgroup and utilizing paired-sam ple t-tests. The alpha level for subgroup was set at .006. To examine differences between the posttest scores of the WM, VL, and TO groups on the Word Knowledge and Morphological Analysis Tests, a two-way ANCOVA with two between-subjects factors (Group x Subgroup) was conducted for each measure, with the pretest scores serving as the covariate. If a two-way interaction was revealed at the .05 level, the file was split on subgroup, and 2 one-way ANCOVAs were conducted: one for the SWDs and one for the NSWDs. If the main effect of group was significant at the .025 level, further follow-up analyses were conducted using a Bonferroni adjustment for all comparisons at the .006 level.</page><page sequence="12">HARRIS ET AL. Results Fidelity of Treatment Results Each class within each treatment group was observed three times. A total of 2,700 minutes (45 hours total or 7.5 hours per class) of instructional time was recorded. Results indicated that the instructor implemented an average of 96% of the required instructional behaviors across the WM lessons vs. an average of 98% across the VL lessons. Group Equivalencies and Pretest Results Pretest scores were compared across the three groups on the tests using ANOVAs. No statistically significant difference was found for any test: (a) Strategy-Use Test, F( 1,157) = 2.55, p = .112; (b) Word Knowledge Test, F(2,229) = .003, p = .997; and (c) Morphological Analysis Test, F(2, 229) = 1.37, p = .256. Strategy-Use Test Results Table 3 displays the means and standard deviations for the pretest and posttest results for the two Strategy Use Tests administered separately to the WM and the VL group. With regard to the two-way interaction for the WM group, the Time (pretest and posttest) x Subgroup (SWD and NSWD) interaction was not signif icant, Wilks' A = .997, F(l,77) = .20, p = .660, partial \]z = .003. However, the main effect of time (posttest vs. pretest) was found to be statistically significant, Wilks' A = .075, F(1,77) = 947.03, p &lt; .001, partial r\2 = .925 (a large effect size). With regard to the two-way interaction for the VL group, the Time x Subgroup interaction was not signifi cant, Wilks' A = .995, f(l,77) = .425, p = .516, partial r\2 - .005. The main effect of time (posttest vs. pretest) was statistically significant, Wilks' A = .262, F(l,77) = 217.184, p &lt; .001, partial r\2= .738 (a large effect size). Word Knowledge Test Results The Word Knowledge Test Results are presented in Table 4. With regard to changes from pretest to posttest, the three-way interaction of Time x Subgroup x Group was found to be significant, Wilks' A = .964, f(2,224) = 4.138, p = .017, partial r\2 = .036 (a small effect size). When the file was split on subgroup, the Time x Group interaction was significant for the SWDs, F(2,21) = 12.90, p &lt; .001, partial r\2 = .563 (a large effect size), and for the NSWDs, f(2,203) = 367.388, p &lt; .001, partial ri2 = .780 (also a large effect size). The paired-sample f-tests revealed a significant differ ence between the pretest and posttest scores for the SWDs in the WM group, t(9) = -6.280, p &lt; .001, d = 4.264, and for the NSWDs in the WM group, f(68) = -29.626, p &lt; .001, d = 8.259 (both are large effect sizes). Additionally, significant differences were found between the pretest and posttest scores for the SWDs in the VL group, Â£(5) = -5.391, p = .003, d = 4.226, and for the NSWDs in the VL group, Â£(72) = -26.879, p &lt; .001, d = 6.299 (both are large effect sizes). No differences were found for the TO subgroups. With regard to group differences on the posttest scores on the Word Knowledge Test, the two-way inter action (Group x Subgroup) was significant, F(2,224) = 4.551, p = .012, partial x\2 = .039 (a small effect size). When the file was split on subgroup, the main effect of group was statistically significant for both the SWD sub group, F(2,21) = 12.9, p &lt; .001, partial r|2 = .563 (a large effect size), and the NSWD subgroup, F(2,203) = 367.388, p &lt; .001, partial r\z = .784 (a large effect size). Pair-wise comparisons revealed that there was not a sig nificant difference between the posttest scores of the SWDs in the WM group and the SWDs in the VL group, F(l,21) = .773, p = .390, partial r\2 = .037; however, there was a significant difference between the posttest scores of SWDs in the WM group and the posttest scores of the SWDS in the TO group, F(l,21) = 24.056, p &lt; .001, par tial r|2 = .546 (a large effect size). Additionally, there was a significant difference between the posttest scores of the SWDs in the VL group and the posttest scores of the SWDs in the TO group, F(l,20) = 12.589, p &lt;.01, partial r|2 = .386 (a moderate effect size). Further, there was no significant difference between the posttest scores of the NSWDs in the WM group and the scores of the NSWDs in the VL group, F(l,202) = .902, p = .343, partial r\2 = .004, but a significant difference was found between the scores of the NSWDs in the WM group and the scores of the NSWDS in the TO group, F(l,202) = 574.539, p &lt; .001, partial r\2 = .740 (a large effect size). Finally, there was a significant difference between the posttest scores of the NSWDs in the VL group and the posttest scores of the NSWDs in the TO group, F(l,202) = 543.479, p &lt;.001, partial r|2 = .730 (a large effect size). Morphological Analysis Test Results The means and standard deviations for the Morphological Analysis pretest and posttest scores are presented in Table 4. With regard to changes between pretest and posttest scores, the three-way interaction of Time (pretest to posttest) x Subgroup (SWD and NSWD) x Group (WM, VL, and TO) was significant, Wilks' A = .943, F(2,224) = 6.780, p &lt; .01, partial r\2 = .057 (a medium effect size). When the file was split by sub group, the Time x Group interaction was significant for the SWD subgroup, Wilks' A = .613, F(2,21) = 6.630, p &lt; .01, partial r|2 = .387 (a large effect size), and for the NSWD subgroup, Wilks' A = .287, F(2,203) = 251.790, p &lt; .001, partial r|2 = .713 (a large effect size). Paired-sam ple Â£-tests revealed a significant difference between the pretest and posttest scores for the SWDs in the WM group, Â£(9) = -3.45, p &lt; .01, d = 6.942 (a large effect size),</page><page sequence="13">MORPHOLOGICAL ANALYSIS INSTRUCTION and for the NSWDs in the WM group, t(68) = -21.256, p &lt; .001, d = 4.646. The posttest scores were signifi cantly higher than the pretest scores in each case. No significant differences were found for the subgroups within the VL and TO groups. With regard to the differences between the posttest scores of the groups on the Morphological Analysis Test when the pretest scores served as the covariate, the two-way interaction of strategy group and disability subgroup was significant, F{2,223) = 6.61, p = .002, par tial r|2 = .06 (a medium effect size). When the file was split on subgroup, the main effect of strategy group for the SWDs was significant, F(2,203) = 250.51, p &lt; .001, partial r|2= .713 (a large effect size). Pair-wise compar isons revealed a significant difference between the posttest scores of the SWDs in the WM group and the SWDs in the VL group, F(l,20) = 8.599, p &lt; .01, partial r|2 = .301 (a large effect size), and the SWDs in the TO group, F(l,20) = 11.801, p &lt; .01, partial r)2 = .371 (a large effect size). Mean posttest scores for the WM SWD group were significantly higher than the mean posttest scores for the VL and TO SWD subgroups. A significant difference was found between the NSWDs in the WM group versus NSWDs in the VL group, F(l,202) = 344.281, p &lt; .001, partial r)2 = .630, and versus NSWDs in the TO group, F(l,202) = 404.275, p &lt; .001, partial r\2 = .667. Again, the WM NSWDs' mean scores were sig nificantly higher than the mean scores for the VL and the TO NSWD groups, and the effect sizes were large. Satisfaction Survey Results The mean level of satisfaction ranged from 5.04 to 6.03 for the WM group and from 5.04 to 5.62 for the VL group on individual items. The mean overall ratings were as follows: WM group, 5.53 (SD = 1.02), and VL group, 5.21 (SD = .80). Discussion The results showed that both groups made significant and comparable gains on the Strategy-Use Tests, with SWDs and NSWDs scoring above a mastery level (mean percentage scores = 87%). Thus, the interventions were effective in teaching the strategies to both SWDs and NSWDs. Additionally, scores on the Word Knowledge Test demonstrate that both interventions resulted in both SWDs and NSWDs learning word knowledge at comparable levels (i.e., mean percentage scores = 70% [or a "C" grade in today's schools]). Hence, both strat egy interventions resulted in students learning the Table 3 Mean Raw Scores and Standard Deviations for the Strategy-Use Test Taken by SWDs and NSWDs in the Word Mapping and Vocabulary LINCing Groups Pretest Posttest Group and Test Means SD Means SD Word Mapping Group &amp; Word Mapping Test Total 1.41 3.14 42.01 7.38 SWD (N = 10) .70 1.57 40.30 7.99 NSWD (N = 69) 1.51 3.30 42.26 7.31 Vocabulary Strategy Group &amp; Vocabulary LINCS Test Total 2.24 3.42 41.14 12.21 SWD (N = 6) .00 .00 35.83 13.53 NSWD (N = 73) 2.42 3.50 41.58 12.01 Note. The total number of points available on the WM Strategy-Use Test was 48; on the VL Strategy-Use Test it was 47. Table 3 Mean Raw Scores and Standard Deviations for the Strategy-Use Test Taken by SWDs and NSWDs in the Word Mapping and Vocabulary LINCing Groups</page><page sequence="14">HARRIS ET AL. Table 4 Mean Raw Scores and Standard Deviations for the Word Knowledge Test and Morphological Analysis Test for SWDs and NSWDs Pretest Posttest Group and Test Means SD Means SD WORD KNOWLEDGE TEST Word Mapping Group Total 1.08 1.70 14.46 4.14 SWD (N = 10) .20 .42 10.50 5.19 NSWD (N = 69) 1.20 1.78 15.03 3.67 Vocabulary LINCS Group Total 1.09 1.37 14.01 4.82 SWD (N = 6) .67 1.63 8.83 4.58 NSWD (N = 73) 1.12 1.41 14.44 4.61 Test-Only Group Total SWD (N = 6) 1.07 .88 1.45 2.10 .82 .88 1.09 1.73 NSWD (N = 73) 1.09 1.37 .81 1.01 MORPHOLOGICAL ANALYSIS TEST Word Mapping Group Total 15.52 5.86 50.76 16.37 SWD (N = 10) 16.90 4.95 36.10 16.38 NSWD (N = 69) 15.82 5.99 52.88 15.35 Vocabulary LINCS Group Total 17.39 6.09 21.47 7.22 SWD (N = 6) NSWD (N = 73) 16.17 17.49 5.23 6.18 18.67 21.70 4.89 7.36 Test-Only Group Total 15.44 6.28 17.26 9.12 SWD {N = 6) 16.88 3.94 17.50 3.42 NSWD (N = 73) 16.39 6.53 17.23 9.62 Note. The total number of points available on the Word Knowledge Test was 20. The total number of points available on the Morphological Analysis Test was 88. Table 4 Mean Raw Scores and Standard Deviations for the Word Knowledge Test and Morphological Analysis Test for SWDs and NSWDs</page><page sequence="15">MORPHOLOGICAL ANALYSIS INSTRUCTION meaning of isolated words at a socially significant level. The results of the Morphological Analysis Test indicate that both SWDs and NSWDs in the Word Mapping (WM) group made significant gains and scored signifi cantly higher on the posttest than subgroups in the Vocabulary LINCing (VL) and Test-Only (TO) groups. These results suggest that the WM intervention, a gen erative vocabulary intervention, enabled students to identify more word parts within words, identify the meanings of more word parts, and predict the meaning of more words than the VL and TO groups. On the Morphological Analysis posttest, they earned a mean raw score of 50, vs. 21 by their VL and 17 by their TO peers. This means the WM group earned about 60% of the points available for analyzing unknown words on the posttest vs. 18% on the pretest. Across all the tests, no significant differences were found between the gains made by the SWDs and NSWDs in the Word Mapping group. Overall, these results of the tests of student perform ance are similar to the findings of previous studies that have compared the gains of students with disabil ities with those of their nondisabled peers. Specifically, both groups can learn the strategies and content they are explicitly taught; however, students with disabili ties tend to score lower than students without disabili ties. Thus, although both interventions are equally pow erful in teaching vocabulary strategies and word knowl edge of isolated words, they are not comparable in teaching the meaning of word parts and how to predict the meaning of unknown words. This is important, because students must learn large numbers of words each year to keep pace in academic core classes. In addi tion, if students are able to earn a score of 50% on a word analysis test, their scores on college entrance tests and state tests may be enhanced, and their overall read ing comprehension may be improved. This study represents an initial effort to investigate the effects of teaching a strategy that students can use for morphemic analysis and to show its effects on the performance of SWDs and NSWDs. The study adds to the literature by comparing the effects of instruction in a generative vocabulary strategy to instruction in a non-generic vocabulary strategy in an effort to identify the contributions of each type of instruction and how the outcomes of the two approaches might differ. Finally, the study is the first to measure student vocab ulary knowledge and analysis using open-ended ques tions (previous studies have used multiple-choice formats). This contribution is important by showing that students learned vocabulary well enough so that they could write the definitions of words or write pre dictions about the meaning of words instead of merely recognizing them or making good guesses among a list of options. A limitation of this study is the small number of SWDs in each group. The investigation was restricted by the number of students in the participating classes; not all students who were receiving special education services were enrolled in the targeted English/language arts classes in the participating school. One of the pur poses of the study was to focus on those students with disabilities who were receiving instruction in inclusive classrooms so that the effects of the intervention could be determined under the conditions present in that type of setting. The study was also restricted by the time available for instruction and the curriculum being taught in the ELA course. In addition, the block schedule imposed condi tions that may have affected student retention of word knowledge and strategies in a negative way. For exam ple, students were supposed to attend two to three 90 minute classes per week; however, interruptions often occurred (e.g., assemblies, snow days), resulting in instruction being offered only once or twice a week. A further limitation is that students in the WM group were not required to learn the meaning of the affixes and roots; they had lists of these meanings during the instruction. How well they might have performed on the Morphological Analysis Test if they had been required to master these meanings is unclear. Another limitation is that the Test-Only classes were not randomly assigned along with the other classes to the groups due to decisions made in the participating school. Nevertheless, the students were in the same grade as the other students and attended the same school, so they provided a normative comparison. Their pretest scores were not different from the scores of the students in the WM and VL groups; thus, they might be considered a reasonable comparison group. A further limitation is that no standardized assess ment was used to measure vocabulary knowledge and reading comprehension. Because the intervention time was short and the number of words and word parts taught was limited, obtaining gains on such global measures was not thought to be possible. In future studies, use of standardized measures will be critical for understanding long-term intervention effects and their power to impact performance on measures valued by policy makers in making adoption decisions. Finally, a researcher, an experienced teacher, taught the intervention classes. Thus, it was not possible to determine whether the intervention can be imple mented with fidelity by other teachers and how much professional development is required to ensure quality implementation by others.</page><page sequence="16">HARRIS ET AL. Implications for Research and Practice Future research studies should not only include larger numbers of SWDs in randomly assigned groups but should also systematically vary key student attributes such as ability, achievement, gender, English Language Learner (ELL) status, age, and disability. Additionally, intervention effects should be determined when instruction is spaced out over an extended time period in which instruction is less concentrated and is more reflective of instructional conditions found in most schools. For example, the interventions could be imple mented daily over a full semester, more words (and word parts) could be taught, the students could apply the strategies in other classes and over an extended period of time, and standardized vocabulary and read ing comprehension tests could be given at the begin ning and end of the school year to determine effects on commonly used group-administered assessments. Moreover, the effects of the intervention when taught by classroom teachers need to be explored as well as the effects of the intervention when classroom conditions are varied such as class size and frequencies of instruc tion (daily versus every other day vs. weekly). To put the results of this study into practice effec tively, several issues need to be addressed: (a) finding ways to teach the knowledge of word parts, (b) deter mining the best conditions under which to undertake a comprehensive vocabulary-building program, (c) con structing a manual to guide professional development of teachers, and (d) designing coaching procedures to support the implementation of WMS instruction. Only with these elements in place can the procedures pre sented here be scaled up to produce the impact needed to improve the vocabulary learning of all students on a national basis. References Anglin, J. M., Miller, G. A., &amp; Wakefield, P. C. (1993). Vocabulary development: A morphological analysis. Monographs of the Soc-iety for Research in Child Development, 58 (Serial No. 238), 1-186. Baumann, J. F., Edwards, E. C., Boland, E. C., Olejnik, S., &amp; Kame'enui, E. J. (2003). Vocabulary tricks: Effects on instruc tion in morphology and context on fifth-grade students' ability to derive and infer word meanings. American Educational Research Journal, 40, 447-494. Baumann, J. F., &amp; Kame'enui, E. J. (2004). Vocabulary instruction: Research to practice. New York, NY: The Guilford Press. Biemiller, A., &amp; Slonim, M. (2001). Estimating root word vocabu lary growth in normative and advantaged populations: Evidence for a common sequence of vocabulary acquisition. Journal of Educational Psychology, 93, 498-520. Blachowicz, C., &amp; Fisher, P. (2000). Vocabulary instruction. In M. L. Kamil, P. Mosenthal, P. D. Pearson, &amp; R. Barr (Eds.), Handbook of reading research, Vol. 3 (pp. 503-523). Mahwah, NJ: Erlbaum. Bryant, D. P., Goodwin, M., Bryant, B., &amp; Higgins, K. (2003). Vocabulary instruction for students with learning disabilities: A review of the research. Learning Disability Quarterly, 26, 117 128. Catts, H. W., &amp; Kamhi, A. G. (1999). Language and language disor ders. Boston, MA: Allyn &amp; Bacon. Deshler, D. D., &amp; Hock, M. F. (2007). Adolescent literacy: Where we are, where we need to go. In M. Pressley, A. K. Billman, K. H. Perry, K. E. Reffitt, &amp; J. M. Reynolds (Eds.), Shaping literacy achievement: Research we have, research we need. New York, NY: Guilford Publications. Ebbers, S. M., &amp; Denton, C. A. (2008). A root awakening: Vocabulary instruction for older students with reading difficul ties. Learning Disabilities Research and Practice, 23(2), 90-102. Ellis, E. S. (1992). The Vocabulary (LINCS) Strategy. Lawrence, KS: Edge Enterprises. Fillmer, H. T. (1977). A generative vocabulary program for grades 4-6. The Elementary School journal, 78(1), 53-58. Graves, M. F. (1986). Vocabulary learning and instruction. In E. Z. Rothkopf (Ed.), Review of research in education, Vol. 13 (pp. 49 89). Washington, DC: American Educational Research Association. Graves, M. F. (2006). The vocabulary book: Learning and instruction. New York, NY: Teachers College Press. Harris, M. L. (2007). The effects of strategic morphological analysis instruction on the vocabulary performance of secondary students with and without disabilities. Unpublished doctoral dissertation, University of Kansas, Lawrence. Hock, M. F., Brasseur, I. F., Deshler, D. D., Catts, H. W., Marquis, J., Mark, C. A., &amp; Stribling, J. W. (2009). What is the reading component skill profile of adolescent struggling readers in urban schools? Learning Disability Quarterly, 32(1), 21-38. Jenkins, J. R., Matlock, B., &amp; Slocum, T. A. (1989). Two approaches to vocabulary instruction: The teaching of individual word meanings and practice in deriving word meaning from context. Reading Research Quarterly, 24, 215-235. Retrieved from PRO VIDE URL Jitendra, A. K., Edwards, L. L., Sacks, G., &amp; Jacobson, L. A. (2004). What research says about vocabulary instruction for students with learning disabilities. Exceptional Children, 70, 299-322. Kamil, M. L. (2003). Adolescents and literacy: Reading for the 21st century. Washington, DC: Alliance for Excellent Education. Marzano, R. J. (2004). Building background knowledge for academic achievement. Alexandria, VA: Association for Curriculum and Development. McCardle, P., &amp; Chhabra, V. (2004). The voice of evidence in read ing research. Baltimore, MD: Brookes Publishing. Moore, B., &amp; Moore, M. (1997). NTC's dictionary of Greek and Latin origins: A comprehensive guide to the classical origins of English words. Chicago, IL: NTC Publishing Group. Nagy, W. E. (2005). Why vocabulary instruction needs to be long term and comprehensive. In E. H. Hiebert &amp; M. L. Kamil (Eds.), Teaching and learning vocabulary: Bringing research to practice. Mahwah, NJ: Erlbaum. Nagy, W. E., &amp; Anderson, R. C. (1984). How many words are there in printed school English? Reading Research Quarterly, 19, 304-330. Retrieved from PROVIDE URL Nagy, W. E., Berninger, V. W., &amp; Abbott, R. D. (2006). Contributions of morphology beyond phonology to literacy outcomes of upper elementary and middle-school students. Journal of Educational Psychology, 98(1), 134-147. Nagy, W. E., Diakidoy, I. N., &amp; Anderson, R. C. (1993). The acqui sition of morphology: Learning the contribution of suffixes to the meanings of derivatives. Journal of Reading Behavior, 25, 155-170. Nagy, W. E., &amp; Herman, P. A. (1987). Depth and breadth of</page><page sequence="17">MORPHOLOGICAL ANALYSIS INSTRUCTION vocabulary knowledge: Implications for acquisition and instruction. In M. G. McKeown &amp; M. E. Curtis (Eds.), The nature of vocabulary acquisition (pp. 19-35). Hillsdale, NJ: Erlbaum. Nagy, W. E., &amp; Scott, J. A. (2000). Vocabulary processes. In R. Barr, M. L. Kamil, P. Mosenthal, &amp; P. D Pearson (Eds.), Handbook of reading research, Vol. 3 (pp. 269-284). New York, NY: Longman. Nation, I.P.S. (1990). Teaching and learning vocabulary. Boston, MA: Heinle &amp; Heinle Publishers. National Assessment of Educational Progress. (2005). The nation's report card. Retrieved from http://nces.ed.gov/nationsreport card/naepdata National Reading Panel. (2000). Report of the National Reading Panel: Teaching children to read. Bethesda, MD: National Institute of Child Health and Human Development. Otterman, L. M. (1955). The value of teaching prefixes and word roots. Journal of Educational Research, 48, 611-615. RAND Reading Study Group. (2002). Reading for understanding: Toward an R&amp;D program in reading comprehension. Santa Monica, CA: RAND Education. Reed, D. K. (2008). A synthesis of morphology interventions and effects on reading outcomes for students in grades K-12. Learning Disabilities Research and Practice, 23(1), 36-49. Sirles, C. (1997). Root awakenings: Vocabulary development using classical word roots. Champaign, IL: Stripes Publishing. Snow, C., Porche, M. V., Tabors, P. O., &amp; Harris, S. R. (2007). Is lit eracy enough? Pathways to academic success for adolescents. Baltimore, MD: Brookes Publishing. Spencer, A. (2001). Morphological theory: An introduction to word structure in generative grammar. Oxford, UK: Blackwell Publishers. Stahl, S. A. (1999). Vocabulary development. Cambridge, MA: Brookline Books. Stahl, S. A., &amp; Fairbanks, M. M. (1986). The effects of vocabulary instruction: A model-based meta-analysis. Review of Educational Research, 56, 72-110. Stahl, S. A., &amp; Nagy, W. E. (2006). Teaching word meanings. Mahwah, NJ: Erlbaum. White, T. G., Power, M. A., &amp; White, S. (1989). Morphological analysis: Implications for teaching and understanding vocabu lary growth. Reading Research Quarterly, 24, 283-304. White, T. G., Sowell, J., &amp; Yanagihara, A. (1989). Teaching ele mentary students to use word-part clues. The Reading Teacher, 302-308. Author Notes Parts of this research study were made possible by Leadership Preparation grant #H325D020019 from the Office of Special Education Programs. The authors assume full responsibility for the contents of the article. ' For more information on the measurement instruments and the instruments themselves, see Harris (2007). 2The words on the Strategy-Use Tests (Word Mapping - Forms A &amp; B; Vocabulary LINCing - Forms A &amp; B) include the following: WM: constrain, resurgence, intercede, assiduous, adjudicate, beneficiary, ascribe, misnomer, magnitude, euphoria, intractable, claustrophobia; VL: entreat, memento, vilify, tutelage, negligible, indefatigable, depict, confidant, brevity, assemblage, reparation, ignominious. 3The 20 target words on the Word Knowledge Test and targeted for instruction included the following: diction, empathy, distort, bene diction, deportation, correlate, intermit, mortal, malnutrition, disport, morphology, contortion, admissible, pathetic, discomfit, malev olence, edit, benefactor, anthropology, philanthropist. 4The words on the Morphological Analysis Test included the fol lowing: malediction, torsion, apathetic, benevolence, extortion, immor tality, remittance, amorphic, pathology, malcontent, anthropomorphic, emission, malefactor, portage. 5The word parts in the prefix, suffix, and roots lessons included the following: prefixes: un, re, in/im, dis, a/an, de, en/em, e/ex, ad, inter; suffixes: y, ty/ity, age, ist, tion/ion, ance/ence, able/ible, al/ial, er/or; roots: bene, co/con/com/cor, mal/male, dic/dict, path, mort, port, fac/fact/fit, mit/mis/miss, anthrop, morph, tort. Please address correspondence about this article to: Monica Harris, Grand Valley State University, 920 Eberhard Center, 301 W. Fulton Street, Grand Rapids, MI 49504; e-mail:harrismo@gvsu.edu</page></plain_text>
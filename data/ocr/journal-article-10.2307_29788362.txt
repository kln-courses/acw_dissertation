<plain_text><page sequence="1">1 ITALO SCARDOVI THE IDEA OF CHANCE IN THE STATISTICAL INTUITION OF NATURAL VARIABILITY 1. In his famous work Le hasard et la necessite (1970), Jacques Monod has argued about the idea of immanent casuality governing all life phenomena, in? sisting upon the essentially accidental nature of mutation and taking Darwin's as? sumption of the absence of a design to its extreme consequences, by depriving man's myths of all residual illusions : "Pure chance, (...) mere chance ? he wrote ? is at the very roots of the prodigious framework of evolution: today, this central biological notion (...) is the only one which is consistent with the reality shown by observations and experience". In fact, even if the idea of "chance" were removed by a different theoretical image of the quantum events and, particularly, by the sudden error arising from copying a nucleotide sequence during DNA replication, there would still be absolute phenomenal indipendence between that error and its consequences upon the genoma of the individual and of the species. Even if the non-deterministic configuration of quantum physics seems to be com? pletely irreversible at the present time, one cannot, in abstract terms, rule out the possibility of new future epistemology concerning the theory on the structure of matter and energy emission which Einstein brought back to the same concept: Einstein, with his truly Spinozian approach, wished himself that the in deter? ministic paradigm dominating particle physics could one day be replaced by a more reassuring system of laws. Though it seems impossible today, Heisenberg's indeter? minacy principle could one day (which maybe will never come) make way for a deterministic interpretation of elementary phenomena and also of the quantum jump which is at the basis of mutation. Well, should that day eventually come and should the sudden event of mutation be brought back to the obedience to a strict deterministic system, so as to become predictable and to lose its essential indeterminacy, there would nevertheless still be an irreducible inconsistency in principles between the replacement of a nu? cleotide in the DNA sequence and the change induced in the protein, starting from the immediate effects on the other linear polymer: the aminoacid sequence. Monod devotes more than one page to the explanation of the concept of biological indeterminacy and of the idea of "essential chance" which undermines all residual anthropocentric illusions: chance which holds in itself the intersection between two phenomenal sequences independent from each other, though each of</page><page sequence="2">2 them has been brought to the deterministic universe order of Newton-Laplace: between the hammer of Dubois the tinsmith and the head of Dupont the doctor, to recall a famous example, there would still be irreducible causal independence. It is the statistical interpretation of intraspecific individual variability which gives this intuition a real meaning: no matter whether it is represented deterministically or indeterministically, mutation still remains a non-aimed event. This is also shown by the fact that the aggregate of mutations turns into an essentially "statistical" result. A designed and aimed mutagenic mechanism would not lead to variability, as it takes place in living species: the accidental variability which, being available to natural selection, becomes the fundamental premise for life and its becoming. All this is clear in the statistical and populationistic dimension of events. As is well-known, Monod appeals to Democritus and his looking upon the universe as to the product of chance and necessity. He could have referred to Ari? stotle's Analytica posteriora where one can find Monod's definition of "essential chance" in a passage which I think is fundamental: "Nothing which is due to chance occurs for something", Aristotle wrote. This all-containing definition stem? ming from the classical ages seems to put an end to the disputes of the modern and contemporary ages upon the epistemological and ontological meaning of chance. Also Aristotle's chance ? he took care not to let it play with natural phenomena ? is "essential". Mutation is therefore accidental in itself because it does not occur in view of any particular result: it is the statistical aggregate of accidental errors, the collective result which plays a role. It is the statistical image of the process which clarifies the role of accidentality in variability and the meaning of natural selection in a non-equivocal way: a process ? we may say ? which is deterministic and at the same time needs all products of chance to trigger off evolution. The following pages will deal with some stages of the increasing awareness about the new intuition ? which is a statistical intuition of reality (from Quetelet to Darwin, from Boltzmann to Heisenberg, from Mendel to Monod). 2. Modern science, the child of the experimental method of Galileo, had given unavoidable laws to nature. In the Principia mathematica (1687) by Isaac Newton, sublime expression of a perfect system, the geometry of a world without history and without deviations is described. Modelled on the celestial mechanics of Kepler, the dogma of fixity was inspiration for any investigation wishing to acquire the rank of science. Accordingly, in the 18th century, the observation of living forms culminates in the Linnean Systema naturae (1758): a schematic representa? tion of species in a timeless nature, where the like forever reproduces the like. As was the universe of Newton, the system of Linnaeus was immutable. Laplace applied the final epistemological seal to deterministic physics. A physics whose remotest causal manifestations could be recognized and predicted by ? in his own words ? "... a sufficiently comprehensive intelligence (...) so as to include in one formula the movements of the largest bodies in the universe and</page><page sequence="3">3 those of the lightest atom . . . " (Essai philosophique sur les probabilites, 1814). Soon enough, however, the idea of evolution, in the universe and on the earth, sneaked into scientific thought together with the awareness that a whole natural phenomenology cannot be reduced to the Newton-Laplace paradigm. As these phenomena, when translated into quantitative terms according to the principles of physics, offered a picture of disordered inconsistency, of a complex and inconstant reality, insusceptible to order. Order, a collective order, was brought about by Adolphe Quetelet. First, he synthesized the unequal pluralities of magnitudes, especially of some somatic traits of men, in their average value ('type'), and then realized that they tend to distribute themselves in a very characteristic form: that which accomodates the repeated instrumental determinations of the same astro? nomic entity. This surprising cohincidence suggested a reassuring interpretation: If the quantitative differences between individuals of a homogeneous population ar? range themselves as do the repeated, accidentally variable measurements of a single entity, this is due to a 'constant cause'. And this 'constant cause' would produce equal outcomes were it not for circumstances extraneous to the genesis of the type, in the same way as the instrumental components of error play a role in the measure? ment of the straight-line rise of the North Star. 3. Bringing the morphological variability of living forms to the theory of accidental errors ? an exalting analogy which made Adolphe Quetelet a protagonist of scientific thought in its endeavour to conquer variability as empirical imma? nence ? was something more than the mere phenomenal transposition of a formal model which was suitable to describe the diverse gradualness of an objective ag? gregate of magnitudes around a type: it satisfied the longing for certainty, the need for order, the search for permanent truths: the spiritual connotations of de ter? minist science which, with Pierre Simon de Laplace, reached its intellectual apogee. Were the biodemographic phenomena seem as the manifestation of providential finality or as the outcome of immanent necessity, the methodologie approach would not change. Along with classic determinism, the new 'collective determinism' appeared to be the tool by which Omnipotent leads seemingly ruleless events to a sort of higher reason ? the regularity of the aggregate. This had been the thesis of Newton and Halley: order comes from God, disorder from his enemy. Any statisti? cal regularity ? in the new Queteletian 'physics' ? responds to a hidden scientific law, and expresses an immediate or remote natural 'cause', the effects of which can be altered by numberless disturbing factors external to it. Variability is thus brought back to regularity, disorder to order. When, in the Recherches statistiques (1844), Quetelet could find in the natural variability the curve of errors used in astronomy (thanks to De Moivre, La? place, Gauss, Legendre, Bessel), the criterion of working by averages was theoreti? cally justified. How, then, could one resist the temptation of seeing that curve as the universal and transcendent protoscheme of natural variability? A suggestion</page><page sequence="4">4 which even men much less inclined to mystical exaltation were not able to escape. Gaiton, for instance. That model was neither unique nor universal: it was, however, the reference framework to develop a new methodology. Quetelet, imaginatively, saw divine regularity in it: and, in the center of gravity of the system, the prototype of a population. Fifteen years after James Clerk Maxwell saw that molecular velocities approximated that same law of variability: working on gas kinetics, he realized that the most likely distribution of the velocities tends to conform to Gauss' curve. "It appears (...) ? he writes in the Illustrations of the Dynamical Theory of Gases (1859) ? that the velocities are distributed among the particles according to the same law as the errors are distributed among the observations in the theory of the 'method of the least squares' ". A statistical concept was then introduced into the gas mechanics. And it was not to remain a technical fact. The statistical intuition and the probabilistic algorythm were soon to take a far different meaning: in a few years' period, Boltzmann will repropose the kinet? ic theory neglecting the movement of the individual molecules, which was not es? sential to his end. What forms the object of science are the collective outcomes, and the statistical properties of the aggregate. A language which had been created from an 'exact science' to read the 'inert matter', which was beginning to be satisfied with probabilistic approximations, became the tool to acquire knowledge on the living world and offered the naturalist a new approach for looking at facts and replacing chaos with order. Where nothing but disorder was thought to prevail, stupefying regularities, mysterious symmetries, unsuspected collective constants were discovered. Here, the sciences of life preceded physical sciences. The latter will continue to dictate gnoseology, but within a radically changed reference frame? work: no longer deterministic, absolute, certain. (It just reveals itself in natural sci? ences when Charles Darwin interprets evolution as a statistical process and Gregor Mendel sees the message of the species pass from one generation to the other as in a game of dice; it appears in physics when Ludwig Boltzmann considers entropy as a probability giving a statistical meaning to the second principle of thermodynamics; it establishes itself methodologically when Werner Heisenberg sets forth his famous principle, Niels Bohr outlines the foundations of his "interpretation of Copenha? gen", and Max Born makes use of Schr?dinger's wave function as a distribution of probability). 4. The astronomic paradigm forced one to consider natural variability as a failure in hitting the target, as a non essential by-product. In Quetelet's conception, in fact, natural variability appears as the deterrninist philosophy of science of the time demanded and dictated: as the outcome of the "maladresses" of a nature whose aim was to actualize the stable type of a species, the ideal mold of a popula? tion, the average man. Sheltered from the grandiose mechanical system of Newton Laplace and still unaware of the impeding crisis of classic determinism, the scien? tific thought of the time gladly saw the individual values arranging themselves</page><page sequence="5">5 around the arithmetic mean according to the proportions of the Newtonian bi? nomial expansion: the final illusion of determinist thought, which was beginning to be threatened by accidentalist traps. To interpret human phenomena by an astro? nomic metric through mean values, however, meant to lose sight of the population as an evolving reality. That was the current attitude: Newton's skies had no history, and the same was true for Linnaeus' species. After taming natural variability, after re-affirming the rights of Linnaeus' immutable order in the universe of Newton-La? place, scientific thought still identifies itself with the physical paradigm and sees the signs of astronomic mechanics also in the phenomena of life, where the unpre? dictable seems to be governed by an obscure collective commandment. Faced to the arcane cohincidence of reality and theory, Quetelet had at? tributed individual variability to the environment, so as to prevent any accidentalist interpretation of phenomena intrinsic to life. And he had subordinated casualness to causalness, necessity to finality. The Gaussian model was quite apropos in that variability and saved the determinist liturgy of the dominant science. Yet, the cautious sneaking of accidentally into necessity is the first sign of a new philosophy of nature. By arranging in a sort of physical order a whole world of things which seemed capricious, disordered, and unpredictable, Quetelet had found the key, in the necessity of the aggregate, to bring back to physical caus? al determinism a reality whose individual constituents seemed to escape it: the men of his social physics are, in their quality, as balls drawn from an urn; in their metric traits, as instrumental deviations from a prototype. In both aspects the law is to be found in the mean value, in the fact that individual values distribute themselves around it. If the rigor of the physical world does not manifest itself with the same straightforwardness in the biological reality ? such is his thesis ? the reason is that we were not able to look beyond the individual. Beyond the individual there is the population, there is the species: this notion was already clear in Quetelet's mind when Darwin was still going around the world on the Beagle. But, a prisoner of his own assumption, Quetelet did not look at the individual differences in the same way as that genious will do. He takes populations into account to reduce 'plural' to 'singular', to replace individuals with the average individual. Here lie the great? ness and limitation of a physicalistic reduction to an immobile nature, where every? thing is, today, what it was in the beginning. The fact is that in Quetelet's picture there is no room left for the idea that the individuals of a population may receive a non identical hereditary message; a different message from that of the 'average man'; who ? he asserted ? " . . . corresponds to the thought of God when He created man". The God of the Genesis must have blown into an average man of clay, and not into an accidental combination of elements. 5. Darwin was the first to identify variability with Nature and the one who, with his Origin of Species (1859) upset a scientific thought which was content with conceiving the individual differences as an "epiphenomenic chaos". Giving a</page><page sequence="6">6 method to the sciences of life meant in fact to start looking at usual phenomena in the light of a new paradigm: to see in the populations the historical outcome of phenomena brought about by innumerable microprocesses which oppose all kinds of determinism and to acknowledge that there is a blind indeterministic spontaneity at the origin of the species and their evolution. A new unifying language was there? fore introduced into science: it was the one developed by the sciences of life by loosing the knots of an obstinate mechanicism and by making statistics the method of a new kind of knowledge. Examining the populations, Darwin had intuited the non-deterministic laws which govern their becoming. Pre-condition for the latter is variability: a statis? tical view which is intended to overcome all deterministic and fixistic hindrances. Mendel had found the algorythm of evolution in the genetic memory which links the generations and makes individuals different, though the same: a simple game of dice. Variability therefore became the image of nature and man and the analysis of variability became the method which allowed a scientific knowledge. The observa? tion of the populations is no longer instrumental and so is the observation of the "pluralities" in the kinetic theory of gases put forward by Ludwig Boltzmann (Vorlesungen ?ber Gastheorie, 1896): it is the collective properties, the statistical regularities, and the result of aggregate which form the subject of the theory. Already before Boltzmann's interpretation of entropy and Gibb's assump? tion of "statistical mechanics", physical science had got used to statistical reasoning and was forced to do so ? as it was thought ? by the limitedness of human know? ledge. Determinism was therefore saved since probability acted instrumentally as an epistemic expedient. Probability was resorted to, but this does not imply that each individuality, either atom or molecule, could escape deterministic laws: stating that they meet by chance was like saying that the laws governing their movements are ignored. However, the question soon arose again (which was implicit in Mendel and explicit in Boltzmann) whether accidentality of an event was really only the expres? sion of an intellective limit. Everything had started with molecular representation and the pertaining kinetic theory: a first statistical assumption was entering the world of physics in the form of apparent extension of classical mechanics into the "populationistic" representation of gases as discrete aggregates of large molecular numbers. A probabilistic model will succeed in structurally unifying the definition of the properties of a system by means of its constituents, identifying the proper? ties of the constituents in those of the system: synthesis lies in the distributive law of probabilities within the system. Clausius had understood that a kinetic theory of gases ? looked upon as population ? cannot be based upon traditional models and that the laws of aggregates made up of a large number of elements can be derived out of an abstraction process, calculating average values. In Clausius' thought, averages were a simplification as well as in Quetelet's opinion; it was like finding the singular in the plural, the determinate in the indeter? minate, nothing more than a technical expedient to analyse molecular macro</page><page sequence="7">7 systems. As a matter of fact, however, there is a tendency towards escaping from classical mechanics, asserting a statistical and probabilistic paradigm. The first significant changes were felt when James Clerk Maxwell made a further step for? ward: from the average values of velocities to the statistical variability of these magnitudes according to the formal model of the accidental error theory. It is a suggestive historical coincidence: physics started to be aware of a new grammar to interpret thermodynamic phenomena in the very year when the Origin of Species brought into natural sciences the sense of phenomenal plurality escaping from individual necessarism, the sense of an in deterministic becoming of the evolutionary lines in which immanent accidentality plays a role. Two fundamental works in the history of thought were even more bound to undermine the canons of the strong and mythical Newton-Laplace's paradigm, to whom we owe two glorious scientific centuries: Gregor Mendel's Versuche ?ber Pflanzenhybriden (1866) and Ludwig Boltzmann's ?ber die Mechanische Bedeu? tung des zweiten Hauptsatzes der W?rmetheorie (1866): again another significant coincidence of dates. In both essays, chance is not the expression of human igno? rance mathematized in the calculation of probabilities: it is the image of the pro? found substrate of phenomena. Maxwell's distribution of molecular velocities imi? tated Quetelet's anthropometric distribution ? not only in that they refer to the same formal model, but also in the instrumental and not phenomenal conception of probability. The conquest of statistical variability in microstructures, which had taken place in the sciences of life, had therefore come to characterizing also the sciences of matter. Yet, it was not bound to affect gas dynamics and heat phe? nomena only: that first timid penetration of chance into necessity would bring a science which has its gnoseological cornerstones in determinism towards a new form of epistemology. 6. In Quetelet's thought individual variability was a disturbing phenome? non which had to be solved in deterministically representable macroscopic magni? tudes (average values), whereas Darwin identifies variability with nature, so that the populations are the expression of an accidental process which goes on without pre-set typologies or pre-established designs. Inspired by Malthus, who was able to establish a relationship between the population aggregate and the limits of the environment, Darwin was particularly concerned with the study of populations: collective historical realities of two equally essential and equally abstract entities: the individual and the species, i. e. two 'immutables'. The physiologic research was centered upon the individual; the naturalists of the 17th century had formulated a coherent definition of the species which, in the following century, became the vital element of a large taxonomic order: Karl Linne's Systerna naturae. The individual and the species were the subject and the end of all predarwinian biology: a biology which collects and classifies, orders and compares. This long descriptive phase of the sciences of life would become determinant when Darwin's genius put forward a statistical paradigm of life phenomena. At the beginning of the 20th century it</page><page sequence="8">8 would turn into the image of a new knowledge. Taxonomic order would no longer be a hindrance to a quantitative treatise, but would, on the contrary, represent its statistical assumption. Aiming at a creationist view, the Systema naturae had postulated the fixity of species: according to this assumption, Linnaeus took no consideration at all of the "individual variability", that is the gradual differences between individuals belonging to the same systematic group. It was just this variability ? still neglected by taxonomists and morphologists ? which suggested the cue to find traces of a historical order in the systematic order. When, at the beginning of our century, the scientific world became aware of the simple but yet great explications of the Laplacian probability set forth by the abbot Mendel in the stillness of his cloister, the statistical method in its most authentic expression became the method of a new biology. The discovery of a law in the natural variability (Quetelet), of his role (Darwin) and his genesis (Mendel) accounts for the methodological novelty of the scientific thought induced by the crisis of deterministic science and by the assertion ? even in the structure of the matter ? of a statistical image of reality. Darwin was the first to identify, within natural variability, an empiric immanence resulting from a casual and spontaneous process without pre-set harmonies or planned changes; he was also the first to think of it as of a new method of looking at the development of life. To find the clue for explaining the universal phenomenon ascertained by Lamarck ? i. e. the adjustment to the environmental conditions seen as a dynamic process of the living forms ? Darwin had shifted from the study of the individual to that of the populations. He had realized that it is through the populations that species develop. In Lamarck's thought, to which the idea of "chance" is completely extraneous, the living forms change in one direction only ? i. e. the useful one ? by mechani? cally adjusting to the environment: and this changing is handed on to the descend? ants. A simple paradigm, which is not exempt from a certain anthropomorphic morality. The paradigm of "natural selection" is nothing alike. Darwin had intuited that heredity had to be a far more complex phenomenon, that the change of forms and structures does not go on in a one-way direction, but develops accidentally in various directions. The selective forces are those which give the evolutionary direc? tions and determine the variants in the populations. In Darwin's thought the indi? vidual differences are extremely important as they account for the material the selection can work upon. What is the source of variability? Darwin openly declares his ignorance which nevertheless does not prevent him from perceiving something essential: the fact that all individuals are accidentally different from one another and the contingent value of all variations. The concept of "chance" entered for the first time and almost secretly in the formulation of a scientific theory. A theory which denies the need for any evolutionary resultant, bringing into the naturalistic thought the image of a casual and contingent reality and of a factual condition which exists but might not exist. Of a nature which, by trying all variations, makes use of empirical experiments without a planned finalism.</page><page sequence="9">9 Thinking of the mechanism of natural selection nowadays, it appears in its indeterministic fullness. Genetics would confirm that evolution, being a histori? cal phenomenon, is unpredictable, and would show that two "identical" copies of a genome are not necessarily as such after a pre-set interval of time has elapsed; and would find the reason for the uniqueness of each evolutionary line in the indeter minism of the molecular processes; and would, in a word, make explicit the statis? tical aspect of natural world Darwin introduced in biological phenomenology. Sta? tistical is, in fact, the populationist cue Darwin draws from the suggestive and cyni? cal essay by Thomas Robert Malthus. Statistical is also the logical process repre? senting the events which take place during evolution: "struggle for life" and "sur? vival of the fittest" mean "differential rate on the reproduction of genotypes". Sta? tistical are the implications of the contrast between the reproductive force of the living forms and the limitative force of the environment: they guide the current biologist in the calculation of the endless mutational and casual variability of a species, of which a living population is but a very small part, and provide him with an interpretative grammar where the individual and accidental event of "mutation" becomes a rule in the "large numbers" through which it repeats and is handed on. This sense of plurality which escapes from all kinds of claimed individual neces sarism, is the epistemological mark of the doctrine of natural selection. 7. The new and determining fact was therefore that the cognitive interest started to be centered upon the populations: a methodologic line, developed in biology earlier than in physics, where mechanistic determinism, having its highest expression in Newton's system, under the "psychological" protection of Laplace's act of faith, is gradually replaced by an indeterministic view. Darwin's scheme pos? tulated a natural process capable of producing deviations from the type, of handing them on and widespreading them. Nowadays, molecular biology recognizes that process in the quantic jumps (accidental errors in the framework of quantum mechanics) which "disturb" the unchanging reproduction of the genome during DNA duplication. And if the thermodynamic processes become statistical laws showing an entropic tendency towards the chaos of molecular populations in a one-way direc? tion which practically allows no reversion, the irreversibility of the biological evolutionary process is granted by natural selection; once an organic character? ization which is not inconsistent with the environmental pressure starts, it "cannot" be reversed. The living nature is made up of populations and of different pluralities of intraspecific cases; in one word, of variability. A variability which evolves with time. In the history of the species time is not the independent variable of Newton's mechanics: it allows a one-way direction only. In Boltzmann's thermodynamics, too, one finds a phenomenically irreversible direction of the entropic degradation of the systems, from order to disorder. The same is true for Darwin's concept of time. Life goes by, evolving from a state to another, which is not necessary but probable: one among the possible evolutionary outcomes of an aggregate. The</page><page sequence="10">10 concept of a necessary, if not pre-set, evolutionary fate has become absurd and in? consistent with that clear accidentalistic plan. And even if it would be possible to know all initial conditions of a system at a certain point in time, it would not be possible to predict its state at a different point: the only thing one can derive from it is the "distribution of probabilities" of the possible states. The intuition, flashed during a happy autumn in the Galapagos Islands, when faced with non-coinciding evolutionary lines within a relatively uniform en? vironment, thus finds, more statistico, its best explication. In this view, which rep? resents a real ideological turning-point in empirical sciences, biology precedes physics and seems to postulate the paradigm of a new mechanics. Without a statis? tical intuition of the real, natural sciences would have never achieved their basic idea, that of evolution through selection of variability; they would have never conceived life as an indeterministic becoming. This is what marked the great epis temological turning in which physical sciences soon played an important role: the end of all necessities, the disappearance of all internal teleologies, the evidence that what exists might have never existed: nothing more than a probable event in the framework of possible events. "Everything which is necessary exists" said De Mai stre, an absolutist Catholic. And Laplace's cosmology, Hegel's phylosophy, Comte's sociology, Bernard's physiology, Quetelet's anthropometry and Kelvin's physics seemed to sing praises to that reassuring aphorism. Evolutionism, on the contrary, suggested a new and disturbing assumption: everything which exists was not neces? sary, but merely possible. Even man. When, in the final edition of the Origin Charles Darwin examined the prob? lems which had been left unsolved, ? the "internal" origin of spontaneous varia? bility and the hereditary transmission of characters, ? it was still 1872: more than seven years before a lone naturalist, Johann Gregor Mendel, found the first es? sential answers in the garden of a Moravian convent. It was, however, only in the new century that his message was given consideration. That kind of research was too new and heterodox and was carried out too precociously both for the method and the contents (more than the latter, it was the former which left disconcerted). The contents dealt with phenomena which did not seem to go along with the natu? ralistic view of time. The method expressively declared the statistical intuition of the hereditary process associated with the sense of the collective phenomenon, of the tendency law revealed by the "large numbers". Mendel was the first observer of natural phenomena who showed this methodologic awareness without hesitating and was the first biologist who intepreted in a probabilistic fashion the events observed in the groups. He therefore anticipated science (and philosophy) of at least thirty years. No one could foresee in those simple calculations the model of a new kind of scientific law because nobody could grasp the determining gnoseological aspect of Darwin's paradigm, too rich in eversive phenomenic connotations to leave room to the methodologic message they contained. Nevertheless, Mendel had intuited a discrete reality in his peas, a reality which is individually unpredictable and ready</page><page sequence="11">11 to form surprising regularities: the "collective truths" of a new science. Mendel had a real statistical inclination which might have accounted for his lack of success. The mid-18th century natural philosophy was not yet ready to change its gnoseolo gy and to see a bit farther than that shy monk could see. How could a scientific world ready to acclaim Newton and Laplace as the rational prophets of the creator of the universe admit it was depriving the phenomena of life of any deterministic or finalistic necessarism? Mendel had chosen an operative condition capable of favouring a close dialogue between experimentation and theory and of promoting quantitative analysis, among the populations, of the numbers obtained by grouping the results in classes. The whole numbers that would lead him to intuit acciden? tally of hereditarity combinations and to grasp their statistical regularity through essential combinatorial developments. This is the first declared accidentalist para? digm in the history of science, the pre-announcement of quantum mechanics which would turn "chance" into the "law" of the universe and would be concerned with the behaviour of a physical "particle" which is as unpredictable as the fate of one of Mendel's "units". Yet, collectively speaking, the phenomenon statistically sticks to its own rule, which accounts both for the survival through the generations of the species' characteristics and the occurrence of the variations which are an essential part of Darwin's evolutionary mechanism. Dividing and crossing, listing and calcu? lating, Mendel had found the key of the hereditary phenomenon, thus being able to explain both persistence and evolution, finding, in a word, the algorythm of the dialectis of repetition and novelty which is at the basis of the evolution of the species. 8. This replacement of necessity through accidentality is the sign that new times have come in natural philosophy: the times of statistics. Not much time elapsed before physics also discovered its own "statistical immanence", by turning its attention to micro-events, as had happened in biology. And once biology had be? come aware of the important turning-point brought about by Mendel, it was able to understand, with the genetics, the stochastic realization of spontaneous variability among the living forms, until it found, in nucleic acids, the combinatorial rules of the transmission of characters from one generation to another. And when a new experimental knowledge could discover the multi-factorial processes which give rise to gradual intraspecific variability then the subsequent logical and formal re-interpretation proposed Darwin's theory in the terms of Mendel's genetics, thus achieving an important methodological unity. It was necessary to go back to Mendel's units, to Mendel's classes, to Mendel's numbers on the basis of a biometric approach which, both conceptually and instrumentally, marks the wonderful history of genetics. A history which is in terms of a closer and closer relationship between biological analysis and statistical method through which (around 1930) the first important logical and formal syn? thesis is drawn: the statistical and mathematical theory of natural selection put</page><page sequence="12">12 forward, independently, by Haldane, Fisher, Wright and Cetverikov. That such conceptualization developed almost simultaneously in cultural situations so dif? ferent and far from one another denotes that science had slowly laid down both the phenomenic and logical foundations for it, and that this new view had made times ready to accept a formal theory within a unitary conceptual framework: "Neo Darwinism", i. e. the "genetics of populations". The new synthesis has ascribed intraspecific variability to an unprogram med accidental process in which also the recombinations of the hereditary set due to sexual reproduction play their role. It is one of Mendel's mechanisms that assures the persistence of genie frequencies; it is one of Darwin's mechanisms which favours the most suitable combinations with the environment so as to change such fre? quencies. The discovery of the genetic code and its universality would then give rise to the methodic koine between biological and non-biological sciences which had accounted for the great illusion of classic mechanicism. The casual and elementary chemical events which, by changing the text of genetic duplication, are at the basis of variability, in providing natural selection with the empirical premises to imple? ment, through populations, the congruence between organism and environment which had deluded Lamarck with its apparent mechanical simplicity, place "chance" at the roots of the phenomena of life. Because ? so writes Monod ? ". only chance is at the basis of all novelties". And even if one should find a specific "cause" for spontaneous mutation, the relationships between the initial micro? scopic event and its collective macroscopic consequences remain contingent. It is a different paradigm: one which forges biology before quantum me? chanics, which, in Born's view, says, has no deterministic prejudices and is com? pletely statistical. It is worth stressing that Planck read his memorable thesis on thermal radiation ? the birth act of the quanta theory ? only a few months after the re-discovery (1900) of Mendel's laws through which biological reality appears in its inherent and essential corpuscularity. Biology had therefore come to the "quan? tities" by means of the classes, i. e. ? writes Schr?dinger ? by means of whole numbers long before physics found its identity in a world of discrete numerable entities. It became therefore possible to treat quantitatively all biological phenom? enology which had so far been extraneous to any formalization. The "sciences of genera" ? as Bergson called the non-mathematized disciplines ? were therefore rapidly approaching the "sciences of laws". 9. Once the attention was turned from the individual to the populations (reproductive communities endowed with a common genie pool), the gradual intra? specific differences, necessarily neglected in the schematic view of the types, be? came the subject of the naturalistic quantitative research. This is centered upon the aggregates, the individual phenotypic variability and the stochastic formation of their inherent genotypic variety. This sense of plurality, together with that of con? tingency, is the epistemological mark of the doctrine of natural selection and of a</page><page sequence="13">13 new way of looking at nature: that of statistics. A way which became essential to a knowledge which is no longer centered upon the concept of necessity, proceeds by means of intuition and offers nothing but probabilities. If from the kinetic theory of gases Maxwell had drawn the conclusion that: " .... the logic for this world is the calculus of probabilities", the contemporary scientific thought is largely inspired by a methodology which considers the calculus of probabilities as the logic of this world. The laws of "chance" do not only appear in those probabilistic schemes of choice from which Boltzmann dared to draw his scandalous parallels between com? binatorial calculation and theory of molecular aggregates. Used in physics to direct the analysis of corrispondent values to swarms of molecules, the calculation of pro? babilities has become the grammar in which certain events seem to find their ex? pression; and in the alphabet of "chance" there started to develop a simplified description of phenomena which would otherwise have been complex. Just a few decades separate the interpretation of entropy as a process due to a gradual ad? justment of mechanical values relative to the motion of molecules of different velocities, whose collective resultant is statistical regularity, from quantum mecha? nics: years which upset physics by intruducing an indeterministic assumption of universal size. The concept of probability therefore penetrates deeply into the science that had supported the conceptual system of determinism. Yet, it was Max Planck, the quanta theorist, who considered statistics just as a "temporary" method to be used faute de mieux in investigating microscopical reality, while waiting to discover the "real laws" capable of subjecting to the discipline of the deterministic paradigm "phenomena whose course ? he wrote ? seems to be at the mercy of chance". He was sure ".that scientific research finds its roots in the concept of cause and that the strictly deterministic hypothesis of a causality without exceptions accounts for the assumption and preliminary condition of scientific knowledge" (Wege zur Physikalischen Erkenntnis, 1923). Planck had no doubts about the existence of undeciphered causality at the origin of those phenomena: they also have to obey "dynamical laws" the place of which is improperly, roughly and approximately held by the "statistical laws". Physical phenomena ? and this is the thesis ? cannot be "at the mercy of chance". Yet, it is by starting from Planck's interpretation of energy distribution in the spectrum of radiant heat that a different theoretical paradigm has established itself in physics, thus dividing scientists into those who believe in Spinoza's uni? verse, where there is no room for "chance" and those who are the supporters of indeterminism, where "chance" plays with the elementary physical events. Planck was far from suspecting that approximate and temporary method, centered on pluralities, and content with average values, was something more than a useful modus operandi and was even becoming a new modus intellegendi: a canon for the interpretation of physical reality, a language of life phenomena and a conception of the world.</page><page sequence="14">14 10. As the classic science, developed with Galileo's physics, found its ideal message in the experimental method, the new in deterministic science carries the cultural mark of evolutionism and finds its interpretative code in statistics. A code which complies both with Galileo's and Darwin's lesson. Every gene, every chromosome, every cell already seems to be the result of combinations which a sort of conservative mechanism translates ".into order, rule and necessity" (Monod). The scientific thought is traditionally directed to? wards order, rule and necessity because it is ".impossible ? again in Monod's words ? to analyse a phenomenon in different terms from those of the invariants it preserves". This is a statistical assumption. The assumption of a science which, by investigating the structures, could lead the unlimited variety of the macroscopic events to the various combinations of the same elementary events: a wonderful simplicity at the origin of the typological diversities and the very variability among specimens from the same type, expressing a biochemical feature common to all human beings. A macromoiecular structure ? nucleic acids and proteins ? which in all individuals is due to a finite number of radicals, nucleotides and aminoacids respectively, in linear sequences. It is in those constituents of life, the depositaries of an universal alphabet, that the message of becoming and changing is written, that the principle of identity and variety is coded and the genesis of the species and its renewal is preserved. Well, all this is implicit in the theory of natural selection. In that broad paradigm, individual variability is no longer the accidental error of a nature which "makes a mistake" in modelling the Linnean prototype, as Quetelet wanted it to be: it is an essential phenomenon in the becoming of a type. A becoming in which chance plays ? as in Mendel's thought ? with necessity. Mendel's key idea, that of a hereditary "unit" incorruptly carrying a message through the generations becomes more precise in the identification of the gene, in the acknowledgement of DNA as the chemical invariant of the hereditary characteristics, in the discovery of the ge? netic code as an elementary language which, in transmitting instructions, makes ac? cidental errors giving rise to the variability of macroscopic structures. If the change in the text transcribed in RNA were not accidental, it would not bring about the statistical variability which is essential to the process of becoming in evolution. 11. A debate, which finds its end together with humanity, is therefore brought into life: is the concept of chance which governs the new "system" merely an easy language for representing phenomena led by an indecipherable determinism or does it reflect the evolution of a nature which "occurs" indeterministically? It is the eternal dilemma between ontological and epistemological meaning of scientific knowledge. It is however scientifically of little importance, whether God plays dice with the world or not ? if we may quote a famous exchange of letters between Einstein and Born: what is certain is that those who cannot refuse to play dice are the physicist who, with his investigation, goes deep into the elementary constitu? ents of matter, or the geneticist who wishes to be involved in the elementary processes of the evolution of the species.</page><page sequence="15">15 "Everything which obtains in the universe is the product of chance and necessity" ? said Democritus of Abdera in the 4th century before Christ. "Nothing which is due to chance occurs for something" ? added Aristotle a few decades after. The ancient atomist did not perhaps imagine he had posed a dualism which would become the very dilemma of any epistemology; nor could the great naturalist from Stagira suspect he had given the most incisive and complete description of casual ness: and, surely, far from him was the idea of an empiric cadence of chance events, of an unsuspected natural order in the outcomes of what happens without finality. What did Plato himself write? "As I deal with human actions, I cannot give you but probabilities". Casualness was the condemnation of man's facts, it had no place in nature: must be certain, necessary, fixed. Two thousands years after, the scientific thought posed the idea of 'chance' at the centre of a new concept of natural reality; the research discovered the accidental nature of elementary events of matter and life; a new scientific methodology encompassed a whole phenomenology, ranging from the physical, the biological and the social field, in a non deterministic and non finalistic paradigm. If Quetelet had seen "chance", in variability, as a kind of superficial disorder which does not disturb the remote design of a trascendent "necessity", the Darwinian and Mendelian science could grasp, the essential and profound meaning of that varia? bility and its ductility to selective adaptation. Once again, we have "chance" and "necessity", but with exchanged roles: chance in the mechanism of reproduction, necessity in the reasons of environment. Here the statistical interpretation of nature finds its roots (1). Discussion still goes on as for the antithesis between casuality and finality, between large numbers and individual fate. But it is now necessary to cope with a science that was capable of bringing the endless variety of macroscopic facts back to the various combinations of the same elementary constituents; that could spot a biochemical substratum common to all living forms in the casual arrangement of monomers in linear topological sequences, depository of the universal language of evolution, where "necessity" leads "chance": as in the case of Boltzmann's mole? cules, Darwin's variants, Mendel's units and Planck's quanta. In those first ingenious intuitions lies the "Rosetta stone" of the alphabet of the secrets of life and man. The alphabet of a science that has opened up to "chance" setting aside the old certainties and the immanent deterministic necessities. (1) These conclusions, which the author of the present paper has reached in last years, have been widely put forth in a series of essays. Some of them are listed in the following: Aspetti attuali della biometria, SIS, XXIV, Roma, 1965; Statistique: un langage empirique en biologie, S.F.O.D.F., 44, Lyon, 1974;R?eggendo Darwin, "Statistica", 4,1974; Statistica come metodologia delle scienze naturali, Accademia Nazionale dei Lincei, CCCLXXIV, 1976; Ipotesi, fatti, teorie nella ricerca biologica, Contributi del Centro Linceo Interdisciplinare di Scienze Matematiche, 37, 1977;J numeri di Mendel, Accademia delle Scienze di Bologna, LXIV, 1976; La disputa tra mendelisti e galtonisti alle origini della biometria, "Genus", XXXII, 1-2, 1976; Adolphe Quetelet tra determinismo e accidentalismo, Accademia delle Scienze di Bologna, LXVI, 1978; Fondements statistiques des sciences sociales, "Epistemologia", V (Special Issue), 1982; Necessita del caso, "Statistica", 1,1982.</page><page sequence="16">16 SUMMARY In this paper, aimed at a configuration of statistics as modus intellegendi of reality, we look for the meaning of the passage from an idea of chance as epistemic boundary of human mind to a phenomenic idea of chance as a constitu? ent of natural processes where the research of statistical properties of aggregates (even if they are parameters of functional relationship) is no more only a technical aspect of the analysis of molecular macrosystems. From the first thermodynamic to the theory of evolution by natural selection and the quantum mechanics, the phenomenologic and methodologic turning point is significant of a new habit in scientific thought. The irreversibility of an in deterministic configuration of nature can be find not only in the "essential" independence between the hammer of Dubois, the tinsmith, and the head of Du pont, the doctor, but also in the absolute phenomenic independence between the quantum jump arising from copying a nucleotide sequence during DNA replication and the effects of that sudden "error" upon the genoma of the individual and of the species. It is the idea of statistical variability which gives a contingent and neces? sary meaning to that accidental element of novelty . This accidentalistic interpretation of natural variability ? that is implicit in the Darwinian view of phenomena of life and its becoming is at the origin of a no longer deterministic gnoseology in which statistics achieves an epistemologic and logic importance. At this point, the more and more esplicit supremacy of an indeterministic interpretation of biologico-molecular and microphysical phenomena suggests a very statistical intuition of nature. RIASSUNTO In questo scritto, ispirato ad una configurazione della statistica come modus intellegendi del reale, si cerca di cogliere il significato del passaggio dalla concezione del caso inteso come limite epistemico della mente umana ad una con cezione fenomenica del caso, inteso quale componente di processi naturali nei cui confronti la ricerca di propriet? statistiche di insiemi (ancorche tradotte in parame tri e in relazioni funzionali) non e pi? soltanto un momento tecnico dell'analisi di macrosistemi molecolari. Dalla prima termodinamica alia teoria dell'evoluzione per selezione natu? rale, alia meccanica quantistica, la svolta metodologica e fenomenologica e signifi cativa di un nuovo assetto del pensiero scientifico. Se non neU'indipendenza "essenziale" tra il martello dello stagnino Dubois e la testa del medico Dupont, Fir</page><page sequence="17">17 reversibilit? della configurazione indeterministica della natura e da vedersi nella in dipendenza fenomenica assoluta tra il salto quantico che insorge nella ricopiatura di una sequenza di nucleotidi durante la duplicazione del DNA e le conseguenze di quell' "errore" improwiso sul genoma dell'individuo e della specie: e il concetto di variabilit? statistica a dare un significato, contingente e insieme necessario, a quell' elemento accidentale di novit?. Questa interpretazione accidentalistica della variabilit? naturale ? che e implicita nell'interpretazione darwiniana del fenomeno della vita e del suo diveni re ? e alle origini di una gnoseologia non pi? deterministica neH'ambito della qu?le il ruolo della statistica assume rilievo logico ed epistemologico. II sempre pi? esplicito dominio della concezione inderministica dei fenomeni micro-fisici e biolo gico-molecolari suggerisce ormai una vera e propria intuizione statistica della natura. RESUME Dans cette etude s'inspirant dune configuration de la statistique en tant que modus intellegendi du reel, on essaye de determiner la signification du passage de la notion de cas comme limite cpistemique de la pensee humaine a une notion phenomenique du cas, vu comme composante des processus naturels vis-a-vis des quels la definition des proprietes statistiques d'ensembles (tout en prenant la forme de parametres et de relations fonctionnelles) n'est plus tout simplement un moment technique de l'analyse de macrosystemes moleculaires. Le tournant marque a partir de la premiere thermodynamique jusqu'a la theorie de revolution par selection naturelle et a la mecanique quantique, a boule verse la pensee scientifique par une nouvelle attitude methodologique et phenome mologique. Si ce n'est pas sous la forme de l'independance "essentielle" du marteau du ferblantier Dubois et de la tete du medicin Dupont, c'est sous la forme de l'inde? pendance phenomenique absolue existant entre l'ecart quantique qui se manifeste dans la transcription d'une chaine de nucleotides pendant la duplication de 1'ADN et les consequences que cette "faute" imprevue repercute sur le genome de l'indivi du et de l'espece, que se traduit le caractere irreversible de la configuration inde terministe de la nature. C'est l'idee de variabilite statistique qui attribue sa significa? tion contingente et aussi necessaire a cet element fortuit de nouveaute. Cette interpretation accidentelle de la variabilite naturelle ? implicite dapres Interpretation darwiniste du phenomene de la vie et de son evolution ? est ? l'origine d'une gnoseologie qui ne peut plus etre deterministe, et dans laquelle la statistique joue un role logique et epistemologique fondamental. La preponde? rance de plus en plus nette d'une image in deterministe des phenomenes micro physiques et biologiques-moleculaires suggere desormais une intuition statistique de la nature.</page></plain_text>
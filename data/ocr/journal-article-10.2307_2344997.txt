<plain_text><page sequence="1">J. R. Statist. Soc. A, 395 (1973), 136, Part 3, p. 395 Some Aspects of the Statistical Approach to Reliability By Z. A. LOMNICKI (Read before the ROYAL STATISTICAL SOCIETY on Wednesday, April 4th, 1973, Professor M. R. SAMPFORD in the Chair] SUMMARY It would be too difficult to give in one paper of a limited length a balanced appreciation of the statistical approach to reliability and in view of this it was decided to discuss only some selected topics. It happens that some widely accepted reliability concepts and methods should be more cautiously applied and even submitted from time to time to some kind of criticism; on the other hand, there are still some reliability questions which have not been investigated strongly enough or have been neglected. At least some of the problems of these two kinds will be discussed in the paper. Keywords: RELIABILITY; SURVIVAL CURVE; HAZARD; MTBF; MTTF; EVENT NETWORKS; REDUNDANCY; MULTIPLEXING; MULTIPLICATION; RENEWAL PROCESSES; FAILURE TO OPERATE; FAILURE TO IDLE; SERIES-PARALLEL NETWORKS; COHERENT STRUCTURES 1. INTRODUCTORY REMARKS IT is generally said that Reliability Theory is only about ten years old. This may be an exaggeration but it should be realized that the first American textbooks were by Bazovsky (1961) and by Lloyd and Lipow (1962); Zelen (1963) was the editor of papers at a Symposium on Reliability in 1962 and Barlow and Proschan (1965) produced their well-known textbook a little later. The Russian book on reliability was written by Gnedenko et al. (1965) [later translated into Polish and German in 1968; and into English in 1970]. It was about that time that reliability began to interest a wider circle of people. It is true that a number of papers on reliability appeared in the 1950's but, by examining the (now classical) bibliographic guide by Buckland (1964), it may be easily seen that almost all papers on reliability were published in the second half of that decade like, for instance, two very important papers on how to improve reliability by the use of relatively unreliable components written by Von Neumann (1956) and by Moore and Shannon (1956). In spite of this, it must be remembered that reliability problems were investigated earlier by various branches of industry and, particularly in the United States, by various official industrial and defence organizations. In this country the Chairman and Managing Director of the firm for which I was working, the late J. D. North, had just finished an investigation of the reliability of military aircraft then in service. The task took five years (1948-53) and was presented in a 13-volume report entitled "Design for Reliability" (see e.g. Crocombe, 1970). (Apart from being an aircraft constructor as early as the First World War, North was also a Fellow of the Royal Statistical Society and an Honorary Doctor of Science of the University of Birmingham.) He told me that in March 1949, as the Chairman of the Requirement Committee of the Air Registration Board, he decided to-read a paper on air safety to the Royal Aeronautical Society (see North,</page><page sequence="2">396 LOMNICKI - Some Aspects of the Statistical Approach to Reliability [Part 3, 1949) and, before starting to prepare this paper, he went to the Library of the Institute of Mechanical Engineers asking for something on reliability. There was neither a paper nor a textbook on such a problem. He told the audience at his lecture that " . . . it is remarkable that there appears to be little or no literature devoted to the reliability of mechanisms ... ". He ascribed this to the fact that " . . . in most engineering applications reliability is provided by large, even extravagant, margins between the "capacity" of machine and the requirements of the environment. This margin is much narrower in aeroplanes and hence the problem of reliability is of much greater importance to members of the Royal Aeronautical Society." The problem became even more acute with guided missiles and spacecraft not to mention the fact that our lives started to be dominated by the all-present computers. Now anybody approaching reliability problems would lodge complaints of an exactly opposite nature: particularly in the last ten years a lot has been written and said on reliability and we are now flooded with articles, papers, reports, symposia proceedings and even textbooks on this subject. Thus today design and production engineers discuss methods of improving reliability in design and production stages respectively. Testing engineers worry about simulating "realistic" environmental conditions, statisticians produce the optimal experimental methods of "life testing", mathematicians construct mathe- matical models of system reliability. Operational research workers are concerned with the "best" methods of scheduling maintenance, replacement and repair of the equipment to obtain great reliability matched with adequate availability and costs. Biologists proudly display facts demonstrating high reliability of living organisms. A new science was even invented by the Americans with the aim of discovering how this great reliability is achieved by Nature and of trying to imitate such methods in building similar electronic, optical or mechanical devices. This is quite a fascinating programme. Dolphins, sonar bats, multi-eyed insects are spied upon .... All these investigations fall under the name of reliability studies, every year opens new vistas, but all the time probability concepts and statistical methods are used. And this is probably why it was decided to devote one of the Ordinary Meetings of the Society to the discussion of reliability problems. Of course, to present the readers with a balanced picture of the development of reliability theory and with an estimation of recent results would be an extremely difficult task surpassing the ability of one specialist and requiring much more space than the pages allotted to this paper. It seems to me that one of the ways of sustaining the interest of the readers would be to try to select some reliability problems and discuss them here. On the one hand, in spite of its youthfulness, reliability theory developed a sort of "folklore", an "aggregate of traditional, popular beliefs, sayings and customs" (as the dictionary defines it) which perhaps should be submitted from time to time to some kind of criticism. On the other hand, there are still reliability concepts which, for some reason, appear not to have been investigated strongly enough or have even been neglected. In this paper an attempt will be made to discuss at least some of the problems of these two types. The widespread application of the negative exponential distribution, the use of MTBF (mean time between failures) instead of MTTF (mean time to failure), the conviction that the assumption of in- dependence is inevitable or that the application of failure distributions with increasing hazard rate always gives pessimistic results will be discussed and it will be stressed that some of these "popular beliefs" require a more critical approach. Similarly, those problems will be mentioned which are not properly discussed in the textbooks</page><page sequence="3">1973] LOMNICKI - Some Aspects of the Statistical Approach to Reliability 397 and papers on reliability although the engineers are forced to take them into account in their everyday work: for instance, the dependence of failure events; also the fact that apart from failure to operate it is necessary to consider failure to idle. 2. RELIABILITY CONCEPTS AND THEIR PRACTICAL IMPORTANCE On opening any book on reliability it can be noticed that the devices investigated display a dichotomic reliability: they either operate properly or definitely fail. In the case of an electric bulb this dichotomic reliability is easily acceptable but. with very many devices it must be artificially created. For instance an amplifier amplifying three times will be regarded as operating properly if the amplification is between 3-a and 3 + b and failing if it amplifies too much or too little; the values of a and b have to be decided by the engineers. If R(t) is the probability that an item working for t time units is still operating properly then clearly R(O) = 1; we also assume that the failure will occur earlier or later so that R(oo) = 0. This survivalfunction R(t) was borrowed from actuaries; it corresponds to their Life Tables (see e.g. Cox, 1962). The conditional probability of an item failing in the time interval (t, t + At), provided that it was operating at time t, is equal to [R(t)-R(t+ At)]/R(t) and if we divide this fraction by At, the ratio R(t At)-R(t) At. R(t) can be interpreted as the failure rate in the interval (t, t + At) and the limit of this ratio when At tends to zero is h(t) =-R'(t)/R(t) (1) and may be described as the failure intensity at time t, known also as age-specific failure rate or hazard of the Americans. Clearly F(t) = 1- R(t) is the failure probability distribution function and F(O) = 0, F(oo) = 1. It follows from (1) that F(t) = 1 -exp {- h(x) dx} (2) and iff(t) = F'(t) is the probability density offailure then f(t) = h(t). exp (- h(x) dx} (3) The shape of the hazard curve is different for different items. Almost all reliability textbooks tell us that generally it is quite large for small values of t (due to "teething" troubles), then it diminishes settling around a constant value and for large t it increases due to ageing, i.e. to wear and tear. The curve is called the "bath-tub" curve and is shown in Fig. 1. It consists of three parts (marked on Fig. 1 by I, II, III) corresponding to initial (early) failures, to random failures and to wear-out (ageing) failures, respec- tively. (For the detailed discussion of this curve see e.g. Shooman, 1968, pp. 170-171.) If we assume that the teething troubles have been removed and that the period of ageing can be ignored then we really assume that the hazard (age-specific failure rate) is constant so that h(t) = c. In this case F(t) =1-exp(-ct), f(t) = cexp(-ct), R(t) = exp(-ct) (4)</page><page sequence="4">398 LoMNICKI - Some Aspects of the Statistical Approach to Reliability [Part 3, and the failure probability density is a negative exponential function. The expected time of failure (sometimes called MTTF, mean time to failure) is in this case E(t) = ftf(t) dt = J'ct exp (-ct) dt = 1/c. (5) h(t) I ' I I I \' I I/ FIG. 1 Writing 0 for the reciprocal of c we see that in this case the expected time to failure 0 can be used to define the failure distribution. Sometimes this parameter 0 is called by a hackneyed name MTBF (mean time between failures) and as long asf(t) is a negative exponential function there is nothing wrong with this. Indeed, MTBF, the mean time between failures of two identical independent items, can be defined as MTBF = j |{ix-yIf(x)f(y)dxdy (6) and forf(t) given by (4) this is equal to 0. However, it is not quite clear why it should be adopted in reliability studies and, as it will be seen later, for other distributions MTBF is different from the expected time to failure. Since MTBF belongs now to reliability folklore and since, at present, other distributions are often applied, it would be perhaps useful to remember that MTBF is generally different from MTTF and that it should not be confounded with the mean time between successive failures as for instance in Smith (1969). In the case of constant failure rate the mathematical model becomes extremely simple, the surviyal curve and other functions being defined by one parameter 0. The methods of estimating this parameter by various life tests have been derived and, since there is no ageing, the items which fail can be replaced during the tests; this leads to life tests with replacement and shortens the test time. Truncated and sequen- tial tests have been further developed, again shortening the duration of tests. All these properties, however, cannot be relied upon in practical cases when the equipment is subject to natural wear and tear or still suffers from initial failures.</page><page sequence="5">1973] LOMNICKI - Some Aspects of the Statistical Approach to Reliability 399 In order to apply these methods, developed for the constant hazard rate, people respon- sible for reliability try to keep the equipment in the middle part of the bath-tub curve firstly by accepting only the items which passed some initial tests (burning-in) thus avoiding the "teething" part of the bath-tub curve and secondly by regularly over- hauling the system, inspecting the items and repairing them thus avoiding the ageing. When discussing this problem with an aircraft engineer, I was told that "in fact it has been found that regular overhaul tends to decrease reliability as overhauled items suddenly start to exhibit teething troubles, etc. A new idea is to observe the failure rate and to overhaul only when this starts to increase due to ageing". In other words it is important when avoiding the ageing part of the bath-tub curve not to move back into the part corresponding to initial failures. Anybody who finds that his car, after having been thoroughly serviced, still shows some old (or new) deficiencies will agree that this is a quite reasonable observation. One of the methods of treating the equipment which is ageing is the application of the so-called Weibull Distribution discussed in most reliability text books. The failure probability density function is given by f(t) = (t)fl- exp (7) and the survival function by R(t) = exp { - (t/O)fl} = 1- F(t). (8) The age-specific failure rate (hazard) is equal to F'(t)/R(t) so that h(t) = pi (,-1) (9) This distribution is defined by two parameters: the shape parameter , and the scale parameter 0. The survival curves R(t) for ,B= 1, 2, 3 and xo are shown in Fig. 2. For B1 we have the usual negative exponential case with the constant hazard rate 1/0 and expected time to failure 0. For P = 2 the hazard increases linearly, for p = 3 as the square of time, etc. If t = 0 the survival curves for all P assume the value e-l as can be seen from Fig. 2. If P is very large then for t &lt; 0 the exponent in (8) is extremely small and R(t) is near to unity; for t&gt; 0 the exponent is very large negative and R(t) is near to zero. This means that for large , all items fail near the time t = 0 and we are in the situation of a man whose equipment lasts almost exactly 0 time units. If this fact is taken into account it may be said that in a way the shape parameter measures the consistency offailure occurrence: the higher the value P the greater the probability that the failure will occur exactly around the time t = 0.t It may be easily checked that for f(t) given by (7) the MTBF defined by (6) has the value MTBF = 2Or(1 + 1/,) (1 -2-1/fl), (10) t Baumgarten (1963) in one of his lectures on reliability quoted in toto a poem by Oliver Wendell Holmes which according to him became a leitmotif of American reliability engineers. The title was "One Hoss Shay" (one horse chaise) and described how his carriage "was built in such a logical way it ran a hundred years to a day".</page><page sequence="6">400 LOMNICKI - Some Aspects of the Statistical Approach to Reliability [Part 3, where F(x) is the Euler Gamma Function so that for P3&gt; 1 the mean time between failures decreases with P. For very large P MTBF is very near to zero which is under- standable when all items fail at almost the same time.t W1.0 X 1~~~~~~~~~~~~0 ~ ~ ~ ~ 0 0*8- 0.7- 0.6 I 0.5- 0.4- 0*3- 0.2- 0*1- 0 TO T, FIG. 2 There now exist methods of estimating the shape and the scale 0 parameters by life testing so that having a sample of components we can get some information about both parameters of survival curve (8) (see e.g. Lloyd and Lipow, 1962). The following example shows how the application of Weibull distribution can elucidate some practical problems: A physicist had to provide a guarantee to the Ministry of Health that some pneumatic equipment produced by his factory would operate properly for a given time T with probability 0-9 so that, with this probability, the patient suffering from a special disease would be served by this equipment. Having found in books the description of the negative exponential distribution he estimated 0 from a sample of his equipment and found that the abscissa To (see Fig. 2) of the point of survival function corresponding to the ordinate 0-9 was rather small, that the patient could be served with probability 0-9 only for a short time. The result was very unsatisfactory and he sought advice from statisticians feeling that the value To obtained by him was too pessimistic. In our firm we advised him to apply the Weibull model: he estimated + A similar result can be obtained for the Special Erlangian failure distribution F having probability density function {p(px)a1- exp (- px)}/(a - 1)! (see Cox, 1962). Then the ratio MTBF/MTTF is equal to (2al) 41-a which for large values of a tends to zero and again MTBF should not be confounded with the MTTF.</page><page sequence="7">1973] LOMNICKI - Some Aspects of the Statistical Approach to Reliability 401 the shape parameter which was found to be near =2. As can be seen from Fig. 2 the resulting guarantee time can be proved to be larger. He felt that even better results could be achieved if he could manage to improve the consistency of failure occurrence by a more careful manufacturing process and was very happy when the next batches of his equipment showed the shape parameter near to /3 = 3 thus increas- ing the guaranteed time even more to the value T1. This example shows that in some cases the exponential approach so fashionable among the manufacturers and some Government authorities may lead unexpectedly to an opposite danger of presenting too pessimistic a picture whilst the real situation can be quite satisfactory. Very often the application of Weibull distribution can be proved to be a better approach and not always the assumption of ageing deteriorates the picture. 3. SYSTEM RELIABILITY AND EVENT NETWORKS In the case of a costly, complicated system (like an aircraft, a ship, an oil refinery or an atomic power station) a different approach to Life Testing is needed; one cannot afford to build a number of such systems and test them to destruction. Instead we study separately the reliability of various components and combine these results, in a systematic way, to arrive at the reliability assessment of the whole system. The task would be easy if the failure of any component meant the failure of the whole system but modern devices are deliberately constructed in such a way (by the use of redundant elements) that the failure of one component does not always spoil the functioning of the system. (One of the aeroplane engines can fail but it will safely reach the target; having both visual and sound warning equipments we shall be informed of danger even when one of them fails, etc.) This complicates the problem and, in cases of such systems with a large number of fundamental units, the finding of a proper solution may become rather involved. 2 3 4 6 FIG. 3 In order to treat the problem in a systematic way the concept of the event network has been introduced in analogy to switching networks of electrical engineers. A switch can be either closed or open and having drawn a switching network one can easily decide which combination of open switches prevents a signal from passing and which combination of closed switches allows it to pass. In the event network switches are replaced by the fundamental components of the system which, like switches, have a dichotomic reliability. Having drawn an event network we can in the same way find which combination of component failures lead to the system being inoperative (and vice versa). These fundamental units may be electrical connections, amplifiers, rectifiers, some mechanical devices like pumps, motors, valves and even human operators together with their mechanical, optical, electrical "extensions", etc. To clarify the usefulness of the concept of event network, let us assume that it is, for instance, presented by Fig. 3.</page><page sequence="8">402 LOMNICKI - Some Aspects of the Statistical Approach to Reliability [Part 3, If Ai is the event of failure of the ith component then the event F of failure of the whole system is in our example: F=A1 or [(A2 orA3) and A4] or (A5 and A6) (11) It is clear that if the events appear in the event network in series then, in the above definition (11) of system failure F, they are connected by "or" and if they appear on parallel lines then they are connected by "and". Formula (11) which describes system failure F in the terms of component failures connected by "or" and "and" is not a very neat way of presenting the results. A simplification is obtained by the application of Boolean algebra (see e.g. Hohn, 1962) when "or" is replaced by Boolean addition and "and" by Boolean multiplication. The expression obtained in this way displays all the possible combinations of elemen- tary events which cause the system to fail and is called "hindrance function". In our example (11) becomes F = A1 + (A2 + A3)A4 +A5 A6 (12) and it could have been read straight from Fig. 3. However, in the case of complicated systems this may be rather difficult and Boolean algebra is a very useful tool not only for finding out which combination of component failures leads to the failure of the system but also for making sure that nothing was omitted. In some textbooks the authors first define the system reliability R and in such a case the event R (that the system operates) is defined by changing "or" into "and" and vice versa and replacing the events Ai (of ith component failing) by the com- plementary events Bi (of ith component operating). Passing to the Boolean expression we obtain the "admission function" R as the complement of function F according to the de Morgan laws. In our example the admission function complementary to (12) is R = B1(B2 B3 + B4) (B5 + B6). (13) The hindrance (and admission) functions appearing above are in their final form logical sums of combined events causing the failure (or the operating) of the system. To evaluate the probability of such a composite event we have to apply the so-called Inclusion Exclusion Theorem (see e.g. Feller, 1951). If the event F is the logical sum of events F = F, + F2 +... + Fng, (14) then according to this theorem the probability P(F) of the event F is given by n n n P(F) = pi- E Pij + E Pijk- ............. +(-)n-lP.12 ..ng, (15) i=1 iJ=1 i,jk=1l where pi is the probability of the occurrence of the event F,, pii the probability of the events Fi and Fj happening simultaneously, etc. In other words P(F) = Sl - S2 + S3 - ... - + (- )Of-ln S(16) where S, is the sum of probabilities Pi and S, the sum of all (f) probabilities of (n) combinations of r events from the set of events F1, F2, ..., Fn.</page><page sequence="9">1973] LOMNICKI - Some Aspects of the Statistical Approach to Reliability 403 If in the above formula for P(F) we omit the terms from S, onwards including S, then according to the so-called Bonferroni's Inequality the error committed has the absolute value less than Sr, the first omitted expression. Thus, for instance, if failure probabilities are very small then approximately P(F) = P1 +P2 + . . . +Pn + error (17) and the absolute value of the error is less than S2. These very well-known concepts of event networks and corresponding Boolean expressions were presented here deliberately to stress one very important fact: formula (16) was obtained without any assumptions about the independence of failures of various components. Thus we can apply the above formulae and Bon- ferroni's Inequality even when, in general cases, this independence is not assumed provided that we know something about the probability say P123 that the events F1, F2, F3 will occur simultaneously, etc. In many cases an engineer assessing the reliability of a system is forced to take such a dependence into account. In the firm for which I worked it was assumed that mechanical and electrical failures of four aeroplane engines were independent but it was clear that, apart from this, there were events like contaminated fuel, increased humidity, considerable frost or a flock of starlings near the airport which may affect all the four engines simultaneously and this dependence was introduced in reliability assessment. It is true that in many practical applications the independence of individual failures can be very often assumed and then the evaluation of P(F) can be completed when the probabilities of these events P1,P2. ... ,Pn are known and PiPjPk written for Pik, etc. However, it is unfortunate that this assumption of independence of events is made very early in most textbooks or taken for granted as something naturally acceptable. To be fair it must be stated that for instance in Shooman (1968) there was an attempt to discuss the dependence and that in recent times the problem of how to avoid this assumption of independence when it is unjustified attracts more and more attention. 4. MULTIPLEXING AND MULTIPLICATION In many systems (e.g. aeroplanes, computers) reliability is of paramount impor- tance and there is the necessity to design systems with extremely small failure proba- bilities. One way of achieving this is to use extremely reliable components. There are, however, limits to this approach: in most cases our technical possibilities are not appropriate enough; in others we can achieve the desired degree of reliability only at prohibitive costs. An alternative way is to design a system in such a way that it contains two, three or more similar or different groups of components, each group being able to execute the same specific task. These parts are generally referred to as lanes. If a system has to fulfil a number of various tasks these are very often referred to as channels. There are two ways of coping with the problem (see e.g. Thomason, 1969). Either all the lanes are executing the same task simultaneously and the failure of one of them does not matter since the remaining ones are operating properly (which is known as multiplexing) or only one of the lanes is operating and the others "stand-by" and are made to replace successively failing lanes (this is known as multiplication). If, for example, our event network is represented by Fig. 3 and if it is required to obtain a higher reliability then it may be decided to build a second similar system of</page><page sequence="10">404 LOMNICKI - Some Aspects of the Statistical Approach to Reliability [Part 3, components 7,8,...,12 and connect both of them into a duplex structure. In this case the hindrance function given by (12) becomes D = {Al+(A2+A3)A4+A5A6}{A7+(A8+A9)A10+AllA12}. (18) If the probability of event F defined by (12) is q, then the introduction of similar redundant elements with failure events A7, A8, ..., A12 leads to P(D) = q2 of course under the assumption that the failures of redundant elements are independent of the failures of the first group of components. Thus duplexing lowers the failure proba- bility from a small number q to a much smaller q2. Similarly, if we have a component with failure probability p and if we combine m such components in parallel then we obtain an m-plexing system and the failure probability becomes very small pm (again under the condition that the independence can be assumed). In the firm where I worked the multiplexing method was applied to the investi- gation of the electric signalling system for supersonic aircraft; there were 5 channels (the task of moving the two external, two internal elevons and the rudder). Each channel was controlled by 4 lanes, lane No. 1 being actuated by the air engine No. 1, etc. The hindrance function became quite involved; in our study we had 440 ways in which the electrical system might fail. To achieve this simplicity we lumped together some events as being due to a suitable set of components (Birnbaum and Esary, 1965, call then "modules"); without this simplification the hindrance function would have 10,756 terms. By assuming some reasonable probabilities (from published data, from the firm's own experience, sometimes from suitable guesses) it was possible to prove that a 4-lane solution had an overall reliability required by the Ministry, that a 3-lane solution would be inadequate and that the 5-lane system would over-satisfy the require- ments increasing unnecessarily the weight and the cost.t The important thing is that the approach described above allows us to investigate various solutions at the design stage and from the shape of the hindrance function it may be seen what are the sources of unreliability, what suitable choices of components can be made and what changes can be introduced into the original design. It must be borne in mind that the situation described above holds only on the assumption that the system operates for a short time T (for which a probability of a lane failure is small) and that, after this short period of operation, it is subjected to examination and, if necessary, to repair so that all the lanes are in their initial state. It is clear that, if the system is allowed to continue for a longer time without these preventive measures, then its reliability will deteriorate since any uncorrected failure of the lane will decrease the redundancy. Thus the,problem arises what will happen to the system when it is allowed to run for longer periods without the individual lanes being inspected and corrected. This is important not only in the case of missiles and artificial satellites but also in the case of modern aeroplanes which being more and more complicated can only be serviced at a few airports throughout the world. Some useful information about the behaviour of the multiplex system under such conditions can be obtained by the investigation of the underlying Renewal Process (see Cox, 1962; Lomnicki, 1967). Here we shall only discuss the case when the improvement caused by the intro- duction of redundant elements is measured by the ratio Rm = MtI/M1, the ratio of the t When quadruplexing was discussed J. D. North remarked that although the use of redundant elements became suddenly fashionable there was really nothing very new in this idea; he designed in 1911 a military aircraft in which the wire connections to the aeroplane's control surfaces were doubled and placed in different parts of the machine to increase its.safety.</page><page sequence="11">1973] LOMNICKI - Somne Aspects of the Statistical Approach to Reliability 405 expected life of the parallel system composed of m elements to the expected life of one element. If the survival function f(t) is a Weibull one given by (8) then it is easy to see that the failure distribution function of a parallel system of m components is given by Fm(t) = [1 -exp {-(t/l0)}]m - k exp /mk(tl 0)} (19) with the failure probability density function rn m tfl(- Jl fm(t)- ( kg k - (5 1)k-' exp {-k(t/l0)f}. (20) But for any A positive {t/ exp (-At6) dt = r(1 + 1/)/A1+11fl so that the expected life of the system is equal to m= tf(t) dt = Or(1 + 1/) E ( ( 1)k () k-llf. (21) Clearly Ml = Or(1 +1/fI and hence m Rn = E (- )k-1 k-1) (22) k=l Writing uO = 1, uk = k-1l3, E for an operator changing Uk into Uk+i, 1 for the identity operator and A for the usual differencing operator A = E- 1 we have from (22) _ Im -( ) Rn= (1-I)k iIIEkuo={1-(1-E)m}uo= 1+A U k==1k A so that Rm = {1 +(-A)+(-A)2+... +(_A)m-l}Ul. (23) The results are given below in Table 1. TABLE 1 The improvement ratios for systems of m components arranged in parallel-Weibull distribution M\9 0 5 1 2 3 4 5 6 2 1-750 1-500 1-370 1-293 1P206 1P159 1 067 3 2-361 1-833 1-591 1-456 1-312 1P237 1-097 4 2-882 2.083 1.746 1.567 1-381 1P288 1-116 5 3 339 2-283 1-866 1-650 1-432 1-322 1-129 6 3-747 2-450 1-962 1-715 1P471 1-349 1-139 7 4-117 2-593 2-042 1-770 1-503 1-371 1-149 8 4 458 2-718 2.111 1-816 1-529 1-388 1-158 9 4-773 2.829 2.174 1-856 1-552 1P404 1-167 10 5 070 2-929 2-231 1-891 1-572 1-419 1P175</page><page sequence="12">406 LOMNICKI - Some Aspects of the Statistical Approach to Reliability [Part 3, For the negative exponential distribution (p = 1) formula (23) yields Rm= I+1/2+1/3+...+1/m; this may be checked with the appropriate column of Table 1 which additionally shows how, with the increasing parameter I, the advantages of multiplexing (measured by this ratio) decrease considerably. It is clear from (22) that for very large P the multiplexing (even of the high degree m) yields the ratio Rm very near to unity so that there is hardly any improvement. This is understandable since in this particular case all failures occur almost at the same time and there is no sense in using redundant elements. A similar situation also obtains for Gamma distributions with parameter a when, with increasing a the advantages of multiplexing gradually disappear. Perhaps it should be stressed here that if we are again interested in the probability of system failing in a very short period of time T then it follows clearly from (19) that this probability is approximately (t/G)(m-l)4 times smaller that in the case of single component, multiplexing becomes highly advantageous and even increases with the value of P. Once more, against all expectations, the Weibull distribution for small values of T gives more optimistic results than the negative exponential distribution. 5. FAILURE TO OPERATE AND FAILURE TO IDLE When investigating the reliability of a system it is necessary to realize that we are very often compelled to take into account not only the failure to operate but also the fact that the device may operate inadvertently (when it should not do so) and this we shall call "failure to idle". The ordnance people use the expression "duds" (ammu- nition which does not explode when fired) and "prematures" (ammunition which explodes unexpectedly). Sometimes the expressions "open" and "closed" ("short") failures are used, borrowed from electrical engineers, but this does not seem suitable since it may suggest that such failures occur only in electrical problems. Perhaps this is why the discrimination between these two kinds of failure is often ignored in the textbooks [here Barlow and Proschan (1965) is an exception; see also Proschan's contribution in Zelen (1963)] and there are a few papers on reliability discussing this difference. Anybody, however, who applies reliability in practice knows perfectly well that the existence of these two kinds of failure cannot be ignored: for instance when something goes wrong with the system there are reliable monitoring devices giving a proper warning but they should be so constructed that they should not give an unnecessary ("nuisance") warning when everything is in order. The danger is that, when the nuisance warning occurs too frequently, the genuine alarm might be disregarded as in the case of the shepherd boy who cried wolf too often. The two kinds of failure were discussed by Barlow et al. (1963) in the case when component failures are distributed according to F(t) with the conditional probability of failure to operate given by p &gt; O and of a failure to idle by q = I-p. They also assumed that the function F(t) was a negative exponential F(t) = 1- exp { - (t/0)} identical for all components and that the component failures were independent. They found for what values of p a parallel system having m components has a higher expected life than other parallel systems with different number of components. It is obvious that, if we have m identical components and if p = 1 then we have only failures to operate (open failures) and in such a case the highest expected life of the system will be obtained when these components are put in parallel. Vice versa if p = 0 we have only failures to idle (short failures) and the best arrangement would be</page><page sequence="13">1973] LOMNICKI - Some Aspects of the Statistical Approach to Reliability 407 to put these components in series. The problem arises what would be the answer if p has a value somewhere between 0 and 1. The series-parallel structures built of m identical components were discussed by MacMahon (1892); some generalizations of his results can be found in Riordan and Shannon (1942), Kn6del (1950), Carlitz and Riordan (1956) and Lomnicki (1972). Thus, for example, for m =4 we have 10 different structures shown in Fig. 4. 1 2 3. 43 IL .-&lt;.- &lt; II' 2 4 III *-?.---I---|- 1J-&lt;a -- . 1 IV .*IV' V v~~~~ FIG. 4. Two-terminal series-parallel networks built of four components. If a is the probability of a component failing to operate and b the probability of it failing to idle then it is easy to evaluate for every structure the probabilities u(a) and and v(b) of these two kinds of failure. They are given for structures shown in Fig. 4 in Table 2. TABLE 2 Structure u(a) v(b) I 4a-6a2+ 4a3-a4 b4 II 2a-2a3 + a4 2b3-b4 III a+a3-a4 3b2-3b3 + b4 IV 4a2-4a3 + a4 2b2- b4 V a+2a 2- 3a3 + a4 b2+b3-b4 VI a 2 + a3 -a4 b+2b 2-3b3+b4 IV' 2a2 -a4 4b2-4b3 +b 4 III, 3a 2- 3a3 + a4 b+b3-b4 II, 2a3-a" 2b-2b3+b4 I' a4 4b-6b2+4b3-b4</page><page sequence="14">408 LOMNICKI - Some Aspects of the Statistical Approach to Reliability [Part 3, It may be easily proved that 1- u(a) = v(l - a). The ratio of the expected time to failure of the system to that of one component can be proved to be R= ( [v{q+pexp (- t/6)}- v{q-qexp (- t/O)}] dt (24) in the case when the system is subjected to the first or to the second kind of failure equally often. For instance in the case of structure IV of Fig. 4 we have u(a) 4a2 - 4a3 + a4, v(b) = 2b2 - 4 (25) and the ratio R is equal to R = . C [2{q +p exp ( t/ 0)}2 {q +p exp (- t/ )}4-2{q-q exp (- t/ )}2 +{ q-qexp(-t/6)}4]dt (26) which, once the integration is performed produces R as the following function of q: R'= 3/4+5q/3-q2/2-q3. (27) Thus for every structure S built of m components this improvement ratio can be calculated as a function of q or p. Denoting this ratio by R8(p) we define the function Rm(p) = max RS(p), (28) s where the maximum is taken over all series-parallel systems built of m components; this function (see Fig. 5) measures the advantage obtained by using m components in the case when p has a given value. The range of p-values for which Rm(P) coincides with R8(p) shows for which values of p this particular system S should be chosen in preference to others as yielding the longest life of the system. Of course in view of duality between structures I and I', II and II', etc. it is enough to study only half of them. The improvement ratios as functions of p are shown in Fig. 5 and it may be seen that only six structures out of ten are to be considered, i.e. structures I, M, IV, IV', II', I'. Similarly for m 5 it is necessary to consider only 10 from 24 possible structures. A more detailed discussion of this problem will be found in Lomnicki (1974) and it should be interesting to find out what changes would occur if instead of exponential failure distribution some other distributions like Weibull or Gamma were used and what results would be obtained if both kinds of failure were subjected to different failure probabilities. 6. COHERENT STRUCTURES If we have n components and if each of them can either operate or fail (dichotomic reliability) then a general structure built of them may be in one of 2n states according to which element operates and which does not. At each state of such a kind a given structure may operate or not so that the structure function may have at each state the value 0 or 1. Consequently we have 221 possible structure functions. It is obvious that many of them are so bizarre viewed as structure functions that they would not correspond to real physical systems and it is for the purpose of characterizing and studying a class of Boolean functions useful in representing physical systems that the concept of coherent structures was introduced by Birnbaum et a!. (1961).</page><page sequence="15">1973] LOMNICKI - Some Aspects of the Statistical Approach to- Reliability 409 2-2 2-o,~~~~~~~~~~~~~~~~~~I 186 14 - 2 O O6 O8 1 .Rs(p) 1-0 0-8 0-6 02 0 O*~02 0*4 0-6 0-8 1.0 p FIG. 5</page><page sequence="16">410 LoMNICKI - Some Aspects of the Statistical Approach to Reliability [Part 3, If, for instance, we have only two components there are 22 = 4 possible states: state (1, 1) when both operate, states (1,0) and (0, 1) when one operates and the other does not and state (0,0) when both fail. There are 24= 16 ways in which we may allot zeros or units to each of the states. If we allot 1 to the first three and 0 to (0,0) then this corresponds to the parallel arrangement of two components. If we allot 1 to (1, 1) and 0 to the remaining states we have the series arrangement of two elements. However, if we allot 0 to (0,0) and to (1, 1) and 1 to the remaining states we obtain a rather bizarre structure which fails when both of them operate or if both fail but operates when one component fails and another operates. A coherent structure is a structure the functioning of which does not deteriorate if a failed component is replaced by an operating one and does not improve if the operating element is replaced by a failing one: in other words it is a combination of components defining a reasonable structure. This definition was at once accepted by engineers and other people interested in reliability as a very appropriate one. The question arises: How many coherent structures can be built with n components? A paper by Hanish et al. (1969) discusses the problem but it is still open. It can be learned from this paper that the problem was really posed by Dedekind (1897); it may be also seen that the number of coherent structures is the same as that of mono- tonic functions of algebra of logic and that is why Barlow and Proschan (1965) prefer to speak about "monotonic" instead of coherent structures. It is rather un- pleasant that in over 70 years the number-theoreticians, logicians and reliability specialists could not produce a neat answer to this problem. The answers up to n = 4 were given by Dedekind, for n = 5 by Church (1940) and for n = 6 by Ward (1946) with the aid of a computer. They gave the solution of the problem concerning the number of labelled structures; these numbers bi are as follows: b1 = 1, b2 = 4, b3 = 18, b4= 166, b5=7,579, b6 = 7,828,352. (See also Hansell, 1967.) It is worth investigating what is the number of coherent structures built of iden- tical components or generally built of n components with a specification (stating that there are ni components (i = 1,2, ...,n) of type i so that their sum is n). Even if the problem were solved for n &gt; 6, the number of coherent structures would be extremely high and it would be interesting to find whether between the classes of coherent structures and the series-parallel ones discussed earlier a special class can be defined of importance in reliability investigations. 7. CLOSING REMARKS AND ACKNOWLEDGEMENTS In this paper an attempt has been made to direct the attention of the readers to the need of critical examination of various hackneyed reliability concepts and at the same time to point out that various parts of reliability theory appear to be treated not strongly enough (or even neglected) in spite of their practical importance. To achieve this a very subjective choice of problems has been made and an apology is due to those who may feel that some very important ideas have been omitted, for instance Bayesian approach to life testing, trading-off reliability against costs, per- formance and availability or many other methods of investigating reliability. The author wishes to stress that his interest in reliability arose in connection with his work at Boulton Paul Aircraft Ltd where he had opportunity to discuss these problems with the late J. D. North, a man who could be regarded as the pioneer of reliability theory in this country. He is very grateful to Mr C. V. Kenmir, the Advanced</page><page sequence="17">1973] LOMNICKI - Some Aspects of the Statistical Approach to Reliability 411 Project Controller at Dowty Boulton Paul who was kind enough to discuss with him the initial stages of this work and to offer a number of really useful comments. He also wishes to record his thanks to Dr W. R. Buckland of the Economist Intelligence Unit who advised him on some aspects of the paper. REFERENCES BARLOW, R. E., HUNTER, L. C. and PROSCHAN, F. (1963). Optimum redundancy when com- ponents are subject to two kinds of failure. J. Soc. Ind. Appl. Math., 11, 64-73. BARLOW, R. E. and PROSCHAN, F. (1965). Mathematical Theory of Reliability. New York: Wiley. BAUMGARTEN, E. (1963). Lebensdauerverurteilungen und Zuverlaissigkeit von Reihen- und Parallel-Systemen. Bericht des Fachausschusses Unternehmungsforschung in der Luft- und Raumfahrt. Frankfurt am Main. BAZOVSKY, I. (1961). Reliability Theory and Practice. Englewood Cliffs, N.J.: Prentice-Hall. BIRNBAUM, Z. W. and ESARY, J. D. (1965). Modules of coherent binary systems. J. Soc. Ind. Appl. Math., 13, 444-462. BIRNBAUM, Z. W., ESARY, J. D. and SAUNDERS, S. C. (1961). Multicomponent systems and struc- tures and their reliability. Technometrics, 3, 55-77. BUCKLAND, W. R. (1964). Statistical Assessment of the Life Characteristic. A Bibliographic Guide. London: Griffin. CARLITZ, L. and RIORDAN, J. (1956). The number of labeled two-terminal series-parallel networks. Duke Math. J., 23, 435-446. CHURCH, R. (1940). Numerical analysis of certain free distributive structures. Duke Math. J., 6, 732-734. Cox, D. R. (1962). Renewal Theory. London: Methuen. CROCOMBE, F. F. (1970). Portrait of a pioneer-J. D. North, 1893-1968. J. Roy. Aeronaut. Soc., 74, 787-796. DEDEKIND, R. (1897). Uber Zerlegungen von Zahlen durch ihre gemeinsamen Teiler. Festschrift der Technischen Hochschule zu Braunschweig bei Gelegenheit der 69. Versammlung Deutscher Naturforscher und Arzte, pp. 1-40. FELLER, W. (1951). An Introduction to Probability Theory and its Applications. Vol. 1. New York: Wiley. GNEDENKO, B. W., BIELAJEV, J. K. and SOLOVIEV, A. D. (1965). Matematycheskoye Metodi v Teorii Nadezhnosti (in Russian). Nauka, Moscow. - (1968a). Metody Matematyczne w Teorii Niezawodnosci (in Polish). Wydawnictwa Naukowo- Techniczne, Warsaw. - (1968b). Matematische Methoden in der Zuverldssigkeittheorie (in German). Akademic Verlag, Berlin. - (1970). Mathematical Methods of Reliability Theory. London: Academic Press. HANISH, H., HILTON, P. J. and HIRSCH, W. M. (1969). Algebraic and combinatorial aspects of coherent structures. Trans. N. Y. Acad. Sci., 31, 1024-1037. HANSEL, G. (1967). Problemes de denombrement et d'evaluation de bornes concernant les e]ements du treillis distributif libre. Publ. de l'Institut de Statistique de l'Universite Paris, 16, 159-218, 219-300. HOHN, F. E. (1962). Applied Boolean Algebra. An Elementary Introduction. New York: Mac- Millan. KN6DEL, W. (1950). tCber Zerfallungen. Monats. Math., LV, 20-27. LIEBLEIN J. (1953). On the exact evaluation of the variances and covariances of order statistics in samples from the extreme value distribution. Ann. Math. Statist., 24, 282-287. LLOYD, D. K. and LIPow, M. (1962). Reliability: Management, Methods and Mathematics. London: Prentice Hall. LOMNICKI, Z. A. (1967). Renewal processes arising in the study of multiplex systems. Aero- nautical Research Council Reports and Memoranda, No. 3444. (1972). Two-terminal series-parallel networks. Adv. Appl. Prob., 4, 109-150. (1974). Some remarks on system reliability. Applicationes Mathematicae (Poland), 14, No. 2 (in press). MACMAHON, P. A. (1892). The combination of resistances. The Electrician, 28, 601-602. MOORE, E. F. and SHANNON, C. E. (1956). Reliable circuits using less reliable relays. J. Franklin Inst., 2623 191-208, 281-297.</page><page sequence="18">412 Discussion of Mr Lomnicki's Paper [Part 3, VON, NEUMANN J. (1956). Probabilistic logic. In Automata Studies (C. E. Shannon and J. Mc- Carthy, eds.). Princeton: Princeton University Press. NORTH, J. D. (1949). Some aspects of the relationship between airworthiness and safety. J. Roy. Aeronaut. Soc., Vol. 53, 915-933. RIORDAN, J. and SHANNON, C. E. (1942). The number of two-terminal series-parallel networks. J. Math. &amp; Physik, 21, 83-92. SHOOMAN, M. L. (1968). Probabilistic Reliability: An Engineering Approach. New York: McGraw- Hill. SMITH, C. S. (1969). Quality and Reliability: An Integrated Approach. London: Sir Isaac Pitman and Sons. THOMASON, R. (1969). Introduction to Reliability and Quality. London: The Machinery Publishing Co. WARD, M. (1946). Note on the order of free distributive lattices. Bull. Amer. Math. Soc., 52, Abstract 52-5-13. ZELEN, M. (ed.) (1963). Statistical Theory of Reliability, Proceedings of an advanced seminar by the Mathematical Research Center, U.S.A. Arnmy, University' of Wisconsin, The University of Wisconsin Press. DISCUSSION OF MR LOMNICKI'S PAPER Professor F. DOWNTON (University of Birmingham): Reliability theory exhibits the usual difficulties experienced in any area into which statistics intrudes, that of com- munication between the practitioner and the theorist. It has, therefore, been an unusual pleasure to hear a paper from Mr Lomnicki, who besides being an excellent mathematical statistician, has had to deal with the day-to-day problems of reliability engineers. For those of us interested in reliability theory he has, however, forecast further difficulties. We are now to be required to delve into biological systems as well. The question of how Nature achieves her reliability looks a fascinating one and I hope that at some future date (or even later in the discussion) we may be told more about its statistical aspects. The basic differences between biological and mechanical structures seem to be twofold. To quote from Lenihan (1972) the first is that "in a man-made structure or machine each component usually has one purpose-but in the body many structures and materials have multiple functions.... The blood is a cooling (or heating) fluid-and a transport system for oxygen and other essential nutrients but also contains substances which can when needed be converted into materials for the repair of broken bones or damaged blood vessels." To adopt Nature's approach would be to ask a car manufacturer to design a cooling system, which also lubricated the engine, maintained the tyre pressures, inhibited rust in the body work and automatically repaired minor accident damage. How far we are from this with mechanical systems can be seen if I remark that many vehicle cooling systems do one thing, sometimes inadequately, and in addition contain a thermostat, which does not 'even fail safe. The second difference (again to quote Lenihan) is that "every healthy heart, liver or kidney does the same job in the same way-but every organ, indeed every cell, has char- acteristics of its original owner and no one else. The situation here is that of mass- production of complex machines using components which, though identical by any normal test, are not interchangeable." At a time when, for example, some vehicle manufacturers are (for quite other reasons) considering changing from production line construction to team construction, perhaps the concept of building a machine from compatible com- ponents is one which could usefully be incorporated. The lack of communication between theory and practice, which I mentioned earlier, is nowhere better illustrated than in what Mr Lomnicki refers to as the "folklore" of the subject. As he points out his definition (6) of mean time between failures (MTBF) has very little relevance to reliability studies; for unrepairable systems it is meaningless and for repairable systems the properties of the times between successive failures arise as much from the mathematical consequences of the observational procedure as from the life</page><page sequence="19">1973] Discussion of Mr Lomnicki's Paper 413 characteristics of the system. That is, in order to obtain information about the distribution of successive intervals between failures (which are not in general independent) we must necessarily measure those successive intervals. It is possible to show (Downton, 1971) that, under not unreasonable assumptions, these intervals will rapidly exhibit exponential like properties for a wide class of failure behaviour. If then data analysis techniques assume (as they generally do) that successive intervals are independent and identically distributed we will be led to the conclusion that the exponential distribution is an appropriate model. In other words we will mistakenly be accepting the only situation, criticized by Mr Lomnicki, where MTBF is the same as mean time between successive failures. The assumption of independence of successive failure times has already been criticized by Ascher (1968), but his criticisms do not appear to have, had much effect. The "bath-tub" curve (Fig. 1) is another fascinating example of the impact folklore has in reliability studies. No one can doubt that Fig. 1 represents the subjective views of reliability engineers on the behaviour of systems to failure, both unrepairable and repair- able. Yet the justifications of it can only be described as naive. For unrepairable systems data extending right through the range of time required in order to establish a hazard rate of this form do not seem to be available. This is in part because life test procedures usually involve some form of censoring so that only early failures are observed. On the other hand, for repairable systems hazard rate has little meaning and renewal rate of components of the system has been suggested as the appro- priate parameter. Quite apart from the unfortunate connotations of the words "renewal rate", which because of their association with renewal theory suggest independent intervals between successive failures, there does not appear to be any available data to support a curve of this shape. This has led to "justifications" of this curve-a typical example is Krohn (1969)- which are not data-based but which argue from the curve to the life characteristics which must lead to it. Thus Krohn argues in the unrepairable case that the "bath-tub" arises from a mixture of three Weibull distributions with shape parameters less than one, unity and greater than one; no other justification is given apart from' the anthropomorphic one that "there is a strong parallel between this curve and the force of mortality curve for human beings". Bearing in mind the differences already noted between biological systems and mechanical ones this hardly satisfies any criterion of scientific proof. For repairable systems (now considering renewal rate) Krohn develops a renewal process with different inter-event distributions to give the appropriate renewal rate curve. I can only quote Krohn's own comment on this, that the curve does "not come directly from the data but (is) a judgement assumption, Whic-h is believed to be similar to that for some electronic equipment". This is not to say that it is not possible to find some data- based concept which would explain the engineer's belief in the "bath-tub" as, in some sense, a measure of risk of failure for repairable equipment; merely that nothing so far published seems to have done so. Mr Lomnicki's paper, by drawing our attention to problems such as these, has, I hope, drawn practice and theory closer together; I therefore take great pleasure in proposing the vote of thanks. Mr A. WINTERBOTTOM (The City University): Mr Lomnicki's survey paper on reliability is most timely. Quoting from the abstract of a paper by R. G. Easterling in a special issue of the LE.E.E. Transactions on Reliability which was devoted to the application of Bayesian methods: "There appear to be two important developing trends in reliability. One is away from the use of statistics by reliability engineers; the other is towards increased use of Bayesian techniques., One source of the latter may be disillusionment with what is regarded as classical statistics; however, one source of the former may be dissatisfaction with what has been called Bayesian statistics." These are the words of a professed classical statistician but in my own contact with reliability engineers I have detected a similar dissatisfaction.</page><page sequence="20">414 Discussion of Mr Lomnicki's Paper [Part 3, Perhaps statisticians are responsible to some extent for this state of affairs. I am sure that this commendable paper will go some way towards remedying this situation by encouraging statisticians and mathematicians to take a greater interest in the diverse problems afforded by a study of reliability. I am particularly grateful that the misuse of MTBF has been exposed. Mr Lomnicki has wisely restricted coverage to some selected topics and I hope that I will be forgiven for mentioning briefly two additional topics with which I have become involved. There are important problems concerning the estimation of the reliability of complex systems. Contracts increasingly require estimates in the form of lower limits for system reliability at some associated probability level. Estimates must often be determined from component test data since the completed system is too expensive to test. This is especially true of weaponry where testing usually destroys the system and there are also additional costs of laying on facilities at firing ranges. Component test data may be represented by (0, 1) variables (pass/fail test data) or else times to failure may be observed. Suppose we take as an example an admission function such as (13) of the paper. Point estimates of the Bi and R are easily determined but interval estimation is usually very difficult. Lower confidence limits for R can be obtained using the following approaches: (i) Asymptotic Normality of maximum likelihood estimators. (ii) Asymptotic x2 distribution of -2 ln A where A is the likelihood ratio statistic. (iii) Bayesian methods. (iv) Special methods and approximations to them for particular systems, usually simple in structure. Of the first three (i) is easiest to apply, (ii) and (iii) presenting formidable computational difficulties. Unfortunately in reliability applications the maximum likelihood estimators have negative skew distributions and this leads to lower limits which are optimistic for small or moderate sample sizes. This is just what the reliability engineer does not want. One line of enquiry here would be to investigate transformations of the maximum likeli- hood estimators which will lead to a more rapid convergence to Normality with increasing sample sizes. In case (iii) it is worth mentioning that Hunting Engineering have developed a Monte Carlo method called CLARA (Confidence Limits and Reliability Assessment) which generates a posterior distribution for system reliability and it can handle systems with hundreds of components. The second topic is that of Software Reliability and it is of growing importance. There has been considerable study of hardware reliability but as yet little work has been carried out in connection with the reliability of software. There are features of software which make it distinct from hardware. Unlike hardware there is no degradation and attempts to correct a program can occasionally make it catastrophically worse. The Central Electricity Research Laboratories at Leatherhead have initiated research in this field in connection with process control in power stations. In process control a stream of information (tem- peratures, pressures, flow rates, etc.) is fed into the computer. The purpose of the program is to condense the data into a form suitable for display so that an operator can take appropriate action as necessary. Such is the complexity of the input data that it is not possible to design programs that are comprehensive enough to deal with all possible configurations of the data. Occasion- ally a fault which is not present in the process will be indicated by the display. This is the analogue of failure to idle in hardware. Prior to commissioning, simulated inputs are fed into the computer and if the program "fails" attempts at repair are made. A first attempt at modelling the reliability growth of software during this stage has been made by J. L. Verrall and B. Littlewood. Their paper is to appear in Applied Statistics, 1973, No. 3. They have conveyed the intention of a programmer to improve a program by taking a Bayesian approach and considering ordered sequences of distribution functions of the</page><page sequence="21">1973] Discussion of Mr Lomnicki's Paper 415 failure rate of the program. In other words repair is probabilistic, it being more rather than less probable that the failure rate is decreased at a repair attempt. Mr Lomnicki has made valuable contributions in the field of reliability and it is very fitting that he was invited to give this paper. I would like to second the vote of thanks. The vote of thanks was passed by acclamation. Professor D. R. Cox (Imperial College): Like the previous speakers, I enjoyed Mr Lomnicki's broad review. The MTBF defined in (6), and its sample analogue, have quite often been considered as a measure of dispersion. It is a curiosity that it can be written as where ,u is the mean time to failure and 2 8 f {R(x)}2 dx is the mean time to failure of a series system of two independent components. This can be seen, for example, from the identity lx-yi = x+y-2min(x,y). The condition that MTBF is equal to ,u is thus P2S = 12t I certainly agree with Mr Lomnicki that MTBF is not usually very interesting in reliability work. Professor Downton has commented on the bath-tub and I too had intended asking about the firm evidence for its common occurrence. A cumulative sum analysis of a life- table would be appropriate if one wanted to isolate the right-hand end but would clearly require a lot of data. An interesting question concerns confidence limits on the successive bounds associated with (1 5)-(17). Do they get wider as the more complex formulae are used? If so there is a level of complexity beyond which it is not sensible to go, even if some relevant information is available. Mr T. R. Moss (UKAEA, Harwell): We, in the UKAEA Systems Reliability Service, have also experienced cases where the Weibull distribution function gives a better fit to the failure pattern than the exponential. This was particularly notable in a study of pneu- matic instrument failures where a prediction based on an exponential model was a factor 10 or so worse than that experienced in the early operating lifetime of the pilot plant. Collecting failure data from a somewhat similar installation and plotting times to first failure for each of the equipment type on Weibull probability paper showed that all of the various types had shape factors ranging between 1-5 and 2. Consequently one could then say with some confidence that the failure frequency would ultimately approach the pre- dicted rate rather than the very low rate indicated by the results from the early life of the pilot plant and would then remain sensibly constant. Concerning Section 4 of the paper (which deals with the Weibull distribution), I think it is important to point out that a three-parameter Weibull model needs to be employed in most cases-the third parameter, of course, being the location parameter. The two- parameter model is used in the paper and with Fig. 2 which shows the square distribution for f = oo can present a misleading picture. In practical cases where there is variability in performance (due to manufacturing and operating variations, etc.) it is difficult to see how : can exceed 3-5 (the value of A for a normal distribution). If A is higher than this the location parameter needs to be adjusted. It is my view that only in very simple assemblies of components, operating within a simple stress spectrum, will the value of A exceed about 2-5. Increasing the number of components and the stresses applied to the equipment</page><page sequence="22">416 Discussion of Mr Lomnicki's Paper [Part 3, increase the variability of performance and ,B will increasingly approach unity-the exponential case. The importance of studying the failure characteristics in the useful-life phase is that one can quickly identify components and failure mechanisms which are dominant and take action to eliminate undesirable features of design or operation which result in tendencies towards wearout modes of failure. In most cases mechanical equipments exhibit wearout characteristics but will generally be operated until they fail and then be repaired (aircraft operation is perhaps an exception). Some variability will, therefore, be introduced and, as Bazovsky shows in his classic example on incandescent lamps, the failure frequency will stabilize after a few generations., Incandescent lamps are simple assemblies operating within a simple stress spectrum and in practice on more complex assemblies we find the failure frequency stabilizes within the characteristic lifetime of the equipment and then stays sensibly constant for some time. So, contrary to other contributors to this discussion, I expect an exponential distribution to develop, although this may take a little time, and at this stage am happy to use it for predicting equipment and system reliability. It is a simple model and can be shown to be adequate. Mr A. J. BOURNE (Systems Reliability Service, UKAEA): In Section 5 of his paper, Mr Lomnicki discusses the concepts of "failure to operate" and "failure to idle". I would agree that these complementary modes of failure can be very important in reliability assessment. They have been extensively examined in critical safety systems in the nuclear industry since the late 1950's under the terminology of "failure to safety" and "failure to danger". However, two specific failure modes of this nature are only part of a general concept of failure behaviour. In my experience of reliability assessment, it has often been necessary to evaluate a number of different failure modes. For instance, in a complex plant or system with multiple outputs, the effect of different failures may lead to a whole range of output combinations, some of which may be acceptable and some of which may not. Also, there may be different degrees of acceptability. In the ultimate, a system's reliability may be described by a continuous distribution of performance values which covers the complete spectrum of possible outcomes. Also, the required performance of a system may be more legitimately described by a continuous distribution rather than a limited number of specific values. In this instance, specific or discrete failure modes disappear and the overall reliability function itself becomes a con- tinuous function instead of a number of particular values for each failure mode. This concept of overall reliability behaviour, which is described more fully in Green and Bourne (1972), has become more important in the past few years. Technological systems of today tend to be designed and operated with very much smaller "margins of safety" so that even small variations in performance achievement or performance requirement can lead to unacceptable or partly unacceptable behaviour. Care needs to be taken in the reliability assessment of such systems since a reliability model in terms of discrete failure modes or catastrophic failure modes may lead to erroneous conclusions. As a second point, I was very interested in Mr Lomnicki's theory of "coherent struc- tures" outlined in Section 6 of his paper. In many structure or network problems it is often necessary to limit considerations to a restricted number of functions and "coherency" may form a useful criterion. I would be interested to know whether Mr Lomnicki has estab- lished coherent structures by a personal examination or whether he has seen ways of doing this automatically. Apart from "coherency", there may be other constraints on a system which limit the structures of interest. These constraints could be cost, efficiency, need for technical. development, etc. and it would be interesting to hear whether Mr Lomnicki has had experience in taking these sorts of constraints into account.</page><page sequence="23">1973] Discussion of Mr Lomnicki's Paper 417 The following contributions were received in writing, after the meeting: Professor Z. W. BIRNBAUM (University of Washington): As pointed out by Mr Lomnicki, reliability theory has recently become a lively and fruitful field of study for statisticians, mathematicians, operations research workers, engineers, biologists and many other specialists, who make use of their particular skills but often lack the broad know- ledge which may be needed to formulate properly and, hopefully, solve the arising problems. It is therefore gratifying to see a paper which combines mathematical insight, statistical techniques and practical experience in dealing with tangible applications, and presents a wide range of rather sophisticated material in a deceivingly simple manner. The practi- tioner's point of view has led the author to a number of observations that needed to be made and are pertinent. To mention just a few: he stresses the distinction between mean time to failure and mean time between failures; he points out that the assumption of an increasing, instead of constant, failure rate does not always lead to more pessimistic con- clusions; the use of Bonferronni's inequality to obtain approximations to system reli- ability without assuming independence of components is simple and useful; he calls attention to the fact that of the two types of failure, failure to function and failure to idle, the second has been often overlooked. An interesting question is raised towards the end of the paper: is there a class of structures, smaller than that of all coherent structures but larger than that of series- parallel systems, which would be of importance in reliability investigations? This question is motivated by the fact that in actual practice multi-component systems are designed in consecutive steps, by first proposing a rather simple structure of a small number of com- ponents, then replacing some of these components by an entire subsystem (module), and by repeating this procedure until a system of many components is designed which satisfies the initial specifications. If in each step a single component is replaced by a module which consists either only of components in parallel or only of components in series, then the result will be a parallel-series system. A generalization of this procedure, still fitting into accepted practice, would consist again of a sequence of steps in which a single component is replaced by a multi-component module, where the modules could be any "k-out-of-n structure". A k-out-of-n structure is defined as a system of n components which functions as long as at least k of its components function; for k = 1 this reduces to a system of n components in parallel, and for k = n to n components in series. Therefore, a class of structures obtained by a sequence of replacements of single components by some k-out-of-n systems is larger than that of all parallel-series structures, and yet within the realm of practical systems design. In fact, one would be inclined to conjecture that this class is in some sense "dense" within the class of all coherent structures, so that the performance of any given coherent structure can be approximated as desired by a structure of our class. Dr R. E. BARLOW (University of California at Berkeley): Mr Lomnicki has written a leisurely, penetrating review of the current status of reliability theory. As pointed out in his introduction, the problem of statistical dependence of failure events has not been adequately dealt with in most of the literature. An attempt to correct this situation has been taken by Esary et al. (1967) and also in a new book by Barlow and Proschan (1974). In place of independence, they assume a weak type of positive dependence called association which seems extremely plausible for very many systems. For example, if we consider a series system of n components with marginal reliabilities Pl, P2, .P., Pn then, under association n pi p SP[system functions] &lt; minimum pi. The lower bound is attained if components are statistically independent. The upper bound is attained if components are completely dependent in the sense that X1 = X2= ... = X" where Xi is the indicator random variable for component i (of course in this case</page><page sequence="24">418 Discussion of Mr Lomnicki's Paper [Part 3, PI = P2 PO = ps) Similar bounds can be given for any coherent system (see Barlow and Proschan, 1974). The connection between event networks and fault trees which are currently of great interest to nuclear safety engineers should perhaps have been mentioned. Although the mathematical theory of fault trees is similar to that of coherent structure theory, the emphasis and terminology are different. This is currently a very fast developing research area. Basic ideas are discussed in the Appendix to Barlow and Proschan (1974). The author's remarks on applications of the Weibull distribution are interesting. In this connection the author has a very nice paper on the Weibull renewal process (Lomnicki, 1966) which deserves a mention. The remarks about failure to operate and failure to idle can be applied more generally to any coherent structure, for example k-out-of-n structures can also be analysed using the notion of duality expressed in the paper by the formula 1-u(a) = v(l-a) below Table 2. The problem of determining the number of coherent structures of order n discussed in Section 6 has been studied most recently by Hirsch et al. (1969) who provide a historical review of the problem and give asymptotic results relevant to bounds on the related Dedekind problem. The author replied briefly at the meeting and subsequently more fully in writing as follows: I am most grateful to the discussants for their encouraging and helpful comments. Apart from a number of very useful remarks some speakers brought out a wide range of problems which deserved to be stressed but which I unfortunately disregarded or was forced to omit in view of the short space at my disposal. Professor Downton rightly emphasizes the twofold basic differences between biological and mechanical structures which make it difficult for technologists to imitate the methods by which Nature has achieved such a great reliability of living organisms. He also addi- tionally explains how, apart from MTBF and MTTF, the mean time between successive failures can be used in reliability studies and stresses the fact that the "bath-tub" curve shown in Section 2 really represents some subjective views of reliability engineers and that any scientific justification of this curve can only be described as naive. Mr Winterbottom justly feels that when restricting coverage to some selected topics I omitted two problems which deserve attention: various approaches (including the Bayesian one) to obtain the estimates in the form of lower limits for system reliability and the growing importance of Software Reliability. Professor Cox shows that MTBF defined by formula (6) can be also written in a simpler form thus allowing us easily to see for what distributions [apart from that given by (4)] it is equal to 0. Agreeing with Professor Downton he complains that really there lacks a firm evidence of the common occurrence of the "bath-tub" curve, a point which was not clearly stressed in the paper. He also rightly remarked that the problem concerning confidence limits on the successive bounds of Bonferroni's inequality should have been more precisely stated in the paper. Mr Moss points out that the three-parameter Weibull distribution might often appear useful and that the values of ,B rarely exceed 3-5. He expresses the opinion that the ex- ponential distribution is still of great importance in predicting equipment and system reliability and one can agree with his point of view at least in the case of repairable systems. Mr Bourne mentions the concepts of "failure to operate" and "failure to idle" dis- cussed in Section 5 and emphasizes that "they have been extensively examined in critical safety systems in the nuclear industry since the late 1950's under the terminology 'failure to safety' and 'failure to danger'". It is a pity that the definition of these two modes of</page><page sequence="25">1973] Discussion of Mr Lomnicki's Paper 419 failure was not given, that it has not been explained by some examples and it has not been mentioned in what publications these can be found. Thus I find it very difficult to judge to what extent the different terminology really applies to the same concepts. He emphasizes that apart from the two specific failure modes of this nature it is often necessary to evaluate additionally a number of different failure modes. I have a feeling that even in such a case some failure modes will belong to the class when operation is prevented and some to the class when idling is unnecessarily interrupted and it seems unavoidable that in the ultimate his "overall reliability function" of the system belongs to one of these two classes and that we have to decide which of the two problems is to be solved. It should be added that the definition of two modes of failure mentioned by Mr Bourne can be found in a paper by Low and Noltingk (1972) in which they stressed that, although suitable for the discussion of nuclear safety systems, these modes cannot be applied generally since in the general case "it is not always obvious which mode of failure should be regarded as safe". Professor Birnbaum suggests that an important class of structures can be obtained by replacing some components in a series-parallel network by multi-component "modules" which can be "k-out-of-n" structures. It is quite likely that by following his advice a useful "bridge" can be built between the class of series-parallel and the class of coherent structures which would be of great importance to reliability investigations. Dr Barlow agreeing that the problem of dependence of failure events has not been adequately dealt with in reliability literature shows how the situation can be improved by assuming a weak type of dependence called association. He also stresses that in some cases the event networks (discussed in Sections 3 and 5) can be replaced by fault trees currently discussed by nuclear safety engineers. He justly notices that the results of Section 5 for series-parallel networks concerning the failures to operate and failures to idle could be applied generally to any coherent structure and particularly to k-out-of-n structures. Having followed his remark for m = 4 and m = 5 I realize that by further investigations a new light can be thrown on the results of this section. REFERENCES IN THE DISCUSSION ASCHER, H. E. (1968). Evaluation of repairable system reliability using the "bad-as-old" concept. I.E.E.E. Trans. on Reliability, R-17, 103-110. BARLOW, R. E. and PROSCHAN, F. (1974). Statistical Theory of Reliability and Life Testing, Vol. I. New York and London: Holt, Rinehart &amp; Winston. (In the press.) DOWNTON, F. (1971). Stochastic models for successive failures. Proc. 38th Session Int. Statist. Inst., 44, Book 1, 677-694. ESARY, J. D., PROSCHAN, F. and WALKUP, D. W. (1967). Association of random variables with applications. Ann. Math. Statist., 38, 1466-1474. GREEN, A. E. and BOURNE, A. J. (1972). Reliability Technology. London: Wiley. HIRSCH, W. H., HANISCH, H. and HILTON, P. J. (1969). Algebraic and combinatorial aspects of coherent structures. Trans. N. Y. Acad. Sci., 31, 1024-1037. KROHN, C. A. (1969). Hazard versus renewal rate of electronic items. LE.E.E. Trans. on Reli- ability, R-18, 64-73. LENIHAN, J. M. A. (1972). What is bioengineering? Contemp. Phys., 13, 295-309. LOMNICKI, Z. A. (1966). A note on the Weibull renewal process. Biometrika, 53, 375-381. Low, T. A. WESOLOWSKI and NOLTINGK, B. E. (1972). Quantitative aspects of reliability in process-control systems. Proc. LE.E., LE.E. Reviews, 119, 8R, 1033-1036. As a result of the ballot held during the meeting, the following were elected Fellows of the Society: ALEXANDER, James, B.Sc. ATKINSON, John Benjamin, M.Sc. BOHRER, Robert Edward, Ph.D. CHEONG, Hock Aun, M.Sc. CHEONG, Kee Cheok, Ph.D. CLARKE, Kenneth Robert, M.Sc. 16 COLE, Mrs. Frances, Dip.Stats. CONNIFFE, Denis, M.Sc. Cox, John Herbert, C.Eng., D.M.S. DALY, Martin Jonathan, B.Sc. DEANS, Alexander David, M.I.S. DENNIS, John Stuart, M.A., F.I.A.</page><page sequence="26">420 Discussion of Mr Lomnicki's Paper [Part 3, DUFF, Ian Francis, M.Sc. FARR, Derek James, B.Sc. FENLON, John Stafford, M.Sc. FESTING, Michael Francis Wogan, Ph.D GOODWILLIE, David Gordon, M.Sc. HAND, David John, B.A. JACKSON, Arthur Duncan, B.Sc. JIAWOOK, Rizgar Nabi, B.Sc. KHALE, Suhas Shankar, B.Sc. LAWRENCE, John Charles, OND-HNC (Electronics) LEE, See-Ching, M.Sc. Student MACPHERSON, Ian Stuart, M.Sc. NACCACHE, Judith Anne, B.Sc. OAKSHOTT, Leslie Andrew, M.Sc. PETHYBRIDGE, Roger John, Ph.D. PORT, Raymond Philip, B.A. POYNTZ, Colin Douglas, M.Sc. REDFERN, Edwin John, M.Sc. REYNOLDS, Enid Marjorie, M.Sc. SCOTT, Roger Gordon, M.Sc. SHANNON, David John, M.Sc. SMITH, John Lawley, M.A. SPEED, Terence Paul, Ph.D. SUYAMBULINGOM, Chellappa, Ph.D. THRUPP, Michael, B.Sc. TURNBULL, Bruce, Ph.D. UREN, Malcolm Brian, B.Tech. VEALE, Dorothy Caroline, B.A. WALL, John Richard, B.A. WESTOBY, Kenneth, B.A. WEXLER, Gwyneth, B.Sc. WILSON, Alex Wilkie, M.Sc. As a result of the ballot held during the meeting of May 9th, 1973, the following were elected Fellows of the Society: ABAKUKS, Andris, D.Phil. ALEXANDER, John Robert, B.Sc. BARNETT, Arthur James, B.Sc. BLUNDELL, Mrs. Sylvia Mary, M.A. BRENNAN, Patrick James, M.Sc. CAULCUTT, Roland, B.Tech. CHARLES, Graeme Stewart, M.Sc. GEDALLA, Lawrence, B.Sc. (Hons.) GIDDINGS, David Roger, M.Sc. HANLEY, Arthur, B.Sc. HARRISON, David Spencer, B.A. HENRY, Colin Randolph HOGAN, Charles Patrick, M.A. KATZ, Eliakim, M.Sc. MOLES, David John, M.Sc. OGLESBY, Robert Andrew, B.Sc. SALAMI, Shakiru Okunola, B.Sc. SAVAGE, John Paul, M.Sc. SUSARLA, Vyaghreswarudu, Ph.D. THOMSON, Michael J. D., M.Sc. WHITEHEAD, Richard McKenzie, M.Sc. WILLING, Pamela Mary, B.Sc. WOODWARD, David Graham, B.A. YARNELL, Paul</page></plain_text>
<plain_text><page sequence="1">Reviews COMPUTERS AND COMMON SENSE by Mortimer Taube Columbia University Press (1961) Nuel D. Belnap, Jr. Department of Philosophy Yale University Can computers be designed and programmed to perform tasks in? volving "quasi-human intelligence, knowledge,andknowledgeability ?'Y/? 1) Taube thinks not. Indeed, in the book under review he labels the pur? suit of such a goal a "scientific aberration/' abusing its supporters as like unto the frauds or fools of astrology. (R2) Taube's book is on the whole pretty silly; not only does its crimson tone make it a difficult book from which to learn, but it is full of bad arguments purporting to prove that this or that aspect of the pro? gram in artificial intelligence is impossible of fulfillment. For antidotes the reader is directed to reviews in Science (March 2, 1962) and Behavioral Sciences (April, 1962), and to a carefully thought out monograph by Paul Armer, "Attitudes toward intelligent machines," published by the RAND Corporation. In this review I should like to concentrate on four connected but distinguishable questions concerning the possibility of developing com? puters with ability to perform such tasks as mechanical translation of natural languages, playing chess or checkers, simulating the functions of the brain in higher-order problem solving, conducting fully automatic warfare, proving substantial theorems in mathematical logic, writing music or poetry, and the like. (1) Is it logically possible that a machine can be made to do these marvelous things? (2) Granting that it may be logically possible, is it really pos? sible; i.e., is there any positive, concrete evidence supporting the claim that machines can be made to do these things? (3) Granting that it may even be really possible (in the prescribed sense), is it economically possible?can we afford it? 34 M.U.L.L.</page><page sequence="2">(4) Granting that it may be economically possible, to what extent is this a good way to spend our admittedly limited time and money? My plan is to take up each of these questions in turn. (1) Can computers think? If this is meant as a question of logical possibility (the "logical 'can'"),the answer will depend?as does any answer to a question of logical possibility?on definitions. If men are (by definition) very complex computers or if computers are (by defi? nition) low grade intellectual organisms, then of course computers can think. Even if men and machines are to be conceived as lying on an n-dimensional continuum as to intelligence (as Armer suggests), the questions as to logical possibility must be given an affirmative answer. But if men have (by definition) essential features which machines fail (by definition) to have?e.g., consciousness or intuition?then obviously the answer must be that machines cannot think. There is unfortunately some controversy about these definitional matters, though the whole thing smacks of the (passe) mechanist-vitalist controversy; Taube is a (passe) vitalist. He argues, for example, that machines cannot simulate brain-function, because (by definition) the function of the brain is "to secure successful behavior of the organism in relation to its enviornment" (p. 71); and machines cannot learn be? cause learning is the change from conscious to unconscious (habitual) activity to attain a desired goal." (p. 47) Taube pairs off his arguments from definition with those of the (passe) mechanists: of course machines can do what the brain does, since* nature has given us a working model" [in man] (R3); and of course machines can learn, since chess and checker playing machines improve their game with time, and learning is "improved performance based on consequences of past performance." (p. 47) This has the ring of word-play. And so it is; but it is not for that reason inconsequential. It is important to realize, as I think the disputants do not, that the argument here is neither "merely" verbal, nor is it an argument about empirical fact; it is rather a dispute about what Kant would have called "regulative principles," principles which are not results of inquiry, but which raiherguide inquiry: regulative princi? ples suggest lines of attack, provide a conceptual frame for asking ques? tions, and even furnish definitions. A man's answer to (1) thus depends on which of the following questions he would answer in the affirmative: (a) Are there "massive analogies" between man and computer? (R4) (b) Or is there a "radical discontinuity" between the two? (c) Or is there, as Armer suggests, a "continuum" stretching between them? To decide between these is to decide between regulative principles. The decision will show itself in the kind of experiments a man will think worth doing, in the kind of questions he will ask, and as we here illustrate, in his choice of definitions: if a man subscribes to "massive analogies*' as a regulative principle, then he will define "learning" in such a way as to guarantee that it can be truthfully applied to both men and machines; if he subscribes to the principle of "radical discontinuity" he will define "learning" in such a way that a machine cannot meaningfully MARCH, 1963 35</page><page sequence="3">(much less truly) be said to learn; and if he chooses the middle of the road "continuum" principle, then he will define "learning" in such a way that its applicability will be a matter of degree. But?and this is the point I should like to make against all disputants?the choice of definitions cannot rationally be used in support of one's choice of regula? tive principles. How, then, can one adjudicate between rival regulative principles? It is in this domain, I submit, that the pragmatic theory of truth comes into its own: a regulative principle is "true if it gives rise to fruitful lines of inquiry, to interesting, answerable questions, and to theoretical? ly fecund schemes of definition. Taube does in fact argue here and there that the assumption that men are machines (or that computers are organisms) has not led to fruit? ful and interesting results; that it has given us programs, policies, and prophecies, but has not increased our understanding of either men or machines. More often, however, he is involved either in showing that arguments for the empirical truth of "the myth of thinking machines" (his subtitle) are circular or fallacious (they are?see especially p. 69 and the long note on pp. 132-133), or in advancing equally circular or fal? lacious arguments for the empirical truth of his own thesis of "radical discontinuity," which we could with propriety call the "myth of conscious? ness." (R5) His chief weakness is his total failure to support the principle of "radical discontinuity" as a regulative principle. Nowhere, except perhaps in his muddy chapter on meaning, does he indicate how acceptance of his principle would lead to interesting questions or viable lines of research. He wants us to reject the programs growing out of the "massive analogies" or "continuum" principle, but gives us not the smallest hint of a program which could take their place. (2) In order even to ask the second question, "Is there any positive evidence giving us reason to suppose that computers can be built and programmed to translate languages, play good chess, prove substantial mathematical theorems, etc.?" we must adopt the "massive analogy" or the "continuum" framework, so that it is at least logically possible that a machine could do these things. But?and here Taube argues cogently?it is important to realize that merely allowing the logical possibility does not answer the question as to the real possibility, unless one adopts the ludicrous (and common) course of arguing from the premiss of mere logical possibility, or from the premiss that there is no evidence against artificial intelligence, to the conclusion that there is some positive evidence for it. Having usefully disposed of this argumentum ad ignorantiam, Taube goes on to detail his claim that in fact there is no evidence supporting the familiar prophecy (Simon and Newell) that "with? in ten years computers will discover important mathematical theorems, write worthwhile music, take over the major part of the field of psychology, and dethrone the current world chess champion" (p. 128), or that mechani? cal translation is just around the corner. Taube's arguments for the real impossibility of mechanical trans 36 M.U.L.L.</page><page sequence="4">lation (taking that as a test case) are uniformly silly. Some of them tacitly seem to suppose that what is wanted is a perfect mechanical translator (p. 35)?as if any human were a perfect translator! Some rely on misapplications of G?del s incompleteness theorem, partly arising from a confusion of syntax and semantics (e.g., p. 34, p. 57): Gbdel showed only that we cannot formalize the notion of mathematical truth, not at all that we cannot formalize mathematical grammaticalness (which indeed he formalizes). Some of Taube's arguments rely on the claim that there is present in humans a faculty of "intuition" or "conscious? ness" denied to machines (pp. 34-35, 93, 96)?this is but a pseudo empirical restatement of his regulative principle of "radical discontinu? ity." One of his arguments has as a premiss the assertion that for formal translatability between two languages A and B, there must be "at some level a one-to-one relation of synonymy between elements of A and elements of B." (p. 33) This last is demonstrably false, inasmuch as there are many examples of effectively inter-translatable formal languages, where in neither direction is the translation-function one-to-one. And as a last example, he in one place argues from the ambiguous philosophical premiss that the minimum carrier of meaning is the sentence, to the re? markable conclusion that the dictionary for any adequate translation program must contain every English sentence as a separate entry (p. 29; see also p. 36). These are all general arguments, different in kind from arguments based on individual computer accomplishments such as the chess-playing machine or the theorem-prover. The obstacle to clear thinking about evidence of this latter sort is that it is difficult to say just what ought to count as "evidence" for the possibility of artificial intelligence on the part of computers, when on the one hand exaggerated claims by certain excitable members of the computing industry get compounded with wildly anthropomorphic descriptions of actual or proposed computer set-ups (R6); and when on the other hand anything that any computer has actually done gets derogated by others as "purely mechanical" and just not good enough to point toward the possibility of artificial intelligence. Some clear-headed analytical work needs to be done on this question of evidence; however, even if we dismiss as irrelevant all computer ac? complishments to date, there remains one argument in favor of the real possibility of artificial intelligence: whenever in the past we have set a lot of bright people to work trying to solve a difficult problem, we have generally found a solution?and this fact is a positive reason in support of the view that we can do so again. (3) This brings us to the third question, that concerning eco? nomic possibility: can we afford to turn loose on this problem sufficiently many bright people for a sufficient length of time? As far as 1 know, nobody has made any adequately grounded estimates of the cost of develop? ing (say) an economically useful mechanical translator capable (say) of reading from a wide range of printed texts. Nor does anyone know (as far as I am aware) how much it would cost to build a world-champion chess MARCH, 1963 37</page><page sequence="5">player. And what is worse, no one knows how to find out. If the de? velopment of artificial intelligence seemed as important as the develop? ment of the Bomb seemed during World War II, so that we could not afford not to pursue it, then we could concentrate our resources on artificial intelligence as we once did on the Manhattan Project, instructing those involved that they must produce results whether possible or not. (4) Since it is not likely that treating the development of arti? ficial intelligence as a crash program is likely to have much appeal, we are faced with the fourth question: is the development of artificial intel? ligence a good thing on which to spend our time and money; and if so, how much should we spend on it? Of course this question is much too broad to have a sensible answer: we are likely to want to spend a good deal on mechanical translation and very little on mechanical chess play? ing. Nevertheless I think we can make the general statement that few or none of us have adequate information on which to base a reasonable judgment on such matters. Nor are we likely to have the means for making intelligent decisions about intelligent machines until we get a better book than Taube's. REFERENCES Rl Quoted from Bar-Hillel on p. 51. This and all page citations are to Taube's book. R2 P. 128; p. 125. R3 Quoted from McCulloch on p. 22. R4 The "massive analogies" principle has two forms: men are rather like machines, and computers are rather like intelligent organisms. Though coming to pretty much the same thing (i.e., nothing) if taken as empirical judgments, they are distinguishable as regulative principles, since each suggests a different line of inquiry, a different set of questions, a different scheme of concepts. R5 See, for example, the extraordinary claim made on p. 93, and repeated on p. 96, that "there exists very substantial evidence that the function of consciousness is to introduce novelty or nonpredictable decision-making into animal behavior as contrast? ed with reflex action. ' R6 I rather suspect that anthropomorphism is just as much out of place in the communications sciences as it is in physics or religion; I intend this observation as an argument against one form of the "massive analogies" principle. 38 M.U.L.L.</page></plain_text>
<plain_text><page sequence="1">Synthese (201 1) 178:207-218 DOI 10.1007/s 11229-009-9544-6 Are creationists rational? John S. Wilkins Received: 23 March 2009 / Accepted: 25 March 2009 / Published online: 1 1 April 2009 © Springer Science+Business Media B.V. 2009 Abstract Creationism is usually regarded as an irrational set of beliefs. In this paper I propose that the best way to understand why individual learners settle on any mature set of beliefs is to see that as the developmental outcome of a series of "fast and fru- gal" boundedly rational inferences rather than as a rejection of reason. This applies to those whose views are opposed to science in general. A bounded rationality model of belief choices both serves to explain the fact that folk traditions tend to converge on "anti-modernity", and to act as a default hypothesis, deviations from which we can use to identify other, arational, influences such as social psychological, economic and individual dispositions. I propose some educational and public policy strategies that might decrease the proportion of learners who find creationism and anti-science in general a rational choice. Keywords Bounded rationality • Epistemic commitment • Creationism • Anti-modernism Where two principles really do meet which cannot be reconciled with one another, then each man declares the other a fool and heretic. [Ludwig Wittgenstein, On Certainty , §611] 1 Kinds of rationality A question I have wondered about for a long time is this: why do people become cre- ationists? Nobody is born a creationist (or an evolutionist, or a Mayan cosmic-cyclist, J. S. Wilkins (ED Department of Philosophy, University of Sydney, Sydney, NSW 2006, Australia e-mail: john@wilkins.id.au Ö Springer</page><page sequence="2">208 Synthese (201 1) 178:207-218 etc.). These are views that one acquires as one learns and integrates into society. But we live, notionally, in a society in which science has learned more about the world in 300 years than in the prior million or so. So why do people become creationists when the bulk of modern thought depends so heavily on science? We can treat this as a general question about those who reject some or all of science - global warming sceptics, HIV-deniers and so forth. "Creationist" here is an instance or representative of this general phenomenon of opposing science in modern society. I ask this question as someone who once was a creationist, although I was trou- bled by it at the time. I know why I took it up, and why I abandoned it, but I wonder whether my experience generalizes? To work through this, I am going to make a rather counterintuitive assumption - creationists are being rational in their choice of world view. Parenthetically, creationists and intelligent designists often claim that science is "just" another religion, and so can be treated as commensurate with their theological views. By using the phrase "world view", I do not intend to give this any purchase. I mean literally that creationists' view of the world is the outcome of belief choices, not that they have, or that science offers, a coherent set of self-supporting beliefs. We usually attack creationists as being ignorant and irrational, but suppose that they are not. Suppose that every step in their doctrinal development is the best available choice for them at the moment. In short, suppose that they are acting as "rational agents" in some to be determined sense. What then? Before we proceed, let us specify definitions, and present the epistemological foun- dation for this claim. "Rational" means different things to different people, and in philosophy it traditionally means something like "making the best inference on the basis of the best evidence". So an ideally rational agent is one who has all the time in the world to gather and evaluate evidence logically, on the basis of the best available goals, using a "wide reflective equilibrium" method, which means making sure that all your epistemic commitments are maximally coherent with each other. This is at best an unachievable state for ordinary people. Of course, traditional philosophy does not require that we are ideally rational, only that we asymptotically approach that ideal, in order to qualify as "rational". We are, however, expected to take into account future expectations as well as present ones, and think our views through in hard detail. But even this seems unrealistic. Cognitive psychology indicates that far from being the, or a, norm, almost nobody is rational in this sense. This is worrisome. What use is a notion of "rationality" as an explanation of epi- stemic choices if nobody actually does it, or even seriously approaches it in practice? Are we left with a view of reason that only Marvin the Paranoid Android can attain (no wonder he was depressed!)? Others have thought this equally worrisome, including Herbert Simon, and more recently the ABC Group set up by Gerd Gigerenzer and Peter Todd (now at Bloomington, Indiana) at the Center for Adaptive Behavior and Cognition at the Max Planck Institute for Human Development in Berlin. Gigerenzer and his colleagues (Gigerenzer 2000; Gigerenzer and Goldstein 1996; Gigerenzer and Selten 2001 ; Gigerenzer et al. 1999) propose what they call, following (Simon 1986, 1978, 1990), "bounded rationality". This is the rationality you have when time is limited and you must make quick, or as they call them, "fast and frugal", heuristic decisions based on limited information. Simon wrote: â Springer</page><page sequence="3">Synthese (201 1) 178:207-218 209 When intelligence explores unfamiliar domains, it falls back on "weak meth- ods," which are independent of domain knowledge. People satisfice - look for good enough solutions - instead of hopelessly searching for the best. They use means-ends analysis to reduce progressively their distance from the desired goal. (Simon 1990, p. 17) The basic idea is that in case where you have to make environmental inferences, such as running away from a predator to use the classic example, there is not sufficient time to consider all the information and come to a wide reflective equilibrium. So you use cues, shortcuts and general heuristics. That is, your "rationality" is bounded by resource limitations - of time, evidence, and cognitive limitations of memory and processing, all of which add up to a cost. As Quine once said (1969, p. 126), "Creatures inveterately wrong in their inductions have a pathetic, but praiseworthy, tendency to die before reproducing their kind". There is, in this case, a survival cost to wrong inductions. A reasoning creature must make a decision rapidly, without the luxury of wide reflective equilibrium, and occasional errors are a cheaper cost than the loss of life. So what to do? Use heuristics that work. Which ones, though? Gigerenzer and Todd identify a number of strategies that people appear to follow, when trying to predict, for example, what things are more common in the environment. They invoke a "take the best" strategy - when you run out of time or resources, simply take the best available solution you have so far encountered. This has a number of steps to maximise one's "return" on cognitive investment. (1) The Recognition Principle - if only one of two objects is recognized, take the one you know. If neither is, randomly pick one. If both are, go to Step 2: (2) Search for Cue Values - recall the cues that are associated with these two choices. (3) Discrimination Rule - decide whether the cue discriminates between them. (4) Cue-substitution Rule - if it does, stop searching for cues. If not go back to 3 and pick a new cue value. (5) Maximizing Rule for Choice - choose the object with the positive cue value. The original version dealt only with inferences that were ecologically valid, that is, in which the cue correlates with the "right" outcome, or correctly predicts the tar- get. This is sometimes called ecological rationality. But there is another kind, which I will call social bounded rationality ("social rationality" has a somewhat different meaning in economics and cognitive psychology generally). Social bounded ratio- nality involves making decisions, not about the ecological world, but choices about what social norms to follow. The payoff in these cases is not survival or environmental knowledge of objects that the cogniser has to navigate and exploit to contribute to survival, but conformance with social norms that might affect individual access to social resources, and indirectly, mating and reproduction opportunities. The recog- nition principle indicates how this applies. If you know of two city names, but one is more familiar to you, you may infer that it is the biggest, a case study done by Gigerenzer and Todd. And you will be right, most of the time. But why is that? The answer is that you hear more from your social contacts, including the media, about the bigger city, so there is a correlation between the cue and the information. â Springer</page><page sequence="4">210 Synthese (2011) 178:207-218 Using the social cues helps you to deal with a large number of previously unen- countered decisions based on small sample sets. And it is a remarkably accurate way to do this. But it is less than reliable about environmental facts that are outside the usual experience of your society. Sometimes, this inference leads you to choose false alternatives. When a child enters into the conceptual world of its society, it relies heavily on these social cues for the basic epistemic commitments on which it basis its further conceptual development. In particular it relies on a series of social authorities, ranging from parental, peer and eventually social sources like teachers and authority figures such as political leaders, public intellectuals, and religious figures. If these authorities are authoritative because they are correct about the facts of the environment, then they are a reliable guide, but often they are authoritative for reasons other than factuality. Even science students at university level are taught concepts that are authoritative for distal reasons. Textbooks will repeat errors of fact or out of date science because the costs of maintaining them to a high degree of accuracy are such that a little error, or a fashionable view of the authors, or a myth that gets repeated, can be tolerated. Nobody is born knowing much. So a fast and frugal inference allows us to quickly gather the conceptual equipment to engage in our society, but this means that we will accept many things that are "true" solely because the environment being cued here is the social environment, not the environment of the non-social world. A case in point is the "common sense" view that we are in control of our actions, when neurology shows us that the "ego", if it exists, tends to construct rationalisations for actions after the action is precipitated (Libet 1985, 2002). I used the term conceptual development above. This was deliberate. The learning process is just as much an individual developmental process as the development of legs or puberty. One major difference, though, is that it may seem that we can back- track in our conceptual development, sometimes called "unlearning", in a way that we cannot do in biological development. In biology, development involves the triggering of differentiation of cells, so that pluripotent stem cells become less able to turn into specialized cells as the lineage develops. Some evidence exists that our cells can be triggered to produce more potentiated cells in special cases. But overall, once a cell has become a neuronal cell, it won't turn into a glial cell or a hemopoietic cell. But it seems to me that our conceptual development is not so different from this. Generally, once we have embedded an epistemic commitment in our conceptual set, it is unlikely to revert in proportion to how embedded it is, as we develop. The last in will be first out, but as you go deeper and deeper, it gets less likely that you will abandon that commitment in proportion to the number of other commitments that depend upon it. Conceptual development is mutually supporting, and a deeply embedded belief may only be revisable at the cost of many other beliefs, rendering the cogniser temporarily confused and conflicted. So let us consider conceptual development in terms of a trajectory of changes that occur from early childhood to maturation. In the next section, I will set up the con- ceptual "spaces" in which pro-science views and "folk tradition" views develop, and argue that it we are to teach people science, we need to change the way in which we teach it, and why. Springer</page><page sequence="5">Synthese (20 1 1 ) 1 78:207-2 18 211 2 Conceptual spaces The development of one's conceptual world is not done in a vacuum. As W. S. Gilbert ironically wrote in Iolanthe . . .every boy and every gal That's born into the world alive Is either a little Liberal Or else a little Conservative! But of course that is not true, as Gilbert knew. Liberals, conservatives, Christians and atheists, scientists and creationists are made, not born. When a child reaches a cer- tain age, they learn many of their base attitudes from those immediately around them, predominantly their family. The space of conceptual alternatives that they encounter is restricted, but at the least each child is predisposed ordinarily to learn from trial and error. This is how language is acquired, and how the knowledge one needs to learn to cross the road, eat a meal, and ask for help is gained. The context into which a child is acculturated includes the educational practices of that society, which are in turn formed out of the conceptual space (Gärdenfors 2000) formed by the traditions of that society. Science is a conceptual tradition, or rather a number of conceptual traditions, passed on from teacher to student at various lev- els, including the popular discourse of science communication via the media. Mostly, though, interest in science begins earlier, at school or through exposure to instructional material. At the commencement point of the child's conceptual development, the child may develop in a number of directions, one of which includes scientific conceptual com- mitments at the level of sophistication relevant to their age and degree of maturity. The child potentially has a "cone of development" of initial states and outcomes. Their actual developmental trajectory through that space of possibilities will depend very largely on the sorts of factors that offer them fast and frugal inferences. A child exposed to only science-directed cues will develop towards a pro-science outcome. A child exposed to only religion-directed cues (or for that matter any folk-based tradi- tion, including folk psychology, folk taxonomy, and the like) will develop towards the outcome of that tradition (Richerson and Boyd 2005). Traditions therefore offer up the cues that influence the epistemic commitments of the developing social agent. Of course, traditions are not "pure" conceptual spaces in the real world, but the toy world example I give here can be extended to more complex cases. Let us assume for the nonce that "science" is a distinct conceptual space from "religion", and that both are "pure"; that is, both are self-contained and maximally coherent conceptual schemes. We will consider overlapping spaces and minimally coherent and self-contradictory schemes later. If a child's cone of possible epistemic commitments begins on the cusp of these two spaces, but he or she is exposed throughout their development to cues from both traditions, the outcome of their development will be the vector of the strength of these cues, weighted according to the depth of the cue exposure, by which I mean that earlier cues will bias the trajectory more strongly than an equal and opposite later cue, by affecting the later "location" in conceptual space of the learner. For instance, if one Ô Springer</page><page sequence="6">212 Synthese (201 1) 178:207-218 is told early on that the Bible is a reliable guide, interpreted according to some her- meneutic (which includes literalism) and theological tradition, then counterevidence offered later in development will be subsequently deflated for that learner. Contrari- wise, if one is exposed early on to scientific results and principles, and is later told that (for example) the Genesis flood is a real event, that proposition will be deflated for that learner on the basis of other cues (such as the dinosaur books they read which told them the world was millions of years old). So far, this is a matter of battling authorities and the subsequent epistemic commitments formed from them. However, if the learner is exposed to scientific practice , such as collecting and classifying spec- imens, or experimental practice in laboratory settings, the learner will acquire their own epistemic commitment to practical norms, as well as propositional concepts. Now suppose that the conceptual spaces overlap to a degree; that is, in the religion case, suppose that there are some shared epistemic values in the religious and the sci- entific traditions. If the commencement point of independent epistemic development occurs in that intersection, the learner may find that an accommodation between the two is necessary, and seek to develop one. Remember, our learner here is an idealized boundedly rational agent who strives for maximal achieveable coherence in their epi- stemic set. So the outcome will depend on whether or not the traditions are compatible as the learner becomes more broadly aware of the commitments each tradition makes. For example, one might study theology and become, as I did, aware that some of the basic commitments of a theological tradition are in fact incompatible with the results of science, in which case the choice is stark - abandon (that part of that) theological tradition, or abandon (that part of) science. Each stage of the learner's development is based on a fast and frugal inference from social cues. In the case of the scientific tradition, this is in large part directly or secondarily based also on environmental cues that are not social, which is to say, on empirical evidence and experiment. But from the naive learner's perspective, each decision will be boundedly rational. This remains true whether or not they become pro-science or pro-folk tradition. So let's diagrammatically show this as a simplification in Fig. 1. If the scientific social cues are restricted to simple "facts" to be memorized for a test or as a marker of inclusion in the "science-based community", however, it would appear that there are few epistemic commitments not also held by the folk tradition. In sum, creationists and pro-evolution proponents will have roughly equal outcomes in influencing learners, unless the learning of one or the other tradition involves acquir- ing a set of distinct epistemic commitments. In the case where it does not, there is nothing to rationally recommend one or the other purely in epistemic terms, and so the learner's choice will not be forced, or at any rate not by rational inference. Modern creationists realize this fact, and so they have a program of developing a "theistic science" epistemology, ranging from the politically inspired (Phillip Johnson) to the philosophical (Alvin Plantinga). Johnson (1995) has painted science as being less com- plete, due to a commitment to "naturalism", than the Christian approach, which also includes "supernaturalism", or, as he puts it, a "theistic naturalism", a commitment to the role of divine activity in creating order in the universe. Plantinga (1996) proposes an "Augustinian science" which can self-consciously avail itself of supernatural causes when the metaphysics of the scientist dictate. â Springer</page><page sequence="7">Synthese (201 1) 178:207-218 213 Fig. 1 Four trajectories of learner development within a pro-science, and a pro-tradition pair of concept spaces. Vertical arrows represent social cues in the direction of the science or folk tradition outcome. The developmental stages are arbitrarily divided into family-based cues, school-based cues, and those encoun- tered in early and late maturity (where "maturity" refers to the epistemic commitments of the learner, not their biological age). The length of each arrow represents the weight of the social cue. The four trajectories shown here are only notional. Depending on the social cues, of epistemic influences, any path within the cone of potential development may be inscribed In the next section, we will consider what happens when two independent trajec- tories develop in a single learner, that is, when compartmentalization fails. 3 Compartments and coherence What happens when rational coherence is not assumed, in the development of crea- tionist views? No child is able to make their epistemic set maximally coherent, and so it is likely that they will acquire a number of mutually inconsistent epistemic values and princi- ples. If your parent tells you to try and see if experiments work out on the one hand, and that you need not do anything but believe the pastor or Bible on the other, this does not register for most young children as a conflict. Young learners are natively active explorers and experimenters to some degree, but this does not immediately translate to being scientific in their endeavors. To be scientific requires more than a trial-and-error approach before it can exclude non- scientific commitments. So as they develop, the learner can acquire distinct sets of views. At some point, what has been called "cognitive dissonance", or the internal conflict between two divergent cognitions (Festinger 1957), may force the learner to Springer</page><page sequence="8">214 Synthese (201 1) 178:207-218 fall in more completely with one or the other set, depending what is more strongly embedded. This is akin to a "conversion experience" in religion - most of those who convert do so because the offered choices more closely match one set of prior devel- opmentally acquired epistemic commitments, forcing the revision or elimination of many of the other sets.1 The learner in this case is only partially rational, in that they can have some degree of mutual contradiction in their belief sets. Of course, under the bounded rationality view, something like this is all but inevitable. If we do not have time to unboundedly consider our epistemic commitments individually, then neither do we have time to unboundedly work through the ramifications of a largish set of views, either. To rep- resent this, let us return to the first figure, now amending it to indicate actual, rather than potential, epistemic development in a single learner (Fig. 2). In this case our learner must make a choice between two mutually exclusive rational sets of epistemic principles and cognitive items. It is more likely in terms of bounded rationality that the earlier views will be more heavily weighted, but as noted above this will also depend upon the force of the social cues upon which that part of the trajectory is based. If more people tell you to rely on the Bible than upon the evidence of observation and experiment, then even if you were exposed early on to empirical reasoning and experiment, the Bible may yet outweigh experience. So crucially a rational choice depends on what sort of exposure one has to scientific matters. I think that direct experience, in which the learner is learning by his or her own activities of experiment and observation, is sufficient to overcome the social cues of authorities. Likewise, inductively similar results by others that closely matches the learner's experience may be enough to overcome authorities. For example, if I do an experiment in the laboratory as a high school junior in which some reaction occurs, a report of other reactions that are sufficiently similar to the one(s) I did is enough to convince me of their veracity, no matter what the local alchemists may tell me. All of this is based on the idealization that we are dealing solely with boundedly rational agents with limited resources and time. Of course, this is not true for even the most "rational" of people - humans have a predisposition to see things in anthro- pocentric terms, and individuals have psychological dispositions of their own. But it does appear to me that we can explain a lot about the reasons why people become anti- science if we take their conceptual development as a process of boundedly rational inference. What deviations from that occur must therefore be imputed to other aspects of human cognition, in particular the social psychological effects such as primacy (forming choices based on the first information encountered), availability (how easy it is to imagine or call to mind), and various forms of consensus enforcement such as groupthink. 1 It may appear that there is a study that contradicts the claim made here by Verhey (2005) that equal exposure to both creationist views and evolutionary biology is sufficient to show more learners the relative value of the latter. Despite some methodological concerns, even if true this study does not contradict my approach here - many students would already have been exposed to creationist material, and possibly this would be the first time they tested those claims against an evolutionary biology that is not a strawman caricature. Also, the mere fact that they are doing university level evolutionary biology might indicate that there prior commitments were less than "folk-based". Here we are considering the wider populace. Ö Springer</page><page sequence="9">Synthese (201 1) 178:207-218 215 Fig. 2 When cognitive dissonance exceeds the individual learner's tolerance limit, then the least deeply embedded of the divergent epistemic sets will be extinguished, forcing a radical revision of prior solutions. The asterisk represents the point at which cognitive dissonance exceeds a tolerance limit for that learner, and commitments revert solely to the other trajectory In the next section, I will suggest what this might mean for educational and public policy strategies for responding to bad science and anti-science. 4 How to oppose public anti-science With this model of the bounded rationality of anti-science in mind, what lessons can we draw from it for public policy and education? Assuming that the model is a good first approximation of why people choose to believe creationist and other anti-science belief sets, several implications might affect our mode of public education and dis- course. The first is that it is highly unlikely that we can argue mature creationists et al. out of their belief sets by merely presenting better information about science. Since they lack the epistemic values that make experimental and empirically gained knowledge worthy, unless they are experiencing cognitive dissonance through a breakdown of compartmentalization, such knowledge is unlikely to sway them. Factual evidence fails to carry the requisite amount of epistemic weight for them, compared to the value of other commitments, for example, to the probative value of the Bible or religious Springer</page><page sequence="10">216 Synthese (201 1) 178:207-218 doctrine. Such people are effectively committed to the extensive cognitive investment they have made over the course of their own conceptual development, particularly the core beliefs on which the subsequent decisions rest. As noted before, the earlier these commitments were made, the more embedded in their belief set they will be, and the harder to dislodge, ceteris paribus. Of course, there will always be a subset of the population that is able to compartmentalize their beliefs under nearly all circum- stances. This follows from the assumption that individuals will vary in their tolerance limits, but also from the fact that not all people have all the time needed to test their competing commitments. This is not to say that proponents of a science-based epistemic set should not try - individual cases will be quite variable on their conceptual investments, and a great number of them, like myself, will have come to these belief choices late, and be vul- nerable to rational argument (by exploring the conflicting rational values they hold). But as a population, the creationist community will be unwilling to endanger their epistemic choices, particularly when they have made an entire scheme out of them. Add to this the community entanglements, and it is most unlikely that they will change willingly. Moreover, there are other, non-rational, constraints on their choices, which will include moral and personal psychological reasons, but that is out of our scope here. It has been suggested that the intentional stance of seeing the world as the results of agency, a form of anthropomorphism, is going to be a major block, and this is true, but that choice can be made less rational in the early stages by showing the learner that many complex situations result from unguided processes. And here is the crucial point. These epistemic commitments must be shown to be irrational early in conceptual development for the population to cease taking that step as a forced conceptual commitment. In short, education is the key (see references in Lombrozo et al. 2006). But the way education of science is often done, both formally and in the popular media, is exactly the wrong way to unforce those choices. Rote learning, emphasis on the "gee whiz" factor without any attempt to explain the under- lying principles both of the processes and phenomena themselves and the way we learn these them, and narrow focus on preparation in education for subsequent tertiary learning in technical and scientific disciplines (particularly medicine and engineering) is not the way to change these epistemic values. All this does is provide the learner with a set of propositions, and no way to find those propositions reasonable when they conflict with other epistemic commitments. All children are at heart inclined to learn by trial and error, I believe. What we need to do is expose children to active learning via the employment of actual observation, experiment and analysis. We can teach our undergraduates all the critical thinking skills we like, but unless they recognize these are worthwhile, the return on our educational investment will be minimal. These days, museums, which for a century were the entré to science for the layper- son without education by observing evidence, focus on the "gee whiz" at the expense of information. For example, it is hard to believe that species are constant and invariant if you see before you a 1,000 shells from a stratigraphie layer covering 20,000 years, but an attempt to lay these out for an exhibition at the Australian Museum in Sydney was foiled by the "exhibit designers", who wanted only a few shells joined by arrows, Springer</page><page sequence="11">Synthese (201 1) 178:207-218 217 or so I was told by a researcher there. Museums are often now entertainment, not education, as many have complained. The crucial way to get people to trust science is to show them, by letting them do it, that science is the premier way to learn about the world. Science is a learning process that relies on no single person, but which each individual can engage in. I am sure science teachers have been trying to get this message across for years, but have been swamped by the demands of curricula designed to make students ready for college and higher education. A better bet would be to educate the population first, and offer ways in which those who are really committed to science, and are therefore much more likely to actually become scientists or otherwise benefit from it, can get ready for the later education. This will have a benefit - the policymakers, usually elected from the general popula- tion of non-scientists, will understand that even if they do not understand the particular discipline that is cognitively relevant to a given social issue, like global warming or HIV/AIDS, that the reasons why the specialists assert these claims is not a matter of simple social construction or dogmatic faith. They may even be better able to assess these claims on their merit, and to critically reject those that are fashionable among scientists but lack the necessary evidentiary support. It might even make Hollywood scriptwriters present science in a better light rather than trading on the prejudices against evil and immoral megalomaniacs out to do anything for the sake of their careers and commercial interests. Given that late conversions are improbable, the task is to ensure that the newer generations are better aware of the epistemic worth of science. Perturb the conceptual development in favor of experiential and experimental knowledge early and the out- comes are likely to be more effectively scientific. We will never be able to eliminate anti-science, for it is often an irrational (in the traditional sense as well as the bounded sense) choice, but we owe it to our society and culture to allow learners who do make boundedly rational choices of beliefs to be able to do so on better grounds than at present. References Festinger, L. (1957). A theory of cognitive dissonance. Stanford, CA: Stanford University Press. Gärdenfors, P. (2000). Conceptual spaces : The geometry of thought, Vol. x (p. 307). Cambridge, MA: MIT Press. Gigerenzer, G. (2000). Adaptive thinking: Rationality in the real world , Vol. xi (p. 344). New York: Oxford University Press. Gigerenzer, G., &amp; Goldstein, D. G. (1996). Reasoning the fast and frugal way: Models of bounded rationality. Psychological Review, 103 , 650-669. Gigerenzer, G., &amp; Selten, R. (200 1 ). Bounded rationality: The adaptive toolbox , Vol. xv (p. 377). Cambridge, MA: MIT Press. Gigerenzer, G., Todd, P. M., &amp; the ABC Research Group. (1999). Simple heuristics that make us smart , Vol. xv (p. 416). New York: Oxford University Press. Johnson, P. E. (1995). Reason in the balance: The case against naturalism in science, law &amp; education (p. 245). Downers Grove, IL: InterVarsity Press. Libet, B. (1985). Unconscious cerebral initiative and the role of conscious will in voluntary action. Behav- ioral and brain sciences, 8 , 529-566. Libet, B. (2002). Do we have free will? Journal of Consciousness Studies 6, 47-57. â Springer</page><page sequence="12">218 Synthese (201 1) 178:207-218 Lombrozo, T., Shtulman, A., &amp; Weisberg, M. (2006). The intelligent design controversy: Lessons, from psychology and education. Trends in Cognitive Sciences, 10 , 56-57. Plantinga, A. (1996). Science: Augustian or Duhemian? Faith and Philosophy, 13 , 368-394. Quine, W. V. O. (1969). Ontological relativity and other essays. New York: Columbia University Press. Richerson, P. J., &amp; Boyd, R. (2005). Not by genes alone: How culture transformed human evolution , Vol. ix (p. 332). Chicago: University of Chicago Press. Simon, H. A. (1978). Rationality as Process and as Product of Thought. American Economic Review 68 , 1-16. Simon, H. A. (1986). Theories of bounded rationality. In C. B. McGuire &amp; R. Radner (Eds.), Decision and organization (pp. 161-176). Minneapolis: University of Minnesota Press. Simon, H. A. (1990). Invariants of human behavior. Annual Review of Psychology 41, 1-20. Verhey, S. D. (2005). The effect of engaging prior learning on student attitudes toward creationism and evolution. Bioscience, 55, 996-1003. Springer</page></plain_text>
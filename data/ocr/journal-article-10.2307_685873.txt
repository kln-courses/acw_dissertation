<plain_text><page sequence="1">DO COMPUTERS THINK ? (II) * MARIO BUNGE 6 Do Machines Abstract ? AT this point the cybernetician might step in arguing that, as there are levels of mathematical work, there are also stages in the develop- ment of machine-building, so that one cannot be sure that future artifacts will not surpass those of the analytic type. A reply to this argument could be: (a) No machine can ever attain the level of abstraction because machines merely represent abstract thought, but they do not handle abstract entities, nor, afortiori, can they create new abstract objects, as they are secluded in the circle of inanimate matter, on which man can stamp his intelligence, but which lacks the material prerequisite to attain intelligence, namely life; (b) is it not much easier and important to beget and to train normal mathematicians ? Our hypothetical cybernetician would probably rejoin that, while it is true that computers so far built lack the capacity for abstraction, other machines have it. For example, the' reading machine' designed by McCulloch and Pitts is said to have such a faculty : it is able to 'recognise' the same general shape, or pattern, in material objects having individual differences (e.g. printing-faces of different sizes and styles). Cyberneticians hold, in sum, that this machine 'recognises universals '. The assignment of the faculty of abstraction depends, of course, on the meaning attributed to the word abstraction. Also, it is plain that cyberneticians use in this connection the common, non-technical acceptation of that word, namely the one according to which abstrac- tion consists of taking away, dispensing with, taking aside. Now, it should be remembered that this is not the sole connotation of the word in question. Moreover, to employ the word 'abstraction' to denote such an operation is often misleading, for it applies not only to mental but also to physical processes. Indeed, on that definition of abstraction it might besaid that the gravitational field has the faculty of abstracting in the highest degree, for it pulls all sorts of bodies, ' abstracting from ', * Part I of this paper appeared in the August Number 212</page><page sequence="2">DO COMPUTERS THINK? or dispensing with, their properties. Would it not be nonsense to hold that? My claim is that the same kind of'abstraction' works in the so-called 'recognitive artifacts '-not, however, the faculty of performing the abstract operations of the synthetic and the critical types referred to above. In fact, what is the mechanism by which 'recognitive artifacts' are said to 'perceive abstract forms'? Essentially it is the principle of specific sensitivity, which operates in wave filters, which ' recognise ' whole groups, or bands, of frequencies. This is not too distant from the humble sieve used in the kitchen to separate bodies of different sizes. In all these cases only physical laws are involved, and not mystenrious ones. The claim that the' reading machine' (i.e. the artifact that converts optical into acoustic signals) is able to abstract, might be justified on the empiricist doctrine of abstraction. According to traditional empiricism, abstraction is only taking away, setting aside, ignoring, or forgetting particulars-never adding anything new; for this school, abstraction is mere schematic representation in thought of facts of experience. This doctrine-shared by detractors of intelligence, like Bergson-may account for the first level of abstraction, the one char- acterised by generalisation through elimination of particulars. This is the kind of induction that dogs do when they put all cats in a single class; it is also the one we make when speaking of the cardinal number of a collection irrespectively of the nature of the elements of it. To this lowest level of abstraction, which we share with the higher animals, the usual definition of abstraction does apply. But this is not the sole level of abstraction attained by man, and the higher levels of abstraction are not entirely reducible to the lower, although they are rooted to it. 7 Can Machines Outdo their Designers? Man is not only able to ignore or to forget-a privilege which he does not share with machines, which, not being able to know, are unable to ignore and to forget. Man is not only able to disregard individual characteristics concentrating on common traits; he is also able to invent new objects not suggested to him, at least directly, by experience. For example, when we speak of moving bodies in general, we stand on the first level of abstraction; but when we refer to bodies and to motion separately, we perform a sort of quartering 213</page><page sequence="3">M. BUNGE of sensibles, thus stepping on a higher level of abstraction. Again, when we introduce the concepts of actual infminity, irrational number, Riemann surface, vector potential, and the like, we create ideal objects lacking an empirical counterpart, although they may be correlated with experimental data through certain intermediaries; here we are moving on a third level of abstraction, the level of ideal objects not originated in simplification (first level) nor in quartering (second level). This third level of abstraction is characterised by new 'emergent' qualities-although the followers of the empiricist tradition maintain that even 'our most remote abstractions are all ultimately reducible to primitive atomic propositions and the calculus of the lowest level' 1 and that, in its turn, atomic propositions are nothing but peculiar nerve impulses. Machines are not entitled to be even compared with their designers in the field of the higher levels of abstraction; as has been suggested above, some of them can 'recognise' universals of the first degree (e.g. squareness)-in the same sense as a home-made hygrometer, lacking a graduated scale, might be said to ' recognise' the universal humidity. The physical processes occurring in 'recognitive artifacts '-and also in non-recognitive ones-are the material correlates of abstraction of the first kind, or level. The same as in the case of computers, what is at stake is a material representation of a mental function, not the function itself. Obviously, machines are usually built because they can do some things which man either can do but painfully or inaccurately (washing machines, differential analysers), or which he cannot do at all (air- planes, radio sets). In this sense they surpass their builders, thereby falsifying the scholastic maxim (adopted though not invented by Descartes) that there can be nothing in the effect that had not been in some way in the cause. But machines cannot surpass man in everything, even though we are told that the new computers 'are capable of learning and thinking far beyond us '. For all their use- fulness, machines are products of culture, whereas their designers are, besides, producers of culture objects. And, rigorously speaking, machines surpass nobody in nothing; what happens is that a given designer of machines may surpass some colleague of his by building an improved machine. 1 W. S. McCulloch, 'Why is the Mind in the Head ? ', in M. Monnier (Ed.), L'organisation desfonctions psychiques, Neuchatel, 1951, p. 38 2 W. S. McCulloch, this Journal, 1954, 5, I8 214</page><page sequence="4">DO COMPUTERS THINK? Perfectibility is indeed a characteristic of living matter absent in machines. Perhaps some machines can 'learn' something, i.e. can make use of accumulated experience. But, (a) theirs is, so to speak, an individual perfectibility, since it is not transmitted to the species machina ratiocinatrix through reproduction nor through culture: it begins and ends in the individual machine; (b) machines do not seem to be able to advance in a sense very different from the way animals progress, namely by trial and error; this is, indeed, the behaviour typical of machines with self-correcting (feed-back) mechanisms, and is the least intelligent way of learning, because it is not planned and because it does not make use of another's experience; (c) rigorously speaking, machines do not 'learn' by themselves, but are 'taught ', either by their designer or by external circumstances.1 Man learns not only as an animal, i.e. through mistakes ; he learns mainly through the agency of society, which acts on the biological and psychological mechanisms of learning. This is why man can dispense, to a large extent, with purely biological progress, advancing at a rate that is without a parallel among lower animals. One of the reasons why man covers levels of learning higher than the peculiarly animal level, is that he is endowed with consciousness: unlike the machine, man is able to know what he does, how he does it, and why he is doing it. Therefore man comes to know, among other things, that he must go forward in order to survive; and in some cases he is even able to discover that he himself deserves the credit for it. 8 Artificial Thought? All machines save both mental and physical toil. But they do not always save work because they do it in our place. For example, a (new) car may save us the effort of walking, but not because it walks instead of us; the car performs a completely, different operation, which amounts to walking only in so far as both motions have the net result of displacing our bodies over space. The same holds for computers and other 'machines that think ': to assert that they think is as erroneous as saying that cars walk. Machines do not save us mental work because they do it, but in spite of the fact that they do something very different, which the designer has correlated with certain mental operations. ' M. V. Wilkes, 'Can Machines Think ?' Proceedings of the Institute of Radio Engineers, 1953, 41, 1230 215</page><page sequence="5">M. BUNGE In this very restricted sense, computing machines can be said to perform what has been called artificial thinking.' Not in the same sense as synthetic compounds, such as vitamins, are called synthetic, for the properties of the artificial and of the natural chemicals are often exactly the same, which is obviously not the case with artificial thought. (Think of the punched card yielded by a computer.) Machines can be said to perform artificial thinking in the same sense as cars can be said to perform artificial walking: because they yield net results which are equivalent to the model in a single respect-whereas in the case of synthetic compounds the identity often covers all known aspects of the end result. Mays 2 has coined an irreplaceable formula for designing 'machines that think' : he said that they think by proxy. The full meaning of this statement should be appreciated, especially since it is metaphorical. To say that digital computers think by proxy does not mean that they think only in a limited way, or lazily, or solely on command-not even that they think for us, nor for our sake. It means that they do not think at all, although they perform operations that represent our thought in a certain field, yielding results devoid of intellectual content but which, when translated into the language of ideas, can usefully be incorporated in reasoning. To marry by proxy may have a legal value, but no more than this; the same happens in connection with machines: man does not delegate thought to the computer for the very simple reason that the computer cannot think, but can instead perform functions which we correlate with thought. Analogously, a portrait may represent a person, but it is not a person; to confuse both may lead to magic. The computer, like every other automatic machine, runs for our sake; it would be wrong to infer from this that it acts as we. To commit this fallacy-and most cyberneticians incur in it-is the same as to confuse the deputy with the deputised thing. This is what people do when they confuse a piano-player with a pianist, or the vicar of God with God. This fallacy, of inferring that something acting for us must in some way or other participate in human nature, is typical of primitive and archaic logic: it is called reasoning by participation, and is the kernel of magic rituals. To conclude essential kinship in nature from mere correlation, from resemblance in pattern, 1 P. de Latil, La pensee artificielle, Paris, 1953 2 W. Mays, 'The Hypothesis of Cybernetics ', this Journal, 1951, 2, 249 216</page><page sequence="6">DO COMPUTERS THINK? is to push analogies too far ; so far, that the difference between science and magic is lost. Needless to say, science began when the very procedure of cybernetics, namely magical play with anthropomorphic analogies and with metaphors, was rejected. 9 Metaphors and their Misuse A distinctive mark of cyberneticians is their love of metaphors. Thus, they use to say that artifacts think, know, receive and give information, learn, wish, and even get sick. This is one of the main troubles with cybernetics, namely, that it does not distinguish between identity and resemblance, between the model and the portrait; that, in short, it uses key concepts in wrong contexts. When a whole science and a whole philosophical literature are built on linguistic traps, one is entitled to distrust the slogans by means of which the new faith is advertised-or, at least, one has the right of smiling atWiener's warnings 1 against that very use of concepts out of their proper context, in which he systematically indulges. However, if the confusion of somebody with its deputy may lead to nonsense, it would be equally foolish not to realise that sometimes there may be something in analogies. Two very different objects may have something in common at some level or in some respect-and usually material objects do have a lot of sides in common. To realise this is as important as to avoid concluding sharing of essentials from mere resemblance in particulars or even from mere correlation, i.e. from similarity in structure. For example, memory in computers and in man are assuredly totally different at the physiological and at the psychological levels, at which machines do not even exist; but there is a similarity of pattern at the physical level, for what is properly called memory in the case of higher animals, and improperly so in the case of artifacts (where it might be called 'storing '), is the capacity for retaining or storing some condition. Not to recognise such general traits shared in common, or likenesses in pattern, may lead us to support dualism or idealism with regard to the mind-body problem, thus favouring the return of the much discredited philosophical psy- chology, still in vogue in Germany and its philosophical dependencies. But to claim that partial identities and formal resemblances are all that matters-holding, for example, that machines can store ideas- 1N. Wiener, 'Some Maxims for Biologists and Psychologists', in M. Monnier (Ed.), L'organisation desfonctions psychiques, Neuchatel, 1951 217</page><page sequence="7">M. BUNGE is to push analogies so far that their heuristic function becomes lost sight of. Now the whole of cybernetics is built on such physiological and psychological analogies. The fact that some of them are deep lends it strength; the fact that they are nothing but analogies deprives cybernetics of methodological solidity-at least in the opinion of those who do not accept the philosophy of the as if The great merit of cybernetics lies, in my opinion, in having pointed out and worked out something which was far from new but which is true, namely, the physical basis of life and mind functions. The main shortcomings of cybernetics are probably, (a) to have proclaimed that life and thought have no such physical basis, for they are just physical phenomena (mechanistic levelling down), and (b) to have levelled computers up to the level of the human nervous system (animistic reduction). The levelling down is effected by means of what has been regarded 1 as the central hypothesis of cybernetics; according to it, the essential mechanism of the nervous system is a purely physical one, namely negative feed-back. The levelling up lies in the claim that there is no distinction in principle between the observable behaviour of a suitably designed artifact, and the behaviour of the human brain.2 This peculiar blend of animism and mechanism, which characterises cyber- netics, might be called animechanism or, as has recently been proposed,3 technozoism. To say it in fewer words, the positive contribution of cybernetics consists, in my opinion, in its emphasis on the existence of connections between levels the very existence of which it denies, namely the physical, the biological, the psychological, the intellectual, and the cultural levels. Io Summary and Conclusions To sum up, we may say that computers count, add, etc., at the physical level, performing operations that are usually not regarded as mathematical (at least by mathematicians), since mathematics, an abstract science, is not interested in cogwheels, relays, electron tubes, electric pulses, etc. It is we who frame a correspondence (when building, 'feeding' and reading the machine) between the concrete 1J. O. Wisdom,' The Hypothesis of Cybernetics ', this Journal, 1951, z, I 2 D. M. MacKay,' Mindlike Behaviour in Artefacts ', this Journal, 1951, 2, lo5 s H. Rodriguez, 'Ciberntica y Pensamiento Humano ', communicated to the International Congress of Philosophy of Slo Paulo (August 1954) 218</page><page sequence="8">DO COMPUTERS THINK? objects handled by the computer and our abstract objects. Without the human initial and final work of translating abstract into concrete objects back and forth, i.e. without the work of coding and decoding, the best of computers is helpless. In this respect, highly automatic machines do not differ essentially from the modest pencil, the simple abacus, or the cheap desk-computer, even though they are essentially different from the technological point of view. Strictly speaking, computers do not compute, machines do not think, but they perform certain physical operations that we co- ordinate with certain mental processes. Since co-ordination, or one- to-one correspondence, defines identity of pattern, the whole resemb- lance between machines and man is an identity of pattern, a formal identity or isomorphism of some of the operations of the machine and a small section of human activity. Without the intervention of man's abstract and purposive activity, which has no counterpart in machines, the most expensive digital computer is mere scrap iron. Machines, however automatic, are tools, that is, material assistants of man. To hold that they compute, think, know, learn, or wish, without specifying that this is only a metaphorical way of speaking; to forget that machines represent some mental functions at the level of technology without performing them; and to forget that these deputies of ours act only on command, whether immediate or long-run, is to confuse resemblance with identity, the part with the whole, the form with the essence, thus incurring in magical thinking. Those who write of the machina ratiocinatrix may astound the layman, edpater le bourgeois, or delight the dilettante; but by so doing they hardly deserve to be called the upholders of a tradition of scientific earnestness. Modern artifacts are marvels of ingenuity, but they are not human and they behave not as humans : if they did, we would not use them; artifacts are peculiar physical systems organised by technology to serve man. Is this not enough ? Why should the merits of their designers be attributed to them ? Why should men 'imagine, not only the forms of the gods, but their ways of life to be like their own' ? Are there not enough idols without that ? Servicio Ticnico Cientifico Juncal 2114 Buenos Aires, Argentina 219</page></plain_text>
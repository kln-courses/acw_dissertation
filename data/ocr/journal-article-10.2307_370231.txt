<plain_text><page sequence="1">ESSA Y REVIEW Artificial Experts Peter Slezak Harry M. Collins, Artificial Experts. Social Knowledge and Intelligent Machines (Cambridge, MA: MIT Press, 1990), xiv + 266pp., $19.95. ISBN 0-262-031 68-X. Al as Laboratory for Gedankenexperiment By any criteria, the explosive intellectual developments in artificial intelligence (Al) are characteristic of a thriving research enterprise. Although it has not produced the androids of science fiction, Al has nevertheless made perhaps the most significant steps beyond the pure speculations of Descartes or Kant towards scientifically testable theories of the mind. In the course of attempting to make machines use language, learn, or see, theories must be made precise, explicit and implementable, and this new rigour forced upon scientists has pro- duced conceptualizations which could not otherwise have arisen. The intellectual ferment and progress in the areas of machine learning and formal learning theory, for example, provides ample testimony to the way in which the most profoundly difficult problems of human psy- chology are giving way to precise insights.' The closely related area of computational models of scientific discovery encompasses not only the induction of numerical laws from empirical data, but also tax- onomy formation and the discovery of qualitative laws. The richness of developments in this field is illustrated in a recent anthology,2 which encompasses the transformations in conceptual frameworks during scientific revolutions, and the role of experimentation in scientific discovery. Social Studies of Science (SAGE, London, Newbury Park and New Delhi), Vol. 21 (1991), 175-201</page><page sequence="2">176 Social Studies of Science Discounting all the hype and 'wishful mnemonics', the actual successes of Al in a mere thirty years or so are sufficiently remarkable to warrant the widespread judgement that it constitutes an intel- lectual and social revolution comparable only to the industrial revo- lution itself. In the midst of this, and the extraordinary burgeoning of recent 'connectionist' developments in Al, it comes as a surprise to discover a declaration that 'The early misplaced confidence of the proponents of artificial intelligence is easy to understand!' As if already able to look back with a long historical perspective on a failed enterprise, Collins' book begins by pronouncing this judgement on the field of Al. The Challenge of AI as Zero Sum Game According to the flyleaf, Collins' book aims to introduce the fields of artificial intelligence and sociology of science to one another. This is undeniably an important and timely enterprise. Quite apart from the impact of the computer on our lives in countless other ways, recently it has come to be an important tool in the understanding of science and the nature of knowledge itself - not through its obvious advantages as a 'number cruncher' or mere research tool, but rather, as Collins rightly observes, because: When one tries to put knowledge into a computer, the questions present themselves in an acute and well-defined form. That is why artificial intelligence research is a natural living laboratory for the science of knowledge. (xi) In this respect, at least, Collins' view is shared by practitioners and proponents of Al. Dennett articulated this important point over a decade ago in a classic paper significantly titled 'Artificial Intelligence as Philosophy and as Psychology'. In a memorable image, Dennett suggested that Al is actually just another way of doing epistemology, the only difference being 'that the Al worker pulls his armchair up to a console'. In this sense, Al is a kind of prosthetic epistemology and, just as Collins observes, Al may be seen as an experimental testing ground for a science of knowledge. With the appropriate caveats, computer programs in Al may be construed as literal theories of the mind and, in this sense, as a way of doing 'top-down' cognitive psychology. Dennett explains: I want to claim that Al is better viewed as sharing with traditional epistemology the status of being a most general, most abstract asking of the top-down question: how</page><page sequence="3">Essay Review. Slezak: Artificial Experts 177 is knowledge possible? ... So I am claiming that Al shares with philosophy (inparticular with epistemology and philosophy of mind) the status of most abstract investigation of the principles of psychology. But it shares with psychology in distinction from philosophy a typical tactic in answering its questions.3 Thus, Al may be seen as a Kantian enterprise in so far as it seeks to answer the most general and abstract questions concerning the nature and conditions of knowledge. It is Kantian also in construing epi- stemological questions as simultaneously questions of cognitive psy- chology; that is, the issues concerning the nature of knowledge are ipso facto issues concerning the structure of the mind. In this conception, Al derives its unique value somewhat in the manner that Wohler's laboratory synthesis of urea has been seen as significant for 'organic' chemistry: the artificial synthesis of an or- ganic compound indistinguishable from the naturally occurring product serves to confirm the principles on which the synthesis is based - namely, an anti-vitalist reductionism. In like manner, the synthesis of intelligence in an artefact would be taken to support a reductionist, materialist, mechanist, individualist, information-pro- cessing account of the human mind. Except for its entrenched usage, the term 'artificial intelligence' would be better replaced by 'synthetic intelligence' in view of the fact that the product in this case, too, purports to be the real thing and not a mere counterfeit. Just as synthetic urea is real urea, so according to the widely held 'strong Al' position, artificial intelligence is real intelligence, and not merely an ersatz or sham, despite its synthetic origins. The case in favour of this position cannot be rehearsed here, but it is important to draw attention to the bearing of this view of Al on our understanding of science. If scientific knowledge is fundamentally the product of psychological processes in individual minds, then among the tasks which might be posed for intelligent machines is that of discovering generalizations about empirical facts of the world - arguably a central part of doing science. Indeed, this is not so much a different problem as inherently part of the enterprise of artificial intelligence as such: that is, the activity we honorifically label 'science' entails observation, pattern recognition, concept formation, class- ification, inductive generalization, logical inference, language, problem-solving, inter alia, which are themselves part of ordinary 'common-sense' intelligence. This is the familiar idea that 'science' is merely the self-conscious extension of ordinary perception and common-sense reasoning about the world.4 To the extent that Al can</page><page sequence="4">178 Social Studies of Science synthesize such ordinary 'intelligence', it will simultaneously solve the fundamental problems concerning the nature of scientific knowledge. For example, as the work of Newell and Simon has shown,5 the intellectual activities involved in reasoning about chess or even humble 'noughts and crosses' (tic-tac-toe) are plausibly seen as the same heuristic 'problem-solving' methods employed in creative sci- entific reasoning. Thus, the interest of Al for the philosophy of science is, as Collins says, that it may serve as a kind of laboratory experiment. In part- icular, it is an empirical experiment in which we can test competing hypotheses such as the 'rationalist' and sociological accounts of science. Collins says: The artificial intelligence experiment is, then, not just a problem of engineering or psychology but an empirical test of deep theses in the philosophy of the social sciences. The possibility of a science of mankind, which emulates rationalist models of natural science, is being tested in attempts to build intelligent machines. (8) Significantly, then, Collins accepts the direct challenge posed by Al in this regard for certain sociological views of science and he opens his book with the assertion of this diametrical opposition: '. . . the exis- tence of any intelligent machine seems to contradict a basic premise of knowledge science because a machine is not a community or a member of a society' (3). Bloomfield,6 too, introduces his recent anthology acknowledging that 'the prospect of non-social "intelligent" machines . . . obviously challenges some of the tenets of sociology'.7 As noted, Collins actually sees the sociological account as having already prevailed in this challenge and as revealing both the delusions of the proponents of Al and the equally misplaced confidence of 'rationalist philosophers of science' (3). Aside from the possible warrant for this hubris, Collins' acknowledgement of the challenge and the diametrical opposition of approaches to science is an impor- tant point. Bloor, too, has conceived of his 'strong programme' as diametrically opposed to 'rationalist', 'mentalist', 'teleological' the- ories. In this conception, there is no room for compromise, since the truth of one is explicitly held to entail the falsity of the other - a zero- sum game.8 The explicit point of my recent argument was to bring this diametrical opposition into sharp focus and to confront sociological approaches to science with the implications of Al in exactly the terms acknowledged by Collins.9 Significantly, Collins now reaffirms this radicalism of the sociological claims which preclude any compromise with mentalist accounts. Collins acknowledges that:</page><page sequence="5">Essay Review. Slezak: Artificial Experts 179 If there can be machines that act indistinguishably from us, then the philosophical distinctions between action and behaviour, and the argument about the peculiar nature of human rule-guided action, will turn out, after all, to be of no significance for the prospects of a science of society. The pigeons of philosophy of social science are coming home to roost in the intelligent computer. (8) Denying the Antecedent Its warrant aside for the moment, Collins' very claim for the victory and vindication of sociological approaches entails agreement on the structure and the terms of the debate. The agreement comes down to endorsing the conditional proposition which may be encapsulated as: If AI is true, then SSK is false. It is crucial to notice the polemical import of this point.'0 The sociological position has rested its fate entirely on the truth of the antecedent, namely the merits or otherwise of the enterprise of Al and cognitive science of which it is a part. Indeed, this is acknowledged in the endorsement by sociologists of sceptical arguments against 'strong Al' such as those of Dreyfus, Weizenbaum and Searle. But this, in turn, is to take a stand on technical issues entirely outside the domain of sociology and belong- ing to mathematical logic and automata theory, computer science, linguistics, psychology, philosophy and neuroscience, inter alia. This is a risky game to play, since sociologists are not on their own turf and have staked their claim against the merits of a vast case for the 'strong Al' thesis which has accumulated at least since Turing's foundational work on the 1930s." Yet Collins has embraced this strategy, with consequences for both the form and content of his book which we will see. In the face of the manifest, if still modest, successes of Al to date, Collins' strategy is not to deny their performance as such, but to suggest that they are a certain kind of anthropomorphic illusion, since they rest upon, and hide, an intrinsic dependence on human, social interpretation. However, quite aside from actual achievements to date, the intellectual interest of Al lies as much in its theoretical promise. Just as the synthesis of life itself was already implicit in the reductionist 'organic' chemistry following the demise of vitalism - long before the practical possibility of such things was apparent, similarly, the possibility of intelligent machines is implicit in the deep theoretical principles on which Al and cognitive science are founded. Sceptics must still confront Minsky's judgement over twenty years ago:</page><page sequence="6">180 Social Studies of Science The advance in the behaviour of machines, over the past hundred years, was like a billion years of biology. Our pious sceptics told us that machines would never sense things. Now that the machines can see complex shapes, our sceptics tell us that they can never know that they sense things. Do not be bullied by authoritative pro- nouncements about what machines will never do. Such statements are based upon pride, not fact. There has emerged no hint, in any scientific theory of machines, of limitations not shared by man.'2 The challenge taken up by Collins is to reveal such limitations on the abilities of machines by comparison with human beings. 'Knowledge Science' Notwithstanding the shared view of Al as a laboratory for testing theories of knowledge, it is important to realize that the term 'Know- ledge science' is Collins' proprietary locution for his own enterprise which, despite its connotations, is not so much a general enquiry as a particular doctrine, and is thus to be sharply distinguished in this respect from epistemology and cognitive science. Specifically, 'know- ledge science' is intended to refer to a doctrine whose 'basic premise' is the essentially social character of knowledge."3 Collins explains: Thus, learning scientific knowledge, changing scientific knowledge, establishing scientific knowledge, and maintaining scientific knowledge are all irremediably shot through with the social. They simply are social activities. (5) To put the issue in its starkest form, the locus of knowledge appears to be not the individual but the social group; . . . Contrary to the usual reductionist model of the social sciences, it is the individual who is made of social groups. (6) Machines That Work Collins' case against Al rests on a claim for the 'social embeddedness of knowledge' and the 'cultural specificity of human behaviour' (8). In the face of the patent successes of research in Al, Collins writes: 'We must explain how it is, in spite of the social nature of knowledge, that we have machines that work' (9). Examples of 'machines that work' given by Collins include a program which he describes as accomplishing what was once the frontier science activity of chemical analysis using spectral data. Collins suggests a social constructivist view according to which the interpretation of such spectra must once</page><page sequence="7">Essay Review: Slezak: Artificial Experts 181 have been disputed and settled 'by forming social alliances, by forcing people to change their minds, and by breaking their hearts' (9). Given that humans learning the task still require socialization in 'chemical society', Collins poses the crucial question for his account: 'How can this analytic computer program work, then, without the equivalent socialization?' (9). Though surprisingly neglecting to give details of this or any other significant expert system, here Collins is presumably referring to the DENDRAL expert system which originated the fundamental ideas of expert systems as domain-specific problem-solving programs. DEN- DRAL analyzes mass spectrographic and other experimental data to determine the structure of complex molecules. DENDRAL encoded the knowledge of expert chemists in the form of rules in a way which has become characteristic of the field, and its performance surpasses all humans at its tasks. The puzzle of such computer programs arises from the social constructivist framework in terms of which the situ- ation is described by Collins. Given the assumptions of a socially constructed or 'negotiated' consensus, the behaviour of the program invites the question: 'How is an apparently social activity emulated by a socially isolated artifact?' (11). Other 'machines that work' and which pose the same problem according to Collins are Weizenbaum's ELIZA and Winograd's SHRDLU. Both programs conduct an English language dialogue with a user, and Collins suggests that both these programs appear to be capable of 'social accomplishments' that would otherwise only be possible for someone who was endowed with relevant aspects of our culture. In short, for Collins, the problem is: 'How can the argument about the social embeddedness of knowledge be true ... if there are intelligent machines?' (8). His answer to this question and the chal- lenge of Al is threefold: First, machines that work rarely do the same work as humans .... Second, machines that don't work can sometimes look like machines that do work. This is because these machines interact with humans who make good their deficiencies. Third, there is a large aspect of human behaviour that mimics machines, and machines can mimic these aspects perfectly. (9) It is undeniable that ELIZA is a program which doesn't 'work' in the sense of really manifesting intelligence and, notoriously, is made to look as though it does. The question, however, concerns the extent to which these features of ELIZA are typical of other programs in Al. In</page><page sequence="8">182 Social Studies of Science this respect, Collins' choice of ELIZA to illustrate his thesis is mis- leading in ways we will see presently. Actions and Behaviour Collins says that the subject of his book may be encapsulated in the questions: 'To what extent can we approach a complete description of action by thinking of it as broken down into many small behaviour- specific acts? To what extent can the ramification of behaviour ap- proximate human action in general?' (45). Thus, the first part of Collins' strategy requires maintaining a principled distinction be- tween mere physical behaviour, however complex, and genuine human action. True actions in this sense are taken to be intentional and, because of their open-endedness, creativity and unpredictability, can be fully described according to plans or rules only in retrospect (43). Thus, much complex human behaviour must be classed as 'machine-like' rather than true action, and it is only such machine- like aspects which are susceptible to exhaustive description - and, thereby, to simulation by computers. Complexity or Culture: From Books to Brains Crucial to Collins' case is his claim that the illusion of intelligent machines arises 'because of the overwhelming temptation to think of computers as artificial brains rather than artificial members of so- ciety' (20). Thus, he rejects the notion that the ultimate success in Al would be achieved by 'getting the same sort of complexity into a machine as is found in the brain' (13). However, Collins does not address the fact that, more than merely a 'temptation', increasingly computers are being taken literally as artificial brains with the extra- ordinary resurgence of 'parallel distributed processing' ('connec- tionism' or 'neural networks') as a major aspect of artificial intel- ligence research. Conversely, computational approaches to neuro- science are increasingly providing insight into the information-pro- cessing character of the brain itself. 14 For Collins, however, the fundamental puzzle of intelligence can- not be merely a quantitative matter of sufficient complexity, otherwise it would be a question of how incremental steps could take us from simpler symbolic systems such as books to artificial human beings.</page><page sequence="9">Essay Review. Slezak: Artificial Experts 183 Because of the apparent implausibility of such a continuum from simple symbolic systems, he suggests that: 'It is not as though a much more complex book will do the trick that a simple book cannot manage' (13). This view is a version of what Patricia Churchland has termed 'principled scepticism','5 by contrast with the 'boggled scep- ticism' arising from the sheer, incomprehensible complexity of the brain. Collins, like other such sceptics, believes that there must be a qualitative, and not just a quantitative, difference. Accordingly, under the heading 'The Social Nature of Artificial Intelligence', he offers an alternative approach to the question - one which 'acknow- ledges the essentially social features of intelligence' itself. Contrary to the orthodox assumption that modelling the brain will explain the mind. Collins says: 'An artificial intelligence is a "Social prosthesis"' (14). The organism into which the intelligent computer is supposed to fit is not a human being but a much larger organism: a social group. The intelligent computer is meant to counterfeit the performance of a whole human being within a social group, not a human being's brain. (14) However, like all other behaviour, presumably even the 'performance of a whole human being within a social group' is mediated by the brain. Collins' novel kind of principled scepticism, seemingly denying the role of the brain as the physical basis for all behaviour, would have deserved more exposition than he has given it. Of particular importance for Collins' entire approach is the fact that, if sheer complexity is irrelevant, then the crucial questions for computers arise equally for the simpler artifacts such as books. Accordingly, we need not be dazzled by the performance of the latest technologies. Complicated, clever, state-of-the-art programs make us think that there is some- thing very cunning in the program that enables it to interact with such apparent social accomplishment. The true depth and universality of the problem, however, appears only when we look at much more simple examples. Take a very simple computer - a pocket calculator; this seems to do arithmetic better than anyone I know. ... Why stop at calculators? What about my slide rule? (11) For Collins, the crucial point is that the puzzle of computers arises for simpler technologies because the key question is 'How is an ap- parently social activity emulated by a socially isolated artifact?' (11). In Collins' view, this puzzle arises as much for the function of the printed word as for computers.</page><page sequence="10">184 Social Studies of Science Thus, Collins suggests that when computers do, admittedly, per- form seemingly intelligent tasks, these are mistakenly identified with human abilities only because we are prone to an anthropomorphic illusion, much as we might personify our motor vehicle. The paradox is already with us and has been with us for a very long time. To the extent that we are prepared to be puzzled by the next generation of thinking machines we should already be puzzled by some existing computer programs, by pocket calculators, by slide rules, by logarithm tables, and by the printed word. In an important sense, all these are machines that work, and they work in a way just as puzzling as the machines that are more easy to anthropomorphize. (9) To understand computers is to understand books and slide rules, whereas to understand books and slide rules is to understand computers. (215) Thus, the second part of Collins' strategy is to show that, despite the shortcomings of our artifacts, human beings tend to compensate for them in ways which disguise their differences. There are four ways in which the illusion of intelligent machines can be maintained: First, machines get better at mimicking our behaviour, though inevitably falling short of fully capturing our truly autonomous actions. Collins says that 'there is an essential difference between the way humans act and the way machines mimic those acts. I have tried to show that machines can mimic us only in those cases where we prefer to do things in a machine-like way' (224). He says that the apparent con- tradiction between the achievements of computers and the social view of knowledge is resolved by this account of 'machine-like actions' (224). Second, we become more charitable to machines as we over- look their deficiencies and overlook our own contribution to their success. Third, we actually start to behave more like machines our- selves by abandoning our 'freedom of action' to accommodate ma- chines. Machines can mimic us when we mimic machines. Fourthly, our image of ourselves becomes more like our image of machines as we see our creativity and other departures from machine-like be- haviour as defects rather than as essential to our nature. The Sociological Imagination We have seen that the 'basic premiss' of Collins' 'knowledge science' is the essentially social character of knowledge. His critique of Al rests on this view of the 'social embeddedness of knowledge'. How-</page><page sequence="11">Essay Review: Slezak: Artificial Experts 185 ever, although Collins has a penchant for such paradoxical perlocu- tions, it remains far from clear what exactly it means to say that 'it is the individual who is made of social groups' (6), or that individual human beings 'participate in knowledge communities but they are not the location of knowledge' (3). On a literal reading, such state- ments are nonsense, and the possible alternatives are left entirely obscure - evidently not thought to require clarification. Collins devotes extravagant attention (an entire section of the book) to the esoteric technical details of semiconductor crystal growing and the minutiae of various other enterprises - presumably as illustrations of his 'basic premiss' - but he has nowhere elucidated the meaning of these cabbalistic incantations for the benefit of the uninitiated, though these statements are, after all, the principal theses of the book. The obscurity serves a useful purpose through suggesting profound, arcane insights which, never being articulated explicitly, are thereby preserved from critical scrutiny. Collins does little to allay the sus- picion of C. Wright Mills that such scrutiny might reveal that the alternative to a nonsensical reading is mere banality.'6 For example, the assertion that 'it is the individual who is made of social groups' is presumably an elliptical way of saying only that people share beliefs, values, customs, and the like, with other individuals in the social groups to which they belong. While undoubtedly true, such claims cannot support a radical critique of Al and the impossibility of machines emulating human knowledge. Machine-Like Action and Free Will As we have seen, Collins' thesis rests on an irreducible component of human action which is intractable to causal, mechanical description in terms of rules. For Collins, 'The partial answer to the paradox of the thinking computer is the human being who, from the outside, might just as well not be thinking. Machines can emulate all those elements of human action that are machine-like or behaviour-spe- cific' (53). In view of the centrality of this issue to Collins' case, it is noteworthy that, besides asserting an alleged asymmetry between describing past actions and predicting future ones (43), he nowhere actually gives the slightest grounds for believing that there are, in fact, such unpredictable aspects of human action. The confusion between the analysis of the past and the future accounts for the</page><page sequence="12">186 Social Studies of Science confidence that some psychologists and computer scientists have in their abilities to describe human action in terms of formulae. (43) Further, Collins says that 'human action is characterized by the way it deals flexibly with each new and unpredicted situation' (43); and he writes of the 'freedom of action' (223), the 'variation and unpredic- tability of mental behaviour' (48) and 'the unanticipated variations of behaviour that human action occasionally manifests in even the most routine-seeming tasks' (53). It is true that in his Discourse of 1637, Descartes, too, saw these features of human creativity as grounds for withholding an exhaustive mechanical account of human beings. For, as he said, humans act out of knowledge rather than merely the 'disposition of their organs' as do animals and machines. Descartes could not imagine that any degree of complexity or ramification of cogs and levers could produce the creative abilities of humans to act in novel and unanticipated ways, and, indeed, his insight was valid for machines of the clockwork kind - the only ones conceivable until 1936. As we have seen, Collins provides the same arguments, and he does so evidently for the same reasons - namely, that he is working with an inadequate conception of 'machines'. Of course, we can't blame Descartes for not having been Alan Turing, but Collins does not have the same excuse; his assimilation of computers with other artefacts fails to appreciate precisely the relevant, novel features of machines which manipulate symbolic information. It is worth mentioning that the attempt to distinguish something which is a genuine action from mere behaviour also has a long history in philosophical literature.'7 Collins' assertions of the unpredict- ability of human actions must be read as claims for some contra- causal free-will, since the alternative to a fully mechanistic, determ- inistic account must involve the resort to such occult notions. Collins makes no reference to this vast literature, but the history of this idea does not provide an encouraging basis on which to found a critique of artificial intelligence.'8 Moreover, the case for a non-mechanistic account of action provides no support at all for any sociological theory. It is important to notice that the central role of the concept of 'machine-like' behaviour in Collins' theory serves to protect his claims against all and any conceivable successes in Al - short of complete androids. Since Collins does not specify which aspects of human behaviour are supposed to be the genuinely autonomous, unpredictable and non-mechanical ones, any successful Al simu-</page><page sequence="13">Essay Review: Slezak: Artificial Experts 187 lation can be simply dismissed as having captured only the 'machine- like' parts of our behaviour. Collins dismisses all existing Al models in this way without consideration of their details, and the remaining, if receding, domain of what is yet unexplained in mechanical terms will always be available to cite as the locus of our 'true' human actions. This argument is as successful as it is empty since the advances in Al, however impressive, will have no impact on it. Algorithmic and Enculturational Models Overlooking the fact that they already exist, Collins suggests that 'the prospect seems distant of making intelligent, problem-solving machines'(4). Whatever their limitations, expert systems in some areas already surpass humans in their performance, though the crucial issue must be not the level but the character of such per- formance. For example, the prospect of machines surpassing all human players in chess is in itself less interesting than the extent to which such machines embody heuristic methods rather than 'brute force'. Actual advances of this kind in Al, though nowhere treated seriously or in detail, are discounted by Collins as a kind of an- thropomorphic illusion. He suggests several respects in which it is the 'messy, crafty, artful and essentially social' nature of science which makes it impossible to model it with computers. First, he contrasts what he calls an 'algorithmic model' of knowledge with an 'enculturational model' (4). Collins' account of the 'algorith- mic model' takes knowledge as 'clearly statable and transferable in something like the form of a recipe', whereas the 'enculturational model' acknowledges the role of 'unconscious social contagion' and 'socially rubbing up against the person' (4) - 'the dimension of learning that has to do with becoming a member of a new cultuire' (110). Collins claims that there is something about these aspects of social life and knowledge which are intractable to codification as 'discrete bits of knowledge or sets of self-contained recipe- like instructions' that is, presumably, they are impossible to embody in a computer program. Collins does not actually give any reasons for this fundamental ineffability, but his evidence for it is the fact that, in his study, scientists trying to build a laser 'solely from printed instructions' in published sources were unsuccessful (7). The inadequacy of this kind of discussion reflects the general</page><page sequence="14">188 Social Studies of Science shortcomings of Collins' approach. He gives no reason at all for believing that what was undoubtedly omitted from published 'printed instructions' could not have been explicitly codified in principle. Cookbook recipes are not fully explicit either. Even if Mrs Beeton does go as far as to recommend first catching your hare, she neglects to specify the method of dispatching it and a myriad other details which could, nevertheless, be made explicit. Moreover, Collins' discussion of this point is characteristically remote from any of the technical issues arising in connection with computer modelling of human behaviour. His point rests on such insights as the fact that 'No amount of writing or talking on the telephone appears to substitute for visiting and socially rubbing up against the person from whom you want to learn' (4). But this correct observation just begs the question concerning how much of other, non-verbal behaviour and social interaction is rule-governed and codifiable. Learning by observing, for example, cannot be accom- plished on the telephone and is likely to be an example of what Collins has in mind. Nevertheless, machine vision and machine learning are thriving areas of Al which Collins neglects to consider. Indeed, learning directly from examples was an important feature of early work on machine vision and is among the paradigms of machine learning currently being developed. Not least of all, among the important, distinctive features of neural network approaches to Al is their capacity for learning without instruction directly from ex- amples, though Collins pays no attention to these issues. Collins' neglect of specific technical issues is evident in this crucial contrast between the 'enculturational model' and the 'algorithmic model'. Collins is operating with a naive and quite inappropriate notion of 'algorithm' which cannot seriously be exemplified by, and restricted to, the examples he cites of 'published sources' or telephone conversations. Significantly, most of what is already encoded algor- ithmically in computer programs could not be conveyed in these ways either! The central, technical question of what may or may not be susceptible to algorithmic encoding cannot be seriously addressed at the superficial level of Collins' discussion. Puns and Perceptions A second reason Collins offers for denying the possibility of AT models of science is the claim that social consensus determines 'what</page><page sequence="15">Essay Review. Slezak: Artificial Experts 189 may be seen and what may not be seen' and, thereby, the outcome of scientific debates (4). Collins thinks that the familiar ambiguity of certain visual stimuli illustrates and supports his case here, since there can be no answer to the question 'What is it really?' and he concludes that the judgement must, therefore, be socially induced. Collins' case here rests on two non sequiturs. First, Collins' argument proceeds from pointing out that: 'No amount of ingenious pattern recognition programming would reveal the truth', and he concludes from this that: 'There is no algorithm for recognizing the pattern' (4). However, this is simply a non sequitur arising from an equivocation on the notion of 'recognizing the pattern'. Second, however, even if Collins is right on this point, the absence of an algorithm does not yet establish that it must be social factors which determine the outcome of the process. Regarding the first non sequitur, certainly, in one sense, 'recognizing' entails successfully or correctly identifying something as revealing the truth, but this sense of the term is irrelevant in the present context. In another sense, the term 'recognizing' may be used to refer only to the process rather than its outcome. In this sense, one can speak of a failed recognition which is no less a process whose mechanisms we might enquire after.'9 Contrary to Collins, the issue is not 'recognizing what an object really is', but how we determine what we think it is, and this latter involves a perceptual judgement which can be explained in terms of the mechanisms of the brain. In understanding science, just as in pattern recognition, the question is not revealing 'the truth', as Collins thinks. Rather the issue is to explain how, in fact, we are capable of interpreting observational evidence as anything at all, and why we prefer some interpretations over others. Even on Collins' own account we identify the patterns as something or other the black and white patches or the bearded face - and it is this cognitive achievement which requires a causal, mechanical explanation. Even if our 'reading' of such stimuli is influenced by 'how our culture sees the image' (4), we need to explain how we can construe or parse it as anything at all. This is the goal of cognitive science and Al, and is hardly to be illuminated by sociology. Thus, it is correct but irrelevant to point to the familiar underdetermination and to observe, as Collins does, that there is no fact of the matter and no true interpretation as such. Only in this irrelevant sense is Collins correct in asserting that 'There is no algo- rithm for recognizing the pattern' - meaning there is no algorithm for discovering the truth and correctly recognizing what the pattern really is. But Collins' argument trades on the ambiguity of this</page><page sequence="16">190 Social Studies of Science statement to deny the very possibility of algorithms which perform the perceptual task itself. Scepticism about the very possibility of describing and modelling psychological mechanisms arises from a kind of confusion which has evidently mesmerized sociologists: Brannigan, too, has concluded the irrelevance of psychology, and the impossibility of Al and computer discoveries in science, on the grounds that the status of being an original discovery is socially accorded.20 It is a similar play on words which leads Collins to deny that psychological mechanisms of pattern recognition can be formally characterized. Regarding Collins' second crucial non sequitur, as noted, the un- derdetermination of judgements by sensory evidence does not, on its own, warrant invoking social factors to explain the outcome. The additional factors required could just as well be divine inspiration or the configuration of the planets. Clearly, independent grounds beyond the underdetermination itself must be provided for preferring socio- logical to theological or astrological explanation. Quine has argued that, notwithstanding the underdetermination of theory by observa- tional data, we invoke other criteria such as simplicity, probability, explanatory coherence, comprehensiveness and so on, in making choices among theories.2' The idea that underdetermination itself, ipso facto, warrants the resort to sociological factors is a common fallacy among sociologists of science. 'Miracle' of Induction Although Collins actually concedes the independent operation of pattern recognition abilities, saying we can exercise certain other judgements 'Only after we have solved the pattern recognition prob- lem' (51), he thinks that the skills themselves are intractable to algorithmic analysis. Regarding these crucial abilities, Collins says: 'All we can say is there is an unsolved problem, one that applies to humans in the same way that it applies to computers'. He says 'A miracle of inductive inference takes place' (51) which is independent of the causal, mechanical stages of such processes. Collins asserts: 'We cannot explain how we do this: we just happen to have these inductive abilities' (60). Once again, this sounds rather like trad- itional assertions of a Cartesian soul which is not subject to causal mechanisms. Such views were always a species of mystery-mon- gering, and Collins gives no arguments at all for seeing the 'miracle' of</page><page sequence="17">Essay Review. Slezak: Artificial Experts 191 inductive inference to be intrinsically beyond explanation by deter- ministic mechanisms. More surprising is the fact that Collins simply ignores the vast research enterprise concerned with 'machine learning' and computational approaches to induction which are presumably relevant to his pronouncements. Undeniably, these constitute an unsolved problem, as Collins says, but this is trivially true at the forefront of all scientific research and does not warrant his conclusion that: 'The computer cannot handle the inductive processes' (53). Collins' extravagant claims to have demonstrated the 'misplaced confidence of the proponents of artificial intelligence' are to be contrasted with the absence of serious consideration of the relevant research. Machines That Mimic People Who Mimic Machines Collins recognizes that he must deal with the problem that there are, after all, computer programs which perform in ways that, prima facie, warrant the claim that they act intelligently. However, it is telling that under the heading 'Machines That Work', Collins chooses to discuss ELIZA, of all things, saying: 'By now almost everyone must have heard of Weizbaum's ELIZA program' (9). Evidently not everyone has heard the rest of the story. The principal interest of ELIZA has derived from the fact that it is distinguished from other programs by having no claim to intelligence at all. ELIZA could perform impres- sively without being based on principles which would warrant at- tributing it any intelligence, but it is precisely in this respect that ELIZA differs from other programs in the field of Al which have some pretensions to embodying intelligent mechanisms. ELIZA's deceptive performance simply reinforces the inadequacy of external, behav- ioural and narrowly linguistic criteria for judging intelligence. Under some circumstances a tape recorder might also fool someone into attributing intelligent discourse to it, but this would be no more relevant to the issue arising from genuine Al programs than ELIZA's 'canned' responses. In particular, ELIZA must be distinguished from Winograd's SHRDLU which twenty years ago embodied features deserving to be seen as theoretically significant aspects of intelligent processes. Collins' vantage point does not permit him to notice the important distinctions among such programs and, apparently unable to discern the specifically relevant details, he predictably assimilates ELIZA,</page><page sequence="18">192 Social Studies of Science SHRDLU and all the rest of Al with pocket calculators and slide rules. Collins' central theses rest squarely on this failure: he says that SHRDLU, like ELIZA only 'appears' to be holding a competent con- versation and that 'Complicated, clever, state-of-the-art programs make us think' that they show genuine accomplishments. Collins suggests that our propensity to be fooled by the newer technological tricks should not hide their fundamental similarity to the workings of other simpler artefacts. Indeed, in the same vein Collins asks: 'What about my slide rule? and why isn't there a companion to McCorduck's book "Slide Rules Who Think"'? This parody is meant to convey the self-evi- dent nonsense in the idea of genuinely intelligent machines. How- ever, the problem with Collins' approach is that it systematically precludes confronting the relevant issues since they arise precisely in the differences between the workings of calculators and those of Al programs. Collins simply assumes that there are no relevant differences without giving consideration to the special features of Al programs on which their putative intelligence rests. His approach thereby begs the fundamental question. Clearly it is this approach which conveniently permits him to avoid any serious treatment of Al and expert systems altogether. If the puzzles of the next generation of thinking machines arise equally for slide rules, logarithm ta- bles and even for the printed word (9), there is no need to undertake any serious examination of the principles underlying Al pro- gramming. Instead of worrying about the technicalities of heuristic search methods, for example, we need only ask 'how things like books manage as well as they do in their interactions with us' (13). Collins undertakes to demonstrate that 'pocket calculators and mainframes alike cannot really do arithmetic at all' (53), but only seem to. He concludes that: 'We have discovered that the calculator doesn't do arithmetic at all' (59). However, the notion that calculators might be doing arithmetic in any way like a human arithmetician is an absurd straw man which is not taken seriously by anyone, least of all anyone in artificial intelligence; and Collins' 'discovery' reflects only his own misguided belief that anyone has ever thought otherwise. His heavy dependence on this point is perhaps the clearest symptom and consequence of neglecting the most elementary fundamentals of Al. There are, of course, programs which do purport to perform mathe- matical and related problem-solving tasks such as Newell and Si- mon's GPS, the MACSYMA expert system or Lenat's AM. The tech-</page><page sequence="19">Essay Review: Slezak: Artificial Experts 193 niques employed in these programs might have been of interest to Collins' readers. For such reasons the book can scarcely claim to have even attempted its avowed project of demonstrating the 'misplaced con- fidence of the proponents of artificial intelligence'. Despite token allusions to expert systems, there is no systematic attempt to explain what these are. And, of course, the subject of expert systems hardly exhausts the topic of Al. The characterizations offered by Collins are completely uninformative: he says: 'An expert system is a computer program designed to replace experts in social interactions', and that they are 'largely based on the knowledge of human experts' (77). Artificial Experts and Natural Amateurs Indeed, the lapses of Collins' book in this regard are sufficiently peculiar to deserve some comment here as symptoms of a more general malaise in the social studies of science. On the face of it, there is something at least paradoxical, not to say absurd, about the implication that the leading researchers and theorists in computer science have failed to appreciate that their work warrants no claims beyond those of slide rules and pocket calculators. In fact, of course, it is the remote vantage point adopted by sociologists which has precluded them from seeing anything of the fine grain the specific concepts, theories, models, and so on which provide the warrant for the claims of Al. It is on this basis that Brannigan,22 not unlike Collins, could only acknowledge advances in 'stand alone PCs'! Indeed, the very expertise of researchers in computer science is taken to be irrelevant to judging even the technical issues themselves.23 This is a presumptuousness which has the inestimable virtue of making anyone an expert without understanding the ideas in question. Such attitudes are perhaps the inevitable consequence of an externalism which neglects the role of ideas in the development of science. For example, on the few occasions that heuristics are mentioned, Collins gives no indication of their character and their significance for the claims of Al. Heuristics are standardly contrasted with algo- rithms because they are methods which are taken to capture the 'intelligent' features of tasks such as problem-solving. The resort to such 'satisficing' techniques is required because of the intractably large number of solutions to many problems which preclude exhaus- tive search. Such methods do not necessarily find the best solution, or</page><page sequence="20">194 Social Studies of Science any solution at all, for that matter, and in this respect, they are unlike the fool-proof methods of algorithms. The intelligence of Al pro- grams is taken to reside in such heuristic techniques, though this conventional usage is, admittedly, slightly confusing because even the heuristic methods are, strictly speaking, algorithms by virtue of being encoded as computer programs. Collins' brief mention of heuristics on a few occasions en passant (19) entirely misses their significance as being at the heart of the claimed intelligence of Al programs. In particular, heuristics need not always be explicit or explicable aspects of our knowledge, as Collins suggests (95), but can represent the unconscious rules on which our abilities depend. Thus, the strong claims for Al, rightly or wrongly, as based on the specific heuristic techniques and features of the programs developed in this domain.24 Although Collins speaks throughout of 'computers' and what they can or cannot do, it makes no sense to speak in this way of 'computers' in general independently of the program, let alone slide rules.25 In particular, the revolutionary significance of artificial intelligence has nothing to do with computers per se, since they have merely provided a powerful medium and a novel formalization in which to embody and test theories concerning intelligence. This idea of computer programs construed literally as psychological theories is one of the foundational ideas in artificial intelligence. For this reason, it is the capacities and undeniable limitations of particular programs which must be at stake, and these are very different depending on the program in question. It is as if one were to reject the claims of heavier- than-air flight by considering the limitations of bicycles without attending to the properties of aerofoils. Although it is a volume in the series entitled 'Inside Technology', Collins' book remains resolutely outside the technology in question, and illustrates the dangers of a sociology which neglects the cognitive content of science. This principle has been elevated into a meth- odological precept ('anthropological strangeness') by Latour and Woolgar,26 and, in some of its manifestations, the social study of science has come to ignore entirely the content of any science at all in favour of an exclusive preoccupation with its own meta-preoccu- pations.27 Of course, the alternative to such principled incompetence is in- consistency. Thus, for example, Schopman's 'Frames of Artificial Intelligence' gives a valuable history of cybernetic ideas which pre- ceded developments in Al and cognitive science, but his discussion reveals a most telling discrepancy between ideology and praxis.28 He</page><page sequence="21">Essay Review. Slezak: Artificial Experts 195 begins with a gesture of obeisance to social constructivist dogma, saying that 'all scientific and technological knowledge can be under- stood as the outcome of a social process or, put differently, an internal logic of scientific development does not exist'.29 But then he proceeds immediately to give just such an internal logic of the devel- opments in the field. At the outset we see the ritual incantation of constructivist jargon: 'a frame emerged within which a stabilization process became possible between different actors', and: 'Within it the opinions of the individual participants contributed to common ideas or, put differently, within the frame, points of view were the outcome of stabilization process, i.e. an interactive process in which individual opinions and social positions determined the outcome'.30 In short, the scientists agreed! Schopman's ensuing discussion neither illustrates, nor draws upon, any of the methodological principles of externalist social constructivism he articulates. Indeed, it does not conform with his particular construal of internalism either; Schopman shares the misunderstanding we have seen in Collins according to which internalist approaches are concerned with finding 'truth' in the sense of a correspondence with 'reality'. As Dennett has candidly confessed,3' philosophers (like sociol- ogists) confront peculiar difficulties as commentators on scientific fields such as Al through their status as dilettantes and amateurs. Though this is a difficulty which must be honestly confronted, it does not preclude important insights, which may, indeed, be seen as providing an essential perspective on the discipline in question. In the past twenty years or so, the philosophical literature, at least, has become immersed in the detailed substantive theories and methods of whatever scientific domain is under examination. By contrast, instead of discussing landmark developments in expert systems such as DENDRAL or MYCIN, Collins devotes copious attention to the nice- ties of bus driving (82), sports coaching, jazz music, soccer playing and cricket. Extended discussions of such activities are analyzed in absorbing detail, complete with lengthy quotations from footballers and golfers, inter alia. Collins provides the reader with extended anecdotal commentary on such matters. For example: 'In the World Cup quarter-final between Brazil and France .. .' or 'Oddly enough, earlier in the same day I watched an equally extraordinary event on TV concerning a different sport. . . .' A full page of footnote dis- cussion is devoted to the detailed complexities of Collins' train journey from Bath to Heathrow, and another footnote tells us: 'Once I needed to find the telephone number of the Day's Inn in Phoenix,</page><page sequence="22">196 Social Studies of Science Arizona. I was told by the operator ... etc.' My irritation with this approach may be idiosyncratic, but the obvious question to ask in relation to these extended, detailed analyses is what they contribute to the central theoretical questions at issue regarding intelligent mach- ines and their knowledge. Readers are left largely to their own ingenuity to answer this crucial question, since the connections are rarely made explicit by Collins. The conspicuous avoidance of substantive technical issues in Al by Collins is to be contrasted with the kind of informed commentary which has become characteristic of the best philosophical writing in cognitive science (e.g. Pylyshyn, Fodor, Dennett, Stich, the Church- lands, Thagard). Just as the philosophical discussions of relativity theory or quantum physics are scarcely to be distinguished from theoretical physics itself, 'philosophical' papers on the mind now- adays have titles like 'Cognitive Neurobiology: A Computational Hypothesis for Laminar Cortex'.32 Collins shows great erudition in the three full chapters devoted to crystal growing, but he provides only token illustrations of expert systems whose show of ersatz technicality is both irrelevant and entirely without any explanatory context to make them intelligible. Knowledge Elicitation In order to illustrate the way in which 'cultural knowledge' is used in 'laser society', Collins provides extended discussion of the length of certain electrical leads in building a laser device. For example, the word 'short' when used in the context of electrical leads in a circuit does not mean 'less than one mile' (1 13). It is not obvious that Collins' lengthy and detailed analysis of these matters is warranted by such profound insights. His book depends heavily on this technique with copious, intimate details of laser-building, glass-blowing, subway travel and coin slot machines all of which are, at best, tenuous in their bearing on the problems of Al. An entire section, forty-four pages in length, is devoted to the details of growing semiconductor crystals. In this overwhelming mass of irrelevant detail and gratuitous erudition, there are only a few cryptic remarks which convey the alleged significance of it all. After pages of unrelieved technicality concerning 'equilibrium distribution coefficients', Collins finally ex- plains their relevance to the subject: 'These, then, are the difficulties of knowledge elicitation' (151). Ten pages later, he helpfully avers: 'In</page><page sequence="23">Essay Review: Slezak: Artificial Experts 197 Suchman's terms, it is the situatedness of this act that is its salient feature' ( 161). Whatever this may mean, after eighteen more pages of crystal-growing, readers who do not give up amid the welter of unintelligible minutiae concerning 'bismuth-arsenic using zone mel- ting' are told at the end only that: 'The last three chapters have been intended to show the difference between abstracting rules of practice for use in a text or an expert system and learning the practice of the same craft' (177). Beyond matters of personal taste, this style of sociological analysis by parable raises certain serious questions. The issue of knowledge acquisition or 'elicitation' being considered here by Collins (89) is central to expert systems and raises a host of problems which are, moreover, of particular interest from the point of view of social sciences - as illustrated in the most insightful and technically in- formed work of Forsythe.33 Forsythe's anthropological perspective is based on her experience as participant observer in leading Al labs, and provides a wealth of unique insights into the world of Al and expert systems. Her important contributions would have deserved extended discussion in a work having the focus of Collins' book. Instead, he relegates one paper of Forsythe and Buchanan to a footnote,34 and his sparing treatment of such work germane to his topic is to be contrasted with the lavish attention devoted to the trivia surrounding cricket and subway travel, inter alia. In neglecting the central ideas of the field he attacks, Collins is at least consistent: he nowhere actually explains or defends his own particular theoretical position, either. Instead of explicit argument, his central thesis concerning the 'essentially social' character of science tends to be slipped in unannounced in the course of Collins' discussions of expert systems. For example, in giving his classification of expert systems, Collins characterizes the knowledge embodied in their rules as 'cultural competence' (101), though this surely deserves some defence. It is, in fact, an eccentric characterization and a contentious claim which is thereby insinuated rather than argued. This intoning of the term 'cultural' (97, 101, 109, 113, 115) to qualify 'knowledge' or skills is a question-begging substitute for explicit argument. Collins' theoretical biases are surreptitiously included in this manner via his terminology which is emphatically not that of the field he discusses. It is somewhat as if one were to use the term 'specially created kinds' unannounced in a discussion of biological species.</page><page sequence="24">198 Social Studies of Science Conclusion Given that Al began trying to model the very highest achievements of mind such as language and problem-solving, it is perhaps not entirely surprising that there has not been a monotonic progress towards the understanding of these phenomena. However, without going down the scale of complexity quite as far as slide rules, at the level of the humble sea-slug Aplysia, we can see recognizable elements of our own capacities. With the recent success in mapping its neural circuitry, there would be little hesitation in seeing all the sea-slug's behaviours as 'machine-like', in Collins' terms. However, we differ from the sea- slug only in the number of our neurones and, indeed, their kind must have been our ancestors. Therefore, notwithstanding Collins' rejec- tion of the continuum from simple to complex systems, here as elsewhere, biology and Al conspire to confirm the computational view of mind. The unprecedented potential of Al as a technology to change our lives requires that its scope and limitations be properly understood. A sociology of science which is epistemologically more modest than the radical constructivist programme might make a unique contribution to the ways such technologies are understood, developed and de- ployed. In view of the recent tu quoque! charges of equal and opposite 'imperialism', it is worth repeating that 'rationalist' approaches of cognitive science and Al do not preclude sociological approaches to science. Thus, there is a clear asymmetry here, and progress towards any joint enterprise requires that the a priori exclusion of mechan- istic, psychologistic theories as a foundational tenet of the sociology of scientific knowledge must be abandoned. Such issues, and the question of the precise scope of sociological and psychological per- spectives, must be open ones to be determined in the course of empirical enquiry itself, and not legislated in advance. 0 NOTES 1. For a valuable recent survey, see Paul Thagard, 'Philosophy and Machine Learning', Canadian Journal of Philosophy, Vol. 20, No. 2, (June 1990), 261-76. See also R. S. Michalski, 'Learning Strategies and Automated Knowledge Acquisition: An Overview', in L. Bolc (ed.), Computational Models of Learning (Berlin: Springer- Verlag, 1987), 1-19; J. G. Carbonell (ed.), Machine Learning. Paradigms and Methods</page><page sequence="25">Essay Review: Slezak: Artificial Experts 199 (Cambridge, MA: Bradford/MIT, 1990). On formal learning theory, see D. N. Osherson, M. Stob and S. Weinstein, Systems that Learn: An Introduction to Learning Theoryfor Cognitive and Computer Scientists (Cambridge, MA: Bradford/MIT, 1986). 2. J. Shrager and P. Langley (eds.), Computational Models of Scientific Discovery and Theory Formation (San Mateo, CA: Morgan Kaufmann, 1990). 3. D. Dennett, 'Artificial Intelligence as Philosophy and as Psychology', in his Brainstorms (Cambridge, MA: Bradford/MIT, 1978), 109-26, at 112. 4. See M. J. Pazzani and M. Flowers, 'Scientific Discovery in the Layperson', and J. Shrager, 'Commonsense Perception and the Psychology of Theory Formation', in Shrager &amp; Langley (eds), op. cit. note 2, 403-35, 437-70. 5. Allen Newell and Herbert A. Simon, Human Problem Solving (Englewood Cliffs, NJ: Prentice-Hall, 1972). 6. Brian P. Bloomfield (ed.), The Question of Artificial Intelligence: Philosophical and Sociological Perspectives (London: Croom Helm, 1987). 7. Ibid, xi. This was precisely the challenge posed in the recent Symposium in Social Studies of Science, Vol. 19, No. 4 (November 1989). Curiously, Collins' bibliography cites only his own contribution to this Symposium. See further responses by H. A. Simon, Collins and others in Social Studies of Science, Vol. 21, No. 1 (February 1991), 143-56. 8. D. Bloor, Knowledge and Social Imagery (London: Routledge &amp; Kegan Paul, 1976), 9. 9. Symposium, op. cit. note 7. 10. It must be noticed in passing that the tactic of Collins and others risks committing the fallacy of 'denying the antecedent'. By virtue of accepting the conditional, the impossibility of Al does not yet establish the truth of SSK. At best, successfully refuting the claims of strong Al would remove this as grounds for inferring the falsity of SSK, and independent grounds are still needed to establish its claims. 11. Bloor has perceived that his sociological programme rests on the related strategy of embracing a radical, Skinnerian behaviourism. See his Wittgenstein. A Social Theory of Knowledge (New York: Columbia University Press, 1983). See also P. Slezak, 'The Strong Programme as Behaviourism', unpublished paper delivered at the Annual Meeting of the Society for Social Studies of Science, Minneapolis, 18-20 October 1990. 12. M. Minsky, 'Machines are More Than They Seem', Science Journal, Vol.4, No. 10 (October 1968), 1. 13. This important difference between an open empirical enquiry and an a priori commitment to specific theory has also been obscured in Bloor's 'strong programme' - as Laudan has pointed out. See his 'The Pseudo-Science of Science', Philosophy of the Social Sciences, Vol. 11, (1981), 173-98; reprinted in J. R. Brown (ed.), Scientific Rationality: The Sociological Turn (Dordrecht: D. Reidel, 1984). 14. For a competent popular account, see W. F. Allman, Apprentices of Wonder: Inside the Neural Network Revolution (New York: Bantam, 1989). See also Eric L. Schwartz (ed.), Computational Neuroscience (Cambridge MA: Bradford/MIT, 1990); James A. Anderson and Edward Rosenfeld (eds), Neurocomputing: Foundations of Research (Cambridge MA: MIT Press, 1988); I. Alexander (ed.), Neural Computing Architectures: The Design of Brain-Like Machines (Cambridge, MA: MIT Press, 1989). 15. Patricia Smith Churchland, Neurophilosophy: Toward a Unified Science of the Mind-Brain (Cambridge, MA: Bradford/MIT, 1986), 315. 16. C. Wright Mills, The Sociological Imagination (London: Oxford University</page><page sequence="26">200 Social Studies of Science Press, 1959). 17. The literature has grappled with Wittgenstein's question: 'What is left over if I subtract the fact that my arm goes up from the fact that I raise my arm?', Philosophical Investigations, I, 621. See A. C. Danto, Analytical Philosophy of Action (Cambridge: Cambridge University Press, 1973) and P. Slezak, 'Actions, Cognition and the Self', Synthese, Vol. 66 (1986), 405-35. 18. See a recent attempt to salvage such ideas within cognitive science by M. Brand, Intending andActing (Cambridge, MA: Bradford/MIT, 1984) and critique in P. Slezak, 'How NOT to Naturalize the Theory of Action', in Slezak and W. R. Albury (eds), Computers, Brains and Minds (Dordrecht: Kluwer, 1989), 137-66. 19. See J. Fodor's discussion of a similar confusion on the part of Ryle, in his The Language of Thought (New York: Crowell, 1975). 20. See Slezak and Brannigan in Symposium, op. cit. note 7. 21. See C. Boorse, 'The Origins of the Indeterminacy Thesis', Journal of Philosophy, Vol. 72, No. 13 (1975), 369-87. 22. Symposium, op. cit. note 7. 23. See Fuller in Symposium, op. cit. note 7. 24. Symptomatic of these problems is the absence from Collins' bibliography of any of the works of Newell, Simon, Fodor, Dennett or Pylyshyn, where the most important expositions and articulations of Al ideas may be found. Among the seminal ideas neglected by Collins, the 'physical symbol system' hypothesis, the notion of 'heuristic search' and the conception of programs as theories are perhaps foremost. See A. Newell and H. Simon, 'Computer Science as Empirical Inquiry: Symbols and Search', in J. Haugeland (ed.), Mind Design (Cambridge, MA: Bradford/MIT, 1981), 35-66. Likewise, Pylyshyn's Computation and Cognition (Cambridge, MA: Bradford/MIT, 1984) has been an important statement of the 'orthodox' computational theory of mind which one might have expected to receive at least passing mention. 25. To be sure all programs are constrained by the limitations of computers as Universal Turing Machines - but Collins does not raise these considerations, though they have received considerable attention. See D. Hofstadter, Godel, Escher &amp; Bach (New York: Basic Books, 1979) and P. Slezak, 'G6del's Theorem and the Mind', British Journalfor the Philosophy of Science, Vol. 33, No. 1 (1982), 41-52. 26. B. Latour and S. Woolgar, Laboratory Life (London: Sage, 1979). 27. S. Woolgar (ed.), Knowledge and Reflexivity (London: Sage, 1988). 28. Joop Schopman, 'Frames of Artificial Intelligence', in Bloomfield (ed.), op. cit., note 6. 29. Ibid., 167. 30. Ibid., 169. 31. Dennett, op. cit. note 3, 109. 32. P. M. Churchland, 'Cognitive Neurobiology: A Computational Hypothesis for Laminar Cortex', Biology and Philosophy, Vol. 1, No. 1 (1986), 25-51. 33. D. Forsythe, 'Engineering Knowledge: An Anthropological Study of an Artificial Intelligence Laboratory', unpublished paper delivered at the Annual Meeting of the Society for Social Studies of Science, Worcester, Massachusetts, 19-22 November 1987. 34. D. Forsythe and B. G. Buchanan, 'An Empirical Study of Knowledge Elicitation: Some Pitfalls and Suggestions', in P. E. Lehner and L. Adelman (eds), Methods in Knowledge Engineering, special issue of IEEE Transactions on Systems, Man and Cybernetics (1988).</page><page sequence="27">Responses and Replies: Collins: Response to Slezak 201 Peter Slezak is Director of the Centre for Cognitive Science and Senior Lecturer in the School of Science and Technology Studies at the University of New South Wales. His research interests include the philosophical issues surrounding artificial intelligence and cognitive science generally. He has published papers on the philosophy of Descartes, Godel's Theorem and the mind and the philosophy of action. He is currently conducting experimental investigations into the problem of mental representations in visual imagery and has recently published a paper on this topic in Analysis. He is co-editor with W. R. Albury of Computers, Brains and Minds: Essays in Cognitive Science (Dordrecht: Reidel/Kluwer). Author's address: Centre for Cognitive Science, University of New South Wales, P0 Box 1, Kensington, New South Wales, Australia 2033.</page></plain_text>
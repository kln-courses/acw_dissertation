<plain_text><page sequence="1">QUANTUM MECHANICS, AMPLIFYING PROCESSES, AND LIVING MATTER* WALTER M. ELSASSER PART I 1. The Failure of Quantum-Biophysics. A quarter of a century has elapsed since quantum mechanics was discovered. Perhaps it is not too much to say, in retrospect, that the time was ripe for this particular development. This is attested, not only by the speed with which the edifice of the theory was com- pleted immediately following the basic discoveries of Heisenberg and Schrodinger, but also by the rapidity, well-nigh unprecedented in the history of science with which the new results were applied to almost every branch of physics and chemistry. A mental readiness on the part of the scientists involved might have had much more to do with this than the facilities of modern communication systems. In these years, early after the establishment of the theory, there was a wide- spread feeling among scientists that the gates had been thrown open for a more rational approach toward the atomistic foundations of biology. There now existed a theory that could account, on a quantitative basis, for the molecular structures and processes involved in biochemistry and biophysics. If there ever was some question as to the quantitative reliability of the theory with regard to any phenomena of atomic and molecular physics (excepting of course the high-energy processes of nuclear physics) they have long been dispelled. Indeed, the labors of recent years in the quantum theory of fields have shown decisively that any quantitative corrections that the theory might have to undergo with respect to atomic processes on the non-nuclear scale are in the fourth or fifth decimal place, and these can assuredly have no bearing on the problems of basic biology. It is surprising, therefore, that the efforts of a number of leading scientists towards penetration of the realm that separates biology from physics should have had relatively little success. That there was a wide- spread interest in and preoccupation with, these problems on the part of physi- cists, especially in the period of the 1930's, of this there can be very little doubt. We may refer, as a main instance, to an article of Niels Bohr (1) that will occupy us in detail later on. Schrodinger's little book (2) has become widely known. We shall forego further quotations here, but a perusal of the scientific papers and occasional writings of some of the prominent mathematical physicists shows that questions of this type have been rather consistently in their minds. The fact that there are virtually no formalized papers or dissertations on the subject should be taken as proof that a first, direct attack failed, rather than as evidence for a lack of intense interest and preoccupation. What, then, is the cause of this lack of early success? Should one look for it * First printed in Proceedings of the Utah Academy of Sciences, Arts and Letters, vol. ?6, 1951. 300</page><page sequence="2">QUANTUM MECHANICS 301 in our still very inadequate knowledge of biochemistry, especially with regard to the structure and function of protein molecules? The author believes that this, in itself, is not a sufficient explanation. Consider, by way of analogy, the spectacular success of atomistic notions in the early development of some branches of chemical physics. The earlier stages of the development of such a subject as crystallography, for instance, become all but incomprehensible without at least some background of speculative atomistic ideas that inspired the ex- perimental researches. Now it is exactly the absence of such imaginative pro- jections, experimentally fertile though oversimplified speculative notions, that strikes one so forcibly in relation to the atomistic foundations of biology. The reason for this failure, then, is perhaps not only to be sought in the gaps of our positive biochemical knowledge, but also in our as yet incomplete under- standing of the broad expanse of the more philosophical implications of quantum theory. We have indicated the rapidity with which the edifice of quantum mechanics was completed. But there have always been a few highly competent voices insisting that the interpretation of the theory was yet open and not as certain as some authors would tend to have us believe. There can be little doubt that the basic mathematical elements that enter into the structure of quantum mechanics are, as such, rather definitive and that future adaptations will, from the analytical viewpoint, appear to be in the nature of identical transformations. But for a certainty, we do not know what would be a complete set of axioms for quantum mechanics in its physical (that is, not purely analytical) context, and there might well be several independent ways of establishing the foundations of quantum mechanics, all using the same analytical apparatus and leading to the same quantitative results in the simpler cases where the calculations are at present subject to direct experimental test, but differing nevertheless from each other in their broader implications. Such a situation is by no means exceptional. To illustrate it, we may quote an out- standing example from the history of physics. It is well known that we can give two quite distinct interpretations of electrodynamics, so long as the displacement current, introduced by Maxwell to account for electromagnetic wave motion, is neglected. One of these interpretations is essentially an extension of the New- tonian concept of attractive or repulsive forces acting at a distance between elementary corpuscles to which, in the electrodynamical case, there are added similar interactions between elementary currents. The second interpretation is based on the notion of the electromagnetic field considered as the carrier of energy; it originated in Faraday's imaginative projection upon electrodynamics of the mechanical concepts of strain and stress developed in elasticity. In their mathematical form, given by Maxwell, these notions have proved vastly better adapted to the treatment of electrodynamics, and more evocative of construc- tive thinking in the minds of those designing new experiments, than the older interpretation. Nevertheless, from the purely mathematical viewpoint the two sets of notions turn out to be fully equivalent in a certain specified and rather large domain; within this domain one scheme of description can be transformed into the other by purely mathematical manipulations.</page><page sequence="3">302 WALTER M. ELSASSSR It would be easy to quote other examples from the history of physics in order to sustain the thesis that the relation between a given mathematical structure and its physical interpretation is by no means unique. Now the boundaries between theoretical physics and the theory of knowledge are somewhat fluid. What is taught in today's schoolrooms as a mathematical transformation of two forms of electromagnetic theory into each other is likely to have appeared to the generation of Faraday as two distinct models of physical nature having different and perhaps contradictory epistemological implications. But the opposite situa- tion can also arise and seems to be not uncommon in modern science: Tested mathematical techniques might be available, but their interpretation in terms of their relationship to physical phenomena might involve considerable diffi- culties. To cite but one modern example, such a situation is apparently chronic in cosmology. The development of the mathematical methods of quantum mechanics has been so spectacularly rapid that it is not surprising to find that the corresponding adaptation of our epistemnological notions has not entirely kept pace with it. Here, we might find the clue to the question posed in the beginning, as to why the application of the results of quantum mechanics to the foundations of biophysics is still in such a rudimentary stage. 2. The Interpretation of Quantum Mechanics. The efforts at finding a satis- factory interpretation of the mathematical procedures of quantum mechanics have centered about two points, the theory of measurement of elementary particles and the relations of quantum theory to the methods of statistical mechanics. In the latter field, the permanent mathematical foundations have been laid by von Neumann (3) and in part by Dirac. The study of the epistemo- logical implications of basic quantum measurements has given rise to a rich and instructive literature; we may cite here, among others, the work of H. Margenau (4). As we hope to show, the measurements of elementary particles have certain rather fundamental relations to statistical mechanics; in order to introduce this subject we shall begin with a criticism of the theory of quantum-mechanical measurements due to P. Jordan (5). To get the gist of Jordan's argument we shall quote, with insignificant changes, one of his examples. Suppose a Geiger counter, made to detect cosmic-ray particles is connected to an amplifier which in turn is made to open a trap door through which a stone can fall. If on putting this device into operation we have, say, a probability of one third that the counter will be activated within the ensuing minute, then we can no longer make a definite prediction about the motion of the stone during this interval of time. All we can say is that there exists a probability of two thirds that the stone will be at rest and a probability of one third that the stone will fall. Jordan points out that this statement contradicts in an uncomfortable way our common- sense knowledge that the stone, being an object of macroscopic experience, does always have a definite location in space. To quote him on another example, "We are unable to make a clock with a hand which does not always point to a definite figure on the dial. This is a well known fact, but a fact of which present theory gives no sufficient account." To remedy this situation, Jordan proposes to introduce an independent physical axiom "that each large accumulation of</page><page sequence="4">QUANTUM MECHANICS 303 microphysical individuals always shows a well defined state in space and time." We shall presently discuss a formulation of this matter which, while less axiomatic than Jordan's, is nevertheless closely akin to his'. We might say, in other words, that there appears a divergence between the notions of description and prediction that is utterly foreign to classical mechanics with its complete determinacy. In order to overcome difficulties of just this sort, the author (6) has introduced the concept of a non-perturbing measurement. By this we mean a measurement of the value of a dynamical variable that does not appreciably alter the course which the relevant variables of the system would take if the measurement had not been made. One can then define a quantity of macroscopic physics as one that can be determined entirely by non- perturbing measurements. To give an example, we can accurately measure the position of the stone at any moment by means of an optical device without significantly affecting its state of rest or motion. Similarly, on replacing the hand of Jordan's clock by the more conventional model of a pointer of a meas- uring instrument, we can, by the use of an optical measuring device coupled to a suitable amplifier, achieve a "measurement" of the position of the first pointer expressed by the position of a second pointer, and so forth ad infinitum. Also, the position of a pointer can be "measured" simultaneously by means of the positions of any number of other pointers. This unlimited reproducibility is characteristic of macroscopic measurements. It is clear that the notion of a non-perturbing measurement is not a rigorous one. If we go to smaller and smaller dimensions of the measured object, quantum- mechanical complementarity will enter more and more and the disturbance becomes larger. There is no precise point at which we could draw the dividing line between perturbing and non-perturbing measurements. We believe that the gradualistic nature of such concepts is characteristic of the problem we are dealing with; it cannot be avoided even at the cost of rather artificial con- structions. This might be deplored by some, but we think that it is only by the persistent use of such a gradualistic mode of description, in one form or the other, that the difficulties in the current interpretation of quantum mechanics can finally be overcome. We see that in spite of a loss of prediction we can give an adequate description of macroscopic objects and events. They are open to continuous inspection by non-perturbing measurements.-For the subsequent notions, the writer is deeply indebted to the philosophy of Alfred Whitehead where he found many of the ideas here used. There might of course be great differences in terminology between the philosophical language of Whitehead and the technical expressions of a physicist.-In our language we shall say that the physical reality of an object, i.e., the sum total of its ascertainable quantitative attributes, can be defined only by its relation to the "classical" reality specified above. Such a I Jordan's subsequent discussion of the importance of the continuous spectrum for the phenomenon of the quantum "jump" brings out a most significant point of the theory and interpretation of quantum processes. We believe, however, that his appeal to the tempera- ture, on p. 273, is erroneous.</page><page sequence="5">304 WALTER M. ELSASSER procedure is in accord with the methods actually employed by the experimental physicist. It has been said too often to need repetition, that if the physicist measures for instance the position of an electron, he does so by relating it to the position of a pointer, and the pointer is part of the macroscopic, classical world; its position can be reproduced without perturbation and without ambiguity by other pointers. We cannot ascribe to the position of the electron a meaning apart from its relation to the behavior of the measuring instrument, that is, apart from an interaction with the macroscopic world. Indeed, any critical survey of the technique of measuring must lead to the conclusion that the basic ascertainable facts are macroscopic facts and that all other facts must be defined in relation to these. Now the electron whose position we measure cannot be invested with a definite position before the measurement took place; such an assignment would fail to have an operational meaning (unless the measurement of position had already been preceded by a similar one.) We express this fact by saying that the measuring process has created a new element of physical reality, namely, the position of the electron, that did not exist heretofore. Reality, then, in the microscopic world is but an expression of the ascertainable relationships with the macroscopic realm. This implies that the amount of physical reality inherent in a system, tantamount with the amount of quanti- tative information attributable to it is, in quantum mechanics as distinct from classical physics, not fixed but variable, owing to the fact that the system will in general interact with other systems. Such an interaction may produce an increase as well as a decrease of the amount of quantitative definition of the system depending on the conditions of interaction. In other words the amount of physical reality of a non-macroscopic character contained in a system cannot be specified without reference to its past history. Let us illustrate this by an example taken from the theory of quantum- mechanical measurements. In an atomic beam (Stern-Gerlach) experiment sodium atoms pass through a magnetic field, and in this field their spins become oriented either in the direction of the field or in the opposite direction. It is then possible, by suitable magnetic influences, to separate the beam into two distinct beams whose atoms have opposite spin directions, and one may eliminate one such beam by means of a diaphragm. The remaining beam, consisting of atoms with spins all aligned in the same direction, has characteristic properties through which this alignment of spins exhibits itself, for instance if the beam is made to interact with microwave radiation. Now it is customary to say that in a beam that was not subjected to such an experiment the atomic spins are oriented at random. This statement means that if we perform an experiment on the beam such as to split it into two partial beams with opposite spin directions there will in the average be equal numbers of atoms in the two component beams. Beyond this no operational significance can be attributed to the state- ment that the spins are distributed at random. It is clearly incidental that these results flow from a specially arranged experiment in the physicist's laboratory; if by some freak of nature beam-splitting devices occurred spontaneously in the universe the conclusions to be drawn would be exactly the same. The cDnditions</page><page sequence="6">QUANTUM MECHANICS 305 considered here are extremely simple from the viewpoint of formal quantum mechanics, but are capable of vast generalization. In the technical language of quantum mechanics, the beam before the experiment is in a condition of de- generacy which expresses itself in the randomness of the spin orientations, whereas after the experiment the beam is in a well defined pure quantum state. Degeneracy is a general characteristic of the quantum mechanics of more complex systems and it always involves essential elements of randomness in the description of the system. Without going into an analysis of the relations of quantum theory and statistical mechanics (3) it may suffice to say that in any interaction between systems in which the degree of degeneracy is reduced, the intrinsic definition of the microscopic state and hence the degree of physical reality inherent in the corresponding system is in general increased. As we have pointed out before, it is necessary to relate the condition of a microscopic system to macroscopic bodies and events which are the primary constituents, as it were, of physical reality. It is possible to distinguish two principal modes of physical relationship between the microscopic world and the macroscopic one. The first mode is represented by averages. Thus the center of gravity of the stone is the weighted average of the positions of its microscopic constituents. Similarly the intensity of a light beam represents an average of the energy of the quanta contained in it. Again, the concentration of a solution represents an average over the number of dissolved molecules referred to the number cf molecules of the solvent. The mode of averages is the most funda- mental and the most common relationship between microscopic and macroscopic quantities. It is, however, so familiar that we may well forego any additional discussion. The second mode of relation between microscopic and macroscopic phenomena is that of amplification. The physical properties of sufficiently small systems are studied by devices that necessarily involve amplification; only in this way the phenomena of the atomic world can be individually related to the unique effects of the macroscopic world such as the positioning of pointers. Quantum- mechanical measurements involve devices which, while not always designated as amplifiers in the ordinary language, are easily recognized as such, and we shall discuss them in more detail later. The Geiger counter is one- example already mentioned, the photographic plate is another one. The development of the photographic plate, involving the formation of a macroscopic silver grain by a trigger mechanism of a few ions, may be considered as a process of amplifi- cation. '1 he same is the case for the formation of water droplets in a Wilson chamner, and the riumber of examples might be extended almost indefinitely. Frcm the viewpoint precented here the amplifying process is of fundamental importance because it represents the essence of the physical relationship between the micrcscopic object to Le measured and the macroscopic realities. Let us for a moment return to that simpler relationship between microscopic and macroscopic quantities which is expressible in the form of averages. For the mathematical treatment of such problems we have a well-developed and well- understood method, namely, statistical mechanics. In certain cases the applica-</page><page sequence="7">306 WALTER M. ELSASSER tion of the theorems of statistical mechanics is quite simple; this is true when we have prepared a system so that we know its chemical composition and have waited long enough to allow it to reach thermodynamical equilibrium. We can then describe practically all its properties by means of a few parameters. Even if such simple conditions do not prevail, the number of variables that we may choose will for any macroscopic system be small compared to the number of atomic and electronic coordinates. This is not only a practical restriction but essentially a theoretical requirement if variables are to be determined by non- perturbing measurements.2 This brings us back to the gradualistic character, emphasized before, of this interpretation of quantum mechanics. We have used the term "gradualistic" in preference to "approximate" in order to bring out the fact that there is not implied the postulated existence of a more precise reality to be approximated. Description is definite and unambiguous only in the degree in which the corre- sponding measurements are non-perturbing. It is this gradualistic nature of our point of view which has caused the writer and will perhaps cause the reader some difficulties because it is foreign to the traditional habits of the exact scientist. We are accustomed to thinking of the description of nature in terms of a definite mathematical structure, a model, and we are desirous of establishing a one-to-one relationship between the model and the phenomena. But such a relationship exists only in the macroscopic realm. To say that in microscopic physics a model cannot be fitted so as to be the unique expression of observations, and to say that nature is not so constituted as to be uniquely described by a model is a difference in terminology: The former is a statement of physics, the second is a translation into metaphysical terms. For obvious practical reasons the use of definite models (statistical ensembles) is preferable to more vague modes of description; one must say, however, that it is not universally possible to specify one model as the correct one out of an infinite number of competitive ones that represent a given body of experience, that is, non-perturbing measurements. This lack of uniqueness of representation is a feature of all models of statistical mechanics and as such has been extensively studied (for ensembles representing thermodynamical equilibria) by Gibbs and by others after him. Here we meet this question in a philosophical context of which earlier writers were able to rid themselves by suitable assumptions. But one cannot read the introductory chapters of that classic of mathematical physics, Gibbs' Statistical Mechanics, without feeling very strongly that he was fully aware of the epistemological implications of his scheme. 3. The Extension of Complementarity. It has been said by various scientists, notably of late by N. Wiener and others (7, 8), that the organism contains 2 There might arise the question as to what the best way may be to describe statistically a system determined by a set of nonperturbing measurements. In some special cases this questioni is answered by the theorems of statistical mechanics and one can try, as the author (6) has once done, to broadly generalize such methods. It appears to us at present, however, that by the nature of this type of approach a universal unique scheme of representation by ensembles does not exist.</page><page sequence="8">QUANTUM MECHANICS 307 amplifying devices. We fully adopt this notion, in fact in a more general sense than Wiener, but we must make at the outset the remark that the nature of the amplifying processes involved here is so different from those involved in quantum- mechanical measurements that analogies with the latter can be used only with the greatest caution. What they have in common in our view is a physical relation of the microscopic, molecular realm, beset with the familiar uncertainties, with the realm of determinate, macroscopic, classical physics. Each time such a relationship has been established there might be said to occur an increase in the amount of physical reality of the material bodies involved. If such amplifying processes go on continuously, we may propound the notion that the organism is a locus of continuous creation of physical reality. From the standpoint of our interpretation of the relation between microscopic and macroscopic physics we might say that indeed the main function of the organism is the creation of new physical reality. If this is so, then the amplifying devices employed by the organism assume a paramount importance. Thus, in studying the organism from the viewpoint of the theory of amplifiers we might expect to improve our understanding of its functioning and at the same time test the significance and fertility of the epis- temological notions that arise from the interpretation of quantum theory. Before we proceed, however, to outline some rather rudimentary ideas about amplifiers it is important to say just what these biological amplifiers are not, in particular to say in what they differ from the devices that we have discussed in connection with quantum-mechanical measurements. In this context a fundamental remark has been made by Niels Bohr (1) years ago. He indicates that the particular microscopic variables that determine the macroscopic behavior of the organism are essentially unobservable. He expresses this by saying that if we would try to measure with appropriate precision all those internal variables whose knowledge is required for a unique prediction of its future behavior (for instance by using simultaneously a sufficiently large number of Heisenberg microscopes) then the structure of the organic tissue would be disturbed to such a degree that it would no longer be capable of carrying out its vital functions; in other words the animal would die. According to Bohr this behavior is essential to the operation of all organized matter. He designates it as a generalized complementarity: operation of the vital functions precludes knowledge of the microscopic variables; determination of the microscopic vari- ables precludes biological operation of the living organism. This analysis of Bohr's brings out clearly one difference between the amplifying processes used in the measuring process of quantum mechanics and those found in living organisms. The former aim specifically at the determination of one particular microscopic variable, or a very few of them; the latter may be said to be of a distributed character; numerous microscopic variables must enter into them simultaneously in order that the notion of generalized complementarity as outlined by Bohr be applicable. We have little doubt in the correctness of Bohr's ideas, but the similarity with the ordinary complementarity of quantum mechanics is not perhaps as close as it might appear. One aspect of the comple-</page><page sequence="9">308 WALTER M. ELSASSER mentarity of the dynamical variables in quantum theory is that it denies, in a rigorous mathematical sense, an underlying mechanism whereby those variables that remain essentially undetermined in the measuring process could be caus- ally determined. Now while the same would be the case for the variables of the organic amplifier mechanism, it is not so much those variables proper that are of physical interest, but the amplifier mechanism itself whereby an imprint in the macroscopic world is effected. The emphasis on complementarity suggests that we are dealing here with an ultimate absence of mechanism. While this is so in a sense, it is nevertheless a mechanism, namely, the amplifier that is the proper subject of study here. In the case of the quantum-mechanical measure- ment it is, on the purely conceptual plane, possible to consider the isolated interaction between elementary particles apart from the amplifying mechanism whereby this particular event produces an action in the macroscopic, classical world. It is in the nature of the proposed interpretation of quantum theory that it displaces the interest from the elementary particles and microscopic variables, in vacuo, as it were, to the relationship of these individual constituents of the physical universe with the macroscopic reality, i.e., to the amplificatory proc- esses which influence the latter. It is apparent that in the case of biological amplifiers we can no longer, even in principle, effect such a separation between the microscopic events and the devices whereby they are made to produce a macroscopic effect; instead we must investigate the dynamics of complex sys- tems and contemplate the whole enchainment of processes whereby the one passes into the other. Bohr's principle, on the other hand, performs an extremely important func- tion in that it prevents us from premature, crude and inaccurate interpretations. It eliminates once and for all the possibility of relating macroscopic effects of the organism to specific, localizable individual events in the realm of atomic physics. This is all to the good as empirical biologists have never taken kindly to such a view. Clearly, any statement to the effect that a definite atomic event is uniquely related to a macroscopic action would be in violation of Bohr's principle. What remains is the study of those complicated systems of dynamics that, figuratively speaking, reach down to the elementary phases of the molecular realm which they connect dynamically, by amplification processes, to the phe- nomena of macroscopic physics. Again, in the scheme of our interpretation of quantum mechanics Bohr's analysis finds easily its proper place. It is of course closely related to the sta- tistical, indeterminate relationship between microscopic and macroscopic physics that we have been discussing. The notion of a non-perturbing measurement was originally suggested to the writer by Bohr's paper. But as we have tried to point out (6) the notion of generalized complementarity might be applied to non-living systems as well, and is connected with the structure of quantum statistical mechanics. Take for instance a gas in an enclosure in equilibrium; its thermodynamical variables can be determined by non-perturbing measurements, whence numerous physical properties of the system can be predicted. If, how- ever, we would try to measure all the coordinates of all the molecules of the gas</page><page sequence="10">QUANTUM MECHANICS 309 by means of an array of Heisenberg microscopes, we would in fact produce an explosion, and the previous description of the system by means of a suitable canonical or similar statistical ensemble would become utterly invalid. Con- versely, the continued validity in time of such a statistical model is based on the requirement that the measurements employed be of a non-perturbing character. * * * * At this point of our analysis we shall insert a very brief digression that leads beyond the borders of our subject into the philosophy of biology proper: An epistemological study of the atomistic foundations of life will have to steer clear of the Scylla of mechanism of the Charybdis of vitalism. If by Bohr's argument we introduce a sufficient amount of microscopic indeterminacy so as to prohibit the prediction of the behavior of the organism on the basis of purely physical measurements, we seem to leave the door wide open to arbitrary vitalistic speculations. It is our belief that one must close the door again by introducing the postulate that the behavior of the organism is nevertheless determinate. This determinacy need not be of the exhaustive kind found in classical physics, but would contain statistical elements after the example of quantum statistics. It will nevertheless have to lead to definite results in the case of continued series of comparable observations. As we have excluded the case where such determinacy is purely mechanical, it must needs be biological. By this we mean that the predictions are derived jointly from such features of the system as are physically determinate and from certain other features that are not to be described in terms of the procedures of measurement of the physicist. The latter are biological. Since any determinacy consists in the relationship of present or future behavior to the past, this relationship refers to the preceding existence of the system as a living being, that is to the past, either of the indi- vidual organism, or of the species to which it belongs by reproduction. This reasoning leads us directly to the laws of biology proper and its elaboration would far transcend the confines of this paper. PART II 4. Structure and Efficiency of Amplifiers. Given the importance that ampli- fying devices have from the point of view taken here we must devote a few pages to a discussion of their main properties. It is hardly possible to do justice to such a subject short of writing an extensive textbook on amplifiers. Un- fortunately, the existing texts on amplifiers are either quite elementary or too much involved in specific engineering problems to be of much interest to a more general public. Here we shall try to bring out certain basic concepts whose knowledge is important in the theory of amplifiers; we shall try to illustrate these by a number of examples representing devices that are used in engineering practice. We are well aware of the deficiencies of such a brief review, but per- haps it will induce some readers, better acquainted with biology than the author, to give thought to the application of the theory of amplifiers in biophysics. It is quite difficult to define an amplifier in formal and rigorous mathematical terms, but one can give a definition of such a system that is reasonably adequate</page><page sequence="11">310 WALTER M. ELSASSER for practical purposes. One starts with the notion of an open system, that is a system that has input and output terminals through which energy enters and leaves. An amplifier is then an open system in which the output power (that is, rate of energy output) is a function of the rate at which energy enters a certain input, the control input. The relation between the two energy flows is such that only a fraction of the output power is supplied from the control input itself. Hence most of the power flowing out of the system must be supplied from elsewhere. In continuous operation of an amplifier the power must be supplied through a separate third terminal, the power input. It is, however, possible to store energy in the system and to release it upon the triggering action of a control input. This type of amplifier must evidently operate intermittently; it must be re-charged during an interval of time in which it cannot, as a rule, be triggered. On turning first to the mathematical characteristics of amplifiers we find that all such devices belong to the broad class of non-linear dynamical systems. They cannot, however, by any means be identified with non-linear systems as a whole but forn only a restricted class of these. To bring out a principal mathe- matical characteristic of amplifiers we consider for a moment a linear dynamical system. In addition to linearity such systems are commonly endowed with a second fundamental dynamical property, namely, reciprocity. The principle of reciprocity for such systems is enunciated for an open system in the following form: If a certain force (or voltage) is applied to one terminal, A, of the system then the amplitude (or current) which is produced at another terminal, B, is the same as would be observed if the force were applied at B and the amplitude determined at A. Mathematically, the existence of such reciprocity relations expresses itself by the symmetry of the matrix or matrices that appear in the linear equations. Since the principle of reciprocity is fulfilled for a large number of linear systems that occur in the practice of the physicist or engineer, it is sometimes more or less implicitly assumed that any linear system is also a reciprocal one. Thus one is inclined to ascribe properties to linear systems that fundamentally are not so much dependent on linearity as they are on the validity of the principle of reciprocity. For our present purposes it is of some importance that these two independent properties of dynamical systems be kept apart. There exist basic mechanical and electromagnetic systems which are linear but not reciprocal. Two types of these are known to the physicist: mechanical systems with gyroscopic forces and electromagnetic systems with magnetic forces. The deviations from reciprocity that appear in these are of a singular type. In the context of this paper we shall certainly not have to deal with dy- namical systems that involve either of these two types of forces; we may dis- regard them for our purposes. There is another vast class of dynamical systems that can be described by linear equations which do not obey the reciprocity principle, this type of equation occurs when a linear system can be used to approximate the behavior of a non-linear system. In general such an approxi- mation can only hold for a limited domain of variability of the dynamical variables. Two types of linear approximations are commonly used, the local</page><page sequence="12">QUANTUM MECHANICS 311 approximation and the approximation in the mean. The local approximation is confined to a small neighborhood of a given set of values of the dynamical variables and originates by means of a series development of the equations of motion about this particular point. The approximation in the mean represents the average behavior over a domain of finite extent by means of linear equations: one may remember how, in calculus, a curve is represented by a tangent in the immediate neighborhood of one point and by a secant over a somewhat larger interval. The approximations of non-linear systems so found in general no longer obey the reciprocity principle. This method of approximating non-linear systems by linear ones lacking reciprocity is extremely powerful, as evidenced by the fact that almost all the mathematical theory of electronic amplifiers in existence is of this type. The analysis of these asymmetrical linearized equations has been developed to a considerable degree of refinement. Such systems are usually designated as "active" networks to distinguish them from the "passive" networks fulfilling reciprocity. One can infer that the mere suppression of reciprocity (being about the only property that distinguishes the two types of equations) goes a long way toward defining the dynamical properties of those non-linear systems that may be termed amplifiers. We have found, in our studies of the subject, that the analysis of a system with respect to existence or failure of reciprocity is probably the most important step in the understanding of any amplifier mechanism. We shall now treat some examples of simple amplifying mechanisms. We shall consider a set of devices all of which embody the same fundamental principles although they are taken from different branches of physics. Take first a simple electromagnetic relay which closes and opens a switch. There are two terminals for the primary circuit and two for the secondary. The primary current goes through a coil which attracts a magnet and thereby closes the switch in the secondary circuit. The absence of reciprocity is conspicuous: A small voltage on the primary suffices to change the resistance between the secondary terminals from near infinity to near zero, but no amount of voltage across the secondary terminals will give rise to a change in the resistance of the primary. An example of a very closely similar nature is furnished by a stopcock or valve in a pipe carrying a liquid. Here again, if the stopcock is well con- structed no amount of pressure of the liquid will produce a change in the stop- cock's position. The two devices, in addition to failing to obey reciprocity are also highly non-linear in some other respects. Another example belonging to the same type of system is offered by an ordinary vacuum tube, a triode. Here we have three terminals, a power input, the cathode, a control input, the grid, and a power output, the plate. This differs from the relay in that the primary (grid) circuit and the secondary (plate) circuit now have a common terminal, the cathode. The relation between the two circuits fails again of reciprocity, the grid voltage controls the plate circuit, but not conversely. In contradistinction to the relay which has only two output positions, open or closed, the amplifying action of the vacuum tube is continuous: to a small increment in grid voltage there corresponds a small change in plate current. Over a limited interval of</page><page sequence="13">312 WALTER M. ELSASSER variability it is possible to linearize these relations; one is thus led to the con- ventional linear theory of electronic amplifiers. We finally consider an example of this same series taken from quantum theory. Assume that we have an atomic system having the three principal levels shown in the diagram, where A and B are close together as compared to the separation between these two and C. Now A may be a metastable level in which the system can remain in semi-permanence if not disturbed. In the neighborhood of A there is, another level, B, from which the atoms can fall freely to C with liberation of energy. A small perturbation producing transitions from A to B represents the control input. The source that furnishes atoms in state A (what- ever the nature of this source may be, and we need not inquire into it here) is the power input and the energy liberated in the transition from B to C is the power output. (One might be surprised to find a simple system of quantum mechanics among the non-linear devices under discussion, inasmuch as he think ZIP' -B -A FIG. 1 of quantum-mechanical systems as linear. The reason is simply that the dy- namical variables chosen are the input and output powers rather than the popu- lation densities of the levels, in which latter all relations would be linear.) Quantum-mechanical transitions of the type shown occur for instance in the luminescence of solids where highly stable excited states exist which under a slight perturbation, e.g. by heat, transform into other states that emit visible radiation. The same scheme may be interpreted chemically: Level A may repre- sent a relatively stable compound, or sat of compounds. Under suitable, ener- getically slight influences, such as the action of a catalyst, the system may go over into a neighboring state whence a more stable compound can be formed with release of energy. Catalysis is clearly one form in which we may be sure to encounter amplifier action in the basic, chemical activities of living organisms. We return once more to the electronic vacuum tube, the prime representative of a technical amplifier. In actual amplifying devices such a tube is connected with others of its type and also with passive circuit elements such as resistors</page><page sequence="14">QUANTUM MECHANICS 313 and condensers in order to form devices that execute a variety of useful func- tions. Particularly important among those accessory connections are those that achieve what is known as "feedback." In these networks a small part of the output power is returned to the control grid in such a way that the degree of amplification determined by the grid becomes dependent on the output of the amplifier itself. This device may be used to stabilize the output of the amplifier upon a given value of current or voltage so that automatically, on any deviation from the desired output, the control changes the output back in the direction of the desired value. Another, related system of feedback, using a relay, is the familiar thermostat. Here the temperature of the body heated by the secondary current of the relay determines the current through its primary in such a way that by alternation of the relay position this temperature remains close to a constant value. The applications of the feedback principle in engineering prac- tice are innumerable and so well known that they need not be discussed further. These highly stable, feedback type amplifiers are quite different from the devices, designated as amplifiers earlier in this paper, that serve as detecting or measuring apparatus in the realm of elementary particles. We must therefore say a few words about the physical properties of the latter. Their most signifi- cant characteristic is that they involve more or less pronounced instabilities. This implies in practice that their output power is supplied from energy internally stored in the device, so that their operation is intermittent. The Geiger counter is unstable (or semi-stable) with respect to an electrical discharge. All that is required to set it off is the presence of a few free electrons in the gas of the counter; these, on being accelerated toward the anode of the counter create new free electrons by ionization of the gas molecules; they in turn produce additional free electrons, and this cascade process continues until complete electrical break- down of the counter occurs. After this, a finite recovery time is required until the counter is ready for renewed operation. In the Wilson chamber the super- saturated water vapor is unstable and will spontaneously condense as soon as suitable condensation nuclei are present. The condensation nuclei are usually provided by the ions produced by a passing high-energy particle. The process of the formation of silver grains in the gelatinous solution of a photographic plate is basically similar, but somewhat more complicated. In the photographic plate the record is permanent whereas the Wilson chamber can be restored to its original condition by removing the droplets and introducing more supersatured water vapor. This distinction is of course secondary from the viewpoint of Part I, since in both cases a definite modification of the macroscopic world has been created. Another characteristic of these detecting and measuring devices closely con- nected with their instability is the fact that they are highly irreversible in the thermodynamical sense. The breakdown of the Geiger counter, or its equivalent such as the development of the photographic plate, might almost be considered prototypes of thermodynamically irreversible processes. The degree of irre- versibility may vary from one device to the other, but a perusal of the customary detection devices for elementary particles indicates that practically all of them</page><page sequence="15">314 WALTER M. ELSASSER involve pronounced thermodynamical irreversibility. As we shall see presently, the amplifiers in the more conventional sense of the term, used in engineering practice, are capable of approaching thermodynamic reversibility. What, then, is the nature of the distinction between the two types of amplifiers, the thermodynamically irreversible intermittent type and the thermodynamically much more reversible, feed-back stabilized continuous type? We think that the difference is, from our viewpoint, not one of principle but of degree, not relating to the fundamentals so much as to performance characteristics of the devices involved. If extreme rates of amplification are required, as is the case in the detection of a single elementary particle, then the device employed will, as a rule, be highly unstable. It is a rather general observation in the design practice of amplifiers that the stability of an amplifier is the lower, the higher the rate of amplification. It is possible to artificially destabilize an amplifier by feedback; in this scheme part of the output is returned to the control in such a way that the output is further increased. This is known as positive feedback, as distinct from the stabilizing feedback which is called negative feedback. In the limit of extreme positive feedback the amplifier becomes completely unstable and goes to the saturation of its amplifying capacity after any excitation of the input, whereupon it may collapse. Such a system is very closely similar to the Geiger counter in its dynamical behavior, both being characterized by an extreme degree of instability. It seems therefore that dynamical stability is a significant criterion of amplifier performance and that on stressing this viewpoint we can comprehend a large variety of amplificatory devices in a simple scheme. In such a scheme thermo- dynamical irreversibility has its proper place. It would be an exaggeration to say that there is a quantitative relation between instability and irreversibility, but it is true that highly sensitive amplifiers with low stability tend to involve rather pronouncedly irreversible processes. WVe have here distinguished between reversibility, a thermodynamical concept and reciprocity, a purely mechanical one. From the viewpoint of general me- chanics, lack of reciprocity means the presence of a one-sided constraint. In the more unstable types of amplifiers thermodynamically irreversible processes are used to generate lack of reciprocity of the dynamical variables. Lack of reci- procity, not lack of reversibility appears as the essential feature of the amplifier. Certain amplifiers of engineering practice can be very nearly reversible in the thermodynamical sense. An example is furnished by the recent invention of the transistor. This amplifier is a development of the crystal rectifier that has long been used in radio engineering. The crystal rectifier consists essentially of a block of semi-conductor, such as silicon metal, with which a thin metallic wire is in contact. If a voltage is applied a surface electrostatic charge develops at the contact which affects the resistance in an asymmetrical way so that more current flows for a given voltage in one direction than in the other. If now a second metal wire is added whose contact is in the immediate neighborhood of the first one, the system becomes an amplifier. It is found that the two contacts influence each other electrically, and the device can be arranged in a circuit in such a way</page><page sequence="16">QUANTUM MECHANICS 315 that the power carried by one wire, the control, is much smaller thain the power carried through the other wire, that is, amplification results. The transistor is a 4"cold" amplifier and the dissipation in the contacts is small, so that the tran- sistor- approaches rather closely a thermodynamically reversible system. So far as the author can see, there exists no inherent difficulty in the limiting concept of a thermodynamically reversible amplifier. Abstractly speaking, this represents a system that is thermodynamically reversible but has constraints that make it mechanically irreciprocal. From the engineering viewpoint an amplifier that does not involve irreversible dissipation is of course preferable to one that does. We might measure the efficiency of an amplifier (as distinct from its rate of amplification) by the degree of approximation to thermodynamical reversibility that it realizes. We shall finally discuss another characteristic of amplifiers that is intimately related to reversibility and is especially found in the reversible ones. This property is the geometrical asymmetry of amplifying devices. If an amplifier is a mechanical system with constraints that enforce unidirectional displace- ments, then we would expect that these asymmetric dynamical constraints show up in a reduction of the degree of structural symmetry of the device itself. There is one case where this need not be so, namely, when the amplifying action is produced purely by thermodynamical irreversibility. Thus, if we consider an explosion as the amplification of the event occurring in the fuse, it is clear that the exploding mixture can be fully isotropic and uniform. The more we go toward thermodynamical reversibility in amplifiers, the more commonly it will be true that the unidirectional mechanical action of the system is founded in a lack of symmetry of the device itself. A survey of the most common amplifying devices of engineering shows this to be indeed fulfilled. Such devices as the vacuum tube, the transistor, an electric generator with field coils (which might be considered as a type of amplifier) and numerous others of this type, invariably show low geometrical symmetry of their essential functional elements. The case of the vacuum tube triode (and of the transistor) deserves some more attention. These devices are rectifiers (diodes) in their simplest form before they become amplifiers by the addition of a control element. A rectifier is clearly the simplest irreciprocal device, it is a one-dimensional circuit element that is asymmetrical with respect to its two terminals. We can naturally expect that a physical structure that serves as a rectifier exhibits a pronounced geo- metrical asymmetry with respect to its terminals. In a triode there are two distinct rectifying actions, one applying to the primary (cathode to grid) circuit and the other to the secondary (cathode to plate) circuit. Neither of these in itself represents the asymmetry in the coupling between primary and secondary circuits that results in the amplification property. It would seem, however, that the presence of a rectifier action in each of the two circuits separately favors an asymmetrical coupling between the two which then will lead to amplification. While this may be exemplified in detail by the vacuum tube triode and the transistor, it does not seem that the conditions of this behavior have been studied systematically. Whatever this relation may be, it seems clear that in</page><page sequence="17">316 WALTER M. ELSASSER the practical cases known the connection is very close between rectification, amplification, and the geometrical symmetry properties of the underlying struc- tures. Even though the relation is so far only qualitatively understood, it appears to be of considerable suggestive value in dealing with amplificatory devices from an abstract viewpoint. 5. Cybernetics. We owe a great advance in our understanding of the func- tioning of higher organisms to the discovery of the close analogy that exists between the structure and principles of operation of the nervous system on the one hand and those of certain electrical networks employing feedback devices on the other. N. Wiener has introduced the term "cybernetics," now widely used, for the functional theory of such systems; we refer to his book of the same name (8) for the numerous elaborations that we cannot discuss. There can be no doubt that the nervous system has formal properties, with respect to the transmission of nervous impulses, that are those of an "active" electrical net- work. Each nerve cell is provided with long filaments through which electrical impulses can travel at a given measurable speed, of the general order of 100 m/sec. One is not dealing here with a purely electrical disturbance, but with an electro-chemical process taking place in a semi-stable system capable of a "charged" and a "discharged" state such as we found before in the Geiger counter. Here, however, the discharge initiated at one place spreads and travels along the nerve filament. After the passage of such an impulse a finite recovery time elapses until the fiber is capable of transmitting another impulse. At any one time a segment of the fiber is either at rest or being discharged, so that the fiber resembles an array of switches (or Geiger counters for that matter) each capable of only two alternate positions. As a result the amplitude, that is volt- age, of the pulse is not variable but determined by the discharge mechanism; the only available variable is the rate at which pulses are transmitted; this rate can vary from a maximum limited by the recovery time to a value many times smaller, and the rate at which pulses are transmitted is a measure of the inten- sity of the stimulus applied. It is remarkable that an entirely similar system of transmitting messages through the spacing of standardized electrical pulses has in recent years found extensive application in high-frequency telegraphy where it is known as the pulse-code modulation system. We encounter here one of those numerous cases where engineers have developed methods that, on second sight, prove to have been used by Nature long ago. It has been demonstrated that in a nerve fiber impulses can travel with equal ease in either direction. If a nerve fiber is artificially stimulated somewhere in the middle, impulses travel from there to either side. Hence we can say that, with respect to the propagation of impulses, the nerve fiber obeys the principle of reciprocity. The ends of the various nerve fibers are connected together by means of special cells known as synapses. The synapse is a rectifier of a very high degree of efficiency, that is, it lets nerve impulses pass readily in one fixed direction, but not at all in the opposite direction. The combination of nerve fibers and synapses clearly constitutes an "active" network in the sense defined above. There exists, however, a rather remarkable difference between this</page><page sequence="18">QUANTUM MECHANICS 317 method of transmitting messages and that employed in analogous systems of electrical engineering. In the nervous system the power for the propagation of the impulse and for maintenance of its strength against dissipation is supplied continuously along the transmission lines, but these lines are not themselves endowed with rectifying properties; we thus have here a functional separation between power input and rectification. In the network of the electrical engineer, on the other hand, the transmission lines such as wires or cables merely carry power along without supplying and replenishing it; these lines alternate with electron tubes which combine the function of an amplifier that feeds power into the network and the function of a rectifier that enforces unidirectional trans- mission. The rectifying action is indispensable, as we have seen, if a system is to have feedback properties which greatly enlarge the possibilities of its adjust- ment to the action of a control input. Synapses have another very important property. It is known that several nerve endings can come together at the input end of one synapse; conversely, several nerve fibers can issue from the output end of one synapse. We can then assume that an impulse entering a synapse from one nerve fiber leads to impulses in all fibers issuing therefrom. In this way very complex effects may be produced. An impulse may be distributed to several places of the nervous system or the brain; also by increasing the number of fibers carrying the impulse a sort of am- plification may be achieved. Most important perhaps is the possibility of feed- back inherent in this type of network: impulses can be taken off the ending of a nerve and re-injected into the circuit at a place which is anterior with respect to the direction of travel of the pulses. The findings of nerve-physiologists indi- cate that the functioning of the nervous system and its center, the brain, is primarily based upon a vast and extremely intricate pattern of nerve fibers connected by synapses. These simple structural principles can be arranged to give a vast number of functional applications. Especially interesting is the way in which the action of muscles is coordinated by means of sense impressions that are led to the brain in form of impulses; the brain in turn converts these into other impulses going to the motor nerves. Another such example is the nervous system's control of the body's equilibrium in standing or walking which ap- pears to be based on quite similar functional principles as the control of an air- plane or rocket by an automatic pilot. The number of examples could of course easily be extended. The temptation is great for us to dwell on this fascinating subject whose im- pact on our scientific and cultural notions seems only in its beginning. Further elaboration would, however, lead away from our main theme and we shall there- fore confine ourselves to one additional comment. This concerns the fact that the nervous mechanism described constitutes a purely mechanical, strictly causal model. Nothing could make this clearer than the exhaustive analogy between the structure and processes of the nervous system and those of the feedback devices of the electrical engineer so much emphasized by Wiener. Certain scientific schools of thought of the past, particularly some flourishing in the last century, have often been accused of an exaggeratedly mechanical inter-</page><page sequence="19">318 WALTER M. ELSASSER pretation of the organism. In some respects, however, they seem to have failed in the opposite direction, by underestimating the potentialities of such explana- tion. This is related to the fact that much of the traditional thinking in the physical sciences has been in terms of systems that we may designate as passive, which do not contain rectifiers, feedback devices, and controlled amplification (uncontrolled amplification, such as explosions or other instabilities seem always to have aroused the interest of the physicist). It is true that prior to the advent of electronic engineering the mechanisms indicated were all but non-existent outside the living organism; hence it is not surprising that their potentialities were not realized earlier. In emphasizing the mechanical and causally determined nature of these models as applied to the living organism we do not wish to lose sight of the essential limitations of the mechanical view. It is interesting that cybernetics starts out with a frame of mechanical ideas; undoubtedly, as inquiry will broaden to more complex functional situations of the organism, the border- line of biological phenomena in the narrower sense must sooner or later be crossed. This means that one arrives eventually at a point where the organic processes involved can no longer be described by mechanisms which in their entirety are subject to causal analysis based on non-perturbing measurements. Instead we will at some place encounter a definite loss of physical predictability, as formulated in Bohr's principle. At that point the engineering analogues of the amplificatory process that occur in the organism will progressively fail. This idea brings us back to the subject of this paper which is the connection between the microscopic (atomic) and the macroscopic phenomena, the way in which the former modify macroscopic reality by acting upon the latter. On using the term amplification in a broad sense we have considered this action as a particular process of amplification. Now so far in the present section we have spoken of amplifiers, and more generally active networks, in an obvious macro- scopic sense, well removed from the problems and philosophical quandaries of atomic physics. A nerve fiber which can be studied in much detail under the microscope is a very large object from the point of view of its elementary molecu- lar constituents. We shall presently have to deal with the application of our notions to phenomena in the organism involving molecular dimensions. Before we do this one more comment seems appropriate. It is clear almost to the point of triviality, that the character of the nervous system as an active transmission network expresses its functional adaptation as a specialized organ. It must have a structure of this general type in order to per- form its proper functions, just as the heart is essentially a pump or as the eye has a design equivalent to that of a photographic camera and so on for every specialized organ. In a sense, however, the nervous system is also the most vital of organs. Its function is to produce appropriate responses to certain classes of stimuli. If we consider a small organism, say a single cell, the protoplasm is no longer so highly differentiated and there is no separate nervous system. Never- theless the property of responding to a stimulus by appropriate action is one of the fundamental properties of all organic life and is present in the simplest cell. There are of course other properties that are essential, such as metabolism</page><page sequence="20">QUANT'UM MECHANICS 319 but this ability of responding to a stimulus is so universal that no definition of organic life has ever been attempted in which it does not figure prominently. It is indeed hard to see how any organism can survive in the long run unless it produces in the average reactions that are duly related to the stimuli of the environment. Now it is characteristic of this relation between stimulus and re- sponse that the physical power for the response is supplied by the organism itself rather than by the stimulus. If one replaces the term stimulus by "control input" and the term response by "power output" he has arrived at the definition of an amplifier as given earlier. It should be said that this correspondence is super- ficial at present, since we are rather ignorant of the mechanism of response in the case of the single cell. But the idea is provocative enough to induce us to give more thought to the application of the ideas previously developed to the microscopic, i.e., molecular behavior of organisms. Stimuli, by the way, are not necessarily external. In a complex organism there are many internal stimuli. The action of a nerve upon a muscle may be indirectly external, but directly it is an internal stimulus. Many internal stimuli are chemical in nature. The action of hormones is of this type. The hormone then plays the role of the control input in our amplifier model. The basic activity of the living organism is of course chemical. There are always some concomitant physical phenomena, mechanical and electrical, in the living cell but a true understanding of the microscopic functions of the living organism is primarily a question of chemistry. This fact is so well established that we need hardly give any explanations or excuses if from now on we deal with the microscopic phenomena of the organism as if they were solely chemical. We shall try to confront our previous notions of amplifiers, etc. with some of the known facts of biochemistry. The arguments are of necessity highly qualita- tive, given the formidable complexity of the empirical phenomena. 6. Molecular Reactions and Asymmetry. We have mentioned the fact that catalysis may in a sense be considered as an amplificatory process. Catalysts are ubiquitous in the living organism where they are designated as enzymes. Some of their peculiarities (such as the fact that the catalytically active group is attached to a protein molecule) are not yet understood, but it seems certain that their mode of operation is in most respects closely analogous to that of inorganic catalysts. Many chemical reactions proceed at ordinary temperatures with extremely slow or imperceptible speed. If the reacting molecules are in contact with the catalyst, certain forces come into play that allow the reaction to proceed at a much more rapid pace. The catalyst thus serves as a control organ amplifying the rate of reaction. As a rule the catalyst is not itself altered thereby. Clearly, the relation between the catalyst and the reacting molecules fails of reciprocity in the sense that the reaction itself has no influence upon the catalyst. The latter might perhaps be compared to a stopcock in a pipe connect- ing two vessels. If one of the vessels is filled with a gas and the other is empty the gas will stream from one vessel into the other upon opening of the stopcock. The simile is apt in the sense that in both cases the control organ merely allows the process to take place but has no influence upon its direction. The direction</page><page sequence="21">320 WALTER M. ELSASSER of the chemical reaction has no relation to the presence of the catalyst and is not changed by it. In the chemist's laboratory reactions are usually irreversible in the thermodynamical sense and proceed in the direction determined by the laws of statistical mechanics (increase of entropy). We have noted that from our viewpoint thermodynamical irreversibility appears as a unidirectional con- straint that determines the direction of the process involved, and in most chemi- cal reactions the course of the reaction is so determined. If on the other hand a system is close to thermodynamical equilibrium but is prohibited from attaining the full equilibrium configuration by the slowness of a chemical reaction, the catalyst merely assists in the attainment of the equilibrium. A theorem of statis- tical mechanics asserts that the ultimate equilibrium is independent of the mode or speed whereby it has been realized, hence it is-ultimately independent of the presence or particular nature of the catalyst. We now come to a second point regarding the chemistry of the living organ- ism. It is true that our knowledge of organic chemistry in vivo is still very inade- quate, but one fact has emerged with considerable clarity. Whereas the chemist uses highly irreversible reactions extensively, the living organism tends to re- main as closely as possible to thermodynamical equilibrium. Hence the great majority of reactions taking place in the living cell are more or less reversible in the thermodynamical sense. In order to achieve this condition, chemical reactions that involve large energy exchanges are broken down in the living tissue into sequences of much smaller steps, each taking place near-reversibly in the neighborhood of thermodynamical equilibrium. Let us quote a brief sum- mary from a modern text of organic chemistry (9): "Catalysts, it will be recalled, change the rate of a reaction but do not alter the position of an equilibrium. Since in the living cell a continuous and rapid metabolic process is going on, we are concerned primarily with rates of competing chemical reactions. Further- more, biochemical reactions as a rule liberate or absorb relatively small amounts of energy; a balanced or nearly balanced equilibrium is often at hand. It seems that living cells operate with reversible reactions where possible and can utilize or absorb energy in only small increments. Thus in the oxidation of carbohy- drates a complex series of changes takes place so that at no one step is anything near 100 kg-cal of energy liberated, which would result if all at once one carbon atom of a carbohydrate were oxidized by air to carbon dioxide. Apparently this necessity for reversible reactions with relatively small energy changes is a char- acteristic of biochemical transformations." If the chemist wants to synthesize some compound he proceeds by letting certain other compounds, his raw materials, react with each other. The organism has many other functions besides the manufacture of complex compounds, and most of those functions must be achieved more or less simultaneously in the living cell by means of chemical reactions. The processes in which some release of energy takes place quite suddenly, as in the discharge of the nerve fiber or in the contraction of the muscle, are probably not the most typical instances- of the chemical behavior of the living tissue. Even in the nerve cell it seems that the organism achieves a much better approximation to thermodynamical re-</page><page sequence="22">QUANTUM MECHANICS 321 versibility than would be attainable by electrical engineers confronted with a similar problem. As a rule, however, the reactions are much slower, and owing to the fact that they are broken down into long chains of intermediate steps they seem capable of rather careful control at each step through suitable cata- lysts. It is known that the enzymes, the catalysts of the cell, are highly specific, that is, each enzyme will in general accelerate only one definite reaction and will have no effect on other reactions going on simultaneously. Since there are many steps in the chains of reactions and a variety of catalysts may be present, it becomes clear that a much more intricate control of this play of reactions is possible than would be in the power of the chemist in his test tube. In the above quotation the importance of competing reactions was emphasized. This may be illustrated by the fact that in a living cell there is not only a gradual burning up of carbohydrates to carbon dioxide and water, which process supplies energy, but there is in the very same cell and at the same time a synthesis of carbo- hydrates from simpler compounds, as has been demonstrated by experiments with radioactive tracers. This example may suffice here to illustrate the delicate balance of simultaneous chains of reactions in the cell. A state of complete thermodynamical equilibrium is of course inert and static; it is not capable of change unless it be in response to correspondingly strong external forces. Hence, although in the organism the deviations from true equi- librium may be fairly small, it is precisely these deviations that are significant for its activity. We have noted before that in systems that are far from equi- librium thermodynamical irreversibility acts as a one-sided constraint that forces the process to go in a definite direction. In the neighborhood of thermo- dynamical equilibrium this constraint becomes ineffective. We have seen that in certain dynamical systems, notably the "cold" rectifiers and amplifiers of electronics, unidirectional constraints of a purely mechanical nature exist that show up in the asymmetry of the structures employed. If we suspect the organ- ism of a behavior that is closely akin to amplification we are led to inquire into the structural asymmetries that are known to the biochemist. We shall try to do this by first indicating very briefly some facts known and shall then discuss their interpretation. The asymmetry of the organic compounds found in the living organism is one of the most remarkable facts of biochemistry. Simple molecules are quite commonly rather symmetrical structures; thus in CO2 the three atoms lie in a straight line forming a rod; in NH3 the atoms are at the corners of a tetrahedron whose base is an equilateral triangle formed by the three H atoms. More com- plex molecules may or may not be symmetrical, but it is a fact of experience that most of the molecules occurring in living tissue are highly asymmetrical. If a structure fails to have any element of geometrical symmetry, then there exist always two varieties of the structure that are related to each other as an object is to its mirror image: The relation of the right to the left hand is the common example of this type of asymmetry. In chemistry this is known as stereo-asymmetry. A stereo-asymmetric molecule is a molecule completely lack- ing any element of symmetry, and there exist always two such compounds hay-</page><page sequence="23">322 WALTER M. ELSASSER ing exactly the same gross composition while their molecules are related as mirror images to each other. We might call one variety arbitrarily the right- handed and its mirror image the left-handed molecule. Two substances, one of which contains only right-handed, the other only the corresponding left-handed molecules are indistinguishable in almost all their physical characteristics. They are also indistinguishable chemically if either of them reacts with a symmetrical molecule, but their reactions differ if the reacting partner is itself a stereo-asym- metrical molecule of one definite "handedness." If the chemist synthesizes an asymmetrical compound out of symmetrical ones, the result is invariably a sub- stance in which right-handed and left-handed molecules occur in equal amounts. It is then possible (though in practice quite difficult) to separate the ones from the others by letting the mixture react chemically with a substance composed of stereo-asymmetric molecules that are all of the same "handedness." Very many molecules found in the living organism are stereo-asymmetrical. It is an invariable rule that of the two mirror-image forms the organism contains only one and never contains the form of opposite "handedness." A prime exam- ple of an asymmetrical molecule is sugar. Not only does the human organism contain only right-handed sugar, dextrose, and its derivatives, but the digestive system while readily assimilating dextrose is unable to digest its mirror-image molecule, laevose. The higher polymers of sugar, that is large composite mole- cules whose simpler sub-structures are the sugar molecules, namely, the starches and cellulose, make up a large fraction of the organic matter of plants. Here again, only molecules of one "handedness" are involved. The most important asymmetrical constituents of organic tissue are the protein molecules. Proteins are complex polymers whose relatively simpler molecular sub-structures are the amino-acids. The amino-acids are thoroughly known to the chemist and all of them are stereo-asymmetrical. Again here, in extracts from the living tissue, invariably only molecules of one "handedness" are found, and if it were not for the fact that some of these molecules can be synthesized in the laboratory, their mirror-image form would never be known to the chemist. Proteins make up (apart from water and from some rather inert substances such as fats) the largest part of the animal body; they are certainly its most critical constituents from the biological viewpoint. This selective character in regard to molecules of one "handedness" expresses itself not only in the structure of the molecules but also in the chemical reac- tions occurring in the living cell. The selective assimilation of right-handed sugar by the human body has been mentioned. It is possible to separate the two components of a mixture of stereo-asymmetric molecules by feeding the mixture to certain bacteria. They will eat up one component, whereupon the bacteria are filtered out, leaving only the mirror-image component. Many complex organic compounds that have a strong physiological action are built up of stereo- asymmetrical molecules, e.g., many hormones, vitamins, and numerous drugs. In practically all these cases it is found that the molecule of one symmetry has an intense physiological effect, whereas the mirror-image molecule will have a much weaker effect or no effect at all. Even the taste or smell of the two sym- metry types is often distinctly different.</page><page sequence="24">QUANTUM MECHANICS 323 It might occur to the reader that the maintenance of such a system of one- sided structures must require some rather intricate accessory apparatus and special efforts on the part of the organism (if such anthropomorphic language be permitted). Clearly all those very common chemical reactions which produce molecules of opposite symmetry in equal amounts must be carefully avoided and the whole system of chemical processes must be geared to the reproduction of the asymmetry as the metabolic process goes on. Just what this implies in special chemistry we hardly know. It would seem, however, that there must be some major biological reason underlying this behavior. Unfortunately the dynamics (including chemical dynamics) of highly asym- metrical systems has received very little attention from the purely theoretical viewpoint. It was known to the founders of the kinetic theory of gases that mo- lecular asymmetry introduces some characteristic modifications into the mecha- nism of energy exchange between molecules, but the subject has found scant attention, with one notable exception (10). Leaving out many details it might be said that so far as the problem is understood, the introduction of asymmetries leads to a complication of molecular interactions (both mechanical and chemical) in the sense that relatively simpler processes will be drawn out into longer and more involved chains of successive reactions. This theoretical conclusion is gratifying sin-ce it points in exactly the same direction as the purely empirical results regat ling the nature of biochemical reactions which we have quoted before. On the other hand this tendency is assuredly not confined to stereo- asymmetrical molecules, but is the consequence of all kinds of structural com- plexities. The latter are certainly plentiful in organic chemistry. It is likely that molecular asymmetry has a great deal to do with the involved and gradual character of biochemical reactions, also with the specificity of enzymes and similar problems. It seems, however, doubtful to the author whether the func- tional meaning of stereo-asymmetry can be exhaustively expressed in these terms. Let us now see whether molecular asymmetry may not, in addition, be inter- preted in other ways. Throughout this paper we have been concerned with amplifiers, first in connection with microscopic (quantum-mechanical) meas- urements, and then while considering the living organism. Such amplifying devices as are used by the living organism must, at least in general, be stable and controllable, quite distinct from the unstable behavior of an explosive re- action. For all we know, stable and controllable amplification requires feedback. Feedback in turn is dependent upon some form of rectification, that is, a failure of the principle of reciprocity in operations of a dynamical system. We have seen that such failure occurs in a variety of simple electrical and mechanical devices used by engineers. In such devices there exist unidirectional constraints of a purely mechanical nature as opposed to the unidirectional actions that are en- gendered by thermodynamical irreversibility. Now we noted the intimate con- nection between the structural asymmetry of a device and its capability for rectification. This leads to the following question: Is the structural asymmetry observed by the organic chemist indicative of a failure of the principle of reci- procity in the microscopic (molecular or near-molecular) operation of the living</page><page sequence="25">324 WALTER M. ELSASSER tissue? Lest we fall into the very common error of applying concepts formed elsewhere to a new realm where they are not yet defined, and may in fact not even be capable of definition without a major change in meaning, we must pro- ceed with caution. Nevertheless, it appears to the author that the whole weight of the arguments which we have tried to collect in this paper points in such a direction. We might therefore try to ascertain whether there is any intrinsic contradiction in such a hypothesis, remaining conscious all the time that in applying mechanical and electrical notions to the chemistry of the organism, these notions are bound to be modified in the process of their application. Fortunately, quantum mechanics does not make any fundamental distinction between electrical and chemical processes; the description of both derives from the same basic mathematical formalism. It is also true that the quantum-me- chanical interactions between simple constituents of matter, electrons, atoms, and simple molecules, do obey the principle of reciprocity; they proceed equally well in one direction and in its reverse.3 It might seem absurd at first sight to expect that mere complexity of structure or dynamics should invalidate such a simple and fundamental principle. That this is possible, however, is clearly indicated by examples, such as the crystal rectifier discussed before. The crystal rectifier is a system whose operation is rather well understood in terms of quan- tum mechanics. What happens in this case is that the dynamical variables which we use to analyze the behavior of the system are quite different from the posi- tional coordinates of electrons or atoms which form the first stage, as it were, of a quantum-mechanical description. Thus the characteristic dynamical vari- ables of the rectifier are the voltage at its terminals and the current flowing through it; their relation lacks reciprocity. In going from the original, micro- scopic variables describing the motion of elementary particles to these macro- scopic variables new properties make their appearance that it would have been all but impossible to discern in the first scheme. It is not necessary that the new variables be macroscopic; it is essential that they describe different dynamical properties of the system. We have encountered a similar case when we inter- preted the quantum-mechanical scheme of Fig. 1 as an amplifying device as distinct from the interpretation in more conventional terms of quantum theory. The science of theoretical mechainics, including a variety of aspects of quantum mechanics, abounds with instances of the emergence of new properties in the transition from one system of dynamical variables to another. As the example of the crystal rectifier and some similar ones indicate, there is nothing intrin- sically contradictory in the assumption that complex molecular aggregates behave in a way that is most suitably described by the notion of unidirectional constraints applied to their significant variables. 3The mathematical reader will notice here that we have failed to discriminate between the two slightly different though intimately related forms of the principle: The one for linear networks as enunciated before and the general reciprocity principle of mechanics which says that on reversal of all velocities a system moves backwards along its original orbit. This simplification seems justified for the qualitative applications made here, and refinement is easy when required.</page><page sequence="26">QUANTUM MECHANICS 325 Although a crystal rectifier does not involve appreciable thermodynamical irreversibility, there is a force, the voltage applied, that drives the device (and in terms of which the failure of reciprocity is formulated). A non-static system that has structural and dynamical organization, that is more than a mere dis- sipative mixture of chemical compounds, must have driving forces. If directive effects are not thermodynamical they will be mechanical or electrical. The chemi- cal activity of protein molecules is accompanied by exceptionally strong elec- trical fields, and there is every evidence that the organization of the protoplasm is bound to these electrical effects. This fact leads one readily into speculations regarding the analogy between effects observed in electronics and these micro- electric phenomena. In inorganic crystals there is found to occur migration of excited electrons or quanta, usefully employed in some electronic devices. It has sometimes been opined that similar processes take place in the extended struc- ture of the protein molecule. Our factual knowledge is avowedly limited, but the recent careful review by Franck and Livingston (11) indicates that migra- tion of energy in protein molecules has little similarity with processes in elec- tronic devices. We therefore think that the preceding notions of dynamics, such as lack of reciprocity, should be understood to apply to processes that are quite close to conventional chemistry. It remains to be seen whether there can be an outright failure of reciprocity in pure chemical reactions, specifically be- tween asymmetrical molecules in the presence of an asymmetrical catalyst, so that such a reaction would proceed preferentially in one direction. The author has not tried to embark on the difficult mathematical studies that would be in- formative of the minimum conditions requisite for such an occurrence. Also, in such a study one would have to take account of the physical parameters such as osmotic pressure and particularly the micro-electric fields which profoundly influence the chemical dynamics of the living tissue. We do believe that investi- gations of this type are not out of reach of present-day scientific techniques. In the course of such endeavors the somewhat schematical concepts of reciproc- ity and of its failure as used here will no doubt find their appropriate refinement in reference to complex systems. The universal stereo-asymmetry of organic molecules would seem to offer incentive and promise of success to this line of thought. Intimately connected with the postulated existence of amplifier mechanisms in the chemical operation of the organism is the problem of the limitations of physical predictability as embodied in the principle of Bohr. Any progress in this direction must of course be based upon a reasonably clear understanding of the physical operation of the amplificatory processes involved. This insight can be gained but slowly and the implementation of Bohr's principle will no doubt remain one of the most difficult tasks of science for a long time to come. University of Utah REFERENCES 1. N. Bohr, Nature, 131, 421, 457 (1933). 2. E. Schr6dinger, What is Life, Cambridge University Press, Macmillan, New York, 1945.</page><page sequence="27">326 WALTER M. ELSASSER 3. J. von Neumann, Mathematische Grundlagen der Quantenmechanik, Springer, Berlin, 1933, Dover, New York, 1943. 4. H. Margenau, Philosophy of Science 2, 48, 164 (1935); 4, 337 (1937); The Nature of Physical Reality, McGraw-Hill, New York, 1950. 5. P. Jordan, Philosophy of Science, 16, 269 (1949). 6. W. M. Elsasser, Physical Review, 62, 987 (1937). 7. Rosenblueth, Wiener, and Bigelow, Philosophy of Science, 10, 18 (1943). 8. N. Wiener, Cybernetics, John Wiley, New York, 1948. 9. Conant and Blatt, The Chemistry of Organic Compounds, 2nd edition, Macmillan, New York, 1947; chapter 20. 10. R. C. Tolman, Statistical Mechanics, Oxford University Press, 1938; chapter 5. 11. J. Franck and R. Livingston, Reviews of Modern Physics, 21, 505 (1949).</page></plain_text>
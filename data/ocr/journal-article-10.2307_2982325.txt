<plain_text><page sequence="1">183 Learning and Inference By VIOLET R. CANE Newnham College, Cambridge [Read before the ROYAL STATISTICAL SOCIETY on Wednesday, January 17th, 1962, the PRESIDENT, Dr M. G. KENDALL, in the Chair] SUMMARY The results of some learning experiments are used to test the assumptions upon which linear mathematical models of learning rest, and these assump- tions are found to be invalid. It is found that, if the problem confronting a subject in a learning situation is regarded as a decision problem, in the sense used in statistical theory, it is possible to regard his response as consistently determined in a way similar to a statistical decision procedure, provided proper account is taken of the effect of his previous experience on the sort of hypotheses he considers and the prior probabilities he attaches to them. Some suggestions are made for a physiological model that would produce behaviour of this kind. 1. INTRODUCTION IT has been suggested often enough that the process of inference, or inductive logic, is equivalent to learning from experience; and statisticians certainly seem to regard statistical induction as in some way leading to a best method of behaving in the light of a given amount of information. Only Savage, I think, discusses behaviour directly, in that he bases his theory on preferences among acts; but all statistical theories, by the use of one principle or another, supply methods of evaluating the data at our disposal so as to determine exactly (or almost always exactly) how to choose between various competing beliefs about the state of the world; and it is usually assumed that, once this choice is made, we shall know how to act. Thus any statistical theory may be described as offering a rational method of determining behaviour in terms of knowledge of past events. As to whether it is rational to try to do this, I should perhaps remind this Society that at a previous meeting Irwin pointed out (discussion on Anscombe, 1948) that inductive inference is based on faith in the proposition that we can learn from experience. That human beings have this faith may be judged from their behaviour, and the same may be said of most other creatures; in fact, experimenters have demonstrated time and again that, by suitable manipulation of a subject's experience in a given situation, they can get him to respond to it in almost any way they choose. Thus we may infer- by a circular argument-that the propensity to learn, so generally found, is biologically useful, that is, it produces behaviour which conforms with events in the external world. Whatever is thought of this argument, we can certainly accept that learning occurs and statistical inference occurs, and ask the question "What is the relation between them ?" It is a question that covers an enormous field. I must, through ignorance, confine myself to a small corner of it. I propose only to consider experiments on learning in a two-choice situation, to ask whether the type of mathematical models called linear</page><page sequence="2">184 CANE - Learning and Inference [Part 2, models (Bush and Mosteller, 1955; Bush and Estes, 1959) represent adequately the results obtained in such experiments, and to see if the ideas that seem necessary to interpret these results are paralleled by concepts formulated by statistical theorists. A great deal of work has already been done on a similar problem, that of testing whether subjects respond in the way recommended by decision theory or games theory. This is, however, mainly devoted to analysing "asymptotic" behaviour, when the subject is supposed to have finished learning and settled down into a "steady state"; whereas I wish to consider the process of learning, that is, what occurs in the earlier trials in an experimental situation. It seems, indeed, extremely difficult to decide when asymptotic behaviour has been reached, and the conflicting results of various experimenters may be mainly due to the different numbers of trials assigned to the learning stage. 2. THREE LEARNING EXPERIMENTS In a two-choice learning situation the subject is repeatedly put into a position where he must make one of two possible responses, and where there are only two outcomes, which may be described as "success" and "failure". Many of these experiments are of one of the following types: (i) for human beings; a subject sits before a machine (a one-armed bandit) which has two light bulbs, one on the left and the other on the right, and a button below each. He is told that, at each trial, he has to predict which light will come on and to signify his choice by pressing the appropriate button. If he chooses the correct button he scores a point, for which he is usually paid. (ii) for human beings; a similar machine is used, but in this case if the correct button is chosen the light above it goes on, if the wrong button is chosen there is no light (this is a two-armed bandit). It differs from experiment (i) in that neither button, or both buttons, may be correct at a given trial. In these two experiments one trial immediately follows another. (iii) for rats; a rat which has been starved for something like twenty-four hours is put into a runway from which arms lead left and right. When he has moved into one of these arms he is kept there and, if he has made a successful choice, finds a small amount of food. Sometimes the trials in such an experiment are a day apart, sometimes two or three are run on the same day, usually less than an hour apart. In the latter case it is assumed that any food consumed during the experiment does not materially affect the rat's appetite. This experiment is similar to (ii) in the sense that the rat only gets information about the arm he visits; I have labelled it as a separate type because it is impossible to explain to the rat what he is required to do, and it is known that instructions affect behaviour (e.g. Edwards, 1961). I shall consider only those experiments in which the reinforcement schedule-the scheme which determines what response (or responses) shall be rewarded at each trial -is decided in advance; in the first experiment this will be some sequence of the terms "left" and "right"; in the other two it may include "both" and "neither". The sequences are usually determined in a random, or quasi-random, manner and a schedule is described as x: y, where x and y are, respectively, the probabilities of reward on the right and left sides. If learning is to take place the experimenter must arrange that one side, which I shall take to be the right, occurs more often than the other in this schedule. Then x &gt; y, and for experiment (i), y I - x. The combination</page><page sequence="3">1962] CANE - Learning and Inference 185 of the ith term in the schedule with the ith response of a subject determines the out- come, for him, of the ith trial. Thus a sequence of trials can be represented by symbols R(s), R(f), L(s), L(f), where R and L stand for right and left and s and f stand for success and failure. This is by no means a complete record of the experiment: one might, for instance, note the time elapsing before a response is made, or the sort of hesitations and uncompleted responses that occur, and some theories of learning deal with these (e.g. Audley, 1960; Bower, 1959). The linear models for learning, however, are formulated solely in terms of the choice made and its outcome. 2.1. The Meaning of Probability Statements in the Description of Learning If a large number of subjects do one of these experiments, an obvious way of summarizing the changes in behaviour that occur in the course of the experiment is to calculate the proportion, p,(R), of subjects who choose R at the ith trial; pl(R) would be about i and p,(R) should, in a successful experiment, tend to 1 as i increases. Provided we can regard these subjects as a random sample of the population, p,(R) can be taken as an estimate of the probability that a subject chosen at random will make the correct response at the ith trial. Conditional probabilities, for instance p2(R I R(s) at 1), can be estimated in the same way and will have the same sort of interpretation. Such an approach is usually good enough for deciding whether a change in the experimental conditions-say, the sort of instructions or amount of reward given-has any effect. In most mathematical theories of learning, however, it is assumed that it is meaningful to talk about the probability of correct response at the ith trial for a single subject, this probability being conditional on his experience in the first (i- 1) trials. If a subject has only a probability of responding in one way rather than another in these experiments, however, he can hardly be basing his actions on inference, since any system of inference would lead-almost always-to determinate behaviour. It is therefore worth considering in what sense we might speak of the probability of a response in relation to a single subject. First of all, I do not see that this idea, that a subject might vary his response at a given trial, can be verified directly by experiment; for any repetition with the same subject in the same situation simply gives us more of the learning experiment; while, if a group of subjects assumed to be identical behave differently, we cannot know that their responses are not in fact determined by events in their earlier life. (It might be thought that rats reared under laboratory conditions could be treated as similar to each other; in fact, hand-reared laboratory birds show much greater variation in their behaviour than wild birds (Vince, 1960).) All we can do is to discuss what this idea might mean. Imagine, therefore, that we could repeat the ith trial; if the subject made a different response, how could this variability be interpreted? One suggestion (see Restle (1959, p. 421); this is a modification of Estes' theory) is that any given situation contains a number of stimulating elements, some indicating one kind of response and some another, and that the subject acts upon whichever of these chances to catch his eye; what happens in the course of learning is that more and more of the elements in the situation indicate the correct response. Thus the response is random in the same way that the result of tossing a coin is. Alternatively we might suppose that the subject arrives at a definite decision based on all the information, past and present, that he considers relevant but allow for the possibility of his making errors-as de Finetti has pointed out, an individual might act in accordance with the probability</page><page sequence="4">186 CANE - Learning and Inference [Part 2, axioms and yet make mistakes in arithmetic. This also involves a random element, but it seems to me of rather a different kind, and it can sometimes be detected. For example, there is a best strategy for experiment (i), that is, to predict the side on which the light has occurred more often; I have found that some subjects use this strategy consistently until the number of trials is rather large, when they begin to make mistakes which are clearly due to errors in counting. There is one further case in which the response at the ith trial would not be invariant, and that is if the two sides were not discriminably different. In experiment (i), for a subject who counted accurately, this would occur only when the light had appeared equally often on the two sides; but if a subject relied upon a mere impression of frequency then there would probably be a discrimination threshold, i.e. he would not treat a frequencyf2 as discriminably greater than a frequency f1 until f2 &gt;f1(1 + c), where c is a positive constant (assuming that Weber's law would hold). Thus there are various ways in which a random element could occur in a subject's decision procedure. However, I feel that what learning theorists chiefly mean in talking about the probability of a correct response at the ith trial is that the experi- menter can only make probability statements about what a subject will do next, given his responses so far. This seems to be the same as describing a group of subjects having the same experience on the first (i- 1) trials. 3. LINEAR MODELS Mathematical linear models of learning are based on the following assumptions: (i) since the situation in which the subject is placed is always the same, the change in behaviour observed on successive trials must be the result of the responses and reinforcements that occur; thus a record of these comprises the relevant data of the experiment; (ii) if the experimenter knows the first i terms of such a record he can make some statement-a probability statement-about the response that will be chosen at the (i+ I)th trial. These probabilities will depend on the preceding responses and reinforce- ments and on some parameters whose values will depend on the conditions of the experiment, i.e. pi+1(R) =f (record, 0). (The conditions of the experiment include any known previous experience common to the whole group of subjects, e.g. the administra- tion of a drug. In theory, the parameters 0 might be different for different subjects within the group but in practice estimates of the parameters are usually made from the whole group); (iii) the whole effect of the i preceding trials is summed up in pi+1(R). In con- sequence of this, pi+1(R) can be expressed in terms of p,(R), the response and outcome of the ith trial, and 0. A linear relationship is taken as a first approximation. Thus pi+1(R) = 61pi(R)+ 02 if R(s) occurs at trial i, and there are three other equations of the same type corresponding to R(f),L(s),L(f). Put pl(R) = pi, so that pi(L) = l-pi = q,. Since perfect learning occurs when one side, say R, is continually rewarded we must have lim p=l1, so that pi+ = (1-6)pi+ 6; also if the reward is the same on whichever side it occurs we must have f+1 = (1-6)q,+ 0</page><page sequence="5">1962] CANE - Learning and Inference 187 for the case L(s). If we assume that R(f),L(f) have symmetrical effects we arrive at the set of equations (A) p+, = (1 - O)p + 0 if R(s) at trial i = (1 - l)Pi + 02 , R(f) = (1- )P, ,, L(s) ,, = (l- 01)Pi+ 0 - 2 ,,L(f) where 6 and 01 lie between 0 and 1 andO &lt; 02 &lt;1 01. In experiment (i), R(f) and L(s) convey the same information to the subject so it is usual to take 0 = S1 and S2 = 0 for such experiments (occasionally also for experiments (ii) and (iii)). It will be seen that the first of the equations (A) implies that the success of a response increases the probability that it will occur at the next trial. For a reinforcement schedule x : y we have E(pi+1) = (01- 0) (x-y) E(pi2) + [x(0-02) +Y(201- -02-)+ 1 - 2(01- 02)] E(pi) + (01 - 2) (1 -y) and if E(p) E(pi2), E(pi+1) all tend to 1 as i tends to infinity, either x = 1 or 01 = 02. However, since extinction can occur, the equations for R(f) and L(f) must have limit- ing solutions for which pn+1 =Pn = 2, and then 02 = 01 and p.+, = (1- b1)p. + 1S1 for both cases. (A learnt response is said to be extinguished if the subject no longer chooses it in preference to other possible responses; in two-choice experiments extinction can usually be accomplished by changing to a 0: 0 reinforcement schedule, and the subject generally reverts very quickly to random choice, i.e. p(R) = .) Thus the population as a whole cannot learn to give consistently the better of two responses except in the special case where one response is always successful-nor can a single subject invariably be relied upon to do so. If these models do represent the process of learning, then subjects of learning experiments do not behave like statisticians. Galanter and Bush (1959) have tested such models experimentally and find them totally inadequate to deal with certain aspects of learning-the slowness of initial acquisition, the effect of over-learning, and the rapidity of extinction. Therefore something must be wrong with the assumptions, and I propose to consider them in some detail. 3.1. Enquiry into Some Assumptions The third assumption includes the first two, so I shall begin by asking "Does pi(R) sum up the situation at the beginning of the ith trial?" This question was, I think, first put by La Berge (1959a, b) and tested by means of experiment (i). He gave his subjects n trials with a reinforcement schedule of 0-5 : 0-5, and then changed this, without a break in the sequence of trials, to one of 09: 0 1. For four groups of subjects A, B, C and D, n was 0, 20, 100 and 200 respectively. The trials with the second reinforcement schedule form the main experiment, and for this p_(R) was about i for each group. The rate of learning of the four groups was, however, different; 80 per cent. of the subjects were responding correctly by trial number 27, 35, 49, 49 in groups A, B, C and D respectively. A linear model could, of course, deal with this situation by using different parameters for the four sets of results. However, if the parameters change with the previous experience of the subject then in any learning experiment different subjects should be assigned different parameters</page><page sequence="6">188 CANE - Learning and Inference [Part 2, and a linear model cannot represent the learning of a whole group. For instance in the case of experiment (i), where 0 = 01, 02 = 0, and x = 1-y, if we have E(pi+J) = x-(x-p1)(1 _- 6)i for the jth subject, over a group of k subjects we shall have k-1 2E(pi+j) = x - k-1(x -Pl) (1 -Oj)i and this cannot be put into the form pi+, = x - (x -pl) (1- 6)i for all i. The dis- crepancy between the learning curves for a uniform group and a mixed group would be most noticeable for the early trials, and it is here that linear models are notably unsuccessful. La Berge's result can, however, be described in terms of statistical inference, qualitatively at least. One would say that the subject entertained the hypothesis that the reinforcement schedule was 0 5: 0 5 with a degree of belief (or prior probability) that depended on his previous experience; and the fact that there is little, if any, difference between the results for groups C and D suggests that he must also entertain the hypothesis that the reinforcement schedule may change. A necessary implication of a linear model if learning is to occur at all is that, if a response is reinforced at one trial, it should be more likely to occur at the next; in particular, that p2(R|R(s))&gt;pl(R). This follows from the fact that, if Pi+l = (1 - ) Pi+ 02 when R(s) occurs at trial i, then pi+, &gt;pi if 02&gt; 01Pi; 02/61 iS the limiting value of pi as i-&gt; oco and must be noticeably greater than 2 if any learning occurs, whereas Pi should be very near 2. Experimental evidence does not support this. Data quoted by Sternberg (Sternberg, 1959; p. 362, Table 4) give, for 243 subjects doing experiment (i), a value for pl(R) of 0-636 and a significantly lower value for p2(R I R(s)) of 0-546. The results obtained by Galanter and Bush in some experiments of type (iii) give corresponding values of 0 49 and 0-46 (their experiments I and II combined) and of 0 50 and 0 45 (their experiments III and IV combined). (In the latter two experiments the rats were given some pretraining; they were allowed to go into the first part of the maze-not the arms-and could find food there.) Since Galanter and Bush report their experiments in full, that is, give the response and outcome for each subject at each trial, it is possible to investigate the effect of reinforcement at later trials. In their experiment I they had 24 rats to whom they gave three trials a day, for thirty-six days, with a 0 5: 0 reinforcement schedule. They find, among other things, a daily recovery effect, so that an interval between trials of about 221 hours cannot be equated to one of about 45 minutes. For this reason I have calculated p(R) only for the first trial of each day, and p(R I R(s)), etc. refers to the first two trials of a day. The results are shown in Table 1. It will be seen that for the first nine days p(R I R(s)) is never greater than p(R); also p(R I L) and p(L I R), although they fluctuate a good deal, do not show any trend away from 0 50 for the first twelve days at least. It appears that there are two sorts of learning occurring in this experiment; the subject first learns to choose the more successful response at the first trial of the day-this begins at about the sixth day-and then learns to suppress alternation after an R response; this begins at about the tenth day. The response to the third trial appears to be dependent on the result of the second in much the same way as the second is on the first. If we work out for each rat the last day on which he gives the response L at the first trial, the median number of days is 15; the medians for the second and third trials are 24k, 26k. For the three other experiments, in which the reinforcement schedule was 1: 0, the medians are</page><page sequence="7">1962] CANE - Learning and Inference 189 4, 5, 4; 7, 8, 7; 8, 7, 8; in these experiments, the two kinds of learning seem to proceed at much the same rate and it is difficult to disentangle their effects. (The effect of pretraining, incidentally, has been to delay learning.) Galanter and Bush think that a linear model cannot account for the rapidity of extinction. I am not sure that this is true. In the extinction situation, Pi = 1 (or very nearly) and we should havepn = 1(1- Ol)-1 + 2, which would tend to -1 very rapidly for 01 near 1. The only question then is whether this value of 01 can be incorporated TABLE 1 Days . . .1 2 3 4 5 6 7 8 p(R) * . 50 *71 *46 *42 *42 *67 *71 79 p(R R(s)) * . 42 *71 45 - 30 *38 p(R R(f)) . - - - 60 - - 59 50 p(R L) . . . 50 29 54 *71 *71 50 *43 *33 Days . . . 9 10 11 12 13 14 15 16 p(R) . . 75 *75 *71 75 *83 *71 58 79 p(R R(s)) . . 50 83 - 44 - - 1.0 79 p(R R(f)) - - 59 - *65 *88 _ p(R L) . . . 50 33 57 *67 50 *43 *60 *60 into the equations for the learning situation which precedes extinction. If the effects of R(s), L(s) are assumed equivalent to those of L(f), R(f), respectively, the initial rate of extinction would be about twice the initial rate of learning; it is usually found to be much greater than this. What the linear model cannot deal with is the effect of over-learning on extinction and the fact that a partially reinforced response extinguishes more slowly than one invariably reinforced. If subjects doing experiments (ii) or (iii) under a reinforcement schedule.x: 0 ultimately reach a stage when they invariably choose the correct side, then the only relevant fact, if a linear model is used, is that pl(R) = 1 at the beginning of the extinction experiment. Yet it is generally found that the rate of extinction is slower if n, the number of leaming trials, is increased (x constant) or x decreased (n, suitably large, constant). The first of these results is similar to that of La Berge, and can be interpreted in terms of the strength of the belief that R is the correct response. The second result is more interesting because, in fact, there has been less evidence during the learning experiment in favour of R. It has been suggested that, during the learning experiment, subjects become accustomed to runs of failure if x &lt; 1 and therefore are not affected by the failures that occur under extinction until the run has become unexpectedly long; and something of the sort must surely be true. This means, however, that the subject is in effect estimating the value of x; he is not dealing simply with the two hypotheses that R is the better response, or L is, but considering a whole set of hypotheses defined by the possible values that x might take (probably a finite set, corresponding to discriminable differences in x). Bakan (1953), in suggesting that learning might be described in terms of inverse probability, seems to me to deal only with two hypotheses (of the form, "If I go right, reward follows"), though he has not in fact considered the situation that arises in experiment (ii) with an x: y reinforcement schedule; and I do not myself see how to deal with it in his terms. In any case, I feel that he designs hypotheses from the point of view of the experimenter, who knows what the experiment is about, and not from that of the subject, who does not.</page><page sequence="8">190 CANE - Learning and Inference [Part 2, 3.2. The Effect of Experience on the Formulation of Hypotheses Let us consider experiment (iii) from the point of view of a rat; he does not know that it is the same maze at each trial (experimenters in fact often do their best to conceal this), he does not know that there is likely to be food in the maze, nor does he know that the experimenter is using a random reinforcement schedule. He looks for food in the maze because he is hungry. If he happens to turn left and finds no food there, it is clearly better for him to try the right at the next trial if it is the same maze, and it does not matter what he does if it is a different one. If, however, he happens to turn right at the first trial and finds food there, he eats it, and at the next trial it is still better to try the other arm because he knows there was no food on the right when he left. In particular, rats who were accustomed to 20-hour (or more) food deprivation might well expect that, once food had gone from a place, it would be a long time before it appeared again. I suspect that the reason why the rats that had pretraining in Galanter and Bush's experiment, with 1: 0 reinforcement schedule, learnt more slowly was that they had had several days of such deprivation before the experiment proper. For these, p(LI R(s)) remained at about 0 50 for four days, whereas for those without pretraining the probability dropped from 0 50 on the first day to 0-25 on the second, and remained low. For trials soon after the first the rat should still choose the opposite arm from the one last visited, because each was empty when he left it but one has been left unexplored for longer and therefore there has been more time for replenishment. Roughly we might say that, if the time interval between trials is equal, and the probability of replenishment after one such interval is 1- T, then for two such intervals it is 1 - IT2. If there are three trials a day, then at the first trial a day the probabilities for the two sides will be 1- _Tk and 1- _ k+l, k = 30 approximately, which are probably not discriminably different. Thus the correct response should be learnt more rapidly for the first trial each day because there is no incentive to alternate. What the rat learns, in fact, is that one side is replenished more rapidly than the other. We might write down an approximation to this state of affairs as follows: previous experience has led the rat to classify situations by the rate of recurrence of food; if we call such a rate A, the probability that food will have recurred by time t (assuming a Poisson process) is 1 - exp (- At). The rat must start with some prior distribution of probability for A, and this will be the same for each arm (unless he has a "side preference"). After a certain number of trials on experiment (iii) suppose the distribu- tion of A for the two sides is given by PL(A) and pR(A) and suppose that at the last trial he responded R and at the one before L. Then his expectation of food on the left and the right is jPL(A) [1-exp(-2At)] dA and JPR(A) [l-exp (-At)] dA, respec- tively, and we may suppose that he chooses in accordance with the larger. If he chooses L and fails, the posterior distribution for A, on that side, becomes pL(A) exp (- 2At)/ [JPLA) exp (- 2At) dA] while pR(A) remains the same; similarly, if he chooses R and succeeds, the probability distribution for the right becomes PR(A) [1- exp (- At)]/ [PA) (1- exp (- At)) dA]. This is not, of course, an easy formulation to handle because each change in the distribution depends on the time interval between visits to an arm; moreover we must suppose that each rat has not only a personal prior distribution but also, probably, a personal threshold as to what</page><page sequence="9">1962] CANE - Learning and Inference 191 he finds discriminable. Many experimenters have reported, however, that rats tend to alternate even when food is available in both arms at each trial, and that the probability of alternation drops with the time interval between trials (see, for instance, Dember and Fowler (1958)), and no explanation that is not equivalent to "there is something about rats that makes them alternate" has been put forward; so it seems worth suggesting -one that would imply reasonable and consistent behaviour on the part of the rat. Because any theory that predicts that learning will occur can be tailored to fit observed learning curves fairly well, it is usual to test linear models by the extent to which they can reproduce the "fine-grain structure" of the response sequences; predictions are made from the model of the average number of errors before the first success, the total number of errors, the number of alternations and other similar statistics, and these are compared with the averages from a group of subjects. It would I think be difficult to test the model I have proposed in this way. I am con- vinced, however, that this is not the proper method; what one should do is check the assumptions made, or simple deductions from them, directly. As was mentioned above, perhaps the most important deduction from the linear model is that p2(R I R(s)) &gt;p1(R). If this deduction is not verified it is hardly worth investigating the fine-grain structure since something is bound to go wrong near the beginning of the learning experiment; so far as I know it has never been checked with a large number of subjects, and such evidence as I have been able to find suggests that it is not necessarily true. Moreover, a theory of learning should be able to predict, at least roughly, how parameters in the model will change when particular changes are made in the experi- mental conditions. This, I think, can be done if we consider the previous experience of the subject and suppose he works with hypotheses based on it. For instance, we should predict (i) that, when food is always available in both arms, alternation should occur more frequently from the first to second trial than it does later, if the time- interval between trials is short; and we should predict (ii) the effect found in extinction experiments, that the more trials there are on one reinforcement schedule, the slower the subject will be in adapting his behaviour to a new schedule. Other possible predictions are (iii) that a rat should learn more quickly (in terms of the number of trials) if he has only one trial a day, and (iv) should alternate less if, at normal feeding times, he is fed pellets of food one by one; also, since the probabilities calculated above are conditional on the maze being the same maze at each trial, we should expect initial learning to be faster if as many sensory cues as possible are provided for the rat. These predictions are all based on the fact that alternation occurs when food is provided in both arms, and on the assumption that this is so because the rat recalls that there was no food in an arm when he left it. Qualitatively, the arguments for them are as follows: (i) suppose the proportion of the rats choosing R first that choose L second is 2 + S; if the trials follow each other quickly 8 should be fairly large, say about i, because the R side was empty when the rat left and the L side is unexplored. Suppose now a proportion + 81 of these return to R; 81&lt; 8 probably because now the rat is choosing between an arm just left and one left not so long ago; those which chose R at both first and second trials have already had some experience of the rapid rate of replenishment there, therefore the proportion of these turning to L next will be, say, 2O+ 8, 81&lt; &amp; The proportion alternating from 'the second to third trials will be</page><page sequence="10">192 CANE - Learning and Inference [Part 2, (-8) (2 + 811) + (2 + 8) (2 + 81) &lt; 1 + S. The same argument applies to those choosing L first; (ii) for an extinction experiment, say a reinforcement schedule of 1: 0 followed by one of 0: 0, the more trials on the first schedule, the more certain it is that A is large; that is, p(A &lt; A0) for the right side decreases as n increases. In the extinction trials the evidence goes to show that A is small; the smaller p(A &lt; A0) originally, the more evidence is required to make p(A &lt; A0) suitably large; (iii) if the interval between trials is large, there is less reason for the rat to avoid the arm last visited because there has been more time for replenishment, even if A is small. In particular, if he is on a 24-hour deprivation schedule he may learn from this that food recurs about every 24 hours; (iv) if food is replenished at short intervals in his ordinary life, he should assume it more likely to happen in the maze also. It is the existence of this alternative hypothesis, that the maze is different, which really, to my mind, accounts for the rapidity of extinction. The rat is, in effect, being posed the difficult problem of testing continuous production-compare for instance the problem discussed by Anscombe et al. (1947)-and, as explained in that paper, can consider only the cases of a sudden change in the situation or a gradual trend. I do not know of any experiments in which the reinforcement schedule is changed gradually, so I shall explain only how he might deal with a sudden change. Suppose that the rat has to learn to accept that the maze is the same at each trial; let v represent the probability that a maze which looks the same, is the same (i.e. is such that the posterior distributions for A on the two sides should be used), then v will change trial by trial and will have the value -i, say, after the (i- I)th trial. Let PRi,PLi be the probabilities of finding food on the right and left, respectively, if the maze is the same and let po, the same for each side, be the probability of finding food if the maze is different. The probability of finding food on the right is then -TipRi +(1-T)po, and there is a similar expression for the left side. The decision between the two sides depends on the sign of'pRi-PLi; as usual, I assume a discrimination threshold, so that the choice is random if 1T4(PRi -PLi)I &lt; C, for some given c &gt; 0. If R(s) occurs, _TiPRi 71iPRi +(1 - 7i*)PO which is &gt; i if PRi &gt;pO, which must be ultimately true, also the distribution for A for the right side, conditional on the maze being the same, changes in the usual way; there are similar results if R(f) or L(f) occur. After a long sequence of trials on an x: 0 reinforcement schedule, PRi should be approximately x, &gt;PLi, and 7i will be near 1, say 1- . If now the reinforcement schedule is changed to 0 : 0, when R(ff) occurs the probability attached to the hypothesis that the maze is the same becomes approximately (1 -3)(1 -x) (1 - ) (1 - x)+(1 + Po) - thus, if x = 1 it drops to zero, and in general the rate of decrease will depend on the size of 1- x and on 8, which will in turn depend on the number of reinforcement trials; ultimately, I i(PRi -PL) I &lt; C. The sort of hypotheses that subjects adopt in experiments (i) and (ii) are bound to be very different from those above; they may again, however, be considered as based on the subjects' previous experience. (Such experience includes the instructions</page><page sequence="11">1962] CANE - Learning and Inference 193 given at the beginning of the experiment; see Edwards (1961).) In experiment (i), a subject told to predict which light would appear might possibly assume that there was a random reward schedule, in which case he might either work with a uniform prior distribution for x- or, from previous experience of experimenters or gambling machines, a non-uniform distribution. (After experience of gambling machines this would probably be of the form Cxm(l -x)m, m large; after experience with experi- menters it would more likely be proportional to [xr(l - x) + xs(l - X)r], rt s.) He might equally well, however, suppose that he had to look for a temporal pattern and then we should have to assume that he assigns prior probabilities to initial sequences such as RLRLRLR or RRRLRRR (I have taken these of length seven since immediate memory is effective for about this number of symbols). He might also make the "gambler's error" of supposing that, because the light had appeared on the right for a long sequence of trials, it ought soon to appear on the left. I am not sure that this is an error if it is considered from the point of view of a subject's finite experience. Suppose that in n occurrences of a situation a particular outcome had been observed about 1n times, and that in the next n' occurrences it was observed n' times. For some not too small value of n', the subject would interpret this as a change in the situation (cf. extinction experiments); that is, what he means by a stable situation is one for which successive estimates of probability do not vary much. In consequence of this, if he is committed to thinking the situation stable, he expects some sort of balance within blocks of a given size. In fact, to ensure that a subject learns the right thing, experimenters often use sequences which are not random but made up of balanced randomized blocks; and, for all I know, manufacturers of gambling machines may do the same. Thus the "error" could have been learnt from experience. One can eliminate hypotheses about patterns either by giving suitable instructions (Nicks, 1959) or by using a situation such .as drawing a card from a freshly shuffled pack containing cards of two kinds (Neimark and Shuford, 1959). The second of these experiments has the additional advantage that it visibly displays the random character of the sequences; since the number of possible hypotheses is thereby limited, we should expect learning to be faster in this case. Unfortunately it is not possible tp discover from the data reported whether this is so. What Neimark and Shuford did find, however, was that if subjects were asked to estimate the proportions of the two kinds of card, on the basis of those which had already been drawn, before making their prediction, they gave the correct response more often. Whether this requirement simply made them count more carefully or whether it actually drew their attention to the existence of a best strategy is not clear. The best strategy for experiment (i), if the possibility of patterns is excluded, is to predict the light which has so far occurred more often. It is by no means obvious what the best strategy is for experiment (ii). The distinction between the two would be clearer-at any rate for the subject-if urns were used for the experiment. In experiment (i) we should use one urn containing a proportion x of red balls, the remaining balls being white, and ask the subject to predict the colour of the next ball in a sampling with replacement procedure. He would score a point for a correct prediction. In experiment (ii) we should use two urns, containing proportions x and y of red balls, respectively, and ask the subject to choose the urn from which we should take a ball (again sampling with replacement). He would score a point if the ball selected were red. This sort of experiment is rather like real life where we can usually only know the outcome corresponding to the response we actually make, and not the outcome of any other we might have made. Each response is a terminal decision for</page><page sequence="12">194 CANE - Learning and Inference [Part 2, that trial but the outcome is an experiment as far as later trials are concerned, and no real terminal decision (to stick to one urn) need ever be reached. Thus at each trial the subject has two aims, (a) to give the best decision on that trial, and (b) to gain information to aid him in making future decisions. The same considerations apply in experiment (iii); the rat is usually supposed to be so hungry that he acts in accordance with (a); if he acts in accordance with (b) he is said to be displaying exploratory behaviour. De Valois (1954) finds that there is more alternation, i.e. exploratory behaviour, when a rat has been deprived of water for 6 hours than when he has been deprived for 22 hours. A subject of experiment (ii) has to maximize his score over a number of trials; he can obviously only do this if he knows, or estimates, how many trials he will have. This problem (the two-armed bandit with a given number of trials) has been discussed in a number of statistical papers (see, for instance, Vogel (1960) and the papers he refers to) but a strategy which will maximize the expected score has only been found for various special cases: if the proportion in one urn is known, or only a finite number of preceding trials is remembered, or a terminal decision is to be made after k trials with each urn (k to be determined from the observations). The solutions (apart from the finite memory case) do not, however, reduce to simple rules that could be used in practice. A conjecture, given by Bradt, Johnson and Karlin, is that the choice should be made as if there were only one trial to come; they say this has been verified to give a best strategy when there are up to 8 trials ahead. Suppose, however, that the subject assigns a uniform prior probability on [O, 1] to both xl and x2 (where xl, x2 are the proportions of red balls in urns U1, U2 respectively). After r1 red, w1 white balls from U1 he will change to U2 if r I+ &gt;1 rl+wl+2 2 9 this may never happen if the true value of xl is appreciably above i, yet, if there are a large enough number of trials ahead, it must be worth trying U2 after a white ball has been drawn from U1 because the second urn may contain only red balls. If the prior distributions are uniform it is clearly worth staying with one urn so long as red balls are drawn from it since the other urn could not produce better results. A possible strategy, therefore, would be for the subject to make a new decision only after a white ball were drawn, and then to choose the urn for which the expected gain up to the occurrence of the next white ball (or up to the end of the experiment) was greater. This is a consistent policy (see Appendix) and would lead the subject to try each urn at least once if the number of trials were sufficiently great, but it suffers from the same sort of disadvantage as the policy of looking only one trial ahead. Suppose that the first ball drawn from U2 were white; then the subject would never choose U2 again if r1+ 1 &gt;1 WI always (if the number of trials ahead is very large), and the amount of evidence from U2 seems very slender for such a decision. I have tried these two experiments, using urns containing five balls; subjects were told the number of balls and the total number of trials they would have, which was twenty. Each subject did both experiments, in randomized order, though never with</page><page sequence="13">1962] CANE - Learning and Inference 195 the same two reinforcement schedules (of which all possible kinds were used) and was paid a penny for each point scored. I compared the relevant results (when the reinforcement schedule was, or appeared to be, 1: 0) with the results from a one-armed bandit given by Steinberg. The results for the single urn were very similar to his (learning was, perhaps, slightly more rapid but as I had only twenty subjects this is not conclusive). For the experiment with two urns, however, learning was very much faster; 90 per cent. or more of the responses were correct from the third trial whereas with the single urn this did not happen until the eleventh trial. Even those subjects who made incorrect responses, in the two-urn experiment, generally did so deliberately, explaining that it was worth a penny to find out more about the other urn. I suspect that the speed of learning was mainly due to elimination'of the "gambler's error" 4. DisCUSSION There is a canon of psychological theory due to Lloyd Morgan which runs: do not attribute an animal's performance to the operation of a more intellectual process such as reasoning, if it can be understood in simpler terms. It is, I suppose, in obedience to this that learning theories tend to be formulated in terms of rules linking a stimulus to a response. In my opinion it is better to formulate them in terms of subjective probabilities and hypotheses, and I should like to justify this. Inference is not an intellectual process, as I said earlier, although thinking about the best way of making inferences may be. It is a physiological process, and one which may reasonably be supposed much the same for other mammals as for man. "Hypothesis" and "probability" are terms invented by human beings to describe certain sensations; but sensations can be present without being named, and we can certainly act on an hypothesis without being conscious of it. Thus it seems quite sensible to describe any animal's behaviour in these terms. The results of learning experiments indicate that we must take account of subjective prior probabilities, and must assume that subjects can entertain more than two hypotheses about a given situation. These hypotheses, however, are suggested by the subject's own experience and are not necessarily those the experimenter would adopt. It may be argued that, by inventing a suitable hypothesis for a subject, we can explain anything at all that he does. However, I do not envisage this approach as an explana- tory one merely. If we can locate the sort of experience that leads to an hypothesis or to a particular level of subjective probability, then we can try to change it experi- mentally; but this requires that we should look at an experiment from the subject's point of view. De Finetti has suggested that psychologists should ask whether human beings naturally, without special training, act in accordance with the axioms of probability. A more interesting question, I think, is whether we can envisage a physiological system that would act thus. Any answer is, of course, purely speculative. I suspect, however, that such a system cannot-or at any rate does not-handle both multiplica- tion and' addition, so that one axiom at least must be sacrificed; the addition rule seems less useful than the multiplication one so we might see how far we can go with- out it. For, say, the experiment with two urns we can suppose that the subject has an array of hypotheses H*, where i and j relate to the states on the two sides, with prior probabilities rir. After a success on one side these would be proportional to Ti2.pi; alternatively, if the success were on the other side they would be proportional to 'irp1. The factor of proportionality could be disregarded if we supposed that 14</page><page sequence="14">196 CANE - Learning and Inference [Part 2, he acted in accordance with the maximum posterior probability, that is, he would select the Hq1 for which this had the greatest value and make a decision depending on the values of i and j. Because Weber's law so often holds (that is, we can only apprehend differences which in the exact measures we choose to adopt are expressed as ratios) it seems worth trying the assumption that his "sensations" are in terms of the logarithm of probability. After s successes and f failures. with the second urn, the hypothesis Hij would have attached to it a weight s logpj +flog qj + log IrO. In writing qj for 1-pj I have of course assumed the addition law of probabilities and also that probabilities must sum to one. However there seems no reason why we should not just give arbitrary weights to the numbers of successes and failures, and so attach to Hij the weight sw1 +fwj + ci, where cj is a prior weight; the size of wj and Wj must reflect the likelihood-in an everyday sense-of a success or failure on that hypothesis. We could thus think of each outcome as adding to or subtracting from the weight attached to a given hypothesis, and of comparisons being made between these weights; a mechanism of this sort, for a finite number of hypotheses, seems quite conceivable and it would produce decisions similar to, though less efficient than, ones determined by probabilities in the usual ways. As a very simple example of this approach, suppose that a rat tested in a T-maze once a day considers only two rates of recurrence of food-slow and fast-and consequently works with a set of four hypotheses, Hij, i,j = 1, 2, where i and j refer to the left and right arms of the maze and 1 and 2 indicate the slow and fast rates. Suppose that the prior weight attached to Hij is ci + c1, where C1&gt; C2; and that, if food is found on the left side, weights w1, w2 are added to H7, H2j respectively, whereas, if food is not found, weights w', w' are added (wl &lt; w2, wj&gt; wD); under the same conditions, weights wI, w2 or w', w' are added to H1i, H42 if the right side is visited. If a zero threshold is assumed it is not necessary to allow for changes in the -probability that the maze is the same. In order to avoid complications with the first few trials, I shall also assume that the first visit to each side is treated as if it were a visit after an interval of one day. For a 1: 0 reinforcement schedule, after 1 turns to the left and r turns to the right, the weight attached to Hij is (ci+cj+lwi +rw1); thus H12 will always have a greater weight than H21 or H22 and will have a weight less than or greater than that of H,, according as r 5 (c1 - c2)f(w2 - w,). If Hl, has maximum weight we may say that the most likely hypothesis is that replenishment is slow on both sides and so, since there is a long interval between trials, choice will be made at random and p(R) = . Correspondingly, if H12 is maximum, p(R) = 1. (If it should happen that (cl - c2)/(w2 - w) were an integer I should assume that, for this value of r, the rat had a chance of w of acting on either hypothesis; but, for simplicity, I shall suppose that this is not the case and put rO = (cl - c2)/(w2 - w1) + 8, 0 &lt; a &lt; 1.) Then P,(R) = a if r&lt;ro after (i- 1) trials; = 1 &gt; rO; thus the rat will invariably give the correct response after n = 1+rO trials. It will be seen that n is a random' variable, having a negative binomial distribution and that the rat might appear to have learnt by some trial earlier than n if the last few random choices were to the right. For a group of rats operating with the same system of</page><page sequence="15">1962] CANE - Learning and Inference 197 hypotheses and weights PLi=i for i=1,2,...,ro = &gt; ( ro)/2i i&gt;rO (for example, if rO = 2, PLi = i/2i for all i) and there would be no learning for the first ro trials, but after that a learning curve of much the usual shape. This would certainly account for the initial slowness of acquisition. A similar method could be used with more categories for the rate of replenishment and more than one trial a day; there must then be different weights for different time- intervals between visits to an arm and also an order of preference between states; for example, if the hypothesis of greatest weight corresponded to slow replenishment on the left and a medium rate on the right, the rat might have to choose between the cases of slow replenishment over a long interval and a medium rate of replenishment over a short one. He would presumably decide in terms of the weights w, w' since these represent the likelihood of food being, or not being, found in these circumstances; this requires an obvious sort of consistency, that if wi &gt; wj then wi &lt; wj. Other kinds of limitations on the weights (for instance, if we require consistency in the statistical sense) are considered in the Appendix. From this very limited enquiry into some learning experiments I would conclude that learning from experience is a much more complex matter than linear mathe- matical models imply; that, although complex, the behaviour of a subject in a learning situation can reasonably be regarded as consistent and determinate, if we allow for such inexactness as discrimination thresholds and errors in recording; and that it is, in fact, similar to statistical inference, at least when such inference takes account of a range of alternative hypotheses and the prior probabilities attached to them. REFERENCES Many of these are chapters in: BUSH, R. R. and ESTES, W. K. (1959), Studies in Mathematical Learning Theory. Stanford, University Press. ANSCOMBE, F. J. (1948), "The validity of comparative experiments", J. R. statist. Soc. A, 111, 181-211. , GODWIN, H. J., and PLACKETT, R. L. (1947), "Methods of deferred sentencing in testing the fraction defective of a continuous output", J. R. statist. Soc. B, 9, 198-217. AUDLEY, R. J. (1960), "A stochastic model for individual choice behaviour", Psychol. Rev., 67, 1-15. BAKAN, D. (1953), "Learning and the principle of inverse probability", Psychol. Rev., 60, 360-370. BOWER, G. H. (1959), chapter 6 in Bush and Estes (1959). BUSH, R. R. and MOSTELLER, F. (1955), Stochastic Models for Learning. New York, Wiley. DE FINETTI, B. (1955), "Les probl6mes psychologiques sur les probabilites subjectives", J. de Psychol. Norm. et Path., 253-259. DE VALOIS, R. C. (1954), "The relation of different levels and kinds of motivation to variability of behaviour", J. exp. Psychol., 47, 392-398. DEMBER, W. N. and FOWLER, H. (1958), "Spontaneous alternation behaviour", Psychol. Bull., 55, 413-427. EDWARDS, W. (1961), "Costs and pay-offs are instructions", Psychol. Rev., 68, 275-284. ESTES, W. K. and SUPPES, P. (1959), chapter 8 in Bush and Estes (1959). GALANTER, E. and BUSH, R. R. (1959), chapter 14 in Bush and Estes (1959). LA BERGE, D. L. (1959a), chapter 2 in Bush and Estes (1959). (1959b), "The effect of preliminary trials on rate of conditioning in a simple prediction situation", J. exp. Psychol., 57, 20-24.</page><page sequence="16">198 CANE - Learning and Inference [Part 2, NEIMARK, E. D. and SHUFORD, E. H. (1959), "Comparison of predictions and estimates in a probability learning situation", J. exp. Psychol., 57, 294-298. NICKS, D. C. (1959), "Prediction of sequential two-choice decisions from event runs", J. exp. Psychol., 57, 105-114. REsTLE, F. (1959), chapter 20 in Bush and Estes (1959). STERNBERG, S. H. (1959), chapters 16 and 17 in Bush and Estes (1959). VINCE, M. A. (1960), "Developmental changes in the responsiveness of the Great Tit (Parus Major)", Behaviour, 15, 219-243. VOGEL, W. (1960), "A sequential design for the two-armed bandit", Ann. math. Statist., 31, 430-443. APPENDIX 1. THE Two-URN PROBLEM The subject is required at each trial to choose from which of two urns, U1 and U2, a ball is to be drawn (and replaced) and he scores a point if the ball is red. He knows that there are red and white balls in the urns but not the total number or the proportions of each colour. Suppose that at some stage r* red balls and wi white balls have been drawn from U* and that there are to be N further trials. Let f(r*, w*, N) be the expected addition to the score if the subject goes on choosing U* until either a white is drawn from it or all N trials have occurred. Then, if, for each urn, the subject assigns a uniform prior distribution on [0, 1] to p, the proportion of red balls, and if he adopts the procedure of choosing the same urn again, if a red ball is drawn from it, and of choosing U1 or U2 according as f(rl, wl, N) f&gt; f(r2, W2, N) (1) if a white ball has been drawn, then this procedure is consistent in the sense that consideration of (1) after a red ball would lead him to repeat his choice. (If the two terms in (1) are equal, either urn may be chosen.) f(r,w,N)- prqw Y ps r+ w !dp S r! w! since, for a given value of p, the probability of an additional score of s or more is ps. The following results can be deduced immediately or after a little algebra: (i) for fixed r and w, f(r, w, N) increases as N increases and tends to r+ 1/w or infinity as N-? co, for w * 0 and w = 0 respectively; (ii) Af(r, w, N) = f(r, w, N+ 1) -f(r, w, N) = E(pN+1) is positive and decreases as N increases; (iii) f(r+ 1, w, 1) &gt;f(r, w, 1) and Af(r+ 1, w, N)&gt; Af(r, w,N); (iv) f(r, w, N) =f(r, w, 1) [1 +f(r+ 1, w, N- 1)]. From (i), (ii), (iii), if f(r, w, N) is plotted against N, the curve formed by joining successive points by straight lines is concave to the axis of N and the curve for f(r+ 1, w, N) lies wholly above that for f(r, w, N). In comparing two curves f(rl, wl, N) and f(r2,.w2, N) suppose without loss of generality that w &gt; w2. Iff(r, WI, 1) 0f(r2, w2, 1), i.e. rl+l r2+1 r1+w1+2 r2+W2+2' then +r1++N+ 1 &lt; r2+N+ I then ~~r1+w,+N+2 r2+W2+N-I2</page><page sequence="17">1962] CANE - Learning and Inference 199 for all N; therefore Af(rl, wl, N) &lt;Af(r2, w2, N) and the first curve lies completely below the second, except perhaps at the first point. If r+l r2+1 rl+wl+2 r2+W2+2' then r1 + N+ 1 r2+N+ l r1+w1+N+2 -r2+w2+N+2 for sufficiently large N; thus we may have Xf(rl, wl, N)&gt; Af(r2, w2, N) for small N and Af(r1, wl, N) &lt;Af(r2, w2, N) for large N and the curves may cross; they will cross once at most, and whether or not they do so can be decided by whether or not r1+l r2+l Wi W2 Consistency requires that if (for n &gt; 2) f (ri, w,, n) &gt;f (rj, wi, n) then f(ri + 1, wi, n-1) &gt;f(rj, w, n-). This is obviously true if wi = wj, for then ri) rj and so ri+ I &gt; r1. If wi1 w1 and the curves for f(ri, wi, N), f(rj, wj, N) do not cross, then f(ri + 1, wi, n-1) &gt;f(ri, wi, n-1) &gt;f(r1, w1, n-1). (2) If the curves cross between No and No+ 1 then either (i) wi&gt;wj and n No or (ii) wi &lt; w1 and n &gt; No + 1. If the curves cross at No + I we may have (iii) n=No + I and a random choice between the urns. In case (i) argument (ii) applies; similarly in case (iii) if wi &gt; w1. In case (ii) and case (iii) with wi &lt; Wj we must have f (ri, wi, 1) &gt;f (ri, wi, 1), since the curves have crossed; if also f(rj+1, wj, n- 1).&gt;f(ri +1, wi, n-1) then by (iv) above f(r1, w1, n) &gt;f(ri, wi, n) which is a contradiction. Therefore f(rj, wj, n -1)&lt;f(rj +1, wj, n -1)&lt;f(ri +1, wi, n -1). Since f(O, 0, N)-?oo as N-&gt;-oo, f(r, 1, N) &lt;f(O, 0, N) for sufficiently large N, whatever r. Therefore if the number of trials ahead is great enough, the subject should certainly try both urns. Clearly a similar procedure may be used if the prior distribution is proportional to prqw, for some integral values of r and w. Also, the same procedure may be applied to any number of urns. 2. THE WEIGHTING OF HYPOTHESES Suppose that HZ stands for the hypothesis "the proportion of red balls is x"; assume that x can be any real number in [0, 1] and that weights u(x), v(x) are attached to H, if a red or a white ball, respectively, is drawn.</page><page sequence="18">200 Discussion on Miss Cane's Paper [Part 2, If the subject acts on the hypothesis with greatest weight, after r red and w white balls he will choose the H for which ru(x) + wv(x) is maximum. If, in the long run, he is to choose the right hypothesis, then this weight must be a maximum for r r x = ~~= _ r+w n say. Using a continuous approximation, this implies xu'(x) + (-x) v'(x) = 0 and xu"(x) + (1- x) v (x) &lt; 0 and a solution to this is u(x) (1 - 6) g(6) dO, v(x) | Og(6)dOg where g(x) is positive and continuous in [0, 1] and u(2), v(i) are arbitrarily taken to be zero. Suppose that the subject finds the hypothesis with maximum weight by a scanning process, and that there is a threshold for discrimination between weights. If the maximum weight is in fact at x = rln, then the weight at x + E is approximately ru(x) + wv(x) + 1 fE2 [rut(x) + wv"(x)] = ru(x) + wv(x) - nE 2g(x), so that if the threshold constant is c, H,+, will not be distinguished from H, if E2 &lt; 2c/(ng(x)). Thus g(x) serves to determine a sort of confidence interval. If g(x) = l/x(l -x), u(x) = log 2x and v(x) = log 2(1 -x) and the "confidence interval" is given by E2 &lt;2cx(l - x)/n. This is the simplest form for g(x) if logical necessity is to be satisfied, i.e. H,&lt; H for all n if one white ball has been drawn, Ho &lt; HZ for all n if one red ball has been drawn. DIsCUSSION ON MISS CANE'S PAPER Dr MERVYN STONE (moving a vote of thanks): Miss Cane has given us a character- istically pleasant mixture of mathematics and life. However, the undertones of the life she describes-people pressing buttons and rats running mazes-are not all pleasant. As the theory becomes more sophisticated, it is not certain that all its applications will be beneficial. In a sense, it may be fortunate that, as Miss Cane lucidly shows, mathematical learning theory is still in its infancy. In her discussion of La Berge's experiments, Miss Cane seems to rule out subject variation of the parameters 6 and Pi. I do not understand her grounds for doing this. If such variations were allowed, the theory would still have predictive power for an experiment of reasonable length like La Berge's. Bush and Mosteller (loc. cit., p. 202) have emphasized the difficulties of estimating the parameters for each subject but, as they point out, maximum likelihood estimation of the parameters in a complicated likelihood function is well within the powers of an electronic computer. For La Berge's data, (0, Pi) could be estimated for each subject in groups B, C and D, using some or all of the results in the 0 5 :0 5 reinforcement schedule. (If all n trials were used, an incidental test of the linear model would be possible, since the empirical distributions of (0, AL) in the three groups should agree statistically.) The estimates would predict the results obtained under the changed reinforcement schedule. Miss Cane remarks that p1(R) was roughly I for each of the three groups, so it is likely that the analysis I have proposed would still produce evidence against the linear theory. However, if we are to weigh the linear theory against</page><page sequence="19">1962] Discussion on Miss Cane's Paper 201 some statistical decision theory, since the latter will generally allow subject variations (for example in the subjective probability distributions), it seems only fair to allow them in the linear theory too. Professor Cox (J. R. statist. Soc. B (1958), 20, 215-232) has argued that if the Bush and Mosteller models "aim at linking the observations to a neurophysiological mechanism" we should "wrestle as vigorously as possible with the resulting statistical complications". I think it would be ungenerous to deny the linear models a possible physiological basis; in fact, the assumption that the previous record is summarized in pl(R) has a physiological ring about it. Miss Cane has not drawn attention to the choice there is when the La Berge data and the Galanter and Bush data force the rejection of the simple linear model. Should we try to patch up the linear model or not? This must be largely a matter of taste. Stemnberg (loc. cit.) has kept the linearity but not the Markovian status of p(R) in order to explain alternation or persistence of response. Luce (ibid.) has introduced non-linearity with his Beta model and has had limited success with the overlearning phenomenon. I guess that Miss Cane's approach has been and will be more fruitful because of its greater flexibility. However, there is a distinct danger of anthropomorphism, that is, a little statistician or rat-stat inside every rat. We see that the rat-stat is an accomplished mathematician. He can calculate jPL(A) [1- exp (- 2At)] dA and must therefore be familiar with characteristic functions; he takes Bayes' Theorem in his stride. Another danger lies in the variety of statistical decision procedures to choose from. To reduce this variety, Miss Cane enjoins us to "consider the experiments from the point of view of the rat". Although a highly anthropomorphic recommendation, it is also a rewarding one since, as Miss Cane shows, it gives an ingenious and satisfying explanation of the alternation effect, based on the specific assumption that the rat-stat sees the experi- ment as two independent Poisson processes. However, I have the impression that Miss Cane is reluctant to be very specific about the mathematical structure of her models- at least in connection with actual data-and would prefer to say, "My model is of this general type and I can make the following qualitative predictions." But a case can be made for employing a precise mathematical model to examine fine-grain structure. The chances of hitting the jack-pot are small but the pay-off would be considerable. In addition, it will be essential to be specific if any physiological tie-up is envisaged. However, I think Miss Cane's attitude is almost justified by the complexities of any fine-grain analysis. For example, consider the data from the encounter of a human subject with a one- armed bandit. By one model, the subject has a prior distribution p(oa) where of is the probability that the right-hand light comes on. After observing a lights on the right and b on the left, he chooses according to the sign of A(a, b) - i where A(a, b) = fp(ax) o"+'(1 - c)b doe/ jp(a) aa(l - )b doe. Given an actual record of the rat's behaviour, R(f), R(f), L(s), L(f), ..., how may the model be tested? The model is possible if a p(o) can be found for which sign [A(a, b) -] agrees with the subject's choice for all the a, b pairs presented. If it happened that min (a - b) for the right-hand choices exceeded max (a - b) for the left-hand choices, there are Beta distributions giving a suitable p(oa). Also, for any p(oa), sign [A(a, b) - i] is increasing with a for fixed b and decreasing with b for fixed a, so that the model is invali- dated by any R(s) L's or L(s) R's in the record. In general, one could search for discrete distributions for ot (pi = P(ot = i/k), i = 0, ..., k) and agreement with the model would require EPi ci &gt; 0 where</page><page sequence="20">202 Discussion on Miss Cane's Paper [Part 2, according as the right-hand or left-hand choice is made. Linear programming techniques might be useful here. For the two-armed bandit, the prior distribution is p(o) p(p) and, at the stage at which the bandit's behaviour is given by r, w, r', w', one model might prescribe that the subject chooses according to sign [A(r, w) - B(r', w')], where p(p) defines B as p(o) defines A. An obvious inconsistency would be if the subject changed arms immediately after a reward but, if this is avoided, the test procedure is even less clear than for the one-armed case. In both cases, the situation is even more hopeless if estimates of the prior distributions are required, say, for prediction in other parts of the experiments. We cannot rely on the length of the data giving consistent estimates, as is the usual case in statistical problems, for the prior distributions effectively operate only for the early part of the data. No doubt some models could be easily tested. For instance, a model might say that a subject, facing a two-armed bandit, changes arms at the first failure. Robbins (reference in Vogel (loc. cit.)) has shown that, even asymptotically, this procedure is not outrageously bad. For uniform prior distributions for a and f, it is optimal for up to three choices but breaks down for the four-choice case after R(f), L(s), L(f). The best way of testing it might be to ask the subject whether he has adopted it. One can hardly ask such a question for more complicated models. Finally, I should like to make the cynical observation that even if it turns out that any mathematical superstructure based on Miss Cane's approach proved irrelevant in psychology there are good chances that it would be useful in statistics. This Society has learnt to expect rewarding thoughts from Miss Cane. I venture to suggest that it has not been disappointed at this trial. I have much pleasure in proposing a vote of thanks. Dr A. R. JONCKHEERE (seconding the vote of thanks): It gives me great pleasure to second the vote of thanks to Miss Cane for her stimulating paper, containing both a critique of currently employed linear statistical models for the explanation of simple learning, and some rather bold speculations concerning the possible use of subjective probabilities. I only want to make one or two points of a general nature. One can take two views concerning the parameters involved in these stochastic learning models. If they are considered as purely descriptive, merely summarizing in compact form some of the salient features of a given sequence of learning trials, it is not really relevant to object that in experiments such as those of La Berge, and Galanter and Bush, one finds that parameter values must be modified according to prior experience and the conditions in which learning takes place. Further, psychologists are by now well aware of the danger of making fallacious inferences concerning the learning process from a study of the characteristics of the "average learning curve". To avoid this, parameter values must be estimated for each learning seqquence obtained from each subject, and a group result represented by substituting the mean of these parameter values in the equation expressing the stochastic process employed; and if there are several different parameters involved, they must be shown to be independent. Only in this manner can one avoid Miss Cane's stricture that " . . . if the parameters change with the previous experience of the subject then in any learning experiment different subjects should be assigned different parameters and a linear model cannot represent the learning of a whole group". It is only if the parameters in these processes are given a rather deep interpretation in terms of the experimental conditions, and the past experience of a subject, that one is entitled to expect their values to remain constant or change in a predictable manner when the learning situation is altered. This approach has been adopted by Estes with his models developed in terms of "stimulus sampling". I should like here to take the opportunity of drawing the attention of statisticians to the problem of devising a satisfactory test of goodness-of-fit, applicable to these non- stationary stochastic processes which are now being developed by learning theorists. In general, given the unique series of choices, from two or more alternatives, made by a</page><page sequence="21">1962] Discussion on Miss Cane's Paper 203 particular individual, we require not only to fit a non-stationary process by estimating the parameters involved, but also to be able to assess the adequacy of this fit. Only if this problem is solved will the present-day proliferation of stochastic learning models be held in check. I come now to the speculation concerning the use of subjective probabilities which Miss Cane has used in developing her own learning models. As has been said, they seem to depend upon the assumption that an individual will act rationally in accordance with certain elementary statistical principles. There are, however, several phenomena which psychologists have observed in the type of situation described by Miss Cane which ought perhaps to be taken into account. When, for example, an experiment is so arranged that at any trial one of two alternative responses is rewarded with probability p, and the other with probability l-p, it is usually found that subjects distribute their successive choices so that the probabilities of their choosing each of the two alternatives match the probabilities of their reinforcement. In this situation, using the notation given in the paper, the limit of pi as i increases is not 1 but p. There seems here to be evidence that subjects are not acting in accordance with ordinary statistical practice, since in order to maximize one's gain, one should of course always choose the side where the reward occurs with greatest probability. This phenomenon of response probability matching has proved' difficult to explain, though the stochastic models developed by Estes and others predict its occurrence. I should like again to thank Miss Cane for her paper, and hope that she will develop further her own type of explanation to the point where it may be tested in the laboratory. The vote of thanks was carried unanimously. Dr R. J. AUDLEY: Miss Cane's paper combines a number of interesting speculations with a considerable body of controversial material. It is difficult in five minutes to tease out those statements which especially demand a critical evaluation, so I have selected two points which have aroused the strongest emotional response in me and I then turn in an uncritical way to another matter that is raised in the paper. First, the preference for subjective probabilities and hypotheses. I do not think learning theories tend to be formulated in terms of rules linking a stimulus to a response because of an application of Lloyd Morgan's Canon, which is after all only the Occam's razor of a particular scientific discipline. The reason for this kind of stimulus-response formulation is to ensure that one's theory can be related to observable events. In cases where the hypotheses that Miss Cane advances can be put in a testable form I do not consider that her approach differs in principle from that of other learning theorists. Whether or not one calls the constructs of a particular theory "subjective probabilities" seems to me to be quite irrelevant, although I do feel that in this paper there is dangerous ambiguity in the way in which the term "subjective probability" is used. What Miss Cane would really seem to be arguing against is the simplicity of the decision processes which the linear models assume. This is to attack a straw man. The so-called mathematical learning theories are a recent development in psychology and must be fairly regarded as preliminary attempts to derive rigorously the properties of a system satisfying certain assumptions. They are as yet largely essays in methodology, Estes' work excepted. They represent only a small fraction of psychological speculation, and rarely do they aspire to the state of a general theory of learning. Thus it seems to me that the comparison of the notions of this paper with the linear learning models is also irrelevant. The paper therefore demands appraisal as a particular psychological theory. This brings me to the next point concerning the application of the theory to experimental material. It is here that Lloyd Morgan would begin to spin in his grave. For example, the account of alternation on p. 191 is fantastic speculation. The hypothesis, although couched in dangerously subjective terms, might in principle be reasonable. That is, if it were not for the body of experimental literature on alternation, which is very improperly dismissed</page><page sequence="22">204 Discussion on Miss Cane's Paper [Part 2, in this paper as leading only to the conclusion that there is something about rats that makes them alternate. All the evidence points to novelty as being the relevant variable. Furthermore there are motivational factors which affect the phenomena. Hungry rats alternate more than thirsty rats, or if one controls for the various factors which are also changed by food and water deprivation, this turns out to mean that rats losing weight alternate more than rats gaining weight. Are the rats supposed to be using different principles of inference in the two cases? By analogy perhaps, yes, but not in the way in which the paper uses the term inference. The third point I want to consider concerns the discussion of the use of probability statements in the description of learning. I accept with some reservations the views on this problem which are expressed in the paper and I am very pleased that the matter was raised. The problem also seems to have important bearing on what kind of data one should employ when testing certain kinds of hypotheses, and what kind of inferences one can draw from data. The problems appear in a wide range of phenomena outside learning, and I should like to exemplify it in the context of choice behaviour. Several theories have been concerned with the transitivity of preferences. For example, with 3 alternatives A, B, and C, rules have been given for deriving the probability of A being preferred to C, given the preference for A over B and B over C. Stated as a psychological theory these rules apply to the individual subject. In practice, once a preference has been expressed for discernibly different objects, the subject is likely to repeat this in future so that no individual probabilities can be observed. If we use the proportion of people possessing a given preference for the purposes of testing the theory, what relevance does this have to the initial hypothesis? The data are statements about the group as a whole and cannot therefore bear directly upon the hypothesis which is supposed, as a psychological hypothesis, to be true for all members of the group. I feel there is a great need for a critical discussion of the kind of legitimate inference which can be made in this kind of situation.t In concluding I should like to say that I have some sympathy for the kind of approach that Miss Cane advocates, especially since I infer that this is in part a demand for a more realistic approach to decision processes, but in this short note I can only indicate an extremely critical view of the way in which the hypotheses have been expressed, and the manner in which certain psychological experiments have been interpreted. Dr A. E. MAXWELL: Psychologists, and others interested in learning processes, are in great need of two lucid papers. One of these would tell them what really happens when a rat "runs" a maze (for I understand that the word runs is much too graceful for describing the antics which take place), and the other would tell them what mathematical models of learning aim at. Miss Cane has made a number of attempts to supply us with the latter and we are indebted to her, but she tends to assume that the reader is already immersed in the subject, with the result that her jewels are sometimes hard to digest. The end of the first stage in the development of mathematical models of learning seems to have been reached. Until now we have all been rather toleranf of the pioneers, but it now appears that, as Horace so aptly put it a long time ago, "the earth was in travail and a tiny mouse was born". The trouble, as Miss Cane has pointed out, is that the linear models-until now so popular with learning theorists-cannot deal with many of the known facts. She mentions the effect of over-learning on extinction, and the fact that a partially reinforced response extinguishes more slowly than one invariably reinforced. To these might be added several problems which arise when experimental subjects perform t During the discussion it was suggested that if one knew what assumptions one was making, no mistakes in inference would occur. This is obviously true, but if one has to make the assump- tion that all individuals are alike in certain respects, when this is known to be untrue, one is again in a quandary. From a statistical point of view it may be better to abandon a problem which involves these difficulties, but I still think it would be worth while to consider what would be the best strategy to employ in approaching this kind of situation.</page><page sequence="23">1962] Discussion on Miss Cane's Paper 205 under different degrees of motivation and linear models again are inadequate for dealing with the observed behaviour. But even when we admit that linear models are inadequate and that our models must be made more elaborate we are not out of the wood. The main trouble as I see it lies in the first of the assumptions which Miss Cane quotes in the section of her paper headed "Linear Models". I refer in particular to the sentence, "the change in behaviour observed on successive trials must be the result of the responses and reinforcements that occur". If we assume that the responses referred to here are entirely overt, and thus measurable, we are greatly over-simplifying the facts and it would be easy to present experimental evidence to support this statement. Miss Cane appears to be very much aware of this when she appeals, in the latter part of her paper, to the concepts of decision theorists with their prior probabilities and latent hypotheses weighted this way or that. This section of her paper seems to be an excellent bit of escapism. Nevertheless her treatment of learning problems in decision theory terms is ingenious and makes very pleasant reading. It is, as she admits, purely speculative but the deceptive attraction of decision theory is that it invariably supplies the best strategy for indecision, for the number of unknowns which have to be introduced makes further action virtually impossible. In her "Discussion", however, Miss Cane is unnecessarily worried about her choice between the "addition" and the "multiplication" axioms of probability theory. As Schrddinger (1947) has shown, and perhaps others have, once we adopt the conventions that our ineasure of probability, p, must lie between 0 and 1 and that the sum of the probabilities of an event and its complement is unity, the addition rule follows from the multiplication rule. Schrodinger further points out that the habit of introducing the multiplication rule as an axiom into probability theory is quite unsatisfactory. It is anything but self-evident and it is his contention that it could not be so. He goes on to show that by stating a further convention, the axiomatic basis of the rule can be reduced to next to nothing. In view of this it seems doubtful whether de Finetti's challenge to psychologists, which Miss Cane quotes, would be a valuable one to pursue. Dr I. J. GOOD: It occurs to me that the tendency of rats to alternate their behaviour during early stages of an experiment might be attributed to two causes not mentioned by Miss Cane. One would be the exploratory instincts of the rat. The other depends on the fact that the amount of food given on any one trial was small, so that the rat might try the other arm of the maze on the next trial in the hope of finding more food on that side. The rat would not know at first that the amount of food to be found would be either nothing or the same small amount as before. On another point, G. Russell and A. M. Uttley (N.P.L. Symposium, 1959, p. 144) have conjectured that the logarithms of probabilities might be represented in the nervous system by means of delays, one idea being that the logarithms of conditional probabilities could then be obtained by subtraction and so could be represented by simple neural circuits. I have myself extended the conjecture, very speculatively, to "weights of evidence", log-odds, amounts of information, and "tendencies to cause" (Cherry, 1961, p. 128). Mr N. L. WEBB: It occurs to me that one could arrange to be presented with rather more information than is given by a series of l's and 0's. It is sometimes possible to isolate "decision times" in psychological experiments, and it may be possible to do so here. If so, would it not then be possible to arrange a trial to associate length of decision time with the complexity of integration sum or whatever it is which is postulated that the rat has to do? At the beginning of the experiment there would be very little information for the rat to go on, but there would be some point in the experiment when whatever one postulated was a more difficult decision to arrive at could be observed to be made within a given time, so that during the experiment variations of difficulty could be associated with variations in decision time. I am not saying that it would happen with rats, because during</page><page sequence="24">206 Discussion on Miss Cane's Paper [Part 2, the intervals between trials they would have time to chew over their food and speculate about the information available but it might be done with human subjects where the trials immediately followed one another. This approach also holds out the possibility of eliminating "between subject" variation. Dr AUDLEY: Observations of decision time provide useful information about the state of an organism on any individual trial, and experiments have demonstrated a relationship between decision time and the probabilities of selecting the various alternatives. Also, most organisms display vacillatory behaviour in any choice situation and this too may be used to augment the rather meagre summary of behaviour given by the sequence of successes and failures. I should like to describe briefly an experiment which I carried out to test an hypothesis about alternation behaviour which was rather like that advanced by Miss Cane. There were two groups of rats run in a T-maze. For one group, there was a single pellet in each arm of the maze; for the other group, a whole heap of pellets on either side. After choosing, the rat was to be allowed to eat a pellet, and was then to be replaced at the beginning of the maze. Would the rats in the second group tend to repeat their first chance, whilst those in the other group alternate theirs? Broadly, the answer was yes. But, to indicate the difficulties of this kind of experiment, no rat ever ate a pellet. Blocks of wood might just as well be used as pellets and do in fact yield the same results. It is surely difficult to introduce "subjective probabilities" in any guise to account for this kind of behaviour. Professor G. A. BARNARD: I am not sure whether Buridan's ass was a figment of scholastic imagination or whether Buridan was one of the pioneers in experiments of the type Miss Cane is discussing. But in any case I think the arguments centring around that animal are relevant to the present discussion. You will remember that the ass was supposed rational and actuated by the principle of insufficient reason, nowadays called the principle of invariance. Confronted with a problem invariant under reflections in its ventro-dorsal plane, the ass insisted on a similarly invariant solution and so went hungry. In so doing he made no choice and I think this possibility of making no choice is one which Bayesians tend to overlook. One would have liked to know how many of the rats displayed an intelligent indecision. I should like to voice a protest against Miss Cane's statement that "inference is not an intellectual process". I do not grasp Miss Cane's distinction between intellectual processes and physiological processes. I should have thought that any intellectual process had a physiological aspect. I am very much with her, however, in thinking that rats are entitled to intellectual respect as are human beings. Professor BARTLETT: I should like to raise one question connected with alternation. It is to what extent animals-certainly human beings tend to exhibit it and there is evidence that animals do, too-have a predetermined pattern of behaviour, which, presumably, would tend to be eradicated in time. It would be nice if we all had open minds and it would be nice if rats had; but perhaps they have preconceived ideas or patterns of behaviour. That is not nonsensical from the biological point of view because primitive creatures tend to work entirely on instinctive methods, which can be changed only by rather severe conditions. I feel that this is rather important. One other point concerns the problems of statistical inference in connection with data of this kind. You must be rather careful about the sort of assumptions you are prepared to make from a statistical point of view. If you are not prepared to make statistical assumptions, you are not prepared to make statistical deductions. If you have sequences different from one rat to another, you may get a limited amount of information from the sequences, as such, because there is certainly an amount of repetition, but in each case there is a limit and you will not get very much unless you are prepared to assume that a group of rats are tending to behave somewhat similarly in a statistical sense. The variations</page><page sequence="25">1962] Discussion on Miss Cane's Paper 207 as well as the similarities can be studied, unless it is assumed that a rat is completely unique and cannot be studied in relation to another rat. The problems are very difficult in that sort of situation, but if clarified in that way, they should not be insuperable. Mr M. BUD: Professor Bartlett's remarks are borne out by observing players at the Monte Carlo Casino. People start with a predetermined faith that something will follow. Unless there is a slight modification which brings success, a realization that there may be a maze-running process involved results in completely erratic behaviour from then onwards and the risk of their losing faith in rational choice. In other words, they behave randomly without gaining faith in any better hypothesis. In The Mint T. E. Lawrence relates how after World War I the R.A.F. endeavoured to make useful soldiers by first demolishing the personalities of recruits in order to substitute new patterns of adaptive behaviour. Mr A. BATTERSBY: I want to ask a question about alleged optimum behaviour. Miss Cane and Dr Jonckheere both mentioned the fact that if food is put very often on one side, the optimum behaviour is always to go to that side. But is that correct? For example, it was suggested that if the food were on one side for 70 per cent. of the time and on the other for 30 per cent., the optimum behaviour for the rat would be to go always to the side where the food occurred 70 per cent. of the time. However (excluding the case where it was 100 per cent. available on one side), is it not possible that the rat is checking that the experimenter has not changed the conditions? Suppose, for example, that the frequencies were changed from 70/30 to 70/100, the rat would be pursuing a better course if it occasionally explored the 30 per cent. side to see what was going on. That is optimal behaviour in a situation which is likely to change rather than remain static. May not the rat's apparently sub-optimal behaviour in fact be "super-optimal", so that it is learning on a second plane about how the rules change rather than what the rules are? Dr GOOD: Even that would not justify the rat's alleged tendency to visit the two sides with relative frequencies equal to those of food placement. ADDITIONAL REFERENCES CHERRY, C. (ed.) (1961), Information Theory. London: Butterworths. Cox, D. R. (1958), "The regression analysis of binary sequences", J. R. statist. Soc. B, 20, 215-242. NATIONAL PHYSICAL LABORATORY SYMPOSIUM (1959), Mechanization of Thought Processes. London: H.M.S.O. SCHR6DINGER, E. (1947), "The foundation of the theory of Probability, I", Proc. Roy. Irish Acad. 51 A, 51-66; 141-150. MiSS CANE, in reply: I admit that Dr Audley's criticism seems fairly overwhelming, although I am not clear that novelty means any more than "exploratory behaviour". Dr Stone thought that I was being rather anthropomorphic and thinking of the statistician inside every rat, but I am, in fact, thinking of the rat inside every statistician. One objection to linear models, even when you regard them as devices for fitting curves, as Dr Jonckheere prefers, is that they do not seem very good at dealing with initial acquisition. If one looks at learning data, one finds a fairly random response, at least near the beginning of the trial sequence. As far as probability matching is concerned, I have looked at a large number of experiments on this and I am convinced that this effect is not found if the experiment goes on long enough. That was certainly true in the experiment I did. With a 70:30 reward schedule I obtained considerably more than 70 per cent. correct responses after a time. I was interested in Dr Audley's point about choice behaviour, but I am not convinced that individuals would make the same decision if they were given the same choice of alternatives on different occasions. Anyone presented with a really complicated choice problem such as that of deciding between three jobs, one of which allows more leisure</page><page sequence="26">208 Discussion on Miss Cane's Paper [Part 2, time, another provides more money and a third is in a pleasant place, surely finds that he veers towards one or the other as his frame of mind, or circumstances, vary. I agree with Professor Barnard that I was wrong to say that inference is not an intellectual process. I do not know what the right word is; I was thinking of something like ability to manipulate symbols which human beings have and which animals probably do not. Predetermined patterns of behaviour may, as Professor Bartlett suggests, very well be important, but the work of the animal behaviourists suggests that patterns which were once thought to be instinctive are learned at a very early age, in the case of birds, even in the egg. It is not altogether clear how one draws a line between instinctive and learnt behaviour. I am very much in sympathy with Mr Battersby about optimal behaviour. The behaviour I have described is optimal only if the subject knows that reinforcement is random and that the rate of reinforcement will not change. This is one of the reasons why I proposed to use urns in experiments, because subjects could then see that the experimenter was not up to any "monkey business". In experiments with a T-maze or "bandit", the subject cannot know that the situation is stable. Miss CANE subsequently replied in writing as follows: I feel that the main problem in regard to the development of learning models is to assess what a model-maker is trying to do, and this requires some specification of what he might do ideally. There seem to be two possible aims: the fitting of curves which may suitably summarize the data, so that comparisons between different conditions may be made in terms of changes in a few parameters; or a description in terms of parameters that may ultimately be related to some neuro-physiological mechanism. Dr Jonckheere seems to prefer the first; but in this case it would surely be simpler to fit the proportion of correct responses to some function of the number of trials, say, to a sigmoid curve or a suitable polynomial. A specific model would be preferable only if, with-the same number of parameters, it fitted the data more closely. Moreover, if a model such as the linear model is to be fitted to group data, it would be preferable to allow for variation within the population by making some assumption about the distribution of the parameters. (For the simplest linear model, which involves C and Pi only, one might reasonably suppose O to lie in a Beta distribution, independently of Pl.) Dr Stone prefers, as I do, the second aim, though, as he says, it presents great difficulties. He has not mentioned another advantage of an exact model-that one may be able to reject it. It seems to me that the whole class of linear models fail in that they predict much faster initial learning than actually occurs, and probably should be rejected for that reason. To Dr Stone's pertinent question as to what should be done next I agree that it is difficult to give an answer; only exploratory behaviour is possible. The particular path I am trying to explore is that leading to models that are crude versions of Bayes' decisions, an example of which was given in the final paragraph. I do not, of course, suppose that rats are familiar with characteristic functions and Bayes' Theorem, but I feel that there should be some sort of Correspondence Principle which would relate decisions made in exact mathematical terms to ones made intuitively, whether by human beings or by animals. In looking for a model of the same type as a Bayes' decision I have not assumed a measure of probability lying between 0 and 1, so I think that Dr Maxwell will find that his remark is not relevant. I agree with Dr Audley that of course all models must be formulated in terms of stimuli and responses and I am afraid that what I said in the paper was not very clear. The difficulty with learning processes is that one cannot assume an invariant, or statistically invariant, relation between stimulus and response and so some sort of theory based on intervening variables must be used. Such a theory can be tested quantitatively and this is obviously necessary at some stage; it can also be checked qualitatively-this is surely valuable if it helps one to reject impossible theories. I am not sure of the relevance of</page><page sequence="27">1962] Discussion on Miss Cane's Paper 209 some of Dr Audley's "qualitative" criticisms. Thirsty rats would, I suppose, be less likely to alternate than hungry ones if they relied on their previous experience, since water is generally found in the same place; but this could easily be checked experimentally by varying the position of their usual water supply. As to loss or gain of weight-perhaps statisticians gaining weight more often use minimax decisions. I am grateful to Dr Good for pointing out that the logarithm of probability might be represented by a delay. I myself thought of the "weight of evidence" as being represented by a change in molecular structure, in a way recently suggested by Gaito (Psychological Review, 68 (1961), 288-292). Finally, I should like to return to the question of what probability of response means in relation to a single individual. Dr Audley suggests that mathematical learning theories should be regarded as attempts to derive rigorously the properties of a system satisfying certain assumptions. I must protest that, no matter how rigorous the derivation, the results are useless if the meaning of the assumptions is not clear. As a result of the ballot taken during the meeting, the candidates named below were elected Fellows of the Society: BEDFORD, John Rodney Charles, B.Sc. HOBSON, Terence Francis Joseph, B.Sc. BRACKEN, Charles Edward, B.Sc., M.Sc. IYER, Jayashree, M.A. BRAITHWAITE, George Roger, B.Sc., Low, Charles Frederick James M.Sc. MCCUNE, Duncan Chalmers, A.B., M.S. BRAUNSBERG, Hannelore, B.Sc., Ph.D. MARKS, Brian Lawton, B.Sc. BRENNAN, Keiran, B.Sc., M.Sc., M.B., MILES, Roger Edmund, B.A. B.Ch., B.A.O., D.P.H. NARAPALASINGAM, Suppiramaniam, B.Sc. CARRUTHERS, Peter McCormick, B.A. O'HERLIHY, Callaghan St. John, B.A. CHAKRABARTI, Saurindrakumar, B.Sc., PAGE, William Frank M.Sc. POPE, Robert CHERNOFF, Herman, B.S., Sc.M., Ph.D. PRINS, Hendrik Johan DOWNES, Michael Barrie, B.A. QUAYLE, Donald Victor, B.Sc. GRESLEY-GREY, Harold Gilman RAO, C. R., M.A., Ph.D. HARBORNE, Edgar Sherriff, M.A. WALFORD, Joan HARDING, Vernon WEGNER, Peter, B.Sc., M.A. HoBBs, Clement Francis, B.Sc. Corporate Representatives HALLIER, Elizabeth, B.Comm., representing the Ministry of Economic Development, Statistics Branch, Entebbe, Uganda. WEBB, Terry Peter, representing Burroughs Machines Ltd.</page></plain_text>
<plain_text><page sequence="1">Toward a Conception of Causality Applicable to Experimentation and Causal Modeling Stanley A. Mulaik Georgia Institute of Technology MULAIK, STANLEY A. Toward a Conception of Causality Applicable to Experimentation and Causal Modeling. CHILD DEVELOPMENT, 1987, 58, 18-32. Misuses, as well as undeserved criticism, of causal modeling have resulted from inappropriate conceptions of the assumptions about causality that underlie the causal modeling methods. In an attempt to bring more clarity to the issue, I examine and reject common criticisms of the causality concept and focus on showing how causality is a relation implied in the grammar of a language about objects. This relation concerns how, by means of functional relations, variable properties of objects determine the variable properties of other objects. Next I emphasize how conceptions of causal relations must be objective by uniting all our diverse observations of these relations according to rules. Then I show how the functional relation concept of causality may be modified to have causes determine not specific outcomes but the probabilities of outcomes, thereby synthesizing determinism with probabilism. This result unifies numerous probabilistic models in psychology as causal models. I then consider how these fundamental considerations about causality may be translated into a network of assumptions that must be explicitly considered in any attempt at causal modeling. This reveals how the same princi- ples underlying experimental efforts to establish causality also underlie causal modeling. I also consider the role of a priori assumptions in causal modeling. The growing interest in causal modeling in the behavioral and social sciences has at- tracted increasing numbers of researchers to the methodologies of path analysis and linear structural equations modeling. However, these methodologies have not always been correctly applied. As with the introduction of any new methodology, there have been appli- cations that were implemented without a clear understanding of the assumptions on which these methodologies are based. This has inspired well-deserved-as well as unde- served-criticism of the use of these methods (Cliff, 1983; de Leeuw, 1985; Guttman, 1977; James, 1980; Ling, 1982) and an effort by a few methodologists, for example, James, Mulaik, and Brett (1982) and Miller (1971), to make these assumptions more evident. In an attempt to bring more clarity to the issue, I will first discuss historical views that have been hostile to the concept of causality and relate them to common misconceptions of the problems inherent in causal modeling. Then, in a following section, I will consider a way of thinking about causality that avoids the usual metaphysical pitfalls associated with discussions of causality. These consider- ations will set the stage for developing a con- cept of probabilistic causality that unifies heretofore seemingly incompatible concep- tions of causality. The result will be a concept that allows us to regard numerous probabi- listic models used in the behavioral and social sciences as causal models, with linear struc- tural equations models a special case. In the last section, I translate these theoretical con- siderations into a faceted (or working) def- inition of causality that serves to highlight the network of assumptions that must be explic- itly considered in any attempt at causal mod- eling. Common Criticisms and Misunderstandings of the Concept of Causality and Causal Modeling Criticisms of Positivist and Instrumentalist Philosophers There is, I believe, a limited sophistica- tion among researchers in the behavioral and social sciences about the concept of causality. This limited sophistication engenders confu- sion regarding the implications of the causal- ity concept for the methodologies of causal modeling. The origin of this limited sophisti- cation is the neglect of the causality concept arising from the hostility toward it of certain empiricist and instrumentalist views of sci- ence that were prevalent between 1900 and Requests for reprints should be sent to the author at the School of Psychology, Georgia Institute of Technology, Athens, GA 30332. [Child Development, 1987, 58, 18-32. ? 1987 by the Society for Research in Child Development, Inc. All rights reserved. 0009-3920/87/5801-0003$01.00]</page><page sequence="2">Stanley A. Mulaik 19 1965 among research methodologists in the social sciences. One such view is embodied in the pos- itivistic claims that causality is a metaphysical concept that has been replaced in science by nonmetaphysical concepts such as functional interdependence (Mach, 1883/1960), associa- tion or correlation (Pearson, 1911), or func- tional relation (Schlick, 1932/1959). The aim of these positivists' efforts was to move sci- ence away from the ideas of necessary con- nection and determinism that they identified with their contemporaries' ideas of causality. Schlick (1932/1959), for example, redefined causality as merely the application of the mathematical idea of functional relation to the description of phenomena. Because of the de- terministic implications of this relation, how- ever, he allowed it was only useful in Newto- nian conceptions of the universe and not in the more modern quantum theoretical con- ceptions, which presume a probabilistic world. Pearson (1911) similarly stressed the probabilistic nature of experience and sought to reorient science around the concept of cor- relation as a measure of imperfect association. Pearson's legacy was a whole field of mul- tivariate statistics built around the correlation concept and its analogues', such as bivariate correlation and regression, multiple regres- sion, partial correlation, canonical correlation, factor analysis, and multidimensional scaling, to name the more important representatives of this field. The impact of the Pearsonian methodology on the behavioral and social sci- ences has been considerable. Those trained primarily in the use of Pearsonian associa- tionist statistics tend to regard the scientific enterprise as one in which the researcher uses statistical methods to discover associa- tions between phenomena. These associa- tions are then interpreted and the theoretical implications are extracted. However, little emphasis is placed on testing these interpre- tations. Associationist Misconceptions of Causal Modeling When introduced to methods that fre- quently are couched in correlational form, such as path analysis and linear structural equations modeling, associationist research- ers tend to regard these methods as special cases of associationist methods whose novel purpose is to discover "causal" connections between phenomena. Thus these researchers take correlational data obtained for a number of variables, specify a general model of pro- posed causal relations, and then fix and free parameters in trial-and-error fashion until they find a specific model that fits the data. The resulting model may or may not show much similarity to their original model, but they will believe that in their finally obtained model they have discovered real causal con- nections. However, a number of things are problematic about this strategy. To begin with, tests of goodness of fit are only relevant with respect to parameters that are fixed in value a priori before the data are seen. The free parameters of a model are al- ways estimated conditional on the values of the fixed parameters in such a way as to ob- tain an optimal fit to the data. If the estimated model fails to fit, it is the fault of the values of the fixed parameters, not that of the estimated free parameters. So, fixing and freeing certain parameters in trial-and-error fashion through a succession of models until a best-fitting model is obtained is equivalent to freeing these parameters in the initial model (but is possibly not quite as efficient in getting good estimates for these parameters). If few or no parameters fixed initially remain fixed at their original values in the finally obtained model, then the resulting goodness-of-fit test may tell us very little about the validity of the model. I will have more to say about this later on. Second, the proponents of causal model- ing methods intended these methods to be used in ways that are quite different from the ways associationist researchers use their sta- tistical procedures. In particular, the causal modeling methods demand much more ra- tional-analytic and definitional activity on the part of the researcher at the outset of a re- search undertaking than do the associationist methods. And the statistical procedures em- ployed by the causal modeling methods are not used primarily for the discovery of causal connections but for the purpose of testing hy- potheses about causal connections. These hy- potheses are generated by the initial rational activity applied to previous experience. Fur- thermore, the causal modeling methods re- quire the researcher's data to meet many more assumptions than is typically demanded of data to be analyzed by associationist statis- tics. Experimentalist and Positivist Views of Causal Modeling Somewhat ironically, those trained in ex- perimental methodologies have a better back- ground with which to grasp how to use the causal modeling methodologies correctly. This is because experimental methods are di- rectly concerned with the conditions that must be met to establish causal connections. Some experimentalists, however, identify</page><page sequence="3">20 Child Development themselves with philosophies of science, such as positivism, that have been hostile to the causality concept. Nevertheless they will readily admit to using their methods to estab- lish functional relations, and, according to the view of causality to be discussed later in this article, functional relations is what causality is all about. Because structural equation modeling is based on correlations, many of these same ex- perimentalists are reluctant to regard the cor- relational methodologies such as path analy- sis and linear structural equations modeling as ever capable of studying causation. These experimentalists claim everyone knows (or should know) that correlation does not im- ply causation. We may say in rebuttal that, whereas correlation does not imply causation, it is also true that causation implies correla- tion. It is this which makes the testing of hy- potheses about causation possible with corre- lational data. A few experimentalists even hold to the erroneous view that the only way one can es- tablish causation is by directly manipulating an independent variable under controlled conditions and observing a functional relation between the values of the independent and the dependent variables of the experiment. A number of considerations give rise to this view: One possible antecedent is John Locke's claim that the idea of causality originated in people's experience of willful action, and thus causality has to do with dis- covering what has to be altered by our activity to bring something about. And, presumably, only after we have in fact altered conditions and brought about the thing in question can we claim to have established causality (Kempthorne, 1978). Although the emphasis on discovering what has to be altered to bring something about is an acceptable conception of causality, the added provision that actual human intervention is required to establish this leads to a view of causality that is too anthropomorphic; that is, it argues that causal connections only exist where human inter- vention and activity have determined out- comes. A more appropriate view of the role of manipulation in experiments is that manipu- lation of an independent variable serves two purposes: (1) it guarantees variation in the in- dependent variable, which is essential to es- tablishing a functional relation, and (2) if per- formed in a consistent manner, manipulation serves as a further control above and beyond other controls of extraneous variation by in- suring that each time one refers to a given value of the independent variable, it repre- sents precisely the same causal conditions. In short, control, not manipulation, is the es- sence of an experiment designed to establish causal relations (Avery &amp; Cross, 1978). And so, if we have good reasons to believe we have natural observations that are free of ex- traneous influences, we can use them to study causal relations without actively intervening to achieve control. A second consideration giving rise to the view that direct manipulation of a causal vari- able is essential to establishing a causal rela- tion is that such direct manipulation guaran- tees that the causal variable is directly observed and thereby unambiguous. In con- trast, so the argument goes, when hy- pothesized cause-and-effect variables are not observed directly but rather are indicated in- directly by observed variables, as in the case of theoretical constructs, any obtained rela- tions between the observed variables may be a function of some other unknown, unob- served causal variables. Said differently, la- tent variable models introduce additional am- biguity to the causal inference that "directly observed" causal variables do not. In response to this argument, one first must note that the issue is not simply one of experimentation versus natural observation in the study of causes. The argument rests, in part, on a demand for certainty and unambi- guity, which direct observation is somehow supposed to insure. But however laudatory certainty and unambiguity may be as goals, they are, according to most recent philoso- phers of science, unrealizable goals in empir- ical research. Furthermore, even if certainty and unambiguity were realizable, direct ob- servation would not ensure their realization. That the appropriate causal factor in an exper- iment will always be correctly indentified is questionable. The history of science contains numerous examples where experimenters at- tributed effects to some manipulation, only to have others determine later that the effects were not due to that but to something else, such as artifacts of experimental subjects, pro- cedure or equipment, or unrecognized sys- tematic influences associated with the experi- mental manipulation. Thus experimentation and direct manipulation are not free from am- biguities and uncertainties. It may be that ex- perimentation is relatively less ambiguous and uncertain in its results than natural obser- vation, but this may be only a matter of de- gree. Finally, some experimentalists oppose causal modeling on the grounds that it is com- mitted to the formulation and testing of hy-</page><page sequence="4">Stanley A. Mulaik 21 potheses and theories. Scientists, they argue, should deal only with observables and atheoretically accumulated descriptions of empirical relations among observables. In re- sponse to this view, we must admit that the proscription against the use of hypothetical constructs and unobserved variables goes counter to the central themes of the causal modeling methods, such as the use of hypoth- eses, especially those that incorporate latent variables as potential causal influences in structural equation models, and item re- sponse theories. However, these proscrip- tions and interdictions against hypotheses and unobservables are but echoes of move- ments such as the Scottish Common Sense Philosophy of the eighteenth and nineteenth centuries, the Comtean positivists of the late nineteenth century, and the logical positivists of the twentieth century that once dominated science but have passed mainly from the scene since (Daniels, 1968; Laudan, 1981; Suppe, 1977). Still, in some areas of the be- havioral sciences their influence persists. In our time, B. F. Skinner (1950) has been the chief critic of the use of theories, hypotheses, and vaguely specified, physiolog- ically reductionist explanations in psychol- ogy, claiming that our preoccupation with them-in contrast to simply describing em- pirical relations-deters the progress of our science. The historical support for that claim is equivocal; for every hypothesis that led some researchers into blind alleys, one can cite hypotheses that led to successful break- throughs. One can also argue that progress in science benefits not from banning theorizing and hypothesizing but from the existence of numerous rival hypotheses and theories, even if they be bizarre, false, and currently untest- able, for these provide the raw material out of which new and potentially useful concepts may arise (Feyerabend, 1978). Skinner's claim also rests on the now questioned as- sumption that there is a theory-free level at which description of nature may proceed (see Aune, 1970; Caldwell, 1982; Feyerabend, 1965, 1970; Huibner, 1983; Munevar, 1981; Polkinghorne, 1983; Tuomela, 1985). A Proposal of a Unifying Concept of Causality With misuses of causal modeling methodologies by associationist statisticians on the one hand, and criticism of these methodologies by a positivistic minority of ex- perimentalists on the other, we need to for- mulate a clearer and more compelling con- ception of causality than that portrayed by the associationist and positivistic accounts. Such clarification should: (a) establish why tradi- tional methods of experimentation are able to study causation as well as why, within certain constraints, we should also be able to do so with correlational methods; (b) show why, by ignoring these constraints, traditional associa- tionist approaches to causality lead to abuses of causal modeling methods with correla- tional data; (c) preserve as much as possible of the useful features of the traditional concep- tions of causality; (d) stress the tentativeness of causal hypotheses, even of those supported by the passing of many empirical tests; and, finally, (e) recognize the limits to the applica- tion of the causality concept. To explicate and evaluate such a concep- tion of causality within the confines of a short article introducing researchers to the philo- sophical foundations of causal modeling is ob- viously a tall order. What follows should be regarded, therefore, only as a sketch of a con- ception of causality that a number of us who advocate causal modeling methods believe meets these goals. Whether the argument will endure under critical examination will only be known in time. A Social, Normative View of Science Science, like other human social institu- tions such as religion, law, mathematics, logic, games, ethics, language, politics, art, architecture, or engineering, is a motley col- lection of evolving and often competing nor- mative practices. Before we explore the implications of this statement, let us first es- tablish that by a normative practice we mean actions prescribed according to someone's rules of appropriate conduct in specified cir- cumstances. Thus one who follows a norma- tive practice uses a rule to guide his or her conduct, but the rule itself does not cause one's actions but merely serves as a criterion for judging the correctness of one's actions. Hence, whatever causes one to act is free to cause one to act correctly or incorrectly ac- cording to the rule. Thus, if one follows a rule, one is also free not to follow it (Baker &amp; Hac- ker, 1984). Normative practices are also taught: someone must "possess" the rule and seek to have others follow it through setting an example or through indoctrination, expla- nation, persuasion, awarding rewards, and inflicting punishments. Some normative prac- tices are readily acquired and closely fol- lowed; others are poorly acquired and adhered to only infrequently. In what sense is science a collection of normative practices, and what does this have to do with causality? Dogmatically speaking,</page><page sequence="5">22 Child Development science concerns obtaining knowledge of the world. A central aspect of science that I re- gard to be a normative practice concerns how one sees, perceives, or judges what is in the world and communicates this to others. There is no necessary way to judge what is in the world. There is no such thing as a foundation of epistemologically necessary elements or forms given to us that we must ground our knowledge on (Suppe, 1977; Tuomela, 1985). In any given situation, there are numerous possible ways we might construe or respond to what is before us. Because we have these alternative possible ways to respond, we have freedom to impose normative practices on acts of judging what is in the world. Much of this normative practice is acquired in child- hood in connection with learning to talk about what is in the world, because then the child learns from others not simply the names for things, but how to identify things to be named, as well as what things are in general. In this way language and judgment as nor- mative practices become inextricably inter- twined (Baker &amp; Hacker, 1984; Hacker, 1972; Wittgenstein, 1953). (This contrasts with the view that the child begins with knowledge of things given to it automatically in a necessary way in cognition and then learns merely to attach names to the things.) The normative practices of judgment are further refined by education and other social activities and are maintained by various social forms of reinforcement-scientists who use the established paradigms in their work get grants, publish, and get promoted, whereas those who stray too far beyond them risk cen- sure from their colleagues. Normative forms of judgment are also maintained by the rein- forcing consequences of actions based on these judgments in interactions with the world. New norms often arise because scien- tists with novel forms of judgment can point to the rewarding consequences of these judg- ments. The Language of Objects and Causality Causality enters into the picture in con- nection with a form of language that has an- cient roots and is frequently used by scientists in talking about the world-the language of objects. To use this language is to follow a normative practice. One does not have to use it: Instead of talking about objects one could talk about sense data and phenomenal im- pressions (as did the empiricists like Ayer, 1936, and Hume, 1739/1969, 1777/1975). But the language of sense data never caught on well among scientists because it seemed un- natural and unnecessarily cumbersome in nat- ural discourse. Furthermore, sense data were regarded as private, and it was difficult to verify whether another person shared the same sense data that you had. Philosophers, like Wittgenstein (1953; Hacker, 1972), also uncovered inconsistencies in the sense-data language. Finally, the language of objects re- tained an advantage over the sense-data lan- guage because there were readily understood conventions for deciding if individuals were talking about the same objects. On the other hand, if we do use the lan- guage of objects, we need not commit our- selves to arguing that this is the only way to talk about the world, as if the world really consists of objects, implying a metaphysical necessity for this practice-a view of some contemporary "transcendental realists" (e.g., Manicas &amp; Secord, 1983). Nevertheless, if one seeks to conform to the language of objects, one is expected to conform to its conventions. According to the language of objects, the world consists of relatively enduring objects bearing properties (see Hacker, 1982). It is important to realize that what we conceive as being a specific kind of object is not deter- mined all at once in experience but rather de- velops over time through learning from others the concept of the object and through thought, action, and subsequent experience regarding it. Some properties of an object endure for a time, and when we observe this against the backdrop of properties that change within it and other objects, we have a basis for know- ing of the continued existence of that object. The activity of an object is described by its changing, accidental, or variable properties. The variable properties of an object are organized into distinct sets of mutually exclu- sive and jointly exhaustive properties, the members of each set sharing some generic quality in common. At any one time, the ob- ject may be described in terms of just one property from each of these sets. Such sets are known as variables (see Skyrms, 1975). For example, we group colors together, forming the variable "color," and we know that if we say "that is red" we cannot also say "that is green" (Wittgenstein, 1975). Now, because science is concerned exclusively with contin- gent (logically unnecessary) relations, it is concerned with relations between different variables and not with relations between the specific values of the same variable (such re- lations being syntactic and not contingent). The term "variable" used here does not re- quire that the values of a variable be quan- tities-they may be qualities.</page><page sequence="6">Stanley A. Mulaik 23 Causal Relations between Objects Traditionally, within the kind of "realist" context we are considering here with respect to objects, causality concerns how the exis- tence of one object is the reason for the exis- tence of another object (Dryer, 1966; Kant, 1781/1958). An object is said to come into ex- istence when certain variable properties of some substance (the substance being an ob- ject out of which the object in question arises) take on the defining values of the object. Thus, before the object exists, there exists some substance (defined by certain fixed properties) with additional variable proper- ties in a certain state. These change into an- other state, and the substance becomes the object in question. The reason for the exis- tence of the object must therefore be the rea- son for the change of the variable properties of the underlying substance. But it cannot be a reason to say that the object is the result of a spontaneous change of the underlying sub- stance into the object in question, for this leaves no reason for the spontaneous change. (A reason must be something other than that which it explains.) But if there is a second substance whose variable properties deter- mine the variable properties of the first sub- stance from which the object arises, then a change in properties of the second substance can be given as the reason for the change in the first substance's properties and hence as the reason for the existence of the object in question. While the change of the second sub- stance is itself unexplained, it stands as a rea- son for the change of the original substance into the object in question. These conclusions are necessary, formal implications of the grammar of a language about objects. Thus causality is a relation specified between ob- jects in the grammar of the language of ob- jects. The necessity of causal relations is grammatical, not metaphysical. Our traditional definition of causality here leads us, therefore, to reject the empiri- cists' reduction of the concept of causality to that of the experience of regular successions. There are numerous regular successions of phenomena in experience that are not re- garded as causal successions (e.g., the regular succession of night following day does not mean that day is the reason for night, and the regular succession of phenomenal properties experienced as one approaches a given object from a given point on repeated occasions is not causal relation according to the traditional definition). (See also Popper, 1965, for a cri- tique of the equating of regular succession with causality.) The grammar of the language of objects also dictates that one must depend on experi- ence to establish causality: because causality concerns how the existence of one object is the reason for the existence of another, and because we cannot know about the existence of things without referring to experience, one cannot verify a specific causal relation with- out reference to experience. Although this generally involves observing whether a par- ticular kind of regular succession of events occurs within experience, one should not con- fuse the concept of causality (a relation in the grammar of the language of objects) with how one would go about verifying its applica- tion (a semantic and pragmatic issue) (Dryer, 1966). Causality as a Functional Relation In stating how the existence of an object is the reason for the existence of another (i.e., how one object is the cause of another), one must state the rule of their connection: The rule of a causal connection is that of func- tional relation. Functional relation is at least as primitive a relation as logical implication (the often cited rival rule for the causal rela- tion); indeed, the form of the relation of logi- cal implication is usually given by truth tables, which exhibit the relation by showing a functional relation. But logical implication is not a relation between variables but between specific values of variables, and we have seen how causality is a relation between the vari- ables of objects. More specifically, by func- tional relation is meant a relation between two sets, such that for each element in the first set there is but a single element from the second set that corresponds to it. In the case of causal relations, the functional relations are between variables representing variable properties of the cause and those of the effect. (We shall shortly see how this concept of the causal relation can be saved from the criticism that functional relations are inappropriate in probabilistic contexts.) To know what an object is means know- ing how one may unite a number of things-in- experience into a concept of a specific object. For example, I see a number of lines and planes and regard this as a chair. But how do I know this is an objective percept rather than a subjective, idiosyncratic way of putting to- gether what is before me into the concept of an object? Kant (1791/1966) argued that con- sistency between the concept of an object and all of one's diverse experiences of it is given by rules that govern how diverse experiences of the object follow from the concept we hold of it. We may take such rules to be part of the</page><page sequence="7">24 Child Development definition of the object, and regard such rules as the basis for regarding judgments about ob- jects to be a normative practice. So, in the instance of what I conceive to be a chair, I should be able to move in space to another point of view and still see lines and planes, perhaps differently related, but still config- ured in ways consistent with my original con- cept of the chair. By contrast, in the case of the Ames chair illusion (where what appears to be a chair becomes a disconnected jumble of lines and planes in three dimensions when viewed from another point), the "chair" is a subjective illusion idiosyncratic to a particular point of view. Objective concepts are thus concepts that join together diverse experi- ences according to rules, and this applies equally to concepts of causal relations be- tween objects. These rules, however, are nor- mative (rather than metaphysical), being part of the definition of the objective concept. Questions about the Adequacy of the Traditional Concept of Causality At the beginning of the nineteenth cen- tury, with Newton's mechanistic conception of nature as a realm of interacting physical objects prevailing, the view of causality just described seemed without criticism. Preced- ing every change in an object there seemed to be a change in some other object that served as its cause. But Newton's physics never an- ticipated radioactive isotopes that decay spontaneously into other elements at unpre- dictable times. Nor did Newton's physics anticipate the revolution of quantum theory during the first three decades of the twentieth century, which was based on the discovery of numerous other changes in nature that did not appear to have a cause. The discovery that many phenomena in the physical world are intrinsically probabilistic and not determin- istic led some, such as Schlick (1959), to argue that causality has been abandoned in physics. If causality cannot be applied to the most fun- damental phenomena of experience, then how could it apply in the social and biolog- ical sciences, which are regarded as reduc- tively dependent on the physical sciences? Schlick's views are the source of many pos- itivistic objections to the causality concept. The Concept of Probabilistic Causality Twentieth-century physicists discovered that when observing particles of matter under precisely the same conditions, they did not always observe the same thing. Still, regu- larities in the frequencies with which certain kinds of events occurred were observed. In these cases, under specified conditions, one could always produce certain outcomes with certain probabilities. Awareness that one did not always ob- serve exactly the same thing under precisely the same conditions also occurred in the biological, behavioral, and social sciences. Typically in these cases error of measurement (the unsystematic presence of numerous, un- known extraneous influences) is invoked to account for this variability in what is ob- served. In theory, such sources of unpredicta- bility could be removed with a fuller knowl- edge of these various extraneous influences. But such is not the case with the probabilistic phenomena of quantum physics. Such phe- nomena are intrinsically and forever unpre- dictable. Psychologists are familiar with the classi- cal errors-of-measurement model that per- meates discussions of regression, analysis of variance, and the variation of scores on intelli- gence tests. Such models regard unpredict- able variance as due to extraneous unsys- tematic causes. Yet there are moderately recent developments in mental-test theory (e.g., item-response theory) that do not invoke the idea of error of measurement. All that is recognized is that at a given level of ability and with items of a specified level of difficulty (both of which are objectively measurable within the model) a subject will answer a question with a specified probability (Rasch, 1960). Models such as these show the way to reconciling the functional relation conception of causality with probabilistic phenomena. The trick is to postulate that the values of an independent or causal variable do not deter- mine the specific outcomes of a dependent variable but rather the specific (conditional) probability distributions with which the values of the outcome variable occur. To illustrate, consider a simple linear structural equation (regression) model wherein the dependent variable is the linear effect of a causal variable. Assume further that for a given value of the causal variable, the value of the effect has added to it a random component due to a disturbance (extraneous) variable. The observed value of the depen- dent variable corresponding to a value of the cause variable is thus not a single value but a random variable. Suppose that the conditional probability distribution of the dependent vari- able, given a specific value of the indepen- dent variable, is normally distributed with a mean value that is a linear function of the value of the cause variable and a variance equal to a value common to the variances of all such conditional distributions. Within the framework of probabilistic causality de- scribed here, how can we see this model as a causal one?</page><page sequence="8">Stanley A. Mulaik 25 Consider that the value of the indepen- dent variable determines a specific (condi- tional) probability distribution defined on the dependent variable by determining the distri- bution's mean. This is sufficient to determine the distribution, if all other information about it is given by specifying that it is normal and has a common variance (which can be esti- mated independently, if need be). Thus, the conditional probability distributions of the dependent variable that are associated with different values of the independent variables may be regarded as elements in the range of a functional relation (where the elements are not single values of a variable but probability distributions). This I admit, is a novel applica- tion for the functional relation concept, but, mathematically speaking, it is entirely proper. Such a way of resolving the conflict of the functional relation concept of causality with probabilistic outcomes is quite new and not generally known (further discussion is given in Mulaik, in press). It is important to realize that it solves those problems raised by Schlick by allowing application of the functional rela- tion concept of causality to probabilistic con- texts over and beyond deterministic ones.1 It is also important to realize that this concept of probabilistic causality unites numerous mod- els in the behavioral sciences, such as analy- sis of variance, the general linear model, linear structural equations models, log-linear models, and item response theory, as causal models. The variety of potential causal mod- els consistent with this conception of probabi- listic causality seems endless. A Faceted Definition of Causality Louis Guttman (Gratch, 1973; Levy &amp; Guttman, 1981; Shye, 1978) has advocated a method of rationally analyzing a concept to display its component concepts, or "facets." I use that method here to provide a clarifying definition of causality: Causality concerns the objective (conception) of the manner by which the variable (properties) of an (object) at a specified (point) in space and time determine unidirectionally by a (functional rela- tion) the variable (probabilistic, nonprobabilistic) (properties) of an (object) at a later (point) in space and time within a closed, self-contained system of interacting (objects), defined in connection with a specific set offixed background (conditions). In this definition, essential, fixed aspects of the definition are italicized. Variables in the definition are designated by surrounding variable names or the names of variable values with parentheses. We can use this definition as a framework for stating a specific causal relation. For example, The frequency of signs of a child's incom- prehension determines (by a monotonically in- creasing function) the subsequent probability that an adult will emit syntactically and semantically simple sentences in the presence of the child, other things being held constant (e.g., other persons are not present, the adult can see and hear the signs of the child's incomprehension, the adult recognizes the signs of incomprehension, sufficient time is al- lowed to elapse between presentation of the child's incomprehension and noting the adult's subse- quent speech behavior, etc.). In this example, the frequency of signs of in- comprehension is a variable property of an object (child). The variation in this property determines the variation of a probabilistic property of another object, that is, the varia- tion in probability of emissions of syntacti- cally and semantically simple sentences (a probabilistic variable property) of an adult (object). Closure is accomplished by having only child and adult present, to prevent the influence of other persons on the adult in question (e.g., another person might tell the adult to speak more simply). Other back- ground conditions specify particular contexts within which the causal relation occurs, for ' As for Schlick's contention that quantum theory dispenses with the causality concept, I think this is not the case (unless we say that it dispenses with Newtonian conceptions of causality). In an extremely lucid account of quantum theory for laymen, Herbert (1985) shows how quantum reality corresponds to a world of diverse kinds of "possibility waves"-each kind corresponding to a different kind of quantum object-that when passed through measuring devices which act as waveform analyzers in known ways produce the various kinds of observed physical particles with theoretically predictable probabilities. Thus the probabilities with which various kinds of particles are observed are a function jointly of the (variable) properties of the "possibility wave" and the (variable) properties of the measuring devices as wave form analyzers. Not only does the theory fit specific cases for which it is designed, but it predicts the probabilities with which certain kinds of particles will be observed in novel experimental situations, thus conforming to the idea of probabi- listic causality given here as an objective concept of a relation uniting diverse forms of experience according to rules. In short, all of the major objections to the causality concept given up to now by empiricist and positivistic skeptics are overcome and should not deter us from using it in our research.</page><page sequence="9">26 Child Development example, the adult's attention and perception are also presumed. Objectivity The definition of causality refers to an ob- jective conception. This unites diverse obser- vations in such a way that the observations are derivable from the conception according to rules. One cannot establish the objectivity of a conception with a single kind of observation since one cannot distinguish whether what is observed is an objective phenomenon or whether it represents an artifact of the means of observation. A common limitation of social and behavioral science research is the depen- dence on single indicators in a study to repre- sent theoretical constructs; this is particularly true in experimental studies. In linear causal modeling, theoretical constructs are repre- sented by latent variables. The causal rela- tions between latent variable and observed indicators are the (normative) rules by which the theoretical concept is linked to observa- tions. At least four indicators are necessary in these models to establish minimal conditions for testing the objectivity of the theoretical concept: Three are used to identify the con- struct with respect to the observations (one can always fit a latent variable to three indi- cators-the so-called just-identified case), whereas a fourth indicator provides an over- identifying condition allowing for a test of the hypothesis that all four indicators have a sin- gle common cause. Another major source of nonobjectivity in the behavioral sciences is the use of explor- atory statistical procedures, such as explor- atory factor analysis, multidimensional scal- ing, multivariate analysis of variance (with its canonical components), multiple regression, and canonical correlation, without any at- tempt to evaluate the generality of the findings against data obtained independently with different methods. As a consequence, it is difficult to tell what is artifact and what is objective in the findings obtained with these methods. Many users of exploratory proce- dures also fail to grasp the normative nature of concepts, assuming that a procedure will de- termine how one must conceptualize the data, rather than realizing that it is the investigator who must establish the norm for making a judgment about the data and then pursue its consequences. Background Conditions If an experiment is to establish causality, it must satisfy certain standard background conditions. These same kinds of conditions also apply in causal modeling applied outside experimental settings. Several authors in the causal modeling literature have discussed these conditions (Dwyer, 1983; Heise, 1975; James et al., 1982), as have numerous philoso- phers of science in recent years (Cartwright, 1979, 1983; Eels &amp; Sober, 1983; Rosen, 1978; Salmon, 1984; Skyrms, 1980; Spohn, 1980). Generally these background conditions are part of a set of assumptions that allow the for- mulation of a testable hypothesis. Background conditions may or may not be testable given the data at hand, but generally reasons are offered to give them some provisional justification. I now turn to consider the more important of these conditions. Relevant objects.-A causal relation is defined between the properties of objects, and its applicability is given by identifying these objects by their fixed properties (e.g., "The adults used in this study were all col- lege-educated, female, from upper-middle- class families, between the ages of... "). The specification of relevant objects circumscribes the domain of objects to which the causal rela- tion will apply. How this is done depends to a certain extent on how one establishes closure, for instance, by isolating objects studied from the influences of objects extraneous to the study, or by excluding objects that vary in- trinsically in some of their properties. For ex- ample, one may hypothesize that subjects dif- fer in the speed with which they solve a problem because of physiological differences in processing rates. Suppose one is interested in showing the causal relationship of this physiological difference to some other vari- able. If one uses the speed in solving the problem as an indirect measure of this physio- logical difference, one must not select sub- jects who use different problem-solving strat- egies, some of which may be less efficient in processing rate than others. If this is not con- trolled at the outset, statistical controls will have to be introduced to account for this ex- traneous variation. Coupling or mediating mechanisms.- Whenever possible, one should specify the causal mechanism or medium by which the effect is produced or transmitted. An ancient principle is that there is no causal action at a distance. Thus, if objects separated in space are causally connected, there must be a me- dium to effect the transfer of change from the causal to the effect object. Of course, ever since Newton put forth the idea of gravitation, this has not been a binding requirement. However, it does serve as a basis for evaluat- ing many causal hypotheses and eliminating those for which there are no known mecha- nisms or media to produce the required ef-</page><page sequence="10">Stanley A. Mulaik 27 feet; a typical illustration is the rejection of ESP as a causal phenomenon, on the grounds that there is no known medium by which its effects may be transmitted. In the "mother- ese" example cited above, vision and hearing are media by which causal effects are trans- mitted. Stating mediating mechanisms is also a useful requirement in those situations where one seeks to evaluate negative evi- dence for a causal relation. If evidence for a causal connection is not established, and yet one knows that the intervening medium by which the hypothesized effect was to be transmitted was intact, then this counts against the hypothesized causal relation. On the other hand, if one knows that the inter- vening medium was broken or interfered with, then the negative evidence can be re- garded as insufficient to discredit the causal hypothesis. Closure.-This is the most commonly vi- olated assumption in causal modeling and the basis for most experimentalists' criticism of causal modeling. Closure concerns demon- strating that any changes in the dependent variable will be due only to changes in the causal variable. In formulating their causal models, many researchers fail to consider ob- vious extraneous variables whose effects must be controlled if one is to establish the objec- tivity of a specific causal relation. Closure is required by the functional relation concept of causality, which states that for a given value of the independent variable there can corre- spond only one value of the dependent vari- able. The presence of extraneous relevant causes of the dependent variable will pro- duce systematic variation in its values at fixed values of the independent variable, thus con- tradicting the principle that the independent and dependent variables are functionally re- lated. Closure is frequently achieved by shield- ing the dependent variable from the influence of possible extraneous causes (the best solu- tion), or by holding constant the values of pos- sible extraneous variables (thus making the causal relation conditional on these constant values), or by including the extraneous vari- able within the causal system, so that the ef- fects of various causes may be disentangled mathematically. Experimenters also have the option to randomly assign observational units to experimental treatments. This guarantees independence, in the long run, of the treat- ment effects from relevant causes embedded in the observational units (in the short run, however, it might not; see Urbach, 1985). However, randomization does not eliminate systematic effects of extraneous variables that may be introduced in some treatments during the experiment. Experimenters are in the best position to achieve closure, because they can arrange situations for observation that are free of known extraneous causes. However, that should not prevent psychologists from study- ing causation outside the laboratory if they can choose their observations carefully. Re- member that astronomers study physical causes without being capable of active inter- vention in the phenomena to achieve control. They do this by selecting situations for obser- vation believed to be free of extraneous causes, and the isolation of space together with our general knowledge of possible causes makes some form of control possible. Psychologists can do the same. In the last analysis, however, closure is a hypothetical assumption that may not be testable by the data at hand. One must use judgment to de- cide whether likely extraneous variables have been eliminated or controlled and proceed on that basis, realizing that one's colleagues may find reasons to disagree. Specification of causal direction.-Many of the data used in causal modeling are corre- lational. As is well known, correlation does not determine the direction of causation. Fur- thermore, given numerous variables, it is quite possible to fit different specifications of the direction of causality to the same pattern of correlations. Although time ordering often rules out certain causal orders, one must select one of several hypotheses of causal di- rection and then proceed to test how well it fits. Stability.-The parameters of causal models can only be estimated uniquely and in an unbiased fashion when, given the values of exogenous variables, the endoge- nous variables of the system have attained sta- ble, equilibrium values as a result (Heise, 1975, p. 226). The effects of changes in exoge- nous variables take time to work themselves through to stable values in the endogenous variables, and measures of variables should only be taken at this point. The stability re- quirement is based on the functional relation concept of the causal relation, namely, that to each value of the independent variable there must correspond one and only one value of the dependent variable. If the dependent variable is still changing or oscillating, which value represents the effect? The natural solu- tion is to choose the equilibrium value when the changes have stabilized. This require- ment is an important one, especially in longi-</page><page sequence="11">28 Child Development tudinal studies where the time intervals re- quired to achieve equilibrium values for measurement purposes are difficult to deter- mine, as well as in nonrecursive models where equilibrium may sometimes be impos- sible. Dwyer (1983, chap. 11) provides an ex- cellent discussion of this requirement. The point is that when we make measurements, we often do so on the basis of certain assump- tions about causal lag, and these possibly could be wrong. Probabilistic conditions.-In cases of probabilistic causality, where the causal vari- able is hypothesized to determine not indi- vidual values of the dependent variable but conditional probability distributions defined on the dependent variable, a background con- dition may be the form of the distributions of the dependent variable (e.g., specifying that the distributions are normal, Poisson, logistic, etc.). The causal variable may then determine these distributions by determining their re- spective parameters. Form of functional relation.-Another background assumption concerns the form of the functional relation relating causal vari- ables to effect variables. The assumption in the causal modeling discussed in this issue is that the causal relations are linear functions, but in other areas, as in psychometrics, one may assume a nonlinear function (e.g., in Rasch models). Physicists use differential equations routinely to model nonlinear causal relations. On the Role of the a priori in Causal Modeling Many researchers assume that the con- nections they see are given in their data and fail to consider the role that they and their methods play in imposing relations onto the data. For example, because causality concerns the study of functional relations, it may seem a simple matter to take a sample of points and discover how they exemplify a functional re- lation. The problem is that there is no unique way to do this because it is we who choose to see them related in one way and not another. It is important to differentiate between a sub- jective way of seeing a relation and one that has objective import. Subjective ways of see- ing a relation are valid only for a particular sample of data, whereas objective ways are valid for all data presumed to be generated by the same process. In most practical situations, we can never have all data generated by the same process before us. We have to begin with samples of data, impose a relation on them, and then see how well that relation fits other data presumed to be generated by the same process. If the relation fits the additional data as well, then we may regard it as having a provisional objectivity and be willing to act accordingly. If it does not fit the additional data, then we may pool old and new data, relax or modify assumptions, and try for a new relation, which we must test with additional data, and so on. An illustrative example.-To illustrate how a priori assumptions and decisions in- fluence the outcome of determining a func- tional relation to fit to data, let us consider a simple example that also illustrates such tech- nical terms used in causal (and other) model- ing as "identification," "degrees of freedom," "overidentification," and "goodness of fit." Many researchers who use causal modeling methods without understanding these terms make serious errors, such as formulating underidentified or just-identified models that cannot be tested with data. The analogue of this in psychological theories is, say, psycho- analytic theory, which in many of its aspects is so underspecified (underidentified) that it can neither be accepted nor rejected by data and hence is only an incomplete theory await- ing further specifications to make it testable. Suppose we have a finite number n of points (xi, yi) in two dimensions defined by the variables x and y. Suppose further that for each value xi there is only one value yi paired with it, and that, similarly, for each value of yi there is only one value xi paired with it. Given these points as representatives of an as yet undetermined functional relation be- tween these two variables, how shall we say these two variables are generally related? Ac- tually there is no unique way. There are infinitely many relations that may be passed through these n points, any one of which may be taken to be their relation. If we confine ourselves to functional relations between the variables, we will have to first decide which is the independent and which the dependent variable. And even among functional rela- tions, say, with x the independent and y the dependent variable, there is an infinity of dif- ferent forms of functions that might be chosen to pass through these data points. We must therefore further presume the general form of the functional relation to be applied to these points. We might assume a polynomial func- tion of the form y = ao + aix + a2x2 +... + ax" of degree p greater than the number of points n. But in making this choice we rule out other equally possible choices, such as Fourier series, which are based on trigono- metric functions. Whereas a polynomial func-</page><page sequence="12">Stanley A. Mulaik 29 tion puts together a function to fit the points by adding together different power functions of the independent variable, a Fourier series adds together various component sine and cosine functions of different periods or fre- quency to form the function that fits the data points. We might attach ontological significance to these component functions. For example, if we think the underlying phe- nomena are wavelike or periodic, then a Fourier series may make sense to use. If not, then although the use of Fourier series will still lead to a function that fits the points, it will not provide us with any deeper insight into the relation. What is crucial to establish- ing the objectivity of it is how the function leads us to interpolate and extrapolate suc- cessfully to other points not currently ob- served. Given our choice of a polynomial func- tion of degree p, there are still an infinity of different specific functions that conform to this choice of general function, all differing by different values of the coefficients ao, al, .... a,. So, how shall we constrain our choice of functions to only those that pass through all the points? Notice that from the coordinates of the n points we can make n equations in the p + 1 unknowns ao, a1,... a,. Y1 = ao + alxl + a2x12 + .+ axl Y2 = ao + aIx2 + a2x2 + .. + a;2 Yn = ao + alxn + a2Xn,2 ... + apXnp Now, as we know from algebra, with n linear equations we can solve for at most n unknowns. This means that in this case we will not be able to identify uniquely an equa- tion from the data that pass through the n points unless we specify a priori r = p + 1 - n coefficients among the p + 1 coefficients ao, ... a, and solve for the rest. But the number of different ways we can choose the coefficients to specify a priori is equal to the number of combinations of p + 1 things taken r at a time. (Even so, having chosen which coefficients to prespecify, we still have infinitely many ways of assigning values to these prespecified coefficients. We may set them to any values, arbitrarily, or according to prior experience or to theory.) The term identification means specifying enough pa- rameters a priori so the remaining parameters may be solved for from the data, and a func- tion determined as a result. Having thus made a series of a priori choices, we have finally arrived at a place where we may identify a relation that passes through all the data points. Having identified a function whose curve passes through all the points, how can we use the data to test whether the assumptions we made to identify the function were appropri- ate so that what results is an objective concep- tion of the relation? We cannot, because our method of identifying the function and solv- ing for unspecified coefficients leads to a curve that necessarily fits all of the points. We can only test a model that, when identified, may not necessarily fit all the data points. The idea of testing for lack of fit allows for assess- ments of objective validity, as opposed to idiosyncracy, of results for the particular selection of points and the arbitrary decisions we have made. Suppose we go back to the beginning and, according to some hypothesis as to why the points should all be joined together by a functional relation, specify a priori the values of more coefficients ao, ... ,a, than we did to just identify the function in the first place. Doing this, we overidentify the hypothesis, that is, we have fewer unknown coefficients to solve for than data points. That means we can pick a set of data points equal in number k to the number of coefficients remaining to be solved for, to provide data for the equa- tions that must be solved to determine the values of the unspecified coefficients. The re- sulting curve will pass through all k of these points exactly. We then use the remaining n - k points to test the hypothesis that the re- sulting curve passes through them as well, under the synthesizing assumption that all data points are generated by the same objec- tive process. If it does not, we may reject the hypothesis. To keep our example simple, we have estimated the unspecified coefficients in such a way that the resulting curve passes exactly through k of the points. In practice, estimation procedures, such as least squares, do not fit the curve to certain points exactly but esti- mate the unspecified parameters of the curve in such a way as to minimize the total lack of fit between the curve and all points, condi- tional on the prespecified parameters' values. If the hypothesis is correct, the fit will then be perfect to them all. If the hypothesis is incor- rect, there will be discrepancies between points and curve, and these discrepancies will be due to a bad choice for the fixed values of the parameters prespecified by the hypothesis to obtain overidentification. It is important to understand that tests of goodness of fit refer to the overidentifying restrictions and not the</page><page sequence="13">30 Child Development values of the free parameters estimated to give best fits conditional on the fixed parame- ters. Now, the number n - k is known as the degrees of freedom of our hypothesis, and it indicates the number of independent condi- tions by which our hypothesis may be disconfirmed. On the other hand, the ratio (n - k)/n is a kind of parsimony index. It indi- cates the proportion of the total number of observable cases that may be used to test the hypothesis. If this ratio is unity, it means we have prespecified by hypothesis the values of all of the observable parameters, and so the curve is completely defined a priori and all data points are then potentially available to disconfirm the hypothesis. A parsimonious hypothesis uses as few of the available data points as possible to determine values of the parameters of a curve to be fit to the set of points. Hypotheses with high degrees of free- dom and high parsimony index values with respect to a set of data have high potential to represent objective phenomena. Earlier I indicated that fixing and freeing parameters of a model until one obtains a model that best fits the data does not allow for a very good test of the objectivity of the result- ing model. It should now be clear that the potential objectivity of a model resides in its parameters fixed a priori, and that you can only test the objectivity of a model by testing fixed parameters against virgin data, that is, data that have never been used to determine the values of the fixed parameters of the model. In this example, we have considered only the mathematical problem of defining a func- tion that expresses a relation between vari- ables given by a set of data points. We have seen that such a function cannot be uniquely defined by the data points alone but requires the making of prior assumptions. Even then, we cannot use the data to test our hypothesis unless we overidentify the hypothesis by specifying additional parameters a priori. But a causal model is not just a mathematical rela- tion. It must be tied to the world, and this is done through specifying background condi- tions. Much scientific effort concerns attempt- ing to test separately the validity of one's specification of background conditions. Much thought is also given to breaking a hypothesis itself into a number of distinct hypotheses and designing the study so that the validity of each of these may be evaluated by the data collected. But no one study can evaluate all of the a priori assumptions made in carrying it out. Thus inferences regarding hypotheses are always conditional. Conclusion Causality is a relation used in connection with a language for dealing with objects that (like length) humans have developed to help them learn how to shape and control their world. In pursuing causes, we seek an objec- tive conception of how objects change and in- duce change that unifies various experiences of them without being necessarily identical with, or determined by, any specific experi- ence. Furthermore, we wish our concepts of change to allow us to anticipate future experi- ence. But because our conceptions of future change are only conceptions, they must be treated as hypotheses to be evaluated against that future experience. Thus causes must be pursued in a pragmatic, hypothesis-testing framework. When experience is consistent with our deduced consequences, we will per- sist in affirming the hypotheses, but when it is inconsistent, we may have to confront the possibility of rejecting either our hypotheses, or those background assumptions we made in order to test the hypotheses, or both. There is no final, absolute truth in such a framework; hypotheses pass or fail the tests made of them. However, any test of a hypothesis depends on many other assumptions, and the hypothesis may be "disconfirmed" for reasons other than its "truth." Moreover, because there may be alternative hypotheses that deduce the same consequences, our hypothesis may be "confirmed" for reasons other than its truth. Choices between hypotheses depend not on how well they fit current data but on how well they fit data they predict to be found. Only if we continuously test our hypotheses against experience, revising them when they do not conform, may we be able to keep pace with the constant changes in our environ- ments, many of which arise from our own ac- tivity (see Aune, 1970). References Aune, B. (1970). Rationalism, empiricism, and pragmatism. New York: Random House. Avery, D. D., &amp; Cross, H. A., Jr. (1978). Experimen- tal methodology in psychology. Monterey, CA: Brooks/Cole. Ayer, A. J. (1936) Language, truth and logic. New York: Dover. Baker, G. P., &amp; Hacker, P. M. S. (1984). Language, sense, and nonsense. Oxford: Basil Blackwell. Caldwell, B. (1982). Beyond positivism: Economic methodology in the twentieth century. Lon- don: Allen &amp; Unwin. Cartwright, N. (1979). Causal laws and effective strategies. Nous, 13, 419-437.</page><page sequence="14">Stanley A. Mulaik 31 Cartwright, N. (1983). How the laws of physics lie. Oxford: Clarendon. Cliff, N. (1983). Some cautions concerning the ap- plication of causal modeling methods. Mul- tivariate Behavioral Research, 18, 115-128. Daniels, G. H. (1968). American science in the age of Jackson. New York: Columbia University Press. de Leeuw, J. (1985). Reviews of Confirmatory fac- tor analysis: A preface to LISREL by J. Scott Long; Covariance structure models: An in- troduction to LISREL by J. Scott Long; An in- troduction to latent variable models by B. S. Everitt; and Causal modeling in nonexperi- mental research: An introduction to the LIS- REL approach by W. Saris &amp; H. Stronkhorst. Psychometrika, 50, 371-375. Dryer, D. P. (1966). Kant's solution for verification in metaphysics. London: Allen &amp; Unwin. Dwyer, J. H. (1983). Statistical models for the so- cial and behavioral sciences. New York: Ox- ford University Press. Eels, E., &amp; Sober, E. (1983). Probabilistic causality and the question of transitivity. Philosophy of Science, 50, 35-57. Feyerabend, P. K. (1965). Problems of empiricism. In R. G. Colodny (Ed.), Beyond the edge of certainty (pp. 145-260). Englewood Cliffs, NJ: Prentice-Hall. Feyerabend, P. K. (1970). Classical empiricism. In R. E. Butts &amp; J. W. Davis (Eds.), The method- ological heritage of Newton (pp. 150-170). To- ronto: University of Toronto Press. Feyerabend, P. K. (1978). Against method. Lon- don: Verso. (Original work published 1975) Gratch, H. (Ed.). (1973). 25 years of social research in Israel. Jerusalem: Jerusalem Academic Press, 1973. Guttman, L. (1977). What is not what in statistics. Statistician, 26, 81-107. Hacker, P. M. S. (1972). Insight and illusion: Witt- genstein on philosophy and the metaphysics of experience. Oxford: Oxford University Press. Hacker, P. M. S. (1982). Events and objects in space and time. Mind, 91, 1-19. Heise, D. R. (1975). Causal analysis. New York: Wiley. Herbert, N. (1985). Quantum reality. Garden City, NY: Anchor/Doubleday. Hiubner, K. (1983). Critique of scientific reason (P. R. Dixon, Jr., &amp; H. M. Dixon, Trans.). Chicago: University of Chicago Press. (Original work published 1978) Hume, D. (1969). A treatise of human nature. Bal- timore: Penguin. (Original work published 1739 and 1740) Hume, D. (1975). Enquiries concerning human understanding and concerning the principles of morals. Oxford: Clarendon. (Original work published 1777) James, L. R. (1980). The unmeasured variables problem in path analysis. Journal of Applied Psychology, 65, 415-421. James, L. R., Mulaik, S. A., &amp; Brett, J. M. (1982). Causal analysis: Assumptions, models, and data. Beverly Hills, CA: Sage. Kant, I. (1958). Critique of pure reason (N. K. Smith, Trans.). New York: Modern Library. (Original work published 1781) Kant, I. (1966). Prologomena to any future meta- physics (P. G. Lucas, Trans.). Manchester: Manchester University Press. (Original work published 1791) Kempthorne, 0. (1978). Logical, epistemological and statistical aspects of nature-nuture data in- terpretation. Biometrics, 34, 1-23. Laudan, L. (1981). Science and hypothesis. Dor- drecht, Holland: Reidel. Levy, S., &amp; Guttman, L. (1981). Structure and level of values for rewards and allocation criteria in several areas of life. In I. Borg (Ed.), Mul- tidimensional data representations: When &amp; why (pp. 153-192). Ann Arbor: Mathesis. Ling, R. F. (1982). Review of Correlation and caus- ality by D. A. Kenny. Journal of American Sta- tistical Association, 77, 489-491. Mach, E. (1960). The science of mechanics: A criti- cal and historical account of its development (T. J. McCormack, Trans.). La Salle, IL: Open Court. (Original work published 1883) Manicas, P. T., &amp; Secord, P. F. (1983). Implications for psychology of the new philosophy of sci- ence. American Psychologist, 38, 399-413. Miller, A. D. (1971). Logic of causal analysis: From experimental to nonexperimental designs. In H. M. Blalock (Ed.), Causal models in the so- cial sciences (pp. 273-294). Chicago: Aldine. Mulaik, S. (in press). Toward a synthesis of deter- ministic and probabilistic formulations of causal relations by the functional relation con- cept. Philosophy of Science. Munevar, G. (1981). Radical knowledge. In- dianapolis: Hackett. Pearson, K. (1911). The grammar of science (Part I. Physical). London: Adam &amp; Charles Black. (Original work published 1892) Polkinghorne, D. (1983). Methodology for the hu- man sciences. Albany: State University of New York Press. Popper, K. (1965). Hume's explanation of inductive inference. In A. Sesonske &amp; N. Fleming (Eds.), Human understanding: Studies in the philoso- phy of David Hume (pp. 69-74). Belmont, CA: Wadsworth. Rasch, G. (1960). Probabilistic models for some in- telligence and attainment tests. Copenhagen: Nielsen &amp; Lydiche. Rosen, D. A. (1978). Discussion: In defense of a probabilistic theory of causality. Philosophy of Science, 45, 604-613.</page><page sequence="15">32 Child Development Salmon, W. C. (1984). Scientific explanation and the causal structure of the world. Princeton, NJ: Princeton University Press. Schlick, M. (1959). Causality in everyday life and in recent science. In E. Sprague &amp; P. W. Taylor, Knowledge and value (pp. 193-210). New York: Harcourt, Brace. Shye, S. (1978). On the search for laws in the behav- ioral sciences. In S. Shye (Ed.), Theory con- struction and data analysis in the behavioral sciences (pp. 2-24). San Francisco: Jossey-Bass. Skinner, B. F. (1950). Are theories of learning nec- essary? Psychological Review, 57, 193-216. Skyrms, B. (1975). Choice and chance. Encino, CA: Dickenson. Skyrms, B. (1980). Causal necessity. New Haven, CT: Yale University Press. Spohn, W. (1980). Stochastic independence, causal independence, and shieldability. Journal of Philosophical Logic, 9, 73-99. Suppe, F. (Ed.). (1977). The structure of scientific theories, 2d ed. Urbana: University of Illinois Press. Tuomela, R. (1985). Science, action and reality. Dordrecht, Holland: Reidel. Urbach, P. (1985). Randomization and the design of experiments. Philosophy of Science, 52, 256- 273. Wittgenstein, L. (1953). Philosophical investiga- tions (G. E. M. Anscombe, Trans.). New York: Macmillan. Wittgenstein, L. (1975). Philosophical remarks (R. Rhees, Ed., and R. Hargreaves &amp; R. White, Trans.). Oxford: Blackwell.</page></plain_text>
<plain_text><page sequence="1">MODELS, INFERENCE, AND STRATEGY J. G. SKELLAM The Nature Conservancy (N. E. R. C.), London, England SUMMARY The nature of mathematical thinking, of scientific thinking, and the relation between them are reviewed and it is argued that many controversial issues affecting fundamental attitudes to probability, conceptual models, inference and explanation are obscured by the inadequacies of language. It is claimed that methodological principles are only a substitute for analysis in depth, and that biometrical science would benefit by a change of emphasis from logic to strategy. It is suggested that valuable information which affects common-sense judg- ments tends to be ignored when formal statistical tools are employed along conventional lines. 1. The Biometric Society exists to promote and encourage mathematical and statistical thinking in biology. It seems proper, therefore, for us to reflect occasionally on the nature of mathematical thinking, the nature of scientific thinking, and the relation between the two. Indeed, there can be very few of our members who have not already given a great deal of serious thought to such matters. That these subjects have already led to so much controversy is in itself an indication of their inherent difficulty; and the intense heat, that has frequently been generated in the process, testifies to the resolute firmness with which thinking people are sometimes inclined to assert their preconceptions, and in so doing, often utterly fail to communicate effectively with one another on fundamental issues. The flood of valuable books and papers on these subjects mounts higher each year, and the field is now so immense and crammed with technical detail and strange symbolism that it is difficult to sketch a single viewpoint, even in the barest of outlines, as I hope to do today. 2. The great difficulty always seems to lie in deciding just where to begin, so I will begin with this self-same difficulty. There are two main approaches. The first way is to state one's premises once and for all in terms of a fixed set of concepts aiid to develop the subject by reasoned steps within that conceptual framework. This I will call the closed way of thinking, exemplified in its most perfect form by the axiomatic systems of mathematics and symbolic logic. The second approach is to start with a provisional set of working premises expressed in terms of provisional concepts with a view to the progressive refinement and I Text, with minor revisions, of an address to the British Region, December 1968, by the retiring Regional President. 457</page><page sequence="2">458 BIOMETRICS, SEPTEMBER 1969 evolution of both premises and concepts. This I will call open-ended thinking, as exemplified by the natural sciences. 3. The researches of logicians, particularly during the last half-century, are already transforming our ideas on closed systems of thinking and the manner in which they can be profitably employed. In a purely formal sense, the rules of chess constitute a mathematical system, but to apply chess to actual warfare would be both superficial and artificial, though there are undoubtedly many analogies. Whether or not mathematical thinking differs from the playing of games is, however, a controversial subject, discussed by Frege at the turn of the century in a series of extremely convincing arguments, in which he demolished the formalist conception of mathematics, whereby mathematical systems are regarded as consisting wholly of a succession of blocks of empty or meaningless marks, a conception which dates back to Leibnitz and is still prevalent today. Perhaps the most important development is the recognition that mathematics provides us with a variety of skeletal languages, whose logical or grammatical properties can be exploited to expand any initial description which can be expressed by axioms when the symbolism is given an appropriate interpreta- tion. Research in this field reveals that there are at least two language levels. First there is the ordinary object language, which can be used to represent a concrete situation whenever a high degree of correspondence can be established between the signs of the object language and certain features of the concrete situation. Then there is also a higher-order language or meta-language which refers to the object language and the way it may be employed. For example, 'Snow is hot' is an object statement, but 'It is not true that snow is hot' is a metalinguistic statement equivalent to "The object statement 'Snow is hot' is a false statement." In pure mathematics the object language is highly abstract and condensed but the metalanguage is usually natural and meaningful as is evidenced by the lines of ordinary script with words like 'therefore' interspersed between the formulae. In the course of the evolution of language, as expounded for example by Russell [1940], ideas are progressively introduced into the object language from the metalanguage. For example, the metalinguistic statement '{A} is so and JB} is so' readily evolves into '{A &amp; B} is so,' the conjunctive symbol '&amp;' carrying with it a shadow, at least, of the meaning of the word 'and.' Notice that the word 'and' has not been deleted from the vocabulary of the meta- language but has been injected into the object language to enrich it. It is interesting in this connection to reflect on the way that the symbol for probability measure enters into the conventional language of mathematical statistics. Reichenbach [1949] starts off by placing it in a formalized meta- language because he replaces the sign 'D' (material implication) in the Proposi- tional Calculus by the sign 'D,' (probability implication). In this way he emphasizes the conditional nature of all probability statements.</page><page sequence="3">MODELS, INFERENCE, AND STRATEGY 459 Now anyone, who has sincerely tried by straight translation to find a realistic interpretation to a mathematical statement expressed in the conventional symbolism of mathematical statistics, will have observed that the contents of the statement include a symbol denoting probability, but that the statement as a whole is asserted as exact, as absolutely true or certain. Now if the mathe- matical statement is to be interpreted objectively as a statement about Nature, it is a bolder man than I who would make such a statement categorically. When we reflect on the facts, first that truth is a metalinguistic concept, which does not normally appear in the object language of science, and second, that truth and probability are semantically related, as is evidenced by the deriva- tion of the German word 'Wahrscheinlichkeit,' and indeed by everyday usage everywhere, we may wonder whether or not we have already got the lan- guage levels of our mathematics and our science out of correspondence. It would appear to me to be far more satisfactory and consistent if we were able to employ probability notions simultaneously in both object language and meta- language. Indeed, I suspect that many of us tend to use three language levels already but without much uniformity or consistency, namely: (1) a formal object language referring to natural processes which are conceived as stochastic and which are described in terms of some fixed parameter p or a particular distribution function, (2) a formal metalanguage in which the probability concept applies to statements and is interpreted epistemically, and (3) a higher order language with two valued logic. The problems connected with objective and subjective conceptions of probability are deeply embedded in the imper- fections of the language we customarily employ. For example, it is rare for the symbolism to reflect the fine distinction between a parameter value (0 say) postulated as an actual but unknown constant in a particular definitive model of a natural process and the variable (0 say) which ranges over the set of con- ceivable values we have in mind when we contemplate the estimation of 00. The common belief among statisticians that the problems of inference would soon be resolved in some facile manner now seems extremely naive. 4. The transfer of the probability concept from the metalanguage to the object language is tantamount to endowing Nature herself with an intrinsic uncertainty. Anthropomorphic projections of this kind are well known in quite reputable branches of science, the most discussed examples being provided by the concepts of 'force' and 'energy' in Newtonian mechanics. The projection of probabilistic notions on to Nature results in the introduction of an important and far-reaching theoretical fiction into science, the fiction that a particular natural situation is endowed simultaneously with two or more mutually exclusive dispositional properties. Such a possibility can neither be verified nor falsified empirically because perfect or exact replication is a pure illusion. In the strict language of mathematical statistics a random variable has one and only one realization, and a finite sequence of simple realizations is itself only a single multivariate realization. The fiction of the random variable as an objective concept is fully justifiable in my pragmatic view solely on the grounds that it</page><page sequence="4">460 BIOMETRIICS, SEPTEMBER 1969 provides us with an extremely useful and workable simplifying idea in circum- stances which are not readily analysable at a more detailed and less remote level of abstraction. 5. In the course of the last century, mathematics has certainly lost little of its glory, but its pre-eminence as the greatest intellectual achievement of man- kind has certainly been challenged. The reasons for this arise in part from a greater appreciation of open-ended thinking, such as has been displayed in modern physics, and in part from a growing realization of the limitations of closed thinking as characterized by axiomatic systems. Researches into the foundations of mathematics, notably the melancholy revelations of Gbdel in 1931, not only proclaim the abject failure of the ambi- tious attempt by Whitehead and Russell to establish mathematics on a purely logical foundation, but also destroyed the hopes of the far less ambitious Hil- bertian School, who had restricted their aims mainly to establishing consistency and completeness. Gbdel's theorems, which as far as I know have not been refuted, lead to the depressing result that even in ordinary arithmetic there exist infinitely many well-formed statements which can neither be proved nor disproved by formal deductive argument from the axioms. Though concrete examples are not available from arithmetic, some mathematicians suspect that Goldbach's celebrated conjecture (that every even number other than 2 can be expressed as the sum of two primes) might possibly be one of these undecidable propositions. From the time of Aristotle the type of explanation that has been most highly esteemed is the kind which demonstrates that a phenomenon is the logical consequence of accepted premises. It is this type of explanation which we have always sought in science. This ideal has prompted us to formulate our premises mathematically whenever possible and to explain and predict phenomena by formal deductive processes. In 1922 Hilbert felt confident in declaring: 'The axiomatic method is now and for all time the instrument suited to the human mind and indispensable for every exact enquiry, whatever its field may be.' It now appears that even if we were fortunate enough to set up a perfect mathe- matical model or theory we should still be unable to unfold it completely and reveal all its properties by deductive methods. It is still far too early to assess the full impact of G6del's revelations and various subsequent discoveries. Hilbert, in accepting them, felt nevertheless that the repercussions on science would not be serious. This may well be so, but a cherished illusion is shattered all the same. 6. Nowadays abstract thinking is highly praised, and justifiably so, but much that passes for abstraction is far removed from it. In Figure 1, the same subject is depicted by Picasso at two markedly different levels of 'abstraction.' The lower picture is at a more naturalistic level comparable to that adopted in most conventional biology, whilst the upper sketch is at a level more comparable to that adopted in most mathematical biology. We may think in abstract of the shape of an object regardless of its colour, of its weight regardless of its</page><page sequence="5">MODELS, INFERENCE, AND STRATEGY 461 Picasso FIGURE 1 THE SAME SUBJECT (A BULL) DEPICTED BY THE SAME ARTIST (PICASSO) AT TWO DIFFERENT LEVELS OF ABSTRACTION volume, as we do in elementary physics, but in most applications of language we are obliged to use the vocabulary which is available, and fit the words together as best we can to give the shade of meaning we intend. In particular, when mathematical language is used to model natural phenomena, considerable distortion, often spoken of politely as simplification or approximation, is in- evitable. Our mathematical models from the beginning are invariably known to be imperfect. What really matters, however, is not their degree of perfection, but their adequacy for prescribed purposes. Though considerable thought may be given to the role of stochastic errors conceived within the framework of an abstract model, surprisingly little atten- tion is normally given to what is often a much more serious source of error and deception, the defects of the model itself. I attribute this attitude largely to the way that statistics is usually taught-as a mathematical discipline of great intrinsic interest imparted to talented students who unfortunately have rarely</page><page sequence="6">462 BIOMETRICS, SEPTEMBER 1969 had proper training in natural science or first hand experience of scientific research-and also to the way most writers of elementary text-books select their illustrative examples, and show us how well the facts of Nature can be used to illustrate mathematical theorems rather than the other way round. This latter evil is deeply rooted in our early schooling, when we encounter such problems as: 'How far does a man run in 2 hours if he runs 10 miles in 1 hour?' This is a biological problem, not an arithmetical one, but children are conditioned into thinking that there is a correct answer, the one approved by the teacher and given at the back of the book, or that there is a perfectly valid tacit assumption or logical principle which enables them to derive the correct answer. The evil is further promulgated by the way young people are led to believe that they actually study mechanics when in reality they are only becom- ing more proficient at juggling symbols in Newton's theoretical world. The point I am trying to establish here is that there is an important difference of emphasis between the application of mathematics to biology and the mathe- matization of biology, and that it is the latter which needs the most encourage- ment, for it is here that the real difficulties lie. Admittedly some of the defects in conventional models are of little conse- quence, as for example those whose effects are progressively diminished by central limit processes, but there are others which seriously affect the outcome, as for example, the subtle, infinitesimal considerations which need to be taken into account in formulating realistic diffusion equations in ecology and genetics (see, e.g., Skellam [1955]). In the field of population estimation it is not at all widely realized that most standard models are highly sensitive to departures from homogeneity assumptions, and unless these are satisfied, an extremely rare event indeed, serious under-estimation of the population may result ac- companied by grossly misleading statements about the accuracy or reliability of the estimates (see, e.g., Skellam [1962]). It is often assumed that elementary empirical relationships can be adequately represented by their mathematical counterparts. Leibnitz, for example, adopted the view that indiscernibles are identical. Now if we imagine a direct- reading balance capable of displaying the sign '0, and if we regard the weights, x and y, of two pebbles as empirically equal should zero be displayed on both oc- casions when they are balanced against each other, left-right and right-left, we might express this empirical fact by writing 'x e y.' At the higher level of ab- straction to which our sophisticated minds are more accustomed, we would rein- terpret this as 'Ix - yJ &lt; E.' Now consider statements of the following form: 'X Z whenever (i.e. given that) X e Y and Y _ Z,' where X, Y, Z are inde- pendent variables with a continuous density function. It is easily seen that all such statements are not true, and then by first considering the joint distribution of X and Z conditional on Y, it becomes immediately apparent (regardless of the value assumed by Y) that as e -O 0, the expected truth value when the given conditions are actually realized tends to 4 and not to unity, as would be the case if the mathematical concept of equality were strictly applicable to an infinitely sensitive balance. This particular anomaly is, of course, trivial in practice, but I believe it not</page><page sequence="7">MODELS, INFERENCE, AND STRATEGY 463 to be entirely without value if it makes us more aware of subtle difficulties which surround the indiscriminate application of mathematical abstractions. My general feeling is that limit concepts are of little use in science if they do not satisfy the practical requirement that lim. property of system = property of lim. system because the scientist usually uses a limit as an approximation in extreme circum- stances. Kdrner's recent book, Experience and Theory is particularly illuminating on the subject of empirical and theoretical relationships for it stresses that the world is neither all chaos nor all order, and that empirical individuation and classification are neither infinitely sharp nor infinitely blurred. Had Confucius lived today he might equally well have said 'When an instrument is razor-sharp and two-edged it is sometimes wiser to use sandpaper.' This remark in my view summarizes the main argument against the indiscriminate use of that over- popularized and dangerous instrument, the significance test, a subject which might be thrashed out openly on some future occasion. 7. Open systems, far more than closed systems are riddled with internal contradiction, and effort is constantly directed to the resolution of the contradic- tions as well as the discrepancies which exist between observed fact and theore- tical expectation. Sometimes this is achieved by mere elaboration, as for exam- ple, by replacing V in Boyle's Law by V - b, so as to make allowance for the space 'occupied' by the molecules. When, however, the resolution of a contra- diction is achieved by actual modification of the basic concepts, as for example, when we replace the blending conception of inheritance by a particulate con- ception, we say that an important theoretical advance has been made. The most quoted illustration of this is the resolution by Einstein of the apparently paradoxical results of a variety of crucial experiments (between 1726 and 1881) bearing on the problem of ether drift. It is salutary to note that this great theoretical advance did not emerge out of a single crucial experi- ment designed to test a particular null-hypothesis, and that crucial experiments are comparatively rare in scientific research. The writers of articles on hypoth- esis testing are often guilty of over-simplification, sometimes amounting to gross distortion, particularly when they try to condense the whole art of scientific research into a single cut-and-dried formulation. Nevertheless, I do sympathize with them, because the classical ideals of simplicity, unification, and universality motivate us all. No doubt, before the day is over, if not already, I too, in my innocence, will have committed the sin of over-simplification. Indeed, this danger lurks behind all attempts to com- municate, and is possibly inherent in the nature of language itself. Open-ended thinking leads to the construction of concepts which are increas- ingly abstract. It thereby imposes an ever widening gap between experience and theory and incurs a serious penalty, the ever growing burden of re-interpre- tation required to bridge the gap. For example, at an early stage in the develop- ment of knowledge, the sentence, 'The sun rises above the eastern horizon,'</page><page sequence="8">464 BIOMETEICS, SEPTEMBER 1969 would have been interpreted literally as in everyday life today. When man's knowledge of astronomy was a little more advanced, the phrase 'rises above' had to be given a new meaning different from the old one, a meaning which was not obvious in ordinary experience because it required us to stand outside our- selves and see ourselves in imagination located on a huge ball around which the sun and stars revolved. In a highly advanced science such as modern physics the chain of re-interpretation extending back from, say, the sophisticated probabilistic wave-packet conception of an electron to the visible scintillation patterns displayed on a fluorescent screen, is long, branched, reticulated, and tortuous. Even in a comparatively unsophisticated science such as biology, a great deal of re-interpretation has taken place already in my life-time, as is evidenced by the succession of meanings that have been given to the word 'respiration' or to the concept of a 'gene.' It always takes time before the human mind is willing to accept new concepts as being worth-while in the first place, and then there are delays in absorbing them, and there are still longer delays before they are f fully assimilated into the general framework of thinking and employed with fluency. That statistical and mathematical ideas are valuable in biology is almost universally accepted, if we are to judge by some of the language and symbolism permitted in biological journals today. But when we see how clumsily mathematical notions are often used, I am forced to the conclusion that absorption has been slow and that little genuine assimilation has yet taken place. Probabilistic notions, despite lip- service to them, feature largely on the surface in a purely formal way in con- nection with such matters as experimental design and the analysis of variance (important as these may be) and are only slowly penetrating to the central core of biological thinking. One reason for this, I believe, is that statistical ideas have been presented to biologists in a foreign language, and are not seen by them as a natural development of their own thinking, but often something more akin to an externally imposed code of prohibitions. A shift of emphasis from logic to strategy would, I feel, be both welcome and helpful. The standpoint adopted here is that traditional logic does not furnish its own justification and if inductive inference is to develop as an applied science, logical concepts will have to undergo progressive modification, replacement and evolution comparable to the conceptual developments which have taken place in physical science. 8. The first broad premise, adopted here, is that man is an animal and that his intellect is part of his biological equipment forged during a long struggle for survival. From sticks and stones he has made simple tools, and with these he has made better tools, and set in train a succession of devices leading up to the powerful instruments we know today. In parallel and in conjunction with this he has also forged in succession a series of increasingly powerful intellectual tools, which he has been successful in passing on from one generation to the next both by imitation and the medium of language. Philosophers, particularly logicians, quite rightly stress the important role of symbolism, but often do so to such an extent as to do injustice to many other aspects of man's intellectual equipment. In particular, his remarkable inbuilt capacity for visual imagery is often scorn-</page><page sequence="9">MODELS, INFERENCE, AND STRATEGY 465 fully dismissed. That we see through the eyes, rather than with them, is a point upon which Plato seems to have had little doubt, for he makes both Socrates and Theaetetus agree that it is so. The point is also discussed in depth from the biological standpoint in Agnes Arber's delightful study, The Mind and the Eye [1954]. Numerous illustrations are afforded by chess of the extent to which the capacity for visual imagery and the ability for logical thought can be combined. For example, Tartakower in a display in Vienna in 1921 played six independent games simultaneously blindfold, and in one declared a forced mate in eight (15 steps) and gave his analysis. The numerous possibilities entertained in imagination were reduced to a single tree with no less than five branches, a single move being given by him at every stage to meet every legitimate alterna- tive available to his opponent. An example of the speed with which the human mind aided by visual imagery can operate is afforded by a chess problem quoted by Pachman ([1963] p. 310). A chess master solves the problem in a minute, a good amateur in about 5 minutes, whilst an electronic computer specially programmed for the purpose took 12 minutes. 9. My second broad premise is that the human race, like other species of living organism struggling for existence, has evolved strategies which favour its survival, at least under the conditions which prevailed when the strategies were evolved. The life-history pattern of an organism is itself the expression of a strategy, as is easily seen, for example, by reflecting on the prodigious reproduc- tive capacity of parasites. Numerous eggs, spores, or seeds are produced, each with a minimal endowment of food because of the extremely small chance of finding a new host. The inbuilt behaviour patterns of individual organisms are again strategies, as is easily seen, for example, by reflecting on the spinning and feeding behaviour of a garden spider. The conditioned reflexes and habits of mammals established by learning processes during their more plastic immaturity are strategies fitting them for survival in later life under conditions similar to the particular conditions in which the strategies were earlier developed. When we reflect further on the genetic mechanisms behind evolutionary change, it seems evident that the survival value of a strategy depends on its effectiveness in a long-run statistical sense. We certainly adopt the statistical criterion when we organize a chess championship to elect the player (or com- puter and software) with the best repertoire of strategies, because we allot points to each game and total up the scores. In this connection may I add that per- sonally I should thoroughly enjoy the opportunity of witnessing a postal tourna- ment between exponents of the various schools of statistical inference, with a view to discovering the conditions which favour one rather than the other. On the whole, I suspect that in a broad class of cases the Bayesians would have a slight edge. The only game I have actually examined on these lines is the simplest one with a succession of Bernoulli trials with fixed but unknown p and unit stakes. Biologists may not be surprised to hear that in the above game nobody does better than the naive empiricist who bets simply and solely on the past record</page><page sequence="10">466 BIOMETRICS, SEPTEMBER 1969 oblivious to all statistical theory. The cautious statistician loses because he wastes his opportunities in the course of assembling sufficient information to make reasonably firm conventional inferences. In a long series of trials he is not however far behind. Any really obstinate statistician who is not prepared to reverse his decisions on the grounds that his methods are based on pure logic, takes the further risk of being wrong indefinitely. Most strategies encountered in the biological realm being inbuilt are virtually inelastic and may be employed over a wide range of conditions. In special circumstances they fail, as for example, when the avoiding reactions of a wild bird take it further away from the food being offered to it by a harmless old lady. It is in the essence of intelligent behaviour that full reliance is not placed on simple universal strategies, but that these undergo changes analogous to dif- ferentiation or adaptive radiation, and are progressively replaced by a complex of sub-strategies each conditional on a set of circumstances to which it is better adapted. The particular strategy which is adopted at any instant is not only conditional on the signals being received at that instant but also on impressions assimilated over a period of time. Effective strategies almost invariably in- corporate sequential and cybernetic features. Elementary games theory tells us that at any stage in a game of chess there always exist one or more optimal strategies for each player. Apart from simple situations there is, however, no hope at present of discovering the perfect chess strategy because the biggest and fastest computers are totally inadequate by a factor of the rough order of a million or more. In chess, therefore, as in life we fall back on general principles, but these are only substitutes for detailed analysis in depth and are not universally valid, as can always be demonstrated by setting up counter-examples. This view-point is readily extended to the wider field of inductive inference and to statistical inference in particular. The so-called principles are then conceived as little more than strategic guides or maxims designed to foster the systematization of experience when we are inadequately equipped to cope with the detailed tactical complexity or are insufficiently informed on the background circumstances. 10. As indicated earlier (see end of paragraph 3) one of the sources of disagreement between the users of the probability calculus seems to centre around the applicability of the notions of constants and variables. A typical example is furnished by the conflicting attitudes displayed by two outstanding architects of our subject to the statement: 'If y is the unknown mean of a normal distribution and if x is an observed value, then Prob (g &lt; x) =-.' Fisher [1955] argued that the statement 'g1 &lt; x' is semantically equivalent to the statement 'x &gt; g.' Neyman [1956] argued that since ,g and x are constants, then the inequality either holds or does not hold. Fisher was evidently using the probability concept metalinguistically and Neyman was using it objectively. Neyman's argument came through to me crystal clear but I was unable at the time to tune into Fisher's wavelength. On reflection, I am now inclined to the view that the problems connected with the inversion of probability state-</page><page sequence="11">MODELS, INFERENCE, AND STRATEGY 467 ments can be resolved, at least in certain contexts, and that it is helpful to think about them in the less idealized framework of a strategic situation. To illustrate, may I beg you to bear with me whilst I relate a somewhat lengthy fable. Long, long ago, in a far away valley, there stretched a vast alluvial plain intersected by rivers, and cut off in the middle was a large flat island inhabited by a tribe of sun-worshipping people who reared goats. In accordance with a decree made in the reign of King Mathematos the Great, numerous tablets of baked clay had been arranged in a pattern of lines radiating outwards from the middle of the island in all directions as far as the river bank. This pattern of landmarks not only served to chart the island, tell the time of day, and indicate the seasons but by its familiarity exercised an influence over all thought and action. Every few years a certain type of predatory carnivore succeeded in reaching the island, where it established a permanent lair, in which it rested by day and around which it wandered by night in search of food. When in the morning the natives discovered the mauled remains of a goat, they would call on the king, who would then send his warriors fanning out in all directions with orders to hunt down the beast in its lair and destroy it. Because this was a dangerous exercise calling for great skill and valour, all relevant details were faithfully recorded in the history. Now it came to pass that Statistok, the medicine man, had given birth to a new idea, the Principle of Collation by MIass Super-position. Those heretics who held that this idea amounted to ignoring all details which it seemed oppor- tune to ignore were promptly cursed and banished. Using this idea, Statistok constructed a new map and two new diagrams dealing with the recurrent problem of the carnivorous beast. Figure 2 shows all historical cases simultaneously on one map, time being ignored. In the language of these people, p denotes a lair and x a mauled goat, corresponding cases being joined by a line. The diagram on the left side of Figure 3 shows the pattern obtained by superimposing all lairs and translating the lines without change of direction. Thus, not only was time ignored but the particular locations of the lairs were ignored, and indirectly those of the goats. The diagram on the right side of Figure 3 shows the corresponding pattern given by superimposing the sites of the mauled goats, directions again being preserved. For every ray of the first diagram, there corresponds a ray in the second, and both figures can be superimposed if one is rotated through half a revolution. This after all was only to be expected, for were they not both alternative ex- pressions of the Great Sun-God, Stochastos, the one being his image by day and the other his image by night? Now it came to pass that the beast once again visited the island, and the king called upon Statistok for council. The medicine man advised him to con- serve effort by starting at the site of the dead goat, and then to describe suitable spaced circles of increasing radius around it. The strategy proved highly successful and Statistok was allowed to enjoy the royal society. The new prin- ciple was so esteemed that acceptance of it was made an essential requirement</page><page sequence="12">468 BIOMETRICS, SEPTEMBER 1969 -~~~~~~~~~~~~A _ a~~~~~n FIGURE 2 MAP OF FICTITIOUS ISLAND SHOWING CORRESPONDING LOCATIONS OF LAIR (g) AND VICTIM (X) at all initiation ceremonies. Eventually everyone was so indoctrinated that to think otherwise seemed absolutely inconceivable. This was also the beginning of the doctrine of empiricism, whereby people started with the facts that were given and progressively worked around them. Many generations passed, until one day a remote descendant of the venerated medicine man lay delirious with fever and had the strange dream that the dreaded carnivore had again visited the island but that there were no goats for it to eat, and driven by starvation, it was about to attack human beings. He dreamt that he had been assigned the task of devising a plan of attack, but how could this be done if there were no goats to start with? On recovery he made a map, from which all references to dead goats were removed, and was struck by the fact that the lairs were located mainly in an ill defined zone about a third of the way inland (Figure 4). This discovery led to the formation of a minor party, the Priorists, who proposed the alternative strategy of concentrating the hunting effort in the lair zone regardless of the position of the dead goat. The traditionalists emphasized the value of concrete evidence, the location of the dead goat, which they deemed to be highly relevant to the particular problem of the moment, and pointed out that they were not interested in finding old lairs or anticipating future ones. Furthermore, they produced a map of their owii (Figure 5) and were able to demonstrate the existence of a goat zone which was roughly similar to the lair zone but much less well defined. They argued that if they started as usual with a dead goat, it was still highly likely that most of their searching would be carried out in the lair zone anyway.</page><page sequence="13">MODELS, INFERENCE, AND STRATEGY 469 J'A FIGURE 3 THE LEFT-HAND DIAGRAM SHOWS THE DISTRIBUTION OF VICTIMS RELATIVE, TO THE LOCATION OF THE LAIR. THE RIGHT-HAND DIAGRAM SHOWS THE DISTRIBUTION OF THE LAIRS RELATIVE TO THE LOCATION OF THE VICTIM. One evening, in order to escape from the eternal wrangling of rival factions, King Bayeplas, later known to some as Bayeplas the Foolish and to others as Bayeplas the Wise, was exceedingly over-indulgent in partaking of the local herb, and suffered the hallucination of seeing himself deposed and his kingdom ruled by three generals, one for the inner region, one for the lair zone, and one for the river zone, each general being responsible for remedying goat deaths in his particular region. This revelation ultimately led to an important reform with three substrate- gies, one for each region. The strategies as before, were based on the super- position of goat sites, but in addition made use of the radial pattern of landmarks on the island (Figure 6). In the case of the inner and outer regions the search areas were markedly eccentric. This policy, in which the strategies were conditional not only on the actual location of the particular goat site of the moment but also on wider considerations, prevailed for many years. The problem was not, however, finally solved until one day a young naturalist returning from an expedition abroad brought back with him a friendly animal, known to us as a blood-hound and to him as Instrumnens adhocus. This animal had the remarkable ability to deal with each case on its merits for it could lead the hunters from the site of a mauled goat directly to the beast's lair. The people marvelled at its superior intelligence and erected a temple in its honour. 11. That there is merit in replacing the traditional notion 'inductive in- ference' by a new concept 'inductive behaviour' has often been advocated, notably by Neyman [1957]. It is therefore not inappropriate for us to regard the rules, which enable us to make confidence assertions, as simple strategies.</page><page sequence="14">470 BIOMETRICS, SEPTEMBER 1969 To~~~~~ fi ou ideas cosie th ipl ae hr thbakrudsttins P "a known to be Normal g, 1), and x is the variable. The propositional formula, x - 2 &lt; / &lt; x + 2 }, then yields (on substituting actual values) a succession of genuine propositions which are true in just over 95% of cases in the long run frequency sense. The strategy consists in marking off an interval of 4 units centered on the observed value of x with the aim of capturing (covering) g, and a guarantee is given that the strategy will succeed in just over 95% of cases. The familiar confidence belt for this case is illustrated by the upper diagram of Figure 7. The weakness of the strategy lies in what at first sight seems to be its strength and appeal, namely that the guarantee holds whatever the true value of the parameter might be. Information about /. is irrelevant to the simple logic of the confidence argument, but is not without bearing on the question of efficiency. The case where we know nothing about /jt other than that it lies in the range - 1 to + 1 is illuminating in this respect. The original rule, though still logically 'sound' is obviously wasteful whenever x falls outside the interval -3 to +3, a rare event only when /.z lies near to 0. Modification of the rule so as to delete these obviously false assertions leads, when we adopt shortness criteria (inter- preted as the minimization of the area of the belt), to a lozenge-shaped central area with lines at g = 1 - and x i s extending outwards to + o and -fco, respectively. There are many alternatives which seem better suited to the case (-1 &lt; ,u &lt; 1), an example being shown by the middle diagram of Figure 7.</page><page sequence="15">MODELS, INFERENCE, AND STRATEGY 471 X ~~~~~~:t- FIGURE 5 MAP OF FICTITIOUS ISLAND SHOWING THE GOAT-ZONE If we try to maintain boundaries to the belt monotonic in both ,u and x (in order to ensure reasonable efficiency and uncomplicated assertions) we are unable to avoid having to prescribe the uninformative assertion that -1 &lt; 1 &lt; 1 whenever x lies near to 0. If the belt as a whole provides 95% confidence and if statements arising from the central region enjoy 100% certainty, doubts arise regarding the reliability to be attached to statements made under the rule when x is markedly different from 0. (This is indisputably so when we use the Lozenge with two lines.) The lower diagram of Figure 7 shows a modified or conditional strategy by means of which confidence assertions made when x lies in a narrow central interval enjoy 100% confidence and those made when x lies outside enjoy 90% confidence. This device is not, however, readily extended or generalized. )A~~~~~~~~~~~~~~~~~~~~I FIGURE 6 THE DISTRIBUTION OF LAIRS RELATIVE TO TEE LOCATION OF THE VICTIM-AND ITS 'RADIUS,' FOR THREE SEPARATE ZONES</page><page sequence="16">472 BTOMETRICS, SEPTEMBER 1969 &lt;(1 -x &lt;p ' 3 1' /_______________ - -- -- - 1&lt; - -1 95 so so 95 .4 v 2 2 4 FIGURE 7 CONFIDENCE BELTS FOR A WHEN X IS N(,g, 1), ACCORDING TO THE PRIOR INFORMATION ABOUT pt Because the original confidence belt provides a less efficient strategy (on intuitive grounds or on shortness criteria, for what they are worth) than do alternative diagrams in the case where knowledge about 1A exists, it is apparently suited to the case where knowledge about 1A does not exist. Since the belt has the same uniform pattern right across the infinite plane, it is apparently more appropriate to the case where our ignorance about 1A is so complete as to apply evenly to the whole range. It seems that, the moment we attempt to combine the notion of inductive behaviour with the notion of information, cryptic shades of prior or indifference distributions raise their frightening heads. In real life the way we judge a statement or react to it depends not only on the confidence we place in the source of the statement but also on the content of the statement itself. A doctor might truthfully claim to prescribe the right remedy in nearly all cases, but if by some aberration of mind he were to advise</page><page sequence="17">MODELS, INFERENCE, AND STRATEGY 473 me to take a tea-spoonful of arsenious oxide after meals, I am bound to conclude that this particular prescription is one of his rare failures, and ignore it. The idea that the reliability of a statement springs solely from its source is peculiar to mathematical thinking, where the source of all genuine soundness is believed to lie in axiom systems. Either the axioms themselves are privileged and unassailable or the statements which emerge are conditional and therefore not unreservedly informative. 12. In mathematical statistics, as in many other branches of pure mathe- matics, it is highly convenient and profitable to make a distinction between the form of a function and the parameters contained in it. At a fundamental level, however, the distinction is by no means so clearly marked, as becomes evident when we reflect on the connection between a function defined by a Taylor Series and the coefficients of the series. To maintain in practice that there is an essential difference between choosing a family of functions (the form) and choos- ing a particular member (the parameter value) is often ludicrous. For example, is the number 2 in Newton's inverse square law part of the form or not? It has indeed been claimed (by Hall) that Newtonian Theory can be made to fit the orbits of the planets better than Relativity Theory if the number 2 in the inverse square law is replaced by 2.000,000,1574. In most theoretical studies on estimation, the form of a distribution, F(x; 0), is given and the parameter value is estimated as a function of the observations (O = kF(X)). To project this pattern of thinking from theory into practice is, however, highly questionable, for how do we know the form? If prior knowledge is sufficient for the form or logical structure of a model to be postulated with a modicum of empirical justification it would be most unusual if information were not available that has bearing on the parameter values. The inferences which emerge from the conventional disregard for this considera- tion are sometimes vastly different and far less informative than those which can be reached by common sense in circumstances in which common sense still merits some respect. I take an example from fishing or trapping, a field in which man, with his long evolutionary history as a hunter, is undoubtedly a born expert. Let there be an unknown number of fish behaving virtually independently in a body of water, each with a fixed probability p of being caught in a single trial of a certain trapping procedure. Let x be the number of fish caught and removed as a result of the first trial, and y the number caught and removed as a result of the second trial. The two trials are executed independently (as, for example, if two sets of lobster pots were laid down using random numbers). Given x and y, the problem is to estimate z, the number of fish remaining. If the observed numbers, x and y, are small, the maximum likelihood esti- mates are not only very odd in themselves but the maximum likelihood attained for each fixed value of z may not change markedly over a considerable range of z, indicating that no great accuracy would be claimed for the estimate anyway. Note that the conventional approach provides us with a single abstract formulation to cover all cases which, by reason of their logical structure can be</page><page sequence="18">474 BIOMETRICS, SEPTEMBER 1960 brought within its scope, and that a single estimate results. To take a typical numerical example: if x = 20 and y = 10, then z = 6. We can easily imagine the reactions of a small boy, who with a tiny fishing net on the end of a long cane scoops up water at haphazardly chosen points as he dashes round the pond. If he caught 20 tadpoles on the first circuit and 10 on the second, would he not be justified in claiming that the pond was swarming with tadpoles? Who in their senses would argue that, even if the theoretical conditions of independence and randomness were fully satisfied, the best estimate of the number left is 6? On the other hand imagine the reactions of a professional fisherman, who casts a wide net from one side of the pond almost to the other and then trawls it almost the full length of the pond. If he caught 20 fish the first time and 10 on a second occasion much later on in the day, he would not violently disagree that 6 is a reasonable estimate of the number of watchable fish remaining. It is clear that the estimate which we make by exercising our natural judg- ment is highly dependent on our impressions about p, that this rough knowledge, conventionally considered to be less respectable than carefully checked numerical data, is highly relevant in the above circumstances to the estimation of z, and that to ignore it on doctrinaire grounds is both wasteful and negligent. The maximum likelihood estimation of z entails the simultaneous estimation of p, and all values of p between 0 and 1 are given equal consideration in the process. To my mind, it is quite wrong to allow an estimate to rest entirely on scanty numerical data whenever a wealth of background information about the order of magnitude of the parameters is at hand. 13. In his address at the Inaugural Meeting of the British Region of the Society in April 1948, Ronald Fisher spoke in most eloquent and convincing terms of the liberation of the human spirit as it learned to handle well-defined abstractions. It has been a great honour for me to address the Region at this its 75th Meeting. My concern too is for the liberation of the human spirit, but I am somewhat disturbed by the thought that the exalted status of mathematics and the veneration which it has so deservedly enjoyed over the centuries might possibly in their turn exercise their own unintentional brand of tyranny over other ways of thinking. Let us therefore never forget that man earned his living as a biologist long before he became a mathematician. MODELES, INFERENCE ET STRATEGIE RESUME La nature de la pensee mathematique, de la pens6e statistique et les relations entre elles sont examinees et on defend l'id6e que de nombreuses controverses affectant les 6tudes fonda- mentales vis A vis des probabilities, des modeles conceptuels, de l'induction et de l'explication sont obscurcies par des inadaptations du langage. On affirmed que les principes mathematiques sont seulement des substitute d'une analyse en profondeur et que la science biometrique serait b6neficiaire si l'on d6plagait l'accent de la logique vers la strategic. On suggere que les renseignements de valeur qui resultant de jugements de bon sens tendent A etre ignores lorsque les outils statistiques formels sont utilises selon des methodes conventionnelles.</page><page sequence="19">MODELS, INFERENCE, AND STRATEGY 475 REFERENCES Arber, A. [1954]. The Mind and the Eye. Cambridge. Fisher, Sir Ronald [1955]. Statistical methods and scientific induction. J. R. Statist. Soc. B 17, 69-78. Hutten, E. H. [1968]. The Ideas of Physics. Oliver &amp; Boyd, Edinburgh and London. Kneale, W. and Kneale, M. [1962]. The Development of Logic. Clarendon Press, Oxford. Ko5rner, S. [1966]. Experiences and Theory. Routledge and Kegan Paul, London. Nagel, E. and Newman, J. R. [1960]. Goedel's proof. Pp. 1668-95 in: The World of Mathematics, Vol. 3. (Ed., J. R. Newman) George Allen &amp; Unwin, London. Neyman, J. [1956]. Note on an article by Sir Ronald Fisher. J. R. Statist. Soc. B 18, 288-94. Neyman, J. [1957]. 'Inductive behaviour' as a basic concept of philosophy of science. Rev. Int. Statist. Inst. 25, 7-22. Pachman, L. [1963]. Modern Chess Strategy. Pitman, London. Reichenbach, H. [1949]. The Theory of Probability. Univ. California Press, Berkeley and Los Angeles. Russell, B. [1940]. An Inquiry into Meaning and Truth. George Allen &amp; Unwin, London. Skellam, J. G. [1955]. The mathematical approach to population dynamics. Pp. 31-46 in: The Numbers of Man and Animals. (Eds., Cragg and Pirie) Oliver &amp; Boyd, Edinburgh and London. Skellam, J. G. [1962]. The estimation of animal populations by extraction processes considered from the mathematical standpoint. Pp. 25-36 in: Progress in Soil Zoology. (Ed., Murphy) Butterworths, London. Received May 1969</page></plain_text>
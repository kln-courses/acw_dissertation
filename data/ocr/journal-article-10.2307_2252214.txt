<plain_text><page sequence="1">O)N THE POINT OF THE IMITATION GAME TURING'S suggestion for an operational test to determine whether computing machinery is performing in a way which we might be justified in calling 'intelligent' has both virtues and vices.' The following are principal: (i) it constitutes an operational definition which, given a computer terminal system, can be used as a criterion (ii) it inivolves direct comparison with a standard or reference point. We can only attack it by saying either that the human com- petitor is not a proper standard of intelligence, or by saying that the constraints imposed by the game situation necessarily obscure the display of intelligence (presumably by either competitor) (iii) it provides a means of measuring one's success in the task of creating an artificial intelligence, but does not readily admnit of any analysis which reveals necessary steps along the path to success. It characterises the goal without giving information as to the direction in which it is to be sought. Of these, (i) is a virtue to which few alternative proposals can lay claiin, (ii) is a virtue to some and a vice to others, and (iii) is a vice or at least a shortcoming which has provoked some impatience even on the part of those actively engaged in artificial intelligence work.2 The respect in which (ii) highlights a virtue is clear. It has always been possible to talk of non-human objects being intelligent or thinking, so long as we were talking metaphorically. The question Tuxing faced was that of recommending a usage which was to be literal; the machine was 'really ' thinking. It is an eminently sensible step to choose as the standard for calibrating this new use, that to which the term was previously confined in its literal sense. When reading attacks on Turing's suggestion, we may profit from bearing (ii) in mind. Does the writer contest the use of a huiman being as a standard, or does he claim that the comparison situation is inadequate, and in which respects. Richard L. Purtill,3 for example, seems to attack neither and we are automatically prompted to ask what difference the pre-programming of either contestant in the game is supposed to make to the adequacy of the test; if we consider the effect of substituting a person acting under hypnotic inistruction instead of the computer then we see that the virtue of the Turing test lies in its allowing us to ignore the arguments about human or machine determinism (as Purtill apparently wishes to). On the other hand we inay well wonder whether (ii) really gives the mnachine a fair chance. It is by no means a primary characteristic of 1 A. N. Turing,' Computing Machinery and Intelligence ', Mind, vol. lix, 1950. 2 B Meltzer, 'Bury the old War-horse!', Bulletin of the AISB Group of the British Computer Society,- no. 12, 1971. 3 R. L. Purtill, 'Beating the Imitation Game', Mind, vol. lxxx, 1971, pp. 290-294. 595</page><page sequence="2">596 P. H. MILLAR: human beings that they be intelligent. Further, if one human being were tested in this way against a range of other human beings, and if he lost pretty consistently we should still not be justified in concluding that he lacked the property of 'intelligence ' entirely. Equally if he were to beat other human beings regularly, we should normally conclude that he was ' more intelligent ' and the others less so-not that the others were faulty specimens from the production line and that the magic ingredient of intelligence had been omitted. It is a vice of the test that it proposes a ' yes '/' no ' decision in a situation where we wish to apply a conicept which is rich in differences of degree. Even more seriously, one might doubt whether those specifically human traits which we normally use to monitor intelligence, would be the right ones for monitoring the intelligence of machines. We should not apply this to Martians, and it is not thought to be neces- sary to conduct such competitions when examining the records of cosmic radio emissions for evidence of intelligent life in other stellar systems. Within the human species cultural variations lead to the inapplicability of standard intelligence tests, and we are quite pre- pared to entertain the possibility that the approach to intelligence testing in children should differ radically from that applied to adults. To put a five-year-old white Canadian and a seventy-year-old Pigmy into the Imitation Game test in order to decide a hypothesis that one or the other of them was not intelligent would be ludicrous. It would be so, not only because intelligence is a continuous variable as sketched above, but also because our touchstone for using the term about human beings is their adaptive behaviour in real-life situations. It is against this, pre-scientific, idea that psychologists still judge their own attempts at measuring intelligence. This will probably remain so until some one operationally-definable measure is found which is both universally and reproducibly applicable and is correlated with a sufficiently elaborate and powerful theory. For the moment we are left with our intuitive approach. Not only does this put particular stress on general adaptation, but a consideration of the way in which we normally apply ascriptions of intelligence will reveal that in cases where we regard items of be- haviour as indicative of intelligence, we see them in relation to the aims of the agent. Computers, however, do not have their aims pre-prograinmed; we can judge the intelligence of human beings by making assumptions about their aims-there is not so much variety, though we meet problems with ' intelligent ' obsessives and criminals but what assumptions should we make for computers?l Turing's test forces us to ascribe typical human objectives and a human cultural background to the machine, but if we are to be serious in contemplating the use of such a term we should be open-minded enough to allow computing machinery or Martians to display their 1 Cf. P. H. Millar, ' On Defining the Intelligence of Behaviour and Machines ', paper to the Second Joint Conference on Artificial Intelligence, London, 1971.</page><page sequence="3">ON THE POINT OF THE IMITATION GAME 597 intelligence by means of behaviour which is well-adapted for achiev- ing their own specific aims. Failure to allow this may be taken as a vice of the Turing test. In conclusion we may note that this final 'vice 'arises because the concepts we apply to human beings are highly interconnected. We may solve the problem either by finding some way to ascribe purposes to computing machinery and then judging their performance in the light of these and of the machine's linmitations, or by retreating somewhat and saying that the Turing test is designed to test, not whether machines can have intelligence, but whether machines can imitate human intelligence. This last question can have a 'yes '/ ' no) answer, and that answer might be interesting quite independ- ently of the debate on the applicability of anthropomorphic terms to non-humans. P. H. MILLAR</page></plain_text>
<plain_text> <page sequence="1"> Chang, J. W., &amp; Wei, H. Y. (2016). Exploring Engaging Gamification Mechanics in Massive Online Open Courses. Educational  Technology &amp; Society, 19 (2), 177–203.   Exploring Engaging Gamification Mechanics in Massive Online Open Courses    Jen-Wei Chang1* and Hung-Yu Wei1, 2  1Graduate Institute of Communications Engineering, National Taiwan University, Taiwan // 2Department of  Electrical Engineering, National Taiwan University, Taiwan // jenweichang@ntu.edu.tw // hywei@cc.ee.ntu.edu.tw  *Corresponding author    (Submitted October 2, 2014; Revised June 30, 2015; Accepted September 13, 2015)    ABSTRACT  Massive open online courses (MOOCs) have developed rapidly and become tremendously popular because of  their plentiful gamification designs, such as reputation points, rewards, and goal setting. Although previous  studies have mentioned a broad range of gamification designs that might influence MOOC learner engagement,  most gamified MOOCs fail to meet learning objectives because of a lack of research regarding suitable game  design, as well as poor rationale for or design of gamification mechanics. This study aims to explore and  identify engaging gamification mechanics for MOOC learners. We conducted a focus group interview with 25  MOOC frequent users to identify 40 gamification mechanics. This study then determined the relative  engagingness of these gamification mechanics by administering an online survey to 5,020 MOOC learners. The  results indicated that the 10 most engaging gamification mechanics accounted for more than 50% of the  engagingness. The mechanics of the Where’s Wally game is extremely engaging for MOOC learners; however,  they it is not been demonstrated in previous relevant studies. Finally, we discuss the top five engaging  gamification mechanics and their implications.    Keywords  Improving classroom teaching, Interactive learning environments, Gamification    Introduction    Massive online open courses (MOOCs) are a current trend for creating online courses for equipping learning  institutions to obtain a free and high quality teaching initiative with relevant visibility on the Internet (Johnson,  Becker, Cummins, Freeman, Ifenthaler, &amp; Vardaxis, 2013; Pellas, 2014). MOOCs refer to web platforms that allow  millions of learners to access various instructional materials and resources without the constraints of time and place,  and additional learning opportunities to supplement traditional classroom instruction, such as Coursera, Udacity, and  edX (Lin, 2010; Stoel &amp; Lee, 2003). MOOCs are interactive, online learning tools that support the learning of  specific concepts by enhancing, amplifying, and guiding the cognitive processes of learners (Altbach, 2014).  MOOCs use the increasing popularity of social networking services (SNSs) such as instant messengers (IMs),  Facebook, and Twitter, to facilitate increased social interaction and engage millions of teachers, learners, and parents  (Lin, 2010). The learner–learner and learner–instructor interaction created by MOOCs is central to knowledge  acquisition and the development of learner cognitive skills, and that interaction is intrinsic to effective instructional  practice (Lee &amp; Hammer, 2011; Tobarra, Robles-Gómez, Ros, Hernández, &amp; Caminero, 2014). MOOCs are an  alternative to traditional models of face-to-face education, and have even been viewed as a threat to traditional  educational institutions and professionals (Millard, Borthwick, Howard, McSweeney, &amp; Hargood, 2013). Thus, the  development of MOOCs has received considerable attention from both educators and learning-technology  developers.    MOOCs have been an increased focus related to learner participation of MOOCs, given rising tuition costs and  concerns regarding learner success and retention rates (Pappano, 2012). Although MOOCs are rapidly developing  and gaining enormous popularity, most of them fail to help learners to remain focused on learning content and lead to  relatively poor learning efficiency and effectiveness. This phenomenon occurs because most MOOC designs do not  provide learners with an engaging experience. Certain researchers have mentioned that MOOCs must enhance  learner digital engagement, which refers to the learning and everyday engagement of learners with available  technologies in their learning ecologies, including both daily life and school contexts (Gurung &amp; Rutledge, 2014).  Therefore, improving learner digital engagement is critical to the development of MOOCs.    Certain studies have proposed gamification as a potential solution to alleviate this problem (Grünewald, Meinel,  Totschnig, &amp; Willems, 2013; Skiba, 2013; Dicheva, Dichev, Agre, &amp; Angelova, 2015). Gamification incorporates  game mechanics into nongame settings to increase user engagement and enjoyment of a product or service, and to  ISSN 1436-4522 (online) and 1176-3647 (print). This article of the Journal of Educational Technology &amp; Society is available under Creative Commons CC-BY-ND-NC 177  3.0 license (https://creativecommons.org/licenses/by-nc-nd/3.0/). For further queries, please contact Journal Editors at ets-editors@ifets.info.  </page> <page sequence="2"> encourage users to perform certain behaviours (Hsu, Chang, &amp; Lee, 2013). Gamification essentially functions as  entertainment that causes learners to enjoy actively participating and engaging with others, such as through  reputation points, rewards, and goal setting. Kapp (2012) indicated that gamification is crucial to the development of  learning technology because numerous elements of gamification are based on educational psychology and techniques  that instructors have been using for years. Simões, Redondo, and Vilas (2013) developed a learning platform for K-6  learners, and suggested that education is an area with high potential for applying gamification because it substantially  promotes learner motivation and engagement with the learning platform. Sung and Hwang (2013) proposed a  gamification mechanism for course websites to improve the learning performance of learners in their learning  attitudes, learning motivation, self-efficacy, and learning achievements. Because of the importance of gamification to  learner engagement, certain popular MOOCs such as Coursera, Udacity, and edX effectively attract and maintain  learners through various gamification designs such as rewards and badges. These gamification design factors form  social engagement loops by providing fun and flow experience as learners interact with websites, which result in  more daily visitors and a higher average time spent on sites (Zichermann &amp; Cunningham, 2011). Consequently,  gamification plays a critical role in the success of MOOCs.    Previous studies have mentioned numerous gamification design factors for MOOCs, which can be classified into  three types of interactivity, as proposed by Moore (1989) (see Figure 1): (a) learner–content interaction, (b) learner– learner interaction, and (c) learner–instructor interaction. Numerous studies have examined the role of learner– content interaction (such as time pressure and status) in facilitating learner engagement through interacting with the  subject matter under study to construct meaning, relate it to personal knowledge, and apply it to problem solving  (Reeves &amp; Read, 2009; Deterding, Sicart, Nacke, O’Hara, &amp; Dixon, 2011). Some scholars have argued that  gamification designs should rely heavily on the mutual support and socializing of learner–learner interaction (such as  peer-tutoring and group identification) because the peer group relationship can enhance regular participation (Choi,  &amp; Kim, 2004; Williams, Ducheneaut, Xiong, Zhang, Yee, &amp; Nickell, 2006; Chen, Sun, &amp; Hsieh, 2008; Jang &amp; Ryu,  2011; Hou, 2012; Lee &amp; Chang, 2013). Other studies have examined the learner–instructor interaction process that  stimulates, enhances, and maintains learner engagement with a subject (such as rewards and goal setting; Ryan &amp;  Deci, 1996; Ducheneaut &amp; Moore, 2004; Hsu, Wen, &amp; Wu, 2009).      Figure 1. The proposed gamification in interactivity framework    Although the aforementioned studies indicated a broad range of factors that might influence gamification, they  depicted neither the actual design mechanics nor the relative engagingness among them. Gamified MOOCs fail to  meet learning objectives because of a lack of research regarding suitable game design, as well as poor rationale for or  design of gamification mechanics. The selection of crucial gamification mechanics is a multiple-criterion decision- making (MCDM) problem. Previous studies (Kahraman, Cebeci, &amp; Ulukan, 2003; Büyüközkan, 2004; Kim &amp; Nevo,  2008) have regarded the analytic hierarchy process (AHP) as an appropriate method for solving these MCDM  problems. Decision makers have to decompose the goal of the decision process into its constituent parts, progressing,  from the general to the specific perspective. The structure of AHP has to include a goal, criteria and alternative  178  </page> <page sequence="3"> levels, ordered into a hierarchy. Each item (criterion, sub-criterion or alter-native) would be divided into an  appropriate hierarchy of detail. Specifically, decision makers judge the importance of each criterion in pair-wise  comparisons, structured in matrices. The scoring of AHP is on a relative basis, comparing the importance of one  decision alternative to another. This study therefore adopted a hybrid methodology combining fuzzy logic techniques  and the analytic hierarchy process (FAHP) approach. This hybrid methodology provides a systematic tool for  analysing learners’ sense of relative engagingness gamification of gamification mechanics and assists decision  makers in decomposing the multi-criteria problem into a hierarchical model.    Identifying the engaging gamification mechanics can establish critical milestones in how to create highly effective  MOOCs. This study aims to explore the gamification mechanics of MOOCs and determine the relative engagingness  of these gamification mechanics. The results can assist MOOC website designers in designing highly engaging  MOOCs. The results also identify the engaging gamification mechanics for instructors to enhance learner’s  engagement.      Gamification in interactivity    Interactivity has been defined differently, each definition reflecting the perspectives of the group using it. Weller  (1988) describes interactivity as an event or a process that occurs when a learner actively adapts to information being  presented by a form of technology that, in turn, adapts to the learner. Merrill, Li, and Jones (1990) argue that  interactivity in learning involves real-time dynamics and mutual give-and-take between an instructional system and a  learner—especially in relation to exchanges of relevant information. Apparently, these definitions address  interactivity’s accounting for the relationships between a learner and the instructional content presented by either an  instructor or an instructional system.     All gamification factors discussed in this study includes three main components: learner–content interaction, learner– instructor interaction, and learner–learner interaction. Learner–content interaction implies learners interacting with  the subject matter under study to construct meaning, relate it to personal knowledge, and apply it to problem solving  (Reeves &amp; Read, 2009; Deterding et al., 2011). Learner–instructor interaction refers to stimulating, enhancing, and  maintaining learner motivation (Ryan &amp; Deci, 1996; Ducheneaut &amp; Moore, 2004; Hsu et al., 2009). Learner–learner  interaction refers to interaction among individual learners or among learners working in small groups (Choi &amp; Kim,  2004; Williams, Ducheneaut, Xiong, Zhang, Yee, &amp; Nickell, 2006; Chen, Sun, &amp; Hsieh, 2008; Jang &amp; Ryu, 2011;  Hou, 2012; Lee &amp; Chang, 2013).    After reviewing gamification factors from literature, we conducted an in-depth interview with five MOOC experts  who had more than 3 years of MOOC developing experience. Therefore, through this process, certain factors were  excluded because they lacked corresponding applications for MOOCs.      Learner–content interaction    Self-expression    Self-expression refers to peoples’ desire to express their autonomy and originality, which shapes their unique  personalities (Hsu et al., 2009; Antin &amp; Churchill, 2011). Learner self-expression involves a feeling of social  toleration, life satisfaction, public expression, and an aspiration to liberty. Gee (2003) conducted a study on digital- game-based learning and considered that assisting learners to build their self-identity in a virtual world can facilitate  learner engagement.       Pattern recognition     Pattern recognition refers to the dynamics of learner-content interaction most associated with unpacking website  complexity (Zichermann &amp; Cunningham, 2011). When learners seek to understand the composition of learning  content and explore hidden meanings or how complex items interact, they are seeking pattern recognition. When  179  </page> <page sequence="4"> patterns are detected, learners organize the learning content around those patterns, and typically feel intrinsically  rewarded simply for having discovered them.      Time pressure     Numerous game designs use time as a motivator for player activity and action (Reeves &amp; Read, 2009; Antin &amp;  Churchill, 2011; Hsu et al., 2013). Time pressure means MOOCs give learners a time limit to perform certain  learning behaviours to encourage them to interact heavily or to complete necessary tasks. For learners, creating time  pressure can arouse more emotional feedback and encourage greater participation because the time pressure is  connected to their goals. For example, certain learning game applications set a 5-s time limit to find targets, which  encourages users to interact heavily with the application during this period. When they fail, a new game  automatically begins 5-s later.       Status     When learners join a social group, status refers to learners’ need for recognition, fame, prestige, attention, and other  learners’ respect (Antin &amp; Churchill, 2011). Status serves as learners’ desire for recognition and encourages learners  to achieve goals enthusiastically. For MOOCs, status also represents each learner’s contribution to course resources  and participation in learning activities. Quantified evaluation is frequently used for representing design mechanics  regarding learner status.      Learner–instructor interaction    Goal setting    Goal setting is related to the most motivating goals, which are those that are just out of comfortable reach (Lin &amp;  Chang, 2005). In the learning environment, learners are motivated to pursue a specified goal because goal seeking  itself is often the primary reward (Antin &amp; Churchill, 2011). Learner goals can comprise personal level goals or  group level goals.      Instruction    When new learners (also called newbies) enter a system, certain instructions are required to teach them social norms  (Montola, Nummenmaa, Lucero, Boberg, &amp; Korhonen, 2009; Antin &amp; Churchill, 2011). Instruction functions as the  social shaping of learning activities and assists learners in mastering an entire system efficiently. Instruction is often  used for debriefing and offering feedback so that learners can understand what occurs in a learning system and how  these events support the instruction objectives (Kapp, 2012). In the context of MOOCs, instruction assists learners in  learning communication and teamwork skills as they collaborate with others.       Rewards     Rewards refer to the gamification factors that satisfy learners’ shared need and motivate them to engage in learning  activities (Ryan &amp; Deci, 1996). For example, learners are motivated to perform additional problem-solving  behaviours to receive additional rewards from websites. The reward mechanism operates by awarding points or  equivalents (e.g., frequent-flyer miles) and effectively forms a reward-behavior cycle (Hsu et al., 2009). Learners  who invest more time in the encouraged behaviours receive more from the learning system. Rewards can be  classified into intrinsic and extrinsic rewards according to their motivation. Intrinsic rewards allow learners to  engage in learning for greater self-fulfillment, and extrinsic rewards allow learners to learn for earning something  (Lee &amp; Hammer, 2011).      180  </page> <page sequence="5"> Learner–learner interaction    Reputation points     Reputation points are a mechanism that encourages learner behaviours based on the estimation of recognition held by  others inside and outside of an organization (Tulathimutte, 2006; Wolf, 2007). The concept of reputation points has  been commonly adopted on online shopping websites such as eBay and Amazon.com to increase system reliability,  reduce risks between users, and assist users in deciding whether to interact with and trust a user based on the  experiences of other users with that user. Several online games, such as World of Warcraft (WOW) and Ultima  Online (UO), use reputation points to recognize users who have fought with other players of comparable experience  levels to obtain special titles and items. Learners’ desire for reputation points can be considered a motivation for  engagement because they play harder to increase their reputation in the game.       Peer tutoring    A peer tutor is anyone who is of a similar status to the person being tutored (Höysniemi, Hämäläinen, &amp; Turkki,  2003; Huang, Yeh, Li, &amp; Chang, 2010). In an undergraduate institution, this is typically other undergraduates,  distinct from the graduate students who might be teaching writing classes; in a K-12 school, this is typically a student  from the same grade or higher.       Competition     Competition refers to a learner’s desire to compete with others, including reaching a higher score and winning over  others (Yee, 2006). When a learner competes with others, the learner with the highest score wins a prize or other  benefit. Thus, learners enjoy the well-being and continue competing with others.       Altruism     Altruism is a learner’s desire to form and maintain relationships with others through certain behaviours, such as gift- giving or asking for help (Antin &amp; Churchill, 2011). Trivers (1971) suggested that altruism is a learner’s desire to  conduct reciprocal behaviours with others based on trust. Altruists indirectly contribute to their fitness through others  who reciprocate. In the MOOC environment, support for gift-giving and charity is the most popular altruistic.  Altruism is also considered a strategy to attract new learners (Antin &amp; Churchill, 2011). For instance, learners can  receive a gift from someone that draws them into the MOOCs, and are subsequently motivated to send gifts to other  learners for reciprocity purpose, eventually creating a great acquisition loop.       Group identification     Group identification represents learners’ affective and cognitive loyalty to a learner group (Lee &amp; Chang, 2013;  Bergami, &amp; Bagozzi, 2000; Jo, Moon, Garrity, &amp; Sanders, 2007; Pisan, 2007). Learners with higher group  identifications are often willing to remain in a group permanently and to strive toward goals, obey the guild  manager’s commands, and devote themselves to group affairs (Seay, Jerome, Lee, &amp; Kraut, 2004).       Peer appraisal    Peer appraisal has been historically used for logistical, pedagogical, metacognitive, and affective benefits (Sadler &amp;  Good, 2006; Conejo, Barros, Guzmán, &amp; Garcia-Viñas, 2013), and offers a promising solution that can scale the  grading of complex assignments in courses with tens or even hundreds of thousands of students. When using  MOOCs, instructors cannot review essays or other open-ended work from thousands of students as they do in smaller  class settings. To remove this limitation, MOOC providers are looking to peer-based assessments, in which students  learn to review the work of their cohorts.  181  </page> <page sequence="6"> Method and result      Identifying gamification mechanics for MOOCs    Materials     The most highly subscribed MOOCs, Coursera, Udacity, and edX, were surveyed in this study. These three MOOCs  represent online learning platforms and have myriads of users worldwide.      Subjects and procedures    Twenty-five frequent users including fifteen distance-learning course teachers, four distance-learning students, and  six MOOC developers were invited to participate in the interview. All of them have more than two years’ experience  in using MOOCs. Participants were asked to identify and discuss gamification mechanics of MOOCs based on the  gamification factors. The interview questions and record are in the Appendix 1.      Result     To improve gamification mechanics, three human–computer interaction experts with more than 7 years of experience  were invited to confirm all of the garnered mechanics. Finally, 40 gamification mechanics were developed following  the in-depth interviews, as shown in Appendix 2. To depict the relationship between gamification elements and  demonstrate and different levels, a concept map was proposed in Figure 2.      Figure 2. The concept map of all gamification mechanics in MOOCs              182  </page> <page sequence="7"> Determining the relative engagingness of gamification mechanics    Questionnaire design and data collection     Shown in Appendix 3, AHP questionnaire was developed to gather MOOC learner assessments of the relative  engagingness of the gamification mechanics in a pairwise comparison-data input format. Each item was assessed  using a 9-point ratio scale, as suggested by Saaty (1990). Each item was scored using a scale comprising equally  engaging, moderately engaging, strongly engaging, very strongly engaging, and extremely engaging. This study  conducted an online survey to gather data. The survey was advertised on four MOOCs and e-learning online forums  in Taiwan to recruit volunteers to participate in this study. After excluding volunteers with incomplete data, 5020  users’ data were collected in this study. Table 1 summarizes demographic data of all subjects. Following primary data  analysis, we deleted incomplete questionnaires and outlier data, leaving 4,891 valid samples (97.43%) for use in this  study.    Table 1. The demographic information of participants in this study    Participants (N = 296) N %  Gender Male 2437 48.55%   Female 2583 51.45%  Frequently-used MOOCs Cousera (https://www.coursera.org/) 2514 50.08%   Proera (www.proera.com.tw/) 2216 44.14%   Taiwan open courseware (www.tocwc.org.tw/) 2057 40.98%   ewant (http://www.ewant.org) 1782 35.50%   Open edX (https://courses.openedx.tw) 1521 30.30%   Share Course (http://www.sharecourse.net/) 1305 26.00%   Taiwanlife (Taiwanlife.org) 1227 24.44%   NTU MOOC (http://www.ntumooc.org/) 963 19.18%   Udacity (https://www.udacity.com) 802 15.98%  edX (https://www.edx.org) 775 15.44%   Others 750 14.94%  MOOCs use experience 1-12 months 655 13.05%  12-36 months  2983 59.42%  &gt;36 months 1382 27.53%  Average age  23.02 years old (Std. = 2.11).        Data analysis    Our proposed fuzzy-AHP approach included seven steps. We first used triangular fuzzy numbers to construct the  fuzzy comparison matrix, as shown in Table 2. Second, we integrated the collected user assessments of each  gamification mechanic, design factor, and design component by using the fuzzy average method proposed by  Buckley (1985). Third, we computed the fuzzy weight of each gamification mechanic by using the approximation  method introduced by Buckley (1985). Fourth, the center of gravity method, a defuzzifying method proposed by  Tzeng and Teng (1993), was performed to defuzzify the weight of each gamification mechanic. Fifth, we normalized  the weights of all gamification mechanics. Sixth, we aggregated each level of the proposed gamification framework  and calculated the relative engagingness value of the fuzzy weight for each mechanic at factor levels. Finally, we  computed the consistency index (CI) and consistency ratio (CR) for each fuzzy comparison matrix. The detailed  process of data collection and the proposed fuzzy-AHP model are in Appendix 4.    Table 2. Membership function and definitions of fuzzy numbers  Fuzzy number Membership  Definition  ~1 ~   (1,1,2) equally engaging  2  (1,2,3) between equally and moderately engaging ~3 ~   (2,3,4) moderately engaging  4  (3,4,5) between moderately and strongly engaging  183  </page> <page sequence="8"> ~5  (4,5,6) strongly engaging ~6 ~   (5,6,7) between strongly and very strongly engaging  7 ~   (6,7,8) very strongly engaging  8  (7,8,9) between very strongly and extremely engaging ~9  (8,9,10)  extremely engaging      Result     The weight of all gamification mechanics is shown in Appendix 5. Among the 40 engaging gamification mechanics,  the top 10 most engaging mechanics, listed in Table 3, can account for more than 50% (51.68%) of engagingness. In  our study, the CR was 0.072 ≤ 0.1, then the output of the pair-wise comparison can be proven sufficiently consistent.    Table 3. Top10 Most engaging gamification mechanics in MOOCs  Gamification mechanics Contribution (%) Accumulative contribution (%)  GM1: Virtual goods     9.52 9.52  GM23: Redeemable points 8.45 17.97  GM31: Team leaderboards  7.34 25.30  GM5: Where’s Wally game  4.76 30.06  GM13: Trophies and badges  4.61 34.67  GM38: Peer grading 4.15 38.82  GM40: Peer emoticon feedback  3.93 42.74  GM6: Memory-game interactions  3.31 46.05  GM9: Check points  2.89 48.94  GM24:Skill points  2.74 51.68      Discussion and implications    In this section, we discuss the top five engaging mechanics following the aforementioned analysis. The practical  implication for both instructor and MOOC website designer is also discussed (see Table 4).    Table 4. The implication for Instructor and MOOC website designer  Top five Instructor MOOC website designer  gamification  mechanics  Virtual goods • Quantify learner’s contribution to • Virtual goods exchange interface  earn virtual goods • Display virtual goods on personal page  • Special challenge for special virtual   goods  Redeemable • Clear redeemable point’s rules. • Dialogues should not contain information that is  points • Integrate the redeemable points into irrelevant or unnecessary.   the course content. • Every extra unit of information in a dialogue  • Allow learners use the points competes with the relevant units of information  accumulated from MOOCs to redeem and diminishes their relative visibility.   real world’ rewards e.g., course • Redeemable points status.   material, items, toys, and game • Reminder learners how far they can proceed to  software to increase course next level of rewards.  participation.  Team • Make simple and visible comparisons • Local view: allow learners immediately see how  Leaderboards between learner’s teams. they rank among their friends and classmates.    • Quantify the team participation • Global view: allows learners to see how they  rank among all learners within the system as a  whole.   184  </page> <page sequence="9"> Where’s Wally • Link the problem solving process • Give obvious cues as learners are stuck.  game with Where’s Wally. • Design various faintly discernible cues.  • Develop learner’s pattern • Display different cues according to learner’s skill  recognition, critical thinking, and level.   sense-making skills.  Trophies and • Immediately reward learner’s • Trophies and badges ladder  badges achievement using trophies and • Display the trophies and badges information  badges. inside the learner’s personal page and  • Develop milestone badges to enhance information portion of the comment page.   learner’s motivation by collecting the  badges.     Among the five most engaging gamification mechanics of MOOCs, virtual goods were the most engaging  gamification mechanic. Such virtual gifts can be linked to leaner’s achievement motivations. The result means  learners engage more with the MOOC in order to earn greater achievement. This finding is consistent with Denny’s  (2013) work. He reported on a large-scale experiment measuring the impact of virtual achievement in e-learning  applications and found the virtual achievement has a positive motivational effect on learner’s engagement. His result  also showed learners prefer earing and owing virtual goods. The practical implication for instructor is to quantify  learner’s contribution and give learners virtual goods if they achieve a certain level.     Instructors can also provide special challenge for them to earn special virtual goods. Virtual goods work as positive  reinforcement for learner’s good performance or regular participation. The practical implication for MOOC website  designer is to provide a virtual goods exchange interface and display the earned virtual goods in the learner’s  personal page.    The second most engaging gamification mechanic was redeemable points, which indicate the redeemable points  engage learners by supporting their personal achievement motivation. This finding is consistent with Grünewald,  Meinel, Totschnig, and Willems (2013)’s work. Grünewald and his colleague (2013) collected 2726 active MOOC  participants’ data to investigate multiple learning styles and found redeemable points engage learners by  strengthening the social incentives. From instructor’s perspective, the implication is to integrate the redeemable  points into the course content. Instructors can allow learners use the points accumulated from MOOCs to redeem real  world’ rewards e.g., course material, items, toys, and game software to enhance the course participation. From  MOOC website designer perspective, they should design simple and clear redeem user interface to assist learners  redeem gifts. Dialogues should not contain information that is irrelevant or unnecessary. Every extra unit of  information in a dialogue competes with the relevant units of information and diminishes their relative visibility. The  redeem interface also have to display the redeemable points status and reminder learners how far they can proceed to  next level of rewards.     The third most engaging gamification mechanic was team leaderboards, which means that learner-learner interaction  such as the comparison and competition of teams receives more attention for MOOC learners compared with  individual leaderboards. The visible competition among teams encourages team members’s highly engagement. This  result is consistent with Chiu, Hsu, and Wang’s (2006) work. They examined knowledge sharing in a virtual learning  community and observed that visible competition among teams substantially increase learners’ reliance on team  effort rather than on their own effort, and thus engage learners to cooperate with team members. From instructor’s  perspective, the implication is the instructor should quantify learner’s team participation and then encourage simple  and visible comparisons between learner’s teams. The practical implication for MOOC website designer should  provide two types of team leaderboards: local and global view. A local view allow learners immediately see how they  rank among their friends and classmates. A global view allows the learners to see how they rank among all learners  within the system as a whole, it will assist learners to check the actual learning performance and establish their  learning goals.     The Where’s Wally game was the fourth most engaging gamification mechanic. This result means learners seek to  understand the world around them, and attempt to discover the hidden meaning or complex items interact in  MOOCs. The problem-solving process of the Where's Wally game also provides strong motivation for learner  engagement, a finding that has not been revealed in the gamification study. In previous learning studies, Where’s  Wally is considered as a type of wordless figure and which is highly correlated to visual literacy for learners  185  </page> <page sequence="10"> (Jalongo, Dragich, Conrad, &amp; Zhang, 2002; Crawford &amp; Hade, 2000). The wordless picture are considered as an  effective learning tool which encourages readers learning behaviour including sense-making, problem solving,  critical thinking, etc. (Avgerinou &amp; Ericson, 1997). Jalongo et al. (2002) also considered the wordless pictures  connect learner’s visual literacy skills, culture literacy (learning the characteristics and expectations of social groups)  and literacy with print. Crawford and Hade (2000) investigated children’s reading of wordless picture books, found  the children make sense of wordless picture books by using sense-making processes. They also found the wordless  picture books let children construct meaning with prior knowledge and experiences, attention to intertextual cues,  multiple perspective-taking, reliance upon story language and rituals, and the implementation of active, playful  behaviours as part of the reading process. Therefore, we consider Where’s Wally game engage learners by connecting  learner’s visual literacy, which contains critical thinking, learning, construct meaning, creative expression, and  aesthetic enjoyment. We also believe the Where’s Wally is the important design features for MOOC because the fact  that a very high portion of all sensory learning is visual. From instructor’s perspective, the implication is linking the  problem solving process with Where’s Wally and developing learner’s visual literacy. Instructors can utilize this  visually engaging mechanics to engage learners in the course. The practical implication for MOOC website designer  is to design various faintly discernible cues (e.g., the sparkling star or exclamation mark) and display different cues  according to learner’s skill level. System can also give obvious cues as learners are stuck.    Finally, trophies and badges, the fifth most engaging mechanic, mean that learners are engaged by collecting the  trophies and badges provided by MOOCs. Most learners prefer to collect as more types of trophies and badges as  possible. This finding is consistent with Law and his colleagues (2011). They examined the relationship between  gamification and the sustainability of mobile learning applications, and proposed that a badge collection is a crucial  enhancer of users’ engagement. Learners who enjoy collecting various types of badges are likely to engage in using  mobile applications. From instructor’s perspective, the implication is immediately reward learner’s achievement  using trophies and badges and develop milestone badges to enhance learner’s motivation by collecting the badges.  The practical implication for MOOC website designer is to design trophies and badge ladder and describe the  particularity of them. Moreover, the designer should display the trophies and badges information inside the learner’s  personal page and information portion of the comment page.       Conclusion and suggestions    In this study, we identified engaging gamification mechanics that influence learners’ engagement in MOOCs. We  proposed an empirical approach to identify 40 engaging gamification mechanics for MOOCs, among which the  mechanic of the Where's Wally game has not been revealed in previous gamification studies. A reasonable  explanation might be that learners tend to try something challenging and become immersed in the problem-solving  process.    This research has both theoretical and practical contributions. From a theoretical standpoint, although previous  studies have mentioned certain gamification design factors, they have not provided a conceptual framework based on  a theoretical foundation. Therefore, they have not covered engaging gamification factors comprehensively or  identified unnecessary factors. Most studies have failed to provide empirical validation of the gamification factors  they have discussed. To solve these problems, we constructed a hierarchical framework of gamification and  systematically validated the engaging mechanics.    Previous studies have not established a relation between conceptual factors and concrete gamification mechanics.  Therefore, even if MOOC operators know which factors are engaging, they do not know how to implement the  concepts into practical system mechanics. This study presents a systematic framework of gamification factors and  mechanics, which can assist MOOC operators to improve their users’ engagement. Moreover, this paper also  provides MOOC operators with empirical data that show which gamification mechanics warrant investigation.    Future research efforts may focus on the connection between the use of gamification mechanics and learning  outcomes, since greater numbers of gamification mechanics do not necessary guarantee better learning performance.   The limitations of this research should be noted. We do not suggest that the explored gamification mechanics we  have discussed represent an exhaustive list. Future research can use various methodologies, such as longitudinal  studies, focus groups, and the ethnography approach, to identify other potential gamification mechanics for MOOCs.    186  </page> <page sequence="11"> R eferences  Altbach, P. G. (2014). MOOCs as Neocolonialism: Who controls knowledge? International Higher Education, (75), 5-7.  Antin, J., &amp; Churchill, E. F. (2011). Badges in social media: A Social psychological perspective. In CHI 2011 Gamification  Workshop Proceedings (pp. 1-4). New York, NY: ACM.  Avgerinou, M., &amp; Ericson, J. (1997). A Review of the concept of visual literacy. British Journal of Educational Technology, 28(4),  280-291.  Bergami, M., &amp; Bagozzi, R. P. (2000). Self-categorization, affective commitment and group self-esteem as distinct aspects of  social identity in the organization. British Journal of Social Psychology, 39(4), 555-577.  Buckley, R. C. (1985). Distinguishing the effects of area and habitat type on island plant species richness by separating floristic  elements and substrate types and controlling for island isolation. Journal of Biogeography, 527-535.  Büyüközkan G. (2004). Multi-criteria decision making for e-marketplace selection. Internet Research, 14(2), 139-154.  Chen, C. H., Sun, C. T., &amp; Hsieh, J. (2008). Player guild dynamics and evolution in massively multiplayer online games. Cyber  Psychology &amp; Behavior, 11(3), 293-301.  Chiu, C. M., Hsu, M. H., &amp; Wang, E. T. (2006). Understanding knowledge sharing in virtual communities: An Integration of  social capital and social cognitive theories. Decision support systems, 42(3), 1872-1888.  Choi, D., &amp; Kim, J. (2004). Why people continue to play online games: In search of critical design factors to increase customer  loyalty to online contents. Cyber Psychology &amp; Behavior, 7(1), 11-24.  Conejo, R., Barros, B., Guzmán, E., &amp; Garcia-Viñas, J. I. (2013). A Web based collaborative testing environment. Computers &amp;  Education, 68, 440-457.  Crawford, P. A., &amp; Hade, D. D. (2000). Inside the picture, outside the frame: Semiotics and the reading of wordless picture books.  Journal of Research in Childhood Education, 15(1), 66-80.  Deterding, S., Sicart, M., Nacke, L., O’Hara, K., &amp; Dixon, D. (2011). Gamification. Using game-design elements in non-gaming  contexts. In CHI’11 Extended Abstracts on Human Factors in Computing Systems (pp. 2425-2428). New York, NY: ACM.  Denny, P. (2013). The effect of virtual achievements on student engagement. In W. E. Mackay et al. (Ed.), Conference on Human  Factors in Computing Systems (CHI 2013), (pp. 763–772). Paris, France  Dicheva, D., Dichev, C., Agre, G., &amp; Angelova, G. (2015). Gamification in education: A Systematic mapping study. Educational  Technology &amp; Society, 18(3), 1-14.  Ducheneaut, N., &amp; Moore, R. J. (2004). The Social side of gaming: a study of interaction patterns in a massively multiplayer  online game. In Proceedings of the 2004 ACM conference on Computer supported cooperative work (pp. 360-369). New York,  NY: ACM.  Gee, J. P. (2003). What video games have to teach us about learning and literacy. Computers in Entertainment (CIE), 1(1), 20-20.  Grünewald, F., Meinel, C., Totschnig, M., &amp; Willems, C. (2013). Designing MOOCs for the support of multiple learning styles.  In D. Hernández-Leo, T. Ley, R. Klamma &amp; A. Harrer (Eds.), Scaling up Learning for Sustained Impact (pp. 371-382).  doi:10.1007/978-3-642-40814-4_29  Gurung, B., &amp; Rutledge, D. (2014). Digital learners and the overlapping of their personal and educational digital engagement.  Computers &amp; Education, 77, 91-100.  Hou, H. T. (2012). Exploring the behavioral patterns of learners in an educational massively multiple online role-playing game  (MMORPG). Computers &amp; Education, 58(4), 1225-1233.  Höysniemi, J., Hämäläinen, P., &amp; Turkki, L. (2003). Using peer tutoring in evaluating the usability of a physically interactive  computer game with children. Interacting with Computers, 15(2), 203-225.  Hsu, S. H., Chang, J. W., &amp; Lee, C. C. (2013). Designing attractive gamification features for collaborative storytelling websites.  Cyberpsychology, Behavior, and Social Networking, 16(6), 428-435.  Hsu, S. H., Wen, M. H., &amp; Wu, M. C. (2009). Exploring user experiences as predictors of MMORPG addiction. Computers &amp;  Education, 53(3), 990-999.  187  </page> <page sequence="12"> Huang, C. C., Yeh, T. K., Li, T. Y., &amp; Chang, C. Y. (2010). The Idea storming cube: Evaluating the effects of using game and  computer agent to support divergent thinking. Educational Technology &amp; Society, 13(4), 180-191.  Jang, Y., &amp; Ryu, S. (2011). Exploring game experiences and game leadership in massively multiplayer online role‐playing games.  British Journal of Educational Technology, 42(4), 616-623.  Jalongo, M. R., Dragich, D., Conrad, N. K., &amp; Zhang, A. (2002). Using wordless picture books to support emergent literacy. Early  Childhood Education Journal, 29(3), 167-177.  Jo, S., Moon, J., Garrity, E., &amp; Sanders, G. L. (2007). Massively multiplayer online role-playing games (MMORPGs) and  commitment behavior: An Integrated model. In Proceedings of Americas Conference On Information Systems (AMCIS) 2007  (Paper 70). Retrieved from http://aisel.aisnet.+org/amcis2007/70  Johnson, L., Adams Becker, S., Cummins, M., Freeman, A., Ifenthaler, D., &amp; Vardaxis, N. (2013). Technology outlook for  Australian tertiary education 2013–2018: An NMC horizon project regional analysis. Austin, TX: The New Media Consortium.  Kapp, K. M. (2012). The Gamification of learning and instruction: Game-based methods and strategies for training and  education. San Francisco, CA: John Wiley &amp; Sons.  Kahraman, C., Cebeci, U. &amp; Ulukan, Z. (2003). Multi-criteria supplier selection using FUZZY AHP. Logistics Information  Management, 16(6), 382-394.  Kim, H. M. &amp; Nevo, S. (2008). Development and application of a framework for evaluating multi-mode voting risks. Internet  Research, 18(1), 121-135.  Law, F. L., Mohd Kasirun, Z., &amp; Gan, C. K. (2011). Gamification towards sustainable mobile application. In 5th Malaysian  Conference in Software Engineering (MySEC) (pp. 349-353). doi:10.1109/MySEC.2011.6140696  Lee, C. C., &amp; Chang, J. W. (2013). Does trust promote more teamwork? Modeling online game players’ teamwork using team  experience as a moderator. Cyberpsychology, Behavior, and Social Networking, 16(11), 813-819.  Lee, J. J., &amp; Hammer, J. (2011). Gamification in education: What, how, why bother? Definitions and uses. Exchange  Organizational Behavior Teaching Journal, 15(2), 1–5.  Lin, S. C., &amp; Chang, J. N. (2005). Goal orientation and organizational commitment as explanatory factors of employees’ mobility.  Personnel Review, 34(3), 331-353.  Lin, H. F. (2010). An Application of fuzzy AHP for evaluating course website quality. Computers &amp; Education, 54(4), 877-888.  Merrill, M. D., Li, Z., &amp; Jones, M. K. (1990). Second generation instructional design (ID2). Educational Technology, 30(2), 7-14.  Millard, D. E., Borthwick, K., Howard, Y., McSweeney, P., &amp; Hargood, C. (2013). The HumBox: Changing educational practice  around a learning resource repository. Computers &amp; Education, 69, 287-302.  Montola, M., Nummenmaa, T., Lucero, A., Boberg, M., &amp; Korhonen, H. (2009, September). Applying game achievement  systems to enhance user experience in a photo sharing service. In Proceedings of the 13th International MindTrek Conference:  Everyday Life in the Ubiquitous Era (pp. 94-97). ACM.  Moore, M. G. (1989). Editorial: Three types of interaction. The American Journal of Distance Education, 3(2), 1–6.  Pappano, L. (2012). The Year of the MOOC [Online article]. The New York Times. Retrieved from  http://www.nytimes.com/2012/11/04/education/edlife/massive-open-online-courses-are-multiplying-at-a-rapid-pace.html?_r=0  Pellas, N. (2014). The Influence of computer self-efficacy, metacognitive self-regulation and self-esteem on student engagement  in online learning programs: Evidence from the virtual world of Second Life. Computers in Human Behavior, 35, 157-170.  Pisan, Y. (2007). My Guild, my people: Role of guilds in massively multiplayer online games. In Proceedings of the 4th  Australasian conference on Interactive entertainment (Article No. 20). Melbourne, Australia: RMIT University.  Reeves, B., &amp; Read, J. L. (2009). Total engagement: Using games and virtual worlds to change the way people work and  businesses compete. Boston, MA: Harvard Business Press.  Ryan, R. M., &amp; Deci, E. L. (1996). When paradigms clash: Comments on Cameron and Pierce’s claim that rewards do not  undermine intrinsic motivation. Review of Educational Research, 66(1), 33-38.  Saaty, T. L. (1990). How to make a decision: The Analytic hierarchy process. European journal of operational research, 48(1), 9- 26.  Sadler, P. M., &amp; Good, E. (2006). The Impact of self-and peer-grading on student learning. Educational assessment, 11(1), 1-31.  188  </page> <page sequence="13"> Seay, A. F., Jerome, W. J., Lee, K. S., &amp; Kraut, R. E. (2004). Project massive: A Study of online gaming communities. In CHI’04  extended abstracts on Human factors in computing systems (pp. 1421-1424). New York, NY: ACM.  Simões, J., Redondo, R. D., &amp; Vilas, A. F. (2013). A Social gamification framework for a K-6 learning platform. Computers in  Human Behavior, 29(2), 345-353.  Skiba, D. J. (2013). On the horizon: The Year of the MOOCs. Nursing education perspectives, 34(2), 136-137.  Stoel, L., &amp; Lee, K. H. (2003). Modeling the effect of experience on student acceptance of Web-based courseware. Internet  Research, 13(5), 364-374.  Sung, H. Y., &amp; Hwang, G. J. (2013). A Collaborative game-based learning approach to improving students’ learning performance  in science courses. Computers &amp; Education, 63, 43-51.  Tobarra, L., Robles-Gómez, A., Ros, S., Hernández, R., &amp; Caminero, A. C. (2014). Analyzing the students’ behavior and relevant  topics in virtual learning communities. Computers in Human Behavior, 31, 659-669.  Trivers, R. L. (1971). The Evolution of reciprocal altruism. Quarterly review of biology, 35-57.  Tulathimutte, T. (2006). Trust, cooperation, and reputation in massively multiplayer online games. Game Research, 7, 53-65.  Tzeng, G. H., &amp; Teng, J. Y. (1993). Transportation investment project selection with fuzzy multi-objectives. Transportation  Planning and Technology, 17(2), 91-112.  Weller, H. G. (1988). Interactivity in microcomputer-based instruction: Its essential components and how it can be enhanced.  Educational Technology, 28(2), 23-27.  Williams, D., Ducheneaut, N., Xiong, L., Zhang, Y., Yee, N., &amp; Nickell, E. (2006). From tree house to barracks the social life of  guilds in world of warcraft. Games and culture, 1(4), 338-361.  Jalongo, M. R., Dragich, D., Conrad, N. K. &amp; Zhang, A. (2002). Using wordless picture books to support emergent literacy. Early  Childhood Education Journal, 29(3), 167–177.   Wolf, K. D. (2007). Communities of practice in MMORPGs: An Entry point into addiction? In C. Steinfield, B. T. Pentland, M.  Ackerman, &amp; N. Contractor (Eds.), Communities and Technologies (pp. 191-208). London, UK: Springer London.  Yee, N. (2006). Motivations for play in online games. CyberPsychology &amp; behavior, 9(6), 772-775.  Zichermann, G., &amp; Cunningham, C. (2011). Gamification by design: Implementing game mechanics in web and mobile apps.  Sebastopol, CA: O’Reilly Media, Inc.   189  </page> <page sequence="14"> Appendix 1. Information of focus group interview    1. Focus group semi-structured questions       Learner-learner interaction    (1). What learner-learner interaction that you have experienced with the use of MOOCs is the most important in  your learning?   (2). What are the engaging gamification designs for learner-learner interaction that you have experienced with the  use of MOOCs? Do you have any example?   (3). What further gamification designs for learner-learner interaction in MOOC is required?      Learner-content interaction   (4).What learner-content interaction that you have experienced with the use of MOOCs is the most important in  your learning?  (5).What are the engaging gamification designs for learner-content interaction that you have experienced with the  use of MOOCs? Do you have any example?  (6). What further gamification designs for learner-content interaction in MOOC is required?       Learner-instructor interaction  (7).What learner-instructor interaction that you have experienced with the use of MOOCs is the most important  in your learning?  (8). What are the engaging gamification designs for learner-instructor interaction that you have experienced with  the use of MOOCs? Do you have any example?  (9). What further gamification designs for learner-instructor interaction in MOOC is required?       2. The record of Focus group interview process      Figure 1. The picture of focus group interview     190  </page> <page sequence="15">   Figure 2. The picture of focus group interview       Figure 3. The picture of focus group interview       Appendix 2. The definition of gamification mechanics in MOOCs    Types of Gamification Gamification Definition  gamification factors mechanics  Learner–content Self-expression GM1: Virtual goods Virtual goods are nonphysical objects and  interaction      money purchased for use in online  communities or online games (e.g., new  avatar options, clothes, weapons, and items).  .    GM2: Personal spaces Personal space is the region surrounding a  person that they regard as psychologically  theirs.    GM3: Avatars Avatars refer to the virtual personality  connected with the screen name or handle of  an Internet learner.    Pattern recognition GM4: Revealing, Revealing, hiding, and combining items are  hiding, and combining web pages contains learning items that  items enable learners to explore and reorganize.     GM5: Where's Wally Learners are challenged to find a specific  game learning object hidden in the website.    GM6: Memory-game Memory-game interactions are game  interactions interactions in which a set of cards are laid  face down on a surface and two objects are  191  </page> <page sequence="16"> flipped face up after each turn. The objective  of the game is to turn over pairs of matching  objects.   Time pressure GM7: Animated An animated countdown timer is a interface  countdown timer design that counts down in seconds, minutes,  hours, and days to any date.    GM8: Time bar A time bar is a graphical representation that  shows the beginning, the duration, and the  end of the learning course in MOOCs.    GM9: Check points Learners can receive immediate feedback as  they progress in the learning tasks.   Status GM10: Experience Learners can accumulate quantitative data to  points demonstrate their mastery of skills or  knowledge.    GM11: VIP VIPs are specific learners who receive high  attention as they log on MOOCs.    GM12: Level-up Level-up gives learner’s notifications as they  achieve certain skill or knowledge level.  Learner– Goal setting GM13: Trophies and Trophies and badges are the most common  instructor badges recognition items found in games because of  interaction their versatility and flexibility.    GM14: Progress bars Progress bar is a visualized representation  can be used to show a user how far along  he/she is in a process.    GM15: Percentage Percentage shows the progress ratio of  learners who have completed a specific goal.   Instruction GM16: Personate Personate helper is an anthropomorphic robot  helper that guides new learners to become familiar  with the system.    GM17: Cartoon guide Cartoon guides are characters that instruct  learners as they enter the system.    GM18: Billboard Billboards are guidelines that guide learner  by providing instructional information.   Rewards GM19: Virtual gifts Virtual gifts are nonphysical objects   that  work as positive reinforcer.    GM20: Virtual Virtual currency is a type of unregulated,  currency digital money that is issued and typically  controlled by its developers, and used and  accepted among the members of a specific  virtual community.    GM21: Praise Praise is the act of making positive  statements about a person, object, or idea,  either in public or privately.    GM22: Recognition Learners can receive recognition from others  based on their excellent learning  performance.  Learner–learner Reputation points GM23: Redeemable Redeemable points are what learners earn  interaction points and use to redeem virtual items/ rewards.    GM24: Skill points Skill points are assigned for specific   activities within the game and are tangential   to both XP and RP. They are a bonus set of  points that allow players to gain experience  or rewards for activities alongside the core.  192  </page> <page sequence="17">   GM25: Talent trees Talent trees are one of the categories in   which a learner’s talents are divided. It is so   named because the talents branch out, similar   to a tree structure.    GM26: Karma points Karma points do not allow players to gain   benefit from keeping their karma points, only   from sharing them. Karma points are   frequently given as part of a regular grind, or   check-in behavior, for example: 3 karma   points are earned for each monthly check in.   Peer tutoring GM27: Peer-led team Peer-led team learning is a model of teaching  learning undergraduate science, math, and   engineering courses that introduces peer-led   workshops as an integral part of a course.   Students who have performed strongly in a   course are recruited to become peer leaders.    GM28: Peer mentoring Peer mentoring is a form of mentorship that   typically occurs between a person who has   lived through a specific experience (peer   mentor) and a person who is new to that   experience (the peer mentee).      GM29: Learning Learning forums are platforms that enable  forums learners to share learning tips, experience,   resources, and knowledge.   Competition GM30: Hall of fame A hall of fame is a structure housing   memorials to famous or illustrious learners.    GM31: Team Team leaderboards list winners’ teams and  leaderboards encourage competitions among all learning   groups.    GM32: Individual Individual leaderboards rank MOOC learners  leaderboards according to their learning achievement and   list individual winners among all   competitors.   Altruism GM33: Gift giving Gift giving is an expression of love or   friendship by giving virtual gifts/ items to  other learners.    GM34: Gift Gift recommendation provides leaners with  recommendation appropriate gift suggestions for social   interaction purposes.      GM35: Gift reminders Gift reminders is used for calling attention to   the gift-giving behavior of learners.   Group identification GM36: Self-organized Self-organized quest teams allow learners to  quest teams organize quest teams to solve complex quests   or questions.    GM37: List of family Lists of family members allow learners to  members organize and join learning community to   interact and learn together.   Peer appraisal GM38: Peer grading Peer grading means a peer arrangement in   which people consider the amount, level,   value, worth, quality, or success of the   products or outcomes of learning peers of   similar status.    193  </page> <page sequence="18">   GM39: Peer comments Peer comments are the constructive feedback   provided by other learning community   members.    GM40: Peer emoticon Peer emoticon feedback refers to a meta- feedback communicative pictorial representation of a   facial expression that allows learners to   interact with each other.      Appendix 3. FUZZY AHP PAIRWISE QUESTIONNAIRE    1. Introduction:    Please compare in pairs the relative engagingness between two given item statements regarding the engaging  gamification mechanics. If a criterion (or sub-criterion) on the left is more engaging than the one matching on the  right, put your check mark to the left of the engagingness “Equal” under the engaging level you prefer. If a criterion  (or sub-criterion) on the left is less engaging than the one matching on the right, put your check mark to the right of  the engagingness ‘‘Equal” under the engaging level you prefer. The notations of relative engagingness are following:   (1) Absolutely – Absolutely more engaging  (2) Very strongly – Very strongly more engaging (3) Strongly –  Strongly more engaging  (4) Weakly – Weakly more engaging  (5) Equally – Equally engaging      2. The definition of gamification:    Gamification means game mechanics into nongame settings to increase user engagement and enjoyment of a product  or service, and to encourage users to perform certain behaviors. Gamification essentially functions as entertainment  that causes learners to enjoy actively participating and engaging with others, such as through reputation points,  rewards, and goal setting.      3. The definition of gamification mechanics in Massive open online courses (MOOCs)    Types of Gamification Gamification Definition  gamification factors mechanics  Learner–content Self- GM1: Virtual goods Virtual goods are nonphysical objects and money  interaction      expression purchased for use in online communities or online  games (e.g., new avatar options, clothes, weapons,  and items).    GM2: Personal Personal space is the region surrounding a person  spaces that they regard as psychologically theirs.    GM3: Avatars Avatars refer to the virtual personality connected  with the screen name or handle of an Internet  learner.    Pattern GM4: Revealing, Revealing, hiding, and combining items are web  recognition hiding, and pages contains learning items that enable learners to  combining items explore and reorganize.     GM5: Where's Wally Learners are challenged to find a specific learning  game object hidden in the website.    GM6: Memory-game Memory-game interactions are game interactions in  interactions which a set of cards are laid face down on a surface  and two objects are flipped face up after each turn.  The objective of the game is to turn over pairs of  matching objects.   Time GM7: Animated An animated countdown timer is a interface design  pressure countdown timer that counts down in seconds, minutes, hours, and  194  </page> <page sequence="19"> days to any date.    GM8: Time bar A time bar is a graphical representation that shows  the beginning, the duration, and the end of the  learning course in MOOCs.    GM9: Check points Learners can receive immediate feedback as they  progress in the learning tasks.   Status GM10: Experience Learners can accumulate quantitative data to  points demonstrate their mastery of skills or knowledge.    GM11: VIP VIPs are specific learners who receive high  attention as they log on MOOCs.    GM12: Level-up Level-up gives learner’s notifications as they  achieve certain skill or knowledge level.  Learner– Goal setting GM13: Trophies and Trophies and badges are the most common  instructor badges recognition items found in games because of their  interaction versatility and flexibility.    GM14: Progress bars Progress bar is a visualized representation can be  used to show a user how far along he/she is in a  process.    GM15: Percentage Percentage shows the progress ratio of learners who  have completed a specific goal.   Instruction GM16: Personate Personate helper is an anthropomorphic robot that  helper guides new learners to become familiar with the  system.    GM17: Cartoon Cartoon guides are characters that instruct learners  guide as they enter the system.    GM18: Billboard Billboards are guidelines that guide learner by  providing instructional information.   Rewards GM19: Virtual gifts Virtual gifts are nonphysical objects   that work as  positive reinforcer.    GM20:Virtual Virtual currency is a type of unregulated, digital  currency money that is issued and typically controlled by its  developers, and used and accepted among the  members of a specific virtual community.    GM21: Praise Praise is the act of making positive statements about  a person, object, or idea, either in public or  privately.    GM22: Recognition Learners can receive recognition from others based  on their excellent learning performance.  Learner–learner Reputation GM23: Redeemable Redeemable points are what learners earn and use  interaction points points to redeem virtual items/ rewards.      GM24: Skill points Skill points are assigned for specific activities   within the game and are tangential to both XP and   RP. They are a bonus set of points that allow players   to gain experience or rewards for activities   alongside the core.    GM25: Talent trees Talent trees are one of the categories in which a   learner’s talents are divided. It is so named because   the talents branch out, similar to a tree structure.    GM26: Karma points Karma points do not allow players to gain benefit   from keeping their karma points, only from sharing   them. Karma points are frequently given as part of a   regular grind, or check-in behavior, for example: 3  195  </page> <page sequence="20"> karma points are earned for each monthly check in.   Peer tutoring GM27: Peer-led team Peer-led team learning is a model of teaching  learning undergraduate science, math, and engineering   courses that introduces peer-led workshops as an  integral part of a course. Students who have  performed strongly in a course are recruited to  become peer leaders.    GM28: Peer Peer mentoring is a form of mentorship that  mentoring typically occurs between a person who has lived   through a specific experience (peer mentor) and a  person who is new to that experience (the peer  mentee).    GM29: Learning Learning forums are platforms that enable learners  forums to share learning tips, experience, resources, and   knowledge.   Competition GM30: Hall of fame A hall of fame is a structure housing memorials to   famous or illustrious learners.    GM31: Team Team leaderboards list winners’ teams and  leaderboards encourage competitions among all learning groups.    GM32: Individual Individual leaderboards rank MOOC learners  leaderboards according to their learning achievement and list   individual winners among all competitors.   Altruism GM33: Gift giving Gift giving is an expression of love or friendship by   giving virtual gifts/ items to other learners.    GM34: Gift Gift recommendation provides leaners with  recommendation appropriate gift suggestions for social interaction   purposes.    GM35: Gift Gift reminders is used for calling attention to the  reminders gift-giving behavior of learners.   Group GM36: Self- Self-organized quest teams allow learners to  identification organized quest organize quest teams to solve complex quests or  teams questions.    GM37: List of family Lists of family members allow learners to organize  members and join learning community to interact and learn   together.   Peer GM38: Peer grading Peer grading means a peer arrangement in which  appraisal  people consider the amount, level, value, worth,   quality, or success of the products or outcomes of  learning peers of similar status.    GM39: Peer Peer comments are the constructive feedback  comments provided by other learning community members.    GM40: Peer Peer emoticon feedback refers to a meta- emoticon feedback communicative pictorial representation of a facial   expression that allows learners to interact with each  other.                    196  </page> <page sequence="21"> 4. The pair-wise questionnaire    Part1: Three gamification dimensions      Absolutely Very Strongly Weakly Equally Weakly Strongly Very Absolutely    strongly strongly  Criterion (or 9:1 8:1 7:1 6:1 5:1 4:1 3:1 2:1 1:1 1:2 1:3 1:4 1:5 1:6 1:7 1:8 1:9 Criterion  sub- (or sub- criterion) criterion)  Learner–                  Learner– content instructor  interaction interaction  Learner–                  Learner– content learner  interaction interaction  Learner–                  Learner– instructor learner  interaction interaction      Part 2: Thirteen gamification factors under dimensions      Absolutely  Very Strongly Weakly Equally Weakly Strongly Very Absolutely       strongly strongly  Criterion 9:1 8:1 7:1 6:1 5:1 4:1 3:1 2:1 1:1 1:2 1:3 1:4 1:5 1:6 1:7 1:8 1:9 Criterion (or  (or sub- sub-criterion)  criterion)   Self-                  Pattern  expression recognition  Self-                  Time  expression pressure  Self-                  Status  expression  Pattern                  Time  recognition pressure  Pattern                  Status  recognition  Time                  Status  pressure  Goal                  Instruction  setting  Goal                  Rewards  setting  Instruction                  Rewards  Reputation                  Peer tutoring  points  Reputation                  Competition  points  Reputation                  Altruism  points  Reputation                  Group  points identification  Reputation                  Peer  points appraisal  Peer tutoring                  Competition  Peer tutoring                  Altruism  Peer tutoring                  Group  identification  Peer tutoring                  Peer  appraisal  Competition                  Altruism  Competition                  Group  identification.  197  </page> <page sequence="22"> Competition                  Peer  appraisal  Altruism                  Group  identification  Altruism                  Peer  appraisal  Group                  Peer  identification appraisal      Part 3: Forty gamification mechanics under factors    Absolutely  Very Strongly Weakly Equally Weakly Strongly Very Absolutely       strongly strongly  Criterion 9:1 8:1 7:1 6:1 5:1 4:1 3:1 2:1 1:1 1:2 1:3 1:4 1:5 1:6 1:7 1:8 1:9 Criterion  (or sub- (or sub- criterion)  criterion)  GM1:                  GM2:  Virtual Personal  goods spaces  GM1:                  GM3:  Virtual Avatars  goods  GM2:                  GM3:  Personal Avatars  spaces  GM4:                  GM5:  Revealing, Where's  hiding, and Wally  combining game  items  GM4:                  GM6:  Revealing, Memory- hiding, and game  combining interactions  items  GM5:                  GM6:  Where's Memory- Wally game game  interactions  GM7:                  GM8:  Animated Time bar  countdown  timer  GM7:                  GM9:  Animated Check  countdown points  GM8: Time                  GM9:  bar Check  points    GM10:                  GM11: VIP  Experience  points  GM10:                  GM12: Level- Experience up  points  GM11: VIP                  GM12: Level- up  GM13:                  GM14: Progress  Trophies and bars  badges  GM13:                  GM15:  Trophies and Percentage  badges  GM14:                  GM15:  Progress bars Percentage  198  </page> <page sequence="23"> GM16:                  GM17: Cartoon  Personate guide  helper  GM16:                  GM18:  Personate Billboard  helper  GM17:                  GM18:  Cartoon guide Billboard  GM19:                  GM20: Virtual  Virtual gifts       currency  GM19:                  GM21: Praise  Virtual gifts  GM19:                  GM22:  Virtual gifts Recognition  GM20:                  GM21: Praise  Virtual  currency  GM20:                  GM22:  Virtual Recognition  currency  GM21: Praise                  GM22:  Recognition  GM23:                  GM24: Skill  Redeemable points  points   GM23:                  GM25: Talent  Redeemable trees  points  GM23:                  GM26: Karma  Redeemable points  points   GM24: Skill                  GM25: Talent  points trees  GM24: Skill                  GM26: Karma  points points  GM25: Talent                  GM26: Karma  trees points  GM27: Peer-                  GM28: Peer  led team mentoring  learning  GM27: Peer-                  GM29:  led team Learning forums  learning  GM28: Peer                  GM29:  mentoring Learning forums  GM30: Hall                  GM31: Team  of fame leaderboards  GM30: Hall                  GM32:  of fame Individual  leaderboards  GM31: Team                  GM32:  leaderboards Individual  leaderboards  GM33: Gift                  GM34: Gift  giving recommendation  GM33: Gift                  GM35: Gift  giving reminders    GM34: Gift                  GM35: Gift  recommendation reminders  GM36: Self-                  GM37: List of  organized quest family  teams members  GM38: Peer                  GM39: Peer  grading comments  GM38: Peer                  GM40: Peer  grading emoticon  199  </page> <page sequence="24"> feedback  GM39: Peer                  GM40: Peer  comments emoticon  feedback        Appendix 4. A fuzzy-AHP approach for determining relative engagingness of gamification  mechanics in MOOCs    Step1.Constructing the fuzzy comparison matrix    Triangular fuzzy νυμβερσM~ ~ ~ij  from 1 to 9  was employed to represent the results of users’ assessments of the pair- wise comparisons between each of the gamification mechanics by constructing a fuzzy positive reciprocal matrix M.  The proposed fuzzy comparison matrix was defined as follows:     M [M~= ij ]  M:fuzzy positive reciprocal matrix   M~ ij = (Lij ,Mij ,Rij )   Lij:the left value of the fuzzy membership function of the collected subject assessments of design mechanic j of  decision element i   Mij:the middle value of the fuzzy membership function of the collected subject assessments of design mechanic j of  decision element i   Rij:the right value of the fuzzy membership function of the collected subject assessments of design mechanic j of  decision element i  M~ = 1ij ~ ,∀i, j = 1,2,,n  M ji     Step 2.Integration of the collected subjects’ assessments of each decision element    There are many possible approaches to integrating subject assessments when calculating the triangular fuzzy number.  In contrast to some studies that apply statistical parameters such as the minimum, maximum, mean ανδ mode to  represent the fuzzy numbers, this study applied the geometric mean method proposed by Buckley [59]. The  computing process is defined as follows:  m~ = (1 ) ( ~ ~ nij n ⊗ m~1ij ⊕m2ij ⊕⊕mij )   m~ ij:Integrated triangular fuzzy numbers    m~ Nij :The value of the pair comparison of the collected subject assessments of design mechanic j of decision factor i  n: The number of subjects      Step 3. Computation of fuzzy weight    After integrating the collected data and calculating the corresponding triangular fuzzy numbers, we used the  Approximation Μετηοδ proposed by Buckley [59] to compute the fuzzy weight. The formula of the  Approximation Method for computing the fuzzy weights is defined as follows:  Z~ (~i = a ⊗ a~ ⊗⊗ a~ )1/ ni1 i2 in ,∀i =1,2,,n    200  </page> <page sequence="25"> W~ ~i = Zi (Z~ Z~ ~ −⊗ 1 ⊕ 2 ⊕⊕ Zn ) 1    Z~i:The geometric mean value of the triangular fuzzy number  a~ij: The triangular fuzzy number of row i and column j in the fuzzy positive reciprocal matrix  W~i:The fuzzy weight of each row of the fuzzy positive reciprocal matrix      Step 4. Defuzzification of decision elements    The weights of the decision elements were represented by fuzzy values. The defuzzification process assigned a  distinct number to each of the decision element. We then used the Center of Gravity Method of defuzzification to  calculate the center of gravity of the triangular fuzzy number. Given a triangular fuzzy number and its three sides,  denoted by Ã= (Lij, Mij, Rij), the defuzzified weight DFij was calculated using the following formula:  DFij = [(Rij − Lij ) + (Mij − Lij )] / 3 + Lij     Step 5. Normalization of defuzzified weights    To compare the relative engagingness of different decision element at different levels, we first normalized the  defuzzified weights. The definition of the normalized weights (NWi) of each decision dimension at each level can be  defined as follows:  NWi = DFij /∑DFij     Step 6. Calculation of the synthesized weight for each element at each level    We calculated the normalized weights of each element at each level after step 5. However, to determine the priority  of each mechanic, it was still necessary to synthesize weights for each decision element at each decision level. The  larger the value of the synthesized weight, the higher the priority of the dimension. The definition of synthesized  weights of each decision element at each level was defined as follows:  NWK = NWi × NWij × NWijk     Step 7. Checking for consistency    Consistency Index (CI) was employed to designate overall inconsistency for the proposed hierarchy and for each  decision dimension.  Consistency Ratio (CR) was also calculated to describe the consistency of the pair-wise  comparisons. The equations for calculating CI and CR for each decision were:  Consistency Index (CI ) λ − n= Max n −1   where λMax  is the maximum eigenvalue, and n the number of decision component  Consistency Ratio (CR) CI= RI   RI is the average index for randomly generated weights obtained from a table of random consistency indices. To  judge the consistency of the pair-wise outputs, if CR was ≤ 0.1, then the output of the pair-wise comparison was  sufficiently consistent. On the other hand, if CR was &gt; 0.1, then the results of the pair-wise comparison were  inconsistent.        201  </page> <page sequence="26"> Appendix 5. The Fuzzy AHP Weight of Gamifiation factors and mechanics table    Criteria Weights Sub-criteria Local Sub-criteria (Layer 3) Local Global  (Layer 1) (Layer 2) weights weights weights  Learner– 0.281 Self-expression 0.372  GM1: Virtual gifts 0.911 0.09520  content GM2: Personal spaces 0.032 0.00335  interaction  GM3: Avatars 0.057 0.00599  Pattern 0.420  GM4: Revealing, 0.279 0.02293  recognition hiding, and combining  items  GM5: Where's Wally 0.403 0.04760  game  GM6: Memory-game 0.318 0.03310  interactions  Time pressure 0.171  GM7: Animated 0.196 0.00942  countdown timer  GM8: Time bar 0.203 0.00975  GM9: Check points 0.601 0.02890  Status 0.037  GM10: Experience 0.332 0.00345  points  GM11: VIP 0.312 0.00324  GM12: Level-up 0.356 0.00370   0.316 Goal setting 0.313  GM13: Trophies and 0.466 0.04610  Learner– badges  instructor GM14: Progress bars 0.260 0.02572  interaction GM15: Percentage 0.274 0.02709  Instruction 0.259  GM16: Personate helper 0.334 0.02734  GM17: Cartoon guide 0.333 0.02725  GM18: Billboard 0.333 0.02725  Rewards 0.428  GM19: Virtual gifts 0.253 0.02422  GM20: Virtual currency 0.251 0.02395  GM21: Praise 0.271 0.02665  GM22: Recognition 0.225 0.02043  Learner– 0.403 Reputation 0.410  GM23: Redeemable 0.511 0.08450  learner points points  interaction GM24: Skill points 0.166 0.02740  GM25: Talent trees 0.160 0.02647  GM26: Karma points 0.163 0.02687  Peer tutoring 0.052  GM27: Peer-led team 0.311 0.00652  learning  GM28: Peer mentoring 0.311 0.00652  GM29: Learning forums 0.378 0.00791  Competition 0.201  GM30: Hall of fame 0.042 0.00340  GM31: Team 0.906 0.07340  leaderboards  GM32: Individual 0.052 0.00420  leaderboards  Altruism 0.039  GM33: Gift giving 0.423 0.00665  202  </page> <page sequence="27"> GM34: Gift 0.374 0.00587  recommendation  GM35: Gift reminders 0.203 0.00320  Group 0.043  GM36: Self-organized 0.613 0.01063  identification quest teams  GM37: List of family 0.387 0.00670  members  Peer appraisal 0.255  GM38: Peer grading 0.404 0.04150  GM39: Peer comments 0.214 0.02200  GM40: Peer emoticon 0.382 0.03930  feedback    203  </page> </plain_text> 
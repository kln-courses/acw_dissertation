<plain_text><page sequence="1">THE JOURNAL OF THE LEARNING SCIENCES, 17: 225-247, 2008 Copyright ? Taylor &amp; Francis Group, LLC ISSN: 1050-8406 print /1532-7809 online |"\ Taylor &amp; Francis Group DOI: 10.1080/10508400801986116 ! J Routledge |^ Taylor &amp;f rands Grou Searching for Signs of Intelligent Life: An Investigation of Young Children's Beliefs About Robot Intelligence Debra Bernstein and Kevin Crowley Learning Research and Development Center University of Pittsburgh Children's worlds are increasingly populated by intelligent technologies. This has raised a number of questions about the ways in which technology can change chil dren's ideas about important concepts, like what it means to be alive or smart. In this study, we examined the impact of experience with intelligent technologies on chil dren's ideas about robot intelligence. A total of 60 children aged 4 through 7 were asked to identify the intellectual, psychological, and biological characteristics of 8 entities that differed in terms of their life status and intellectual capabilities. Results indicated that as children gained experience in this domain, they began to differenti ate robots from other familiar entities. This differentiation was indicated by a unique pattern of responses about the intellectual and psychological characteristics of ro bots. These findings suggest that experience may yield a more highly developed viewpoint that reflects an appreciation of the distinctions between biological life, machines, and artificially intelligent technologies. People who grew up in the world of the mechanical are more comfortable with a defi nition of what is alive that excludes all but the biological and resist shifting defini tions of aliveness.... Children who have grown up with computational objects don't experience that dichotomy. They turn the dichotomy into a menu and cycle through its choices. (Turkle, 1999, p. 552) We are in the midst of a technology revolution. Everyday things are becoming 'smarter" as computational technology becomes ubiquitous and autonomous. Correspondence regarding this article should be addressed to Debra Bernstein, Learning Research and Development Center, 1 st Floor, 3939 O'Hara Street, Pittsburgh, PA 15260. E-mail: dlb36@pitt.edu</page><page sequence="2">226 BERNSTEIN AND CROWLEY So-called smart technologies are now being employed for functions as everyday as house cleaning and playing (e.g., the Roomba and Robosapien) and as extraordi nary as interplanetary exploration (e.g., the Mars exploration rovers). Numerous authors and visionaries have suggested that this infusion of technology will result in significant, long-lasting changes to the way people think, perceive, and under stand themselves, as well as the technology around them (Papert, 1980; Pesce, 2000; Turkle, 1984, 1998, 1999). This article investigates the potential cognitive impact of these cultural changes on children, particularly with respect to children's ideas about intelligence and intelligent technologies. Prior research has suggested that informal exposure to domain-relevant stimuli can have a powerful impact on children's beliefs and ideas (Crowley &amp; Jacobs, 2002). This suggestion is already present in the literature on children and technol ogy, as some researchers have proposed that exposure to intelligent technologies may impact children's understanding of fundamental concepts like what it means to be alive (Kahn, Friedman, Perez-Granados, &amp; Freier, 2004,2006; Turkle, 1998, 1999). The current study further investigated knowledge and belief changes that accompany exposure to and interaction with intelligent technology. We believe that exposure to intelligent technologies, such as robots and robotic toys, pushes children to think more deeply about the unique features of artificially intelligent enti ties. Specifically, we predicted that such exposure would allow children to appreci ate the distinctions between robots and other entities (like animals and machines), including the realization that fundamental concepts such as "alive" may not apply to robots in the same way as they do to other entities (Kahn, Friedman, et al., 2006). In order to test this hypothesis empirically, we examined the impact of different levels of technology exposure on children's beliefs about robot intelligence. Since her early research on children and electronic games, Sherry Turkle has ar gued that exposure to intelligent technology can impact children's conceptual de velopment (see Turkle, 1984). Then and now, Turkle's research has demonstrated how intelligent technologies engage children in complex interactions, which, in turn, yields the development of new ideas about technology. Turkle credited the digital revolution with pushing children toward a more "psychological" under standing of technology. Prior to the 1980s, the majority of children's toys could be understood in terms of their physical mechanisms (e.g., a wind-up car can be un derstood in terms of its gears and springs). But as toys became digital and thus less physically transparent, children began to seek other explanations for why their toys worked the way they did. Turkle (1984,1998) cited numerous instances of children attributing consciousness to technology. To illustrate the point, she provided the example of a child who continually puzzles over why an electronic game keeps beating him. Eventually, the child concludes that the game was cheating, even though cheating requires intention and motivation, which are not characteristics most adults associate with electronic toys. Through his experience, this child has taken a step toward a new way of understanding technology.</page><page sequence="3">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 227 One of the critical ideas underlying Turkle's work is that environmental stimuli can impact cognitive development. Sociocultural theorists have long argued that culture exerts a profound impact on children's development and that cognitive de velopment is best viewed as a mutual interaction between individuals and cultural tools (Cole, 1997; Rogoff, 2003; Saxe, 1999; Vygotsky, 1978). Technology, in par ticular, can change thought. Just as training on the abacus has been shown to alter the mental representations used by Chinese children doing mental arithmetic, playing video games has been shown to sharpen visual attention, spatial, and repre sentational skills in young game players (Maynard, Subrahmanyam, &amp; Greenfield, 2005; Stigler, 1984; Subrahmanyam &amp; Greenfield, 1996). Some researchers have suggested that video games have the potential to significantly transform children's educational engagement and experiences (Shaffer, Squire, Halverson, &amp; Gee, 2005). Perhaps the developmental trajectories of entire communities of children can be altered by the introduction of new tools into their cognitive ecologies (i.e., the spaces where they learn and play; Palmquist &amp; Crowley, 2007). Some of these new tools bring with them a complex set of characteristics and affordances. Robots, particularly those with anthropomorphic or zoomorphic forms, can appear animate, raising compelling questions about what it means to be alive. For this reason, psychologists have often studied the extent to which chil dren's ideas about robots mirror their ideas about biological entities such as people or animals (e.g., Melson et al., 2005). Developmental psychologists may expect that children's ideas about the char acteristics of living and nonliving entities will influence their ideas about robots due to the persistence of na?ve biology theories. Naive theories are frameworks that organize children's knowledge and beliefs about the world in several funda mental domains, including biology, psychology, and physics (Hatano et al., 1993; Inagaki &amp; Hatano, 2002; Wellman &amp; Gelman, 1992,1998). According to the na?ve biology approach, as children mature they are increasingly able to group entities into categories and draw appropriate inferences from those categorizations (Gel man, 1988, 1989; see also Mak &amp; Vera, 1999). For example, young children have displayed the ability to categorize entities as living or nonliving and use those judgments to guide decisions about the attribution of characteristics. The converse assertion, that the presence or absence of certain characteristics can be used to guide decisions about life status, has also been shown in the literature (Back scheider, Shatz, &amp; Gelman, 1993; Gelman &amp; Gottfried, 1996; Massey &amp; Gelman, 1988; Richards &amp; Siegler, 1986; Wellman &amp; Gelman, 1998). Some of the charac teristics that are commonly associated with young children's life status judgments include certain types of movement (even young children are adept at identifying biological and nonbiological causes of movement) and biological characteristics such as growth and healing (Gelman &amp; Gottfried; Gelman &amp; Opfer, 2002; Rich ards &amp; Siegler). It is generally believed that children's ideas about the characteris tics of living things become more accurate with age (Opfer &amp; Gelman, 2001 ; Rich</page><page sequence="4">228 BERNSTEIN AND CROWLEY ards &amp; Siegler), a trend that has also been observed for children's ideas about intelligence and the functions of the brain (C. N. Johnson &amp; Wellman, 1982; Kinlaw &amp; Kurtz-Costes, 2003). One way to interpret the na?ve biology literature is to imagine that children's life status judgments (i.e., whether they believe an entity is alive or not) will predict the types of characteristics they are willing to attribute to an entity. Indeed, some of the literature on children's beliefs about robots has taken this approach. For exam ple, Nigam and Klahr's (2000) work suggested a relationship between life status judgments and the attribution of certain mental states to robots. Other research has investigated young children's willingness to attribute "animistic" properties (e.g., biological characteristics) to robotic animals and found that older children (5 year-olds) were more likely than younger children (3-year-olds) to temper their at tributions based upon the robot's behavior (Okita, Schwartz, Shibata, &amp; Tokuda, 2005). However, recent findings that some children are willing to attribute a variety of characteristics to robots, even when they do not believe the robots are alive, argue for a departure from this point of view. Kahn, Friedman, and colleagues investi gated children's beliefs about a robotic dog (AIBO) as compared to a stuffed ani mal dog and a live dog. Approximately two thirds of the young children (aged 2-6) surveyed attributed mental states, moral standing, and social rapport to both AIBO and the stuffed animal. However, less than 40% of children in the larger sample re sponded that AIBO and the stuffed dog were alive (Kahn, Friedman, et al., 2006). Older children (aged 7-15) attributed more characteristics to a live dog, but more than half still attributed mental states, moral standing, and social rapport to AIBO. Less than a quarter of older children believed AIBO was alive (Melson et al., 2005). This research suggests that beliefs about the life status of a robotic entity do . not necessarily constrain children's beliefs about the entity's characteristics. Similarly, other researchers have examined children's beliefs about whether ro bots and computers have brains, hearts, and other internal characteristics associ ated with living things. Scaife and Van Duuren (1995) found that although few children believed the robot had a heart, many children aged 7 and older believed the robot had a brain (or "a sort of brain even though it is different from ours," p. 370). This finding is interesting in part because it suggests a decoupling of biologi cal characteristics and intelligence for some children?it is possible for an entity to have a brain, but no heart. Additionally, an analysis of response patterns indicated that children aged 7 and older were likely to attribute brains to the "cognitive set" (person, robot, computer), indicating that children were willing to categorize these entities on the basis of their cognitive features. In sum, although there is ample evidence that na?ve theories guide children's decisions about the characteristics of biological entities, it is less clear that these theories always underlie children's assumptions about robots, particularly as chil dren are willing to attribute a wide range of characteristics to robots, only some of</page><page sequence="5">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 229 which are related to their life status judgments (see Jipson &amp; Gelman, 2007, for other factors that may contribute to children's beliefs about the characteristics of robots). What are the other potential sources of influence for these ideas? The psychol ogy literature on childhood expertise suggests that experience with robots might be the most important factor in shaping children's conceptual representations. Indeed, domain-specific experience is often a better predictor of knowledge representa tions and beliefs than general experience or maturational factors (Chi, 1978; Chi, Hutchinson, &amp; Robin, 1989; Chi &amp; Koeske, 1983; Crowley &amp; Jacobs, 2002; Hmelo-Silver &amp; Pfeffer, 2004; K. E. Johnson &amp; Mervis, 1994; Means &amp; Voss, 1985). Young children who are knowledgeable in a particular domain show greater recall memory and more fully developed knowledge representations than novices of any age (Chi, 1978). For example, Chi, Hutchinson, and Robin found that even when participants were matched for age and general cognitive abilities, child ex perts were more likely than novices to organize their knowledge into domain-rele vant categories. There is little doubt that high levels of knowledge and experience can alter children's understanding of important concepts within a domain of inter est (Crowley &amp; Jacobs, 2002; Shaffer, 2006). Thus, we believe that children who have had direct experience with intelligent technologies will be in the process of developing new ways of thinking about that technology. One goal of this study was to answer the question of how children's ideas change as they gain experience in this domain. Our hypothesis, growing from the literature on children and technology (see Kahn, Friedman, et al., 2004, 2006; Turkle, 1999), was that as children gain experience with technology they will move from thinking about robots within the context of their na?ve biology theories to thinking about robots as intelligent technologies. Children who understand ro bots within the context of na?ve biology will treat them as either biological (living) entities or inanimate objects, and assign characteristics according to those judg ments. Children who understand robots as intelligent technology will treat them as a unique type of entity, and we expected to see little relationship between life status judgments and beliefs about the robot's characteristics for children in this latter group. In this article, we track children's evolving understanding about robots by fo cusing on their ideas about intelligence. To do so is to embark on a difficult jour ney. The question of what characteristics mark the boundaries of intelligence is one that is frequently debated, particularly in technology circles. One way that the psychology literature has engaged the question of intelligence is by inquiring about the characteristics that make up an intelligent person. Both children and adults have included descriptions of cognitive skills (e.g., problem solving, decision making) and social skills (e.g., being fair) in their definitions of human intelligence (Sternberg, Conway, Ketron, &amp; Bernstein, 1981; Yussen &amp; Kane, 1985). Young children are particularly apt to include noncognitive charac</page><page sequence="6">230 BERNSTEIN AND CROWLEY teristics, such as being nice, in their definitions of intelligence (Kurtz-Costes, Mc Call, Kinlaw, Wiesen, &amp; Holland Joyner, 2005; Yussen &amp; Kane, 1985). These findings suggest that children associate both cognitive and social/psy chological characteristics with intelligent people. Such findings open up a range of interesting questions, including why these characteristics might co-occur in defini tions of intelligence. Our task at present, however, is to address a much simpler is sue: Does the pattern of characteristics that children associate with intelligent peo ple hold for robots? Robot intelligence may be viewed in a slightly different way. One study found that adults rarely attribute psychological characteristics to technological entities, even if they believe those entities have some intellectual characteristics (Van Duuren &amp; Scaife, 1996). Some researchers have suggested that psychological characteristics are among those that distinguish between the presence of a brain and the presence of a mind, the latter being more commonly associated with bio logical than technological entities (Davis, 2004). Thus, as we begin to explore children's ideas about robot intelligence, we can think about different ways of characterizing those ideas. If children think of robots as akin to biological entities, they may apply a definition of intelligence that in cludes both cognitive and social/psychological characteristics. Children who think about robots as intelligent technology may apply a more technological definition of intelligence to robots, one that includes intellectual capabilities but minimizes psychological capabilities, in keeping with the idea that technological entities are generally perceived to have a lesser capacity for psychological characteristics than are biological entities (Opfer &amp; Gelman, 2001). In the current study, children were asked to articulate their beliefs about the characteristics of different types of technology (including two robots), biological entities, and a simple artifact. These data, along with information about children's prior exposure to robots, were used to determine whether children with different levels of exposure treated robots as akin to biological entities or whether they at tributed a unique pattern of characteristics to the robots. This study goes beyond previous work on children's beliefs about robots by treating prior experience as a factor that may affect beliefs about robot intelligence. The inclusion of this factor allows us to begin exploring the potential impact of technology exposure on chil dren's ideas about intelligence. METHOD Children were asked whether it is appropriate to attribute biological, intellectual, and psychological characteristics to eight different entities, including two robots. Parents completed a brief written survey about the child's previous opportunities learning about or interacting with robots. This survey provided a direct measure of children's level of prior robot exposure.</page><page sequence="7">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 231 Participants Sixty children participated in this study.1 There were 30 children aged 4 or 5 (15 girls and 15 boys; M age = 62.6 months) and 30 aged 6 or 7 (14 girls and 16 boys; M age = 82.6 months). The decision to conduct this study with children between the ages of 4 and 7 was guided by prior research that suggests that early childhood is an important period for the development of na?ve biology beliefs (Hatano et al., 1993 ; Wellman &amp; Gelman, 1998). Participants were recruited from the population of weekend visitors to a children's museum. Materials Forced-choice "bingo" task. The goal of the bingo task was to elicit chil dren's beliefs about the characteristics of different entities: three biological entities (person, cat, plant), two robots (humanoid robot, rover2), a computer, a calculator, and a doll. Children were given eight laminated 5" x 9" cards, each one containing a picture of a different entity. The name of the entity was printed on the bottom of the card. Both of the robots were simply labeled robot. The robots were the main entities of interest in this study. Biological entities and artifacts were included for comparison purposes. Throughout the task, children were asked to judge whether each entity had the following biological (alive, growth, metabolism, reproduction, self-generated move ment), intellectual (think, remember, plan, calculate, learn, situational aware ness3), psychological (emotion and volition), and artifactual (made in a factory, put together) characteristics. The artif actual questions were included in order to make sure that children recognized the robots as nonbiological entities. See Appendix A for complete questions. The questions were printed on colored index cards. At the beginning of each turn, the child was asked to choose a question card. For each question card, the child was asked to answer the question posed by placing a penny on the appropri ate picture(s). For example, if asked "Which things need food or water?" (metabo lism question), the child might respond by placing a penny on the person, plant, and cat. The experimenter would ask the child if there were any other things that needed food or water. After the child decided that he or she had indicated all of the *An additional 10 participants were dropped from the analysis?6 because they did not complete the task, 3 because another family member (e.g., a sibling) interrupted or interfered with the task, and 1 because of recording equipment failure. 2The humanoid robot was the Sony QRIO. The rover was the Personal Exploration Rover, devel oped by the Mobile Robot Programming Lab at the Robotics Institute, Carnegie Mellon University. 3The question on situational awareness was asked of all participants but excluded from analysis. This question was intended to ascertain if children believed the entity was aware of its surroundings; however, the question was often misinterpreted to mean the ability of the entity to be moved to different locations.</page><page sequence="8">232 BERNSTEIN AND CROWLEY entities that needed food or water, the experimenter invited the child to pick up all of the pennies. The child then chose another card, and game play continued. The child continued to choose cards until none were left. Prior experience survey. The survey consisted of 11 questions. The first five questions asked about the availability of robotic toys and/or educational mate rials about robots in the child's home, as well as recent opportunities to engage with or learn about robots. Likert scales were used to rate (on a scale of 1-7) the child's interest in and knowledge about robots and computers, as well as parents' interest in and knowledge about robots. Responses from the survey were used to create a quantitative measure of chil dren's prior experience with robots. Children received 1 point for each robot-re lated activity they participated in, such as visiting a museum exhibit about robots, building a robot, or visiting a Web site about robots. Children also received 1 point for each of the robot-themed items present in their home environment (e.g., robot books or robot videos) and 1 point for each robot toy (e.g., Lego Mindstorms or Bionicles). These points were summed to calculate an opportunity score for each child. A higher score indicated a greater opportunity for the child to learn about ro bots in his or her home environment. Opportunity scores ranged from 0 to 7, with a mean score of 2.47 (SD = 1.74). A median split of opportunity scores allowed us to form two groups for compar ison purposes. Children in the low-opportunity group had scores of 0, 1, or 2 (n = 34). Children in the high-opportunity group had scores of 3 or higher (n = 26). The mean age of the low-opportunity group was 70.6 months (SD = 11.86). This group contained 10 boys and 24 girls. The mean age of the high-opportunity group was 75.2 months (SD = 11.94). This group contained 21 boys and 5 girls. A t test was conducted to determine if the age difference between the low- and high-opportu nity groups was significant. The t test revealed no significant difference between the two groups. However, opportunity scores were moderately correlated with age in months, r(60) = .34, p &lt; .01. A chi-square analysis revealed a significant rela tionship between gender and opportunity group, %2(l,N=60) = 15.56,/? &lt; .001, in dicating that boys were more likely than girls to be in the high-opportunity group. This finding was consistent with previous research that suggests boys are more likely than girls to be interested in conceptual and constructive domains (K. E. Johnson, Alexander, Spencer, Leibham, &amp; Neitzel, 2004). Design and Procedure Families were recruited during their visit to the museum. Data were collected in a quiet space away from the main floor of the museum. Average participation time in this study was 19 min, 52 s. All aspects of data collection were videotaped.</page><page sequence="9">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 233 At the start of the forced-choice task, children were asked to label each of the eight entities on the cards. If the children were unable to label any item, the experi menter provided the name of the item and then asked the children to repeat it back. In order to make sure children understood the task, the experimenter asked two practice questions: "Which cards have things on them that can make noise?" and "Which cards have things on them that you have in your house?" Children were in structed to place a penny on each picture that answered the question. The majority of children understood this procedure after the first practice question. Following the practice questions, children began picking questions from the pile of colored index cards. Although the order of the practice questions was fixed, the order of ex perimental questions was always random, as each child picked the cards in a differ ent order. Adults were asked to complete the survey while the children participated in the forced-choice task. RESULTS The analyses presented here examine the influence of prior experience with ro botic technology on children's ideas about robot intelligence. The section begins with a brief summary of the types of characteristics children attributed to all eight entities (person, cat, plant, humanoid robot, rover, computer, calculator, doll). The next set of analyses explores the relative contributions of prior experience and life status judgments (i.e., whether children believe robots are alive) on children's attri butions of intelligence characteristics to the robots. Finally, we examine the data for evidence that children with different beliefs and experience have unique ways of thinking about robots and intelligence. Summary of Forced-Choice Responses Figure 1 displays children's mean attributions of biological and intelligence char acteristics to all eight entities. A visual inspection of the figure indicates that the humanoid robot and rover both scored reasonably high on the intelligence scale. The finding that young children were willing to attribute intelligence characteris tics to robots was consistent with prior research (see Okita et al., 2005). Both ro bots scored moderate to low on the biology scale. The attribution of self-generated movement accounted for the majority of the biological score associated with each robot. Prior research has reported higher attributions of biological properties to ro bots than were seen in the current data (see Kahn, Friedman, et al., 2004, 2006; Okita et al., 2005). However, this discrepancy may be explained by the fact that children in previous studies viewed (or played with) a physical robot while an swering questions.</page><page sequence="10">234 BERNSTEIN AND CROWLEY ? 2 0 4 Person ^ Cat Humanoid Robot Rover Computer Calculator Do"_,_,_ Plfint 0 12 3 4 Biological Characteristics FIGURE 1 Distribution of intellectual and biological characteristics for all eight entities. The computer and calculator scored moderate to low on the intelligence scale and extremely low on the biology scale. The ability to calculate accounted for the majority of the intelligence scores associated with the computer and calculator. These findings were somewhat consistent with Van Duuren and Scaife's (1996) in vestigations of children's beliefs about computers, although children in the current study were more likely to say that computers could add numbers together. Few other researchers have asked children about calculators. The person and the cat both scored high on the biology dimension, but the cat scored lower than the person on the intelligence dimension. Children's attributions of certain intelligence characteristics to the cat (e.g., thinking and remembering) were consistent with prior research (see Davis, 2004). The plant was treated mod erately on the biological dimension but low on intelligence. Young children's am bivalence about the life status of plants has been documented in the literature (see Hatano et al., 1993), as have their beliefs about the intellectual status of plants (see Davis, 2004; Inagaki &amp; Hatano, 1987). See Appendix B for details of the specific characteristics attributed to each of the eight entities. Consistent with prior research, few children attributed any biological or intelli gence characteristics to the doll (see Van Duuren &amp; Scaife, 1996). Had children as signed these characteristics to the doll, as well as the other artifacts, we might have</page><page sequence="11">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 235 people cat plant doll humanoid rover computer calculator robot FIGURE 2 Mean number of psychological characteristics attributed to each entity. speculated that participants were simply overattributing characteristics to all of the artifacts. However, this finding indicates that the doll was successful as a control artifact. Figure 2 shows children's attributions of psychological characteristics to all eight entities. All children attributed both psychological characteristics (emotion and volition) to the person. Children attributed almost as many psychological char acteristics to the cat, but fewer to the humanoid robot and the rover. Prior research is inconsistent with respect to children's attribution of emotion to robots (see Kahn, Friedman, et al, 2004, 2006; Van Duuren &amp; Scaife, 1996). However, the current findings were well within the range present in the literature. Children at tributed very few psychological characteristics to the other entities. A one-way repeated measures analysis of variance (ANOVA) revealed signifi cant differences between children's attributions of biological, psychological, and intellectual characteristics to the humanoid robot, F(2,118) = 21.50, p &lt; .001. On average, children attributed 30% of biological characteristics, 43% of psychologi cal characteristics, and 59% of intellectual characteristics to the humanoid robot. Pairwise comparisons indicated significant differences between all three catego ries.4 A repeated measures ANOVA was run for the rover and yielded similar re sults, F(2,118) = 17.82, p &lt; .001. On average, children attributed 28% of biologi cal characteristics, 41% of psychological characteristics, and 53% of intellectual characteristics to the rover. Pairwise comparisons indicated significant differences between all three categories. These analyses revealed that children can and do dis tinguish between biological, psychological, and intelligence characteristics for in 4Proportion scores were generated to represent children's attributions of biological, psychological, and intellectual characteristics, as each category included a different number of questions. These pro portion scores were used to run the repeated measures ANOVA. Pairwise comparisons were all signifi cant at/? &lt; .01.</page><page sequence="12">236 BERNSTEIN AND CROWLEY telligent technologies and that they believe entities can possess some of these char acteristics in the absence of others. Children's attributions of biological, psychological, and intelligence character istics to the two robots were highly correlated: for biological characteristics, r(60) = .78; for psychological characteristics, r(60) = .89; for intelligence characteris tics, r(60) = .86; all/?s &lt; .001. This finding confirmed that children treated the two robots similarly and did not attribute characteristics to the humanoid robot based solely upon its anthropomorphic appearance. Previous research with 9- to 11 year-old children suggested that a robot's appearance would impact children's judgments of robot "personality" and emotion (Woods, Dautenhahn, &amp; Schulz, 2004). It is possible that although children may use robot appearance to guide their judgments of anthropomorphic characteristics such as friendliness and shyness, they use categorical markers when making decisions about more concrete charac teristics such as intelligence and biological capabilities. Based upon the strength of the correlations reported previously, data for the humanoid robot and the rover are reported together, as an average robot score, in all future analyses. In order to examine the data for age differences, we conducted a series of t tests to compare the mean number of biological, psychological, and intelligence charac teristics attributed to all eight entities by older and younger children. In all, 24 comparisons were made. The Bonferroni technique was used to adjust the alpha level for multiple comparisons, yielding an operational alpha level of .002 (.05 / 24). No significant differences were found between older and younger children. Based upon these findings, data were collapsed across younger and older partici pants for all further analyses. Alive, Intelligence, and Prior Experience In this section we examine children's beliefs about the intellectual characteristics of robots and explore the extent to which those beliefs are influenced by the amount of prior experience children have had with robots versus their ideas about the robots' life status. Analysis of the former factor was consistent with the hypoth esis that direct experience with robots may impact children's ideas about their characteristics, whereas analysis of the latter factor was included to detect a bias toward life-status-based judgments. In all, 21 children judged both the humanoid robot and the rover to be alive; 5 children were divided in their judgments and said one robot was alive and one ro bot was not.5 For life status comparisons, these two groups were collapsed into a single group. Another 34 children said neither robot was alive. It should be noted that when asked about the artifactual properties of the robots, 55 out of 60 children responded that both robots were made in a factory. Of the children who said the ro bots were alive, nearly all of them said the robots were made in a factory. Children's willingness to attribute both artifactual and animate properties to the ro bots has led some researchers to speculate that the term alive may mean something</page><page sequence="13">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 237 TABLE 1 Summary of Hierarchical Regression Analysis for Factors Influencing Robot Intelligence Attributions Factor R2 AR2 AF p Robot life status .164 .164 11.39 .001 Robot life status, opportunity score .236 .072 5.35 .024 Robot life status, opportunity score, interaction .238 .003 0.19 .663 term (life status x opportunity score) different when applied to biological entities and intelligent technologies (Kahn, Friedman, et al., 2004, 2006). The two factors of interest, children's judgments of whether the robots were alive and opportunity score, were entered as the first two steps in a hierarchical re gression. An interaction term (Life Status x Opportunity Score) was created and entered as the third step. The dependent variable was the average number of intelli gence characteristics attributed to the robots. Analysis revealed a significant effect for robot life status judgments?this variable accounted for 16.4% of the variance in robot intelligence attributions. Opportunity score accounted for an additional 7.2% of the variance. Taken together, life status judgments and opportunity score accounted for 23.6% of the variance in robot intelligence attributions. The interac tion term was not significant (see Table 1). This analysis confirmed that both life status judgments and opportunity score im pact children's judgments of robot intelligence. The mean number of intelligence characteristics attributed to the robots was higher for children who believed one or both robots were alive (M = 3.62, SD = 1.41 ) than for children who did not believe ei ther robot was alive (M = 2.19, SD = 1.76). Additionally, opportunity score and intel ligence attributions were positively correlated r(60) = .31, indicating that children with higher opportunity scores attributed more intelligence to the robots. The next set of analyses examined whether the relationship between the techno logical entities differed as a function of prior experience with robots (i.e., did chil dren with different levels of prior experience group the technologies differently?). For this analysis, we performed a median split on the opportunity score variable in order to compare children with low and high opportunity scores. A repeated mea sures ANOVA was conducted with the number of intelligence characteristics at tributed to the technological entities (robots, computer, calculator) as a within-sub jects factor and opportunity score (low/high) as a between-subjects factor.6 This 5Four children said the humanoid robot was alive but not the rover, and one child said the rover was alive but not the humanoid robot. 6Mauchly's test of sphericity was significant (Mauchly's W = 0.64, df = 2, p &lt; .001), so the Huynh-Feldt correction was applied.</page><page sequence="14">238 BERNSTEIN AND CROWLEY analysis revealed a significant effect for entity, F(1.52, 88.27) = 18.77, p &lt; .001; a significant effect for opportunity score, F(l, 58) = 10.09, p &lt; .01; and no signifi cant interaction. Table 2 shows the mean number of intelligence characteristics at tributed to each entity. On the whole, children with high opportunity scores attributed more intelligence to the intelligent technologies than did children with low opportunity scores. Pairwise com parisons indicated that children attributed significantly more intelligence characteristics to the robots than to the computer or calculator, but there were no significant differences between the number of intelligence characteristics attributed to the computer and cal culator. The general pattern of treating the robots similarly, and treating the computer and calculator similarly, held for children with low and high opportunity scores. Different Models of Intelligence In order to more fully understand children's ideas about robot intelligence, we examined their response patterns to questions about both cognitive and psycho logical characteristics (see the earlier discussion of the frequency of psychologi cal characteristics in different definitions of intelligence). Based on children's prior experience and their answers to the question "Are robots alive?," we identi fied three groups, each of which attributed a distinct pattern of intellectual and psychological characteristics to the robots. The first group consisted of children with low opportunity scores who believed that one or both of the robots was alive. This group was characterized by high intelligence and psychological attri butions to the robots, with a strong positive correlation between the number of in telligence and psychological characteristics attributed, r(13) = .73,/? &lt; .01. These children attributed as much intelligence to the robots as children in the high-op portunity group, but they also attributed more psychological characteristics to the robots than the other two groups (see Table 3 for means). We labeled this group Robot as Animal because these were the types of attributions we would ex pect children to make to animals (see Inagaki &amp; Hatano, 1987). In fact, when we compared these children's beliefs about the robots and the cat using paired t tests, we found no significant differences in the number of psychological or intellec tual characteristics attributed to each entity. In short, children in this group not TABLE 2 Mean (SD) Number of Intelligence Characteristics Attributed to Intelligent Technologies for Each Opportunity Group Low Opportunity Score High Opportunity Score Robots 2.34(1.76) 3.42(1.59) Computer 1.38(1.18) 2.42(1.65) Calculator 1.38(0.85) 2.00(1.50)</page><page sequence="15">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 239 TABLE 3 Mean (SD) Number of Intelligence and Psychological Characteristics Attributed to Different Entities, By Group Intelligence Characteristics (max = 5) Psychology Characteristics (max = 2) Group Robots Cat Calculator Robots Cat Calculator Robot as Animal 3.35(1.72) 3.23(1.24) 1.38(0.65) 1.27(0.88) 1.69(0.48) 0.23(0.60) (/i =13) Robot as Machine 1.71(1.50) 3.24(1.04) 1.38(0.97) 0.55(0.74) 1.52(0.68) 0.10(0.30) (n = 21) Robot as Smart 3.42(1.59) 3.31(1.01) 2.00(1.50) 0.87(0.73) 1.62(0.57) 0.15(0.37) Technology (n = 26) only judged the robots to be alive but believed them to be intellectually and psy chologically similar to the cat. The second group consisted of those children with low opportunity scores who did not believe the robots were alive. Similar to the first group, there was a strong positive correlation between the number of intelligence and psychological charac teristics attributed to the robots, r(21) = .63, p &lt; .01. However, unlike the first group these children attributed very little intelligence and psychology to the robots (see Table 3 for means). We labeled this group Robot as Machine. We used a paired t test to compare their mean intelligence attributions to the robots and the calcula tor and found that this was the only group that did not attribute significantly more intelligence to the robots than to the calculator. To children in this group, there was nothing particularly smart or unique about the robots?they were simply techno logical machines, like the calculator. It is interesting to note that for both of these groups, intelligence and psycholog ical attributions were consistent with life status judgments of the robots. Children who said the robots were alive believed they were significantly smarter, ?(32) = 2.92, p &lt; .01; and more psychological, t(32) = 2.57, p &lt; .05, than children who did not believe they were alive (see Table 3 for means). It would seem that children who believed the robots were alive applied a more biological definition of intelli gence, whereas children who did not believe the robots were alive largely denied them intelligence. Both responses were consistent with a biological point of view. The third group was made up of children with high opportunity scores. This group was characterized by high intelligence attributions and the lowest positive correlation between the number of intelligence and psychology characteristics attributed to the robots, r(26) = .59, p &lt; .01. We called this the Robot as Smart Technology group. This group distinguished itself from the two other groups in a number of ways. First, t-tests revealed no significant differences in the mean num ber of intelligence and psychological characteristics attributed to robots for chil</page><page sequence="16">240 BERNSTEIN AND CROWLEY dren in the 'alive' and 'not alive' groups. Children in this group also saw the robots as distinct from the other entities. An ANOVA was conducted with these children's intelligence attributions to the robots, cat, and calculator as a repeated measure. There was a significant effect for entity, F(2, 50) = 10.95, p &lt; .001. Post hoc com parisons revealed that children in this group attributed significantly more intelli gence characteristics to the robots than to the calculator. The number of intelli gence attributions to the robots and cat did not significantly differ. In the interest of determining whether children in this group viewed the robots and the cat similarly on all dimensions, we used a paired t test to compare psychological attributions to these two entities. Results indicated that children in this group attributed signifi cantly more psychological characteristics to the cat than to the robots, ?(25) = 5.09, p &lt; .001 (see Table 3 for all means). In sum, the attribution of psychological and intellectual characteristics was pos itively correlated for all children. However, these attributions were most related to life status judgments for children in the two low-opportunity groups. Additionally, children in the Robot as Animal group treated the robots similarly to the cat in terms of intellectual and psychological attributions. Children in the Robot as Ma chine group treated the robots similarly to the calculator for intelligence; however, children in the Robot as Smart Technology group treated the robots as a unique type of intellectual entity. DISCUSSION Children have long been intrigued by artifacts on the boundary of animacy (Ackermann, 2005). As intelligent technologies have become infused into every day and informal learning contexts, children's exposure to once exotic technology has become almost routine (see Leinhardt &amp; Crowley, 2002; Nourbakhsh et al., 2006). What are the potential impacts of children's interactions with this technol ogy? The current study sought to answer this question with respect to children's ideas about intelligence. We examined two potential sources of influence on children's ideas about intel ligence in robots: children's prior experience with technology and their ideas about the characteristics of living and nonliving entities. Results indicate that both of these factors are potential sources of influence. For children with little prior expe rience, attributions to the robots were commensurate with life status judgments. Children who believed the robots were alive attributed more intellectual and psy chological characteristics to them than those who did not believe they were alive. Additionally, children with little experience seemed to group the robots with fa miliar objects of similar life status (i.e., a cat and a calculator). These findings sug gest that among children with little experience, life status may have been a particu larly salient characteristic of the robots.</page><page sequence="17">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 241 In contrast, children with more prior experience attributed intellectual charac teristics to the robots that were not generally consistent with their life status judg ments. These children also attributed a unique pattern of intellectual and psycho logical characteristics to the robots?robots might be as smart as a cat, but they are less psychological. Taken together, these findings support the notion of an experience-based shift in children's understanding of robots. With experience, children come to view robots as distinct from familiar entities in two primary ways. First, the issue of alive seems to apply less stringently to robots, as evidenced by the fact that the robot's life status was less closely related to judgments of its intelligence for more experi enced children. Second, robots were assumed to possess a unique type of intelli gence, one that was distinct from the biological definition of intelligence that chil dren generally provide when describing intelligent people or animals. However, it is difficult to know how to classify the more experienced children's ideas about robot intelligence. It is certainly possible that these children are mov ing toward a definition of technological intelligence, but the caveat remains that technological intelligence is a difficult concept. The difficulty was well illustrated by Kahn, Ishiguro, Friedman, and Kanda's (2006) discussion of the difference be tween ontological and psychological claims with regard to robots. An ontological point of view takes into account the robot's actual technical capabilities, whereas a psychological point of view considers the human user's beliefs about the robot's characteristics. For example, although it may be the case that robots are not techni cally capable of feeling emotions, users can (and often do) perceive emotions on a robot's behalf. One weakness of the current study is that the questions about psy chological characteristics failed to account for this distinction. We do not know if the children in the study were responding ontologically or psychologically to our questions about the robot's capacity for feeling emotion and volition. Future re search could investigate the extent to which young children, even those with tech nology experience, are able to differentiate between the two possibilities. Includ ing additional questions about the robot's psychological capabilities may also help expand researchers' understanding of children's beliefs in this area. Future research might also address the question of cognitive parity between bi ological and technological entities. Humans and robots may be able to perform similar cognitive functions (e.g., remembering), but it is not clear whether children perceive these acts as qualitatively different from one another. How much do chil dren really understand about the similarities and differences between artificial and biological intelligence?7 It would be interesting to investigate the extent to which children believe that "thinking like a person" is the same as (or different from) "thinking like a robot." 70f course, there is no easy answer to this question. The artificial intelligence field has been debat ing this issue for some time (see Searle, 1990).</page><page sequence="18">242 BERNSTEIN AND CROWLEY One enduring question in the current study is why some children (particularly children with prior experience) judged the robots to be alive but then deviated from the pattern of characteristic attribution that might be predicted by their alive judgments. Jipson and Gelman (2007) recently examined children's beliefs about entities that challenge the living/nonliving distinction (such as robots) and found that judgments about biological characteristics were highly concordant with an entity's ontological status (alive or not alive), whereas judgments about thinking and feeling were influenced by both ontological status and other charac teristics (such as the presence of a face on the entity). Thus, there is precedent in the na?ve biology literature for movement away from characteristic attributions based strictly upon ontological status for challenging entities. Based upon our data, we suggest that prior experience may help to foster such a move, but our data do not support definitive claims about the particular ways in which this oc curs. It is possible that children's ideas about specific characteristics change be fore their larger beliefs about life status are altered, which might explain why children who said the robots were alive appeared in both the Robot as Animal and Robot as Smart Technology groups but displayed different ideas when asked about specific robot characteristics. Or it is possible, as suggested by Jipson and Gelman, that the alive/not alive distinction is a narrow one that works well for prototypical objects (like cats and chairs) and biological properties but loses some of its meaning when applied to boundary objects like robots and complex characteristics. Our approach was to look at robots as part of an expanding cohort effect. We hy pothesize that children raised increasingly amid intelligent technologies will grow up thinking differently about some concepts that developmental psychologists have previously considered universal and inevitable. For example, imagine a child whose parent has purchased a Roomba (a robotic vacuum cleaner) to clean the floors. Perhaps this child has seen the Roomba stop itself at the top of a flight of stairs, locate its charging station when it was running low on battery power, or per form any number of activities that indicate its ability to perceive and respond to stimuli in its environment.8 Might this child move beyond dichotomies used by her parents (Turkle, 1999)? Kahn, Friedman, et al. (2004, 2006) suggested that chil dren may be developing a new ontological category for intelligent technologies, one that includes machines that are animate and intelligent. Just as children who have pets can reason in more sophisticated ways about living things (Inagaki, 1990), children who live among robots may change the way they think about tech nology. 8This is not a vision of the future: As we write more than 2 million Roombas have been sold. At least two of those went to the homes of children in this study.</page><page sequence="19">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 243 ACKNOWLEGMENTS We are grateful to the following colleagues for their thoughtful comments on this work: Chris Schunn and Micki Chi from the Learning Research and Development Center; Illah Nourbakhsh, Kristen Stubbs, and Emily Hamner from the Robotics Institute at Carnegie Mellon University; and Sasha Palmquist and Catherine Eberbach from the University of Pittsburgh Center for Learning in Out-of-School Environments. Thanks to Jane Werner and the visitors and staff at the Children's Museum of Pittsburgh. We thank the following individuals for their help with data collection and coding: Jenna Brooks, Liza France, Anuja Parikh, Andrea Pat terson, and Nora Webber. REFERENCES Ackermann, E. K. (2005). Playthings that do things: A young kid's "Incredibles"! In Proceedings of the Conference on Interaction Design for Children. Boulder, CO: ACM. Backscheider, A. G., Shatz, M., &amp; Gelman, S. A. (1993). Preschoolers' ability to distinguish living kinds as a function of regrowth. Child Development, 64, 1242-1257. Chi, M. T. H. (1978). Knowledge structures and memory development. In R. Siegler (Ed.), Children's thinking: What develops (pp. 73-96). Hillsdale, NJ: Erlbaum. Chi, M. T. H., Hutchinson, J. E., &amp; Robin, A. F. (1989). How inferences about novel domain-related concepts can be constrained by structured knowledge. Merrill-Palmer Quarterly, 35(1), 27-62. Chi, M. T. H., &amp; Koeske, R. D. (1983). Network representation of a child's dinosaur knowledge. Devel opmental Psychology, 19, 29-39. Cole, M. (1997). Cultural mechanisms of cognitive development. In E. Amsel &amp; K. A. Renninger (Eds.), Change and development: Issues of theory, method, and application (pp. 245-263). Mahwah, NJ: Erlbaum. Crowley, K., &amp; Jacobs, M. (2002). Buildings islands of expertise in everyday family activity. In G. Leinhardt, K. Crowley, &amp; K. Knutson (Eds.), Learning conversations in museums (pp. 333-356). Mahwah, NJ: Erlbaum. Davis, D. (2004). Children 's beliefs about what it means to have a mind. Unpublished doctoral disserta tion, University of Texas at Austin. Gelman, S. A. (1988). Children's expectations concerning natural kind categories. Human Develop ment, 31, 28-34. Gelman, S. A. (1989). Children's use of categories to guide biological inferences. Human Develop ment, 32, 65-11. Gelman, S. A., &amp; Gottfried, G. M. (1996). Children's causal explanations of animate and inanimate mo tion. Child Development, 67, 1970-1987. Gelman, S. A., &amp; Opfer, J. E. (2002). Development of the animate-inanimate distinction. In U. Goswami (Ed.), Blackwell handbook of childhood cognitive development (pp. 151-166). Maiden, MA: Blackwell. Hatano, G., Siegler, R. S., Richards, D. D., Inagaki, K., Stavy, R., &amp; Wax, N. (1993). The development of biological knowledge: A multi-national study. Cognitive Development, 8, 47-62. Hmelo-Silver, C, &amp; Pfeffer, M. (2004). Comparing expert and novice understanding of a complex sys tem from the perspective of structures, behaviors, and functions. Cognitive Science, 28, 127-138.</page><page sequence="20">244 BERNSTEIN AND CROWLEY Inagaki, K. (1990). The effects of raising animals on children's biological knowledge. British Journal of Developmental Psychology, 8, 119-129. Inagaki, K., &amp; Hatano, G. (1987). Young children's spontaneous personification as analogy. Child De velopment, 58, 1013-1020. Inagaki, K., &amp; Hatano, G. (2002). Young children's naive thinking about the biological world. New York: Psychology Press. Jipson, J. L., &amp; Gelman, S. A. (2007). Robots and rodents: Children's inferences about living and non living kinds. Child Development, 78(6), 1675-1688. Johnson, C. N., &amp; Wellman, H. M. (1982). Children's developing conceptions of the mind and brain. Child Development, 53, 222-234. Johnson, K. E., Alexander, J. M., Spencer, S., Leibham, M. E., &amp; Neitzel, C. (2004). Factors associated with the early emergence of intense interests within conceptual domains. Cognitive Development, 19, 325-343. Johnson, K. E., &amp; Mervis, C. B. (1994). Microgenetic analysis of first steps in children's acquisition of expertise on shorebirds. Developmental Psychology, 30, 418-435. Kahn, P. H., Friedman, B., Perez-Granados, D. R., &amp; Freier, N. G. (2004). Robotic pets in the lives of preschool children. In Proceedings of the Conference on Human Factors in Computing Systems (pp. 1449-1452). Vienna, Austria: ACM. Kahn, P. H., Friedman, B., Perez-Granados, D. R., &amp; Freier, N. G. (2006). Robotics pets in the lives of preschool children. Interaction Studies, 7, 405-436. Kahn, P. H., Ishiguro, H., Friedman, B., &amp; Kanda, T. (2006). What is a human? Towards psychological benchmarks in the field of human-robot interaction. In Proceedings of the IEEE International Sym posium on Robot and Human Interactive Communication (pp. 364-371). Hatfield, England. Kinlaw, C. R., &amp; Kurtz-Costes, B. (2003). The development of children's beliefs about intelligence. Developmental Review, 23, 125-161. Kurtz-Costes, B., McCall, R. J., Kinlaw, C. R., Wiesen, C. A., &amp; Holland Joyner, M. (2005). What does it mean to be smart? The development of children's beliefs about intelligence in Germany and the United States. Applied Developmental Psychology, 26, 217-233. Leinhardt, G., &amp; Crowley, K. (2002). Objects of learning, objects of talk: Changing minds in museums. In S. Paris (Ed.), Multiple perspectives on children's object-centered learning (pp. 301-324). Mahwah, NJ: Erlbaum. Mak, B. S. K., &amp; Vera, A. H. (1999). The role of motion in children's categorization of objects. Cogni tion, 71, B11-B21. Massey, C. M., &amp; Gelman, R. (1988). Preschooler's ability to decide whether a photographed unfamil iar object can move itself. Developmental Psychology, 24, 307-317. Maynard, A. E., Subrahmanyam, K., &amp; Greenfield, P. M. (2005). Technology and the development of intelligence: From the loom to the computer. In R. J. Sternberg &amp; D. D. Preiss (Eds.), Intelligence and technology: The impact of tools on the nature and development of human abilities (pp. 29-53). Mahwah, NJ: Erlbaum. Means, M. L., &amp; Voss, J. F. (1985). Star wars: A developmental study of expert and novice knowledge structures. Journal of Memory and Language, 24, 746-757. Melson, G. F., Kahn, P. H., Beck, A. M., Friedman, B., Roberts, T., &amp; Garrett, E. (2005). Robots as dogs? Children's interactions with the robotic dog AIBO and a live Australian shepherd. In Proceedings of the Conference on Human Factors in Computing Systems (pp. 1649-1652). Portland, OR: ACM. Nigam, M. K., &amp; Klahr, D. (2000, August). If robots make choices, are they alive? Children's judg ments of the animacy of intelligent artifacts. Poster presented at the meeting of the Cognitive Science Society, Philadelphia, PA. Nourbakhsh, I., Hamner, E., Ayoob, E., Porter, E., Dunlavey, B., Bernstein, D., et al. (2006). The Per sonal Exploration Rover: Educational assessment of a robotic exhibit for informal learning venues. International Journal of Engineering Education, 22, 111-191.</page><page sequence="21">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 245 Okita, S. Y., Schwartz, D. L., Shibata, T., &amp; Tokuda, H. (2005). Exploring young children's attributions through entertainment robots. In Proceedings of the IEEE International Workshop on Robot and Hu man Interactive Communication (pp. 390-395). Nashville, TN. Opfer, J. E., &amp; Gelman, S. A. (2001). Children's and adults models for predicting ideological action: The development of a biology-based model. Child Development, 72, 1367-1381. Palmquist, S. D., &amp; Crowley, K. (2007). Studying dinosaur learning on an island of expertise. In R. Goldman, R. Pea, B. Barron, &amp; S. Deny (Eds.), Video research in the learning sciences (pp. 271-286). Mahwah, NJ: Erlbaum. Papert, S. (1980). Mindstorms: Children, computers, and powerful ideas. New York: Basic Books. Pesce, M. (2000). The playful world: How technology is transforming our imagination. New York: Ballantine Books. Richards, D. D., &amp; Siegler, R. S. (1986). Children's understanding of the attributes of life. Journal of Experimental Child Psychology, 42, 1-22. Rogoff, B. (2003). The cultural nature of human development. Oxford, England: Oxford University Press. Saxe, G. B. (1999). Cognition, development, and cultural practices. New Directions for Child and Ado lescent Development, 83, 19-35. Scaife, M., &amp; Van Duuren, M. (1995). Do computers have brains? What children believe about intelli gent artifacts. British Journal of Developmental Psychology, 13, 367-377. Searle, J. R. (1990). Is the brain's mind a computer program? Scientific American, 262(1), 26-31. Shaffer, D. W. (2006). Epistemic frames for epistemic games. Computers and Education, 46(3), 223-234. Shaffer, D. W., Squire, K. D., Halverson, R., &amp; Gee, J. P. (2005). Video games and the future of learn ing. Phi Delta Kappan, 87(2), 104-111. Sternberg, R. J., Conway, B. E., Ketron, J. L., &amp; Bernstein, M. (1981). People's conceptions of intelli gence. Journal of Personality and Social Psychology, 41, 37-55. Stigler, J. W. (1984). "Mental abacus": The effect of abacus training on Chinese children's mental cal culation. Cognitive Psychology, 16, 145-176. Subrahmanyam, K., &amp; Greenfield, P. M. (1996). Effect of video game practice on spatial skills in girls and boys. In I. E. Sigel (Series Ed.) &amp; P. M. Greenfield &amp; R. R. Cocking (Vol. Eds.), Advances in ap plied developmental psychology: Vol. 11. Interacting with video (pp. 95-114). Norwood, NJ: Ablex. Turkle, S. (1984). The second self: Computers and the human spirit. New York: Simon &amp; Schuster. Turkle, S. (1998). Cyborg babies and cy-dough-plasm: Ideas about self and life in the culture of simula tion. In R. Davis-Floyd &amp; J. Dumit (Eds.), Cyborg babies: From technosex to technotots (pp. 317-329). New York: Routledge. Turkle, S. (1999). What are we thinking about when we are thinking about computers? In M. Biagioli (Ed.), The science studies reader (pp. 543-552). New York: Routledge. Van Duuren, M., &amp; Scaife, M. (1996). "Because a robot's brain hasn't got a brain, it just controls itself: Children's attributions of brain related behaviour to intelligent artifacts. European Journal of Psy chology of Education, 11, 365-376. Vygotsky, L. S. (1978). Mind in society: The development of higher psychological processes. Cam bridge, MA: Harvard University Press. Wellman, H. M., &amp; Gelman, S. A. (1992). Cognitive development: Foundational theories of core do mains. Annual Review of Psychology, 43, 337-375. Wellman, H., &amp; Gelman, S. A. (1998). Knowledge acquisition in foundational domains. In W. Damon, D. Kuhn &amp; R. Siegler (Eds.), Handbook of child psychology, Vol. 2: Cognition, perception, and lan guage (5th ed., pp. 523-573). New York: Wiley. Woods, S., Dautenhahn, K., &amp; Schulz, J. (2004). The design space of robots: Investigating children's views. In Proceedings of the IEEE International Workshop on Robot and Human Interactive Com munication (pp. 47-52). Okayama, Japan. Yussen, S. R., &amp; Kane, P. T. (1985). Children's conception of intelligence. In S. R. Yussen (Ed.), The growth of reflection in children (pp. 207-241). New York: Academic Press.</page><page sequence="22">246 BERNSTEIN AND CROWLEY Appendix A Forced-Choice Task Questions Biological Characteristics Alive ... Which cards have things on them that are alive? Growth ... Which cards have things on them that can grow? What I mean is, if we looked at these things a long time from now, they would be bigger. Metabolism ... Which cards have things on them that need food or water? Movement... Which cards have things on them that can move by themselves? Reproduction ... Which cards have things on them that can make little ones just like themselves? Can make babies? Psychological Characteristics Emotion ... Which cards have things on them that can feel happy or sad? Volition ... Which cards have things on them that if you gave them a choice, they could decide what to do? Intelligence Characteristics Calculate ... Which cards have things on them that can add numbers together? Learn ... Which cards have things on them that can learn how to do new things? Planning ... Which cards have things on them that if we told them what to do, they could figure out how to do it? Remember ... Which cards have things on them that can remember things? Like if they did something today, they would remember it tomorrow? Situational Awareness ... Which cards have things on them that if we picked them up and put them in the room over there, they would know they were in a new place? Think ... Which cards have things on them that can think?</page><page sequence="23">CHILDREN'S BELIEFS ABOUT ROBOT INTELLIGENCE 247 Artifactual Processes Factory ... Which cards have things on them that were made in a factory? Put Together ... Which cards have things on them that someone had to build? Appendix B Percentage of Children Attributing Characteristics to Each Entity Characteristic Person Cat Plant Computer Humanoid Robot Rover Calculator Doll Biological Alive Grow Reproduce Eat Move Intellectual Calculate Learn Remember Plan Think Psychological Emotion Volition Artifactual Put together Made in factory 100 100 97 100 100 90 100 100 98 100 100 100 17 2 100 92 95 98 100 93 67 12 2 63 93 23 95 10 0 87 3 67 2 73 3 90 0 10 5 12 13 2 0 0 0 77 18 28 33 27 3 20 90 85 42 5 13 7 83 53 55 53 73 60 37 50 97 93 37 5 10 5 83 47 50 45 67 58 30 52 97 92 12 0 0 0 0 93 13 15 23 20 2 13 83 85 5 2 5 2 5 2 2 0 3 3 12 3 78 82</page></plain_text>
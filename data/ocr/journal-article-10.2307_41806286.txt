<plain_text><page sequence="1">Behavior and Philosophy, 38 , 1-29 (2010). © 2010 Cambridge Center for Behavioral Studies Is Neuroscience Adequate as the Forthcoming "Mindscience"? Riccardo Manzotti and Paolo Moderato IULM University ABSTRACT: The widespread use of brain imaging techniques encourages conceiving of neuroscience as the forthcoming "mindscience." Perhaps surprisingly for many, this conclusion is still largely unwarranted. The present paper surveys various shortcomings of neuroscience as a putative "mindscience." The analysis shows that the scope of mind (both cognitive and phenomenal) falls outside that of neuroscience. Of course, such a conclusion does not endorse any metaphysical or antiscientific stance as to the nature of the mind. Rather, it challenges a series of assumptions that the undeniable success of neuroscience has fostered. In fact, physicalism is here taken as the only viable ontological framework - an assumption that does not imply that the central nervous system exhausts the physical domain. There are other options like behavior, embodiment, situatedness, and externalism that are worth considering. Likewise, neuroscience is not the only available epistemic option as to the understanding of mind. Key words : neuroscience, dualism, brain imaging, psychology, reductionism, mindscience Is Neuroscience the New Science of the Mind? Neuroscience is the scientific study of the nervous system. Historically, it started as a branch of biology and eventually spawned a series of sub-disciplines with closer bonds with psychology, computer science, mathematics, and philosophy. In the last years, after what has been called the decade of the brain, the scientific community is increasingly looking at neuroscience as the alleged scientific discipline for the study of the mind or, as a shorthand, the new "mindscience" (Crick &amp; Koch, 2003; Edelmann, 2004; Lamme, 2006; Tononi &amp; Koch, 2008; Zeki, 2002). Somehow, at the end of the 20th century, neuroscience abruptly became the discipline that was going to unravel the problem of the mind and, significantly, that of consciousness: "Increasing knowledge of the neural correlates of consciousness is expected to yield an explanation of consciousness in neuroscientific terms" (Kurthen et. al., 1998, p. 229). In the process, most clinical, methodological, and fundamental psychological disciplines have been flanked by AUTHORS' NOTE: Portions of this paper were previously presented at the VII World Congress of the Association for a Contextual Behavior Science, Entschede (NL), July 2009, and at the 5th International Conference of the Association of Behavior Analysis, Oslo, August 2009. We thank Gary Novak for his helpful comments and suggestions. Please address correspondence to Paolo Moderato, IULM University, Via Carlo Bo, 1, 20143 Milan, Italy. Email: paolo.moderato@iulm.it or paolo.moderato@gmail.it. 1</page><page sequence="2">Manzotti &amp; Moderato analogous neuro-oriented fields: neuro-economics, neuro-linguistics, neuro- philosophy, neuro-ethics, neuro-aesthetics, and so on. It seems now that the only viable option is to study the activity of the central nervous system while all the other disciplines are doomed to disappear in an over-encompassing neural analysis of all aspects of the mind (Churchland, 1986; Churchland &amp; Churchland, 2002; Crick, 1994; Crick &amp; Koch, 2003). For example, Victor Lamme recently wrote that "we need to let go of our intuitive or psychological notions of conscious experience and let the neuroscience arguments have their way. Only by moving our notion of mind towards that of brain can progress be made" (Lamme, 2006, p. 494). On the other hand, the neurologist Semir Zeki explicitly and unabashedly stated that it is "a truth that [he believes] to be axiomatic - that all human activity is dictated by the organization and laws of the brain" (Zeki, 2002, p. 54). Cristoph Koch unabashedly but very clearly wrote that "the entire brain is sufficient for consciousness - it determines conscious sensations day in and day out. . .[L]ikely a subset of brain matter will do" (Koch, 2004, p. 87). In his last book Paul Nunez poses as the crucial question whether "the brain creates the mind?" (Nunez, 2010). Giulio Tononi states that to understand consciousness "A more practical approach is to use the tools of neuroscience that are available now to shed light on the neural structures and activity patterns that underlie consciousness" (Tononi, 2008, p. 239). Even an author like William R. Uttal, while criticizing the widespread tendency to localize mental functions, states that I feel it necessary to identify and repudiate, as clearly as I can, some of the false issues that may be imputed to this book. First, my analysis. . .is not intended in any way to challenge the most basic principle of psychobiology or the cognitive neurosciences, namely, that any human mental process is solely a reflection of or equivalent to some aspect of brain activity. (Uttal, 2001, p. 206) It really seems that the only scientific discipline worth of pinning down mental processes is the one studying brain activities - namely, neuroscience. Although not always explicitly stated, the confidence in neuroscience as the true "mindscience" is gaining momentum. By and large, such a confidence in neuroscience as the new science of the mind assumes two forms. The first one is a metaphysical stance that corresponds roughly to the mind-brain identity theory (Place, 1956) - mental properties are nothing but neural properties. The other one is a somewhat weakened epistemic version. Although it does not make any ontological assumptions, it loosely suggests that most mental phenomena could be explained in neural terms once enough data about their neural implementations are collected. In this regard, the literature is often vague and, although most authors would not commit to a total identity between mental and neural properties, most would lean toward some kind of close dependence between mind and brain. As to the mind, we refer here to all aspects of it - ranging from cognitive skills to the more phenomenologically intractable aspects such as the quality of subjective states, intentionality, and first-person perspectivalness. In other words, we take the mind to be no less than the unified, intentionally and semantically 2</page><page sequence="3">Is Neuroscience Adequate as the Forthcoming "Mindscience"? proficient, phenomenally rich, cognitively skilled, sensory-motor capable phenomenon that characterizes an adult human being in healthy condition. It is surely feasible and useful to study independently each of these phenomena. However, we wonder whether the current understanding of the mind justifies any strong conclusion as to the sufficiency of the central nervous system to explain the mind. For instance, it has been customary to set aside the topic of phenomenal experience (Chalmers, 1994). The "cognitive" mind has been studied independently of its phenomenal aspects. Is this justified until we have a better understanding as to why a human being is conscious? If you accept Francis Crick's tenet that the mind is what the brain does (Crick, 1994), you are then faced with the full-fledged chasm between a domain of cell bodies, axons, dendrites, synapses, receptor sites, neurotransmitters, and so forth, and a domain of representations, intentions, beliefs, phenomenal experiences, voluntary acts, and many other notions we refer to using the mental/intentional idiom. Isn't this persisting chasm the sign that neuroscience has been unable so far to provide an alternative framework? It appears that many assume that a suitable solution to this problem consists in compartmentalizing the issues until some new view emerges. On one side the philosophers deal with the epistemic gap and the hard problem of consciousness (Chalmers, 1994). On the other side the neuroscientists work with real cases. As it has been noted by Steven F. Faux, Much of cognitive neuroscience still relies on mentalistic forms of explanation that either explicitly or implicitly appeal to an inner agent, "the ghost in the machine". . .Although the technology of cognitive neuroscience is impressive. . .those measurements amount to little more than chasing ghosts with Geiger counters. (Faux, 2002, p. 161) According to Daniel Dennett, after all, neuroscience has been accumulating such a huge amount of explanatory debts that have yet to be discharged (Dennett, 1978). To recap, whenever we refer to the mind, we mean, for lack of a substantive reason not to do so, something encompassing all aspects of human mental experience - namely cognitive, phenomenal, and sensory-motor. As a result, in what follows, each of these aspects (and foremost among them consciousness) will be a nonnegotiable aspect of the mind. Historically, the long wait for a scientific discipline centered on the mind was not satisfied by the development of psychology. Today, many authors wonder whether neuroscience will become the new mindscience. This is questionable and so far unwarranted. The present paper has two goals. First, we wish to document the widespread - yet, in our opinion, questionable - conviction that the study of the nervous system will ultimately lead to a scientific explanation of the mind. Second, we wish to critically review the theoretical arguments and empirical evidence that challenge such a conviction. The present paper develops and extends an argument which has been presented every time there was the hope of providing a reductionist explanation of the mind (Searle, 1992). In the first chapter of Varieties of Religious Experience , 3</page><page sequence="4">Manzotti &amp; Moderato William James wrote that "Modem Psychology, finding definite psychophysical connections to hold good, assumes as a convenient hypothesis that the dependence of mental states upon bodily conditions must be thoroughgoing and complete" (James, 1902/2002, p. 16). This convenient hypothesis, which is still only a hypothesis, has been resurrected many times and it is now receiving the widest consensus. This is particularly clear in many popularizations of science (for instance, Trimble, 2007). At the onset we stress that, notwithstanding common beliefs, physicalism does not entail that the mind has to be an emergent property of neural activity. Physicalism only requires that the mind be explained in physical terms. Physics does not consist of the nervous system alone - being "neural" is a subset of being "physical." Equating the mind with the brain is not the only possible option for physicalism. However, it is the only possible option for a physicalist who embraces internalism in some form. Internalism is the view that all the conditions that constitute a person's thoughts and sensations are internal to their nervous system (Adams &amp; Aizawa, 2008; Koch, 2004; Mendola, 2008). Yet, internalism is only one possibility and there is no conclusive evidence for it. There are many other options available to a physicalist, ranging from considering extemalism to equating the mind with behavior. Currently there are many authors who are exploring these alternative possibilities (Clark, 2008; Honderich, 2006; Manzotti, 2006; Robbins &amp; Aydede, 2009; Rockwell, 2005; Tonneau, 2004). However, the prefix "neuro" has become an almost mandatory label to attach to many research projects, particularly if funding and grant requests are involved. In the popular culture and in the scientific community, the prefix has become a dubious sign of scientific soundness (Legrenzi &amp; Umiltà, 2009; Manzotti &amp; Moderato, 2008). Is this just a fashion or is it an unavoidable trend? Even in science there are fashions; in psychology there has been the behavioral fashion, the Hull fashion, the cognitive revolution, and now the neuroscience fashion. It is generally held that the study of the mind is somehow different from other fields of scientific inquiry. A series of obstacles - such as the entanglement between observer and observed, as well as the alleged ontological gap between subjectivity and objectivity - have long hampered any attempt to integrate psychology with the rest of science. So far, it is fair to say that nobody knows if the gap between the mind and the physical world is real, epistemic, ontic, temporary, or even metaphysically necessary. All of a sudden, the dethronement of psychology as the main "mindscience" has had a curious effect: Neuroscience triggered an upsurge of disguised forms of mentalism or dualism (Rockwell, 2005; Uttal, 2004). Consider a sentence such as "Scientists have been able to reach into the mind of a brain-damaged man and communicate with his thoughts" (BBC, 2010, Health Page, 3 February 2010). This sentence comments on research, carried out at in the UK and in Belgium, that involved a new brain scanning method. Or consider Kendrick N. Kay when he writes that "A challenging goal in neuroscience is to be able to read out, or decode, mental content from brain activity" (Kay, et. al., 2008, p. 352). Taken at face value, such claims endorse the idea that the brain hosts the mind. Through the brain we 4</page><page sequence="5">Is Neuroscience Adequate as the Forthcoming "Mindscience"? can get to the mind, which is indeed curious if dualism had really been set aside. Ryle's classic argument can be resurrected as, indeed, it has been done recently by a few (Bennett &amp; Hacker, 2003; Faux, 2002; Ryle, 1949). The mind has not disappeared from scientific and public language; rather, it developed a closer relation with the brain. The brain is now carrying the burden of the soul. Or so it seems. Moreover, in a behavior analytic account, the whole organism - the body - "hosts" the whole behavior, including the cognitive one. Psychology, which ironically William James christened as the discipline with a long past and a brief history, seems to have no fixture. Many of its long established views - behaviorism, functionalism, cognitivism - have been dismissed to be replaced by more neuro-oriented approaches. One of the reasons for this is the ontological void lurking at the bottom of the psychological endeavor. What is the stuff of the mind? This had long been an unanswered and forbidden question, at least since classic behaviorism took center stage. The role of psychology has been that of holding the trench beyond which the vague dreams of philosophy could strip scientific theories of their validity. To succeed, psychology has had to pay a dear price - namely that of lacking sound ontological foundations. At the turn of the 20th century, many began to argue that neuroscience offers the missing ingredients to complete the scientific reduction of the mind. Is neuroscience the psychology of the future? Is neuroscience the long awaited and forthcoming "mindscience"? In the following we will argue that the answer is negative, although this answer does not diminish in any way the importance of neuroscience in understanding the properties of neural processes. However, to anticipate what will follow, neuroscience is ill-suited to deal with the mind both empirically and methodologically. Furthermore, the very fact that neuroscience has been conceived as a putative science of the mind is the outcome of a series of conceptual confusions. We do not criticize the experimental approaches of neuroscience, but rather we try to bring into the open the unwarranted ontological and epistemic premises entailed in most of the available current neuroscientific literature as to the nature of the mind. At the onset, a necessary caveat is that we do not advocate any kind of anti- reductionistic or anti-physicalist approach to the mind. If the mind is a real phenomenon, and there is no reason to deny it, it has to be part of the natural world and thus, in principle, it has to be amenable to scientific understanding. A physicalist expects that science will understand the mind. Yet, a physicalist is not compelled to hold that neuroscience will be able to understand the mind. For instance, electromagnetism was incapable of explaining the source of energy of the sun, yet eventually a different physical explanation was found. Further, as will be stressed at length, assuming in advance that a certain phenomenon has to be explained inside an a priori established domain is like putting the neuroscience cart before the mind horse, so to speak. It is methodologically unjustified. We also have a second caveat. In this paper, we use the two terms "mind" and "consciousness" with some overlap. This could raise some criticisms. However, if consciousness is debunked of awkward metaphysical charges, it is nothing more 5</page><page sequence="6">Manzotti &amp; Moderato than a way to refer to a state of awareness in a subject. In this sense, we adopt a sincerely agnostic stance towards consciousness. We are not alone in this (Aleksander, 2001; Koch, 2004; Metzinger 2000; Revonsuo 2006; Zeki 2001). We do so for the lack of a better and more neutral way to refer to these aspects of the mind. Where and Why Neuroscience Assumes Too Much The fact that neuroscience is the discipline that studies the activity of the nervous system does not guarantee by any means a satisfactory explanation of the mind. The relation between neural activity and the mind has to be demonstrated, not posited as an unquestioned starting point. Currently, the link between neurons and thoughts seem obvious to some and preposterous to others. For instance, many scholars maintain that the mind takes place inside the brain. Where else? Thus, the mind is an outcome concocted by neurons in some way yet to be ascertained. Many neuroscientists implicitly or explicitly assume a view of this sort (Changeux, 1983; Edelman, 2004; Koch, 2004; Revonsuo, 2006; Tononi, 2004, 2008; Zeki, 2001). Neural mechanisms are the mechanisms of the mind. Mind gears are neurons. What else? Anyone suggesting otherwise raises more than an eyebrow in many hardcore scientists. The ghost of dualism and the risk of some cranky metaphysical view daunt most scholars from questioning the identity between neural activity and mental activity. Consider the following proposition: The study of the mind is a subset of the study of the brain [Nl] Is this proposition in any sense tenable? We will claim that it is not. Yet, we suspect that many neuroscientists would agree with the statement (Armstrong, 1968; Churchland, 1986; Churchland &amp; Churchland, 2002; Melzack, 2001; Metzinger, 2000; Tononi, 2008). There is a big difference between the experimental validity of neuroscientific research as such and the unwarranted mental ontology it conveys. Here the validity of neural evidence is not questioned. Yet, as to the nature of the mind, it could be that something is systematically left out of the picture (something physical, of course). In other words, Nl entails the following more ontologically committing claim: The mind is either a property of an activity or an activity occurring in the brain [N2] This further claim is even thornier than the apparently less demanding Nl. Is all our mental life really reducible to the properties of what a bunch of neurons does, albeit in the most incredibly complex way? Are all our ends, feelings, pains, motivations, and emotions nothing but the properties of neural networks? This claim does not seem any longer so convincing, even though some could feel compelled to embrace this view. If you want a confirmation that this is the 6</page><page sequence="7">Is Neuroscience Adequate as the Forthcoming "Mindscience"? prevalent view in neuroscience, nothing is better than Francis Crick's famous claim that the mind is nothing more than what the brain does (Crick, 1994), which paved the way to the doctrine that what we call mind is nothing but the properties of some yet-to-be-identified neural patterns (Armstrong, 1968; Churchland, 1986; Churchland &amp; Churchland, 2002; Metzinger, 2000; Melzack, 2001; Place, 1956; Tononi, 2008). A neuroscientist like Atti Revonsuo states confidently that " Subjective phenomenal consciousness is a real, natural biological phenomenon that literally resides within the confines of the brain " (Revonsuo, 2006, p. 10, italics in the original). Does he provide any evidence for this view? Being an extraordinary conclusion, wouldn't it need some equivalently extraordinary evidence? It is evident that N1 and N2 overlap with the mind-brain identity hypothesis. Yet, mind-brain identity is just a hypothesis waiting for some evidence to support it. Up to now there is no evidence at all, and the fact that many neuroscientists take it for granted is likely the result of the much heralded authority of neuroscience. However, accepting the reduction of mind to neurons only by virtue of the authority of neuroscience begs the question. Another version of the previous claim, apparently weaker, is the following: The mind depends only on what takes place in the brain [N3] N3 still admits plenty of importance to neuroscience, yet N3 is even vaguer than N1 and N2. It doesn't say anything as to the nature of either the mind or the dependence relation. Many neuroscientists, who would be uncomfortable with N1 and N2, would happily embrace N3. N3 does not entail any specific ontological framework, and it is reasonably vague as to the nature of the relation between the mind and the brain. Most philosophers would agree at least with N3. For instance, consider Jaegwon Kim, who states that "if you are a physicalist of any stripe, as most of us are, you would likely believe in the local supervenience of qualia" (Kim, 1995, p. 159), i.e., the mind must somehow depend only on what take place inside the body. He must believe that the notion is so self-evident that it does not need explicit explanation. It is important to stress that the notion of supervenience is much stronger than that of simple covariance or correlation (Kim, 1993). Supervenience entails some kind of nomological or ontological dependence. In other words, the relation of supervenience entails dependence between properties and not simply between contingent occurrences of phenomena. For instance, temperature is both supervenient and identical to average speed of molecules, whereas global warming is not supervenient on levels of carbon dioxide. The relevance of Kim's view and that of many others is not to be underestimated. Yet, a physicalist could appeal to physical phenomena external to the body and thus being a physicalist without accepting the local supervenience of qualia. N3 is vague enough to accommodate certain forms of dualism (for instance, Chalmers' natural dualism). However, it is not vague enough. Once the brain is running, so to speak, the mind is uniquely determined by the brain state. It doesn't matter whether development, upbringing, education, or surrounding stimuli were 7</page><page sequence="8">MANZOTTI &amp; MODERATO necessary to the development of the brain. All these aspects are nothing but contingent causes. N3 could be further weakened as follows: The mind depends partially on what takes place in the brain [N4] This proposition is so vague that leaves room for nearly every possible theory except Leibniz's Monadology. Either implicitly or explicitly, most neuroscientists hold that at least N2 if not also N1 is true, thereby stipulating unwarranted ontological commitments. The point to stress is not, as many philosophers did in the past, that the mind is forever unreachable by science (Harnad, 2000; Jackson, 1996; Shoemaker, 1982). We do not take that route here. Rather, we stress that so far there is no convincing evidence that, whether the mind is explainable as a physical phenomenon, it has to be reducible to a neural phenomenon. The mind is probably a physical phenomenon of some sort - a sort yet to be fleshed out. It would indeed be bad science to look for what the mind is, assuming from the start that it has to be some neural phenomenon, as many have done with no success. Ten Shaky Steps from Neurons to the Mind In this section a series of thorns in the flower of neuroscience is outlined. Our main point is that neuroscience hardly seems to deliver on its frequent bold promises of a future global explanation of all aspects of the mind. For instance, Francois Tonneau observed that The recent history. . .is one of ever more impressive technical advances in neuroscience combined with the ever-growing suspicion that these advances leave the hard problem of consciousness entirely untouched. (Tonneau, 2004, p. 120) So far, many core aspects of the mind have been left largely unexplored by neuroscience - among these are consciousness, intentionality, phenomenal character, unity, and perspectivalness. The epistemic tools of neuroscience seem to lack some essential features. This is not to say that neuroscience is not a rich source of data and models as to how certain processes take place in the nervous system. Still, there are core features of the mind which have not been yet addressed and could never be inside the scope of the nervous system. Neuroscience can be seen as the study of the brain and nervous system, including molecular neuroscience, cellular neuroscience, psychophysics, computational modeling, and diseases of the nervous system. It is questionable whether these topics will ever be able to swallow and encompass the mind (taken as a physical phenomenon). The mind could simply require either a larger or a different scope. Of course, neither the importance of neuroscience nor its usefulness are here questioned. What is at stake is whether neuroscience is enough to adequately understand the physical underpinnings of the mind. We are questioning the alleged 8</page><page sequence="9">Is Neuroscience Adequate as the Forthcoming "Mindscience"? reduction of mental properties to neural properties. We are also questioning the alleged reduction of many mind-related disciplines to neuroscience and its ancillary sub-disciplines. For instance, consider phenomenal experience. Although there are countless studies regarding the neural correlates of consciousness, is there really any attempt to explain how neural firings become phenomenal experience? Is there any forthcoming natural law bridging the gap between physical activity and mental processes? It is fair to maintain that most - if not all - neuroscientific data address what neuroscience is most suited for, namely all the various aspects of neural activity rather than the mind. The shortcomings of neuroscience are here divided in various categories on the basis of their role in preventing the study of neural activity from becoming a study of the mind. Methodological, Technological, and Experimental Issues To record neural activity, current techniques, although highly sophisticated, are still insufficient to provide an explanation demanded by cognitive functions. Furthermore, the step from neural activity to mental content is still theoretically and empirically highly speculative. There is a huge group of methodological shortcomings that hamper available techniques. As methods are refined, some of these difficulties will be partially solved - but not all. Consider fMRI, for instance. It has been heralded as a reliable way to measure neural activity. Although it delivers beautiful images of the hemodynamic response in the cortex, fMRI spatial resolution is around 55 mm3 and temporal resolution is between one and a few seconds. As a result, each voxel contains around 5 million neurons, 2.2 - 5.5 x 1010 synapses, 22 km of dendrites, and 220 km of axons (Logothetis, 2008). An image is like watching the whole of Manhattan for a few seconds and reducing all observed events to some single scalar value. To make matters worse, there are various statistical issues that could result in unreliable results (Bennett, Wolford, et. al., 2009) because random noise and uncorrected statistical thresholds are prone to causing false positives. It has been reported that - using standard acquisition, preprocessing, and analysis techniques - active voxel clusters can be observed in a dead salmon's brain (Bennett, Baird, et. al., 2009). Of course, using more conservative forms of correction, these false positives would disappear. Another source of concern is the complex causal chain linking fMRI results with neural activity and with mental content. Consider the first step: the link between fMRI voxel activation patterns and neural activity. The underlying hypothesis is that the BOLD signal (based on Blood Oxygen Level Dependent contrast mechanism) corresponds to higher level of local neural activation. There are many possible misinterpretations here. Nikos Logothetis recently warned that "fundamental questions concerning the interpretation of fMRI data abound, as the conclusions drawn often ignore the actual limitations of the methodology" 9</page><page sequence="10">MANZOTTI &amp; MODERATO (Logothetis, 2008, p. 869). The issue at stake, roughly speaking, is that the interpretation of fMRI data requires a series of assumptions as to what is the structure of neural activity. For instance, the usual averaging between different control states could hide many shared cognitive areas that have a role in more than one task. Furthermore, it is unknown whether all functions are spatially located. This is like some kind of neophrenology which is far from being either theoretically appealing or empirically demonstrated. As if these problems were not bad enough, many cognitive tasks could result either from an excitation or from an inhibition of certain areas. Smaller cognitive units, called microcircuits, keep a precisely balanced ratio between excitation and inhibition both when active and when at rest. This implies that microcircuits are capable of large changes in activity without changing the overall balance between underlying excitatory and inhibitory elements. Thus, to a certain extent, the BOLD signal is not always correlated with an increased neural activity (Krekelberg, et. al., 2006; Logothetis, 2001): "the fMRI signal cannot easily differentiate between function-specific processing and neuromodulation, between bottom-up and top- down signals, and it may potentially confuse excitation and inhibition" (Logothetis, 2008, p. 877). A further criticism concerns the difference between explanation and localization. Finding the place of a certain cognitive function does not tell much as to what that function is implemented and carried out. Most of fMRI evidence is based on the hypothesis that different aspects of the mind are located in different areas of the brain. Does the granularity of the mind translate into the granularity of the brain architecture? This is questionable, but even if it did, it would remain to be verified how much explanatory power would be realized from a topographical map of the various functions. Of course, if true, this would have an immense clinical and practical value. It could allow better surgical procedures, more reliable assessment of diseases, even more trustworthy mind-reading techniques. However, does the localization of neural activity provide a real insight as to what mental functions are and how they do what they do? Is this all? No, there is one more final radical concern about fMRI (and all other brain recording techniques) as a "mindscope." It is true that there has been a lot of interest in fMRI and other brain measuring devices in order to gain a direct insight into mental content (Haynes &amp; Rees, 2005, 2006; Haynes, et. al., 2007; Kay, et. al., 2008; Thirion, et. al., 2006). Yet these techniques, however impressive, do not yield any true insight as to what the mind is. They correlate previous verbal reports (or some behavioral response) and brain states. The reference to the mind is frankly surprising. For one thing, they do not observe the mind. The mind could be completely removed from their terminology, and their experimental results would be exactly the same. For instance, Kay et. al. (2008) recorded the neural activity that follows certain visual stimuli. Having stored a large dataset of such pairs (visual stimulus + cortical activity measured via fMRI) it was possible to derive the alleged incoming stimulus from a new cortical activity. Any claim as to the alleged intermediated mental content is only a manner of speech. Overall, this 10</page><page sequence="11">Is Neuroscience Adequate as the Forthcoming "Mindscience"? preliminary survey highlights many doubts as to the widespread idea that fMRI offers a glance into one's mental life. Ontological Original Sin Inside neuroscience is a persistent problem that has not yet received a satisfying solution. The problem has to do with the so-called Galilean gap (Manzotti, 2006), later dubbed by David Chalmers as the "hard problem" (Chalmers, 1996). Since Galileo, qualities have been exiled into the mental domain. Yet, if the mental domain was really no more than what the brain does, where would qualities go? The frequently invoked solution is emergentism (Silberstein, 2002). The mind and its qualities are requested to emerge out of certain activities of the brain. As we have seen, neuroscience seems to endorse this philosophical view. For instance, where are colors for a neuroscientist? Since they are neither in the objects nor in the frequencies of the incoming light rays, most authors would maintain that colors are concocted by our brain to differentiate between different dispositions to reflect light (Hardin, 1993; Zeki, 1980, 1983). To sum up, as is show by this example, the old Galilean gap separation is still accepted - mental qualities do not exist in the physical world since they are somehow created in the brain. This widespread belief hides a logical error. Let us see why. Consider the premise that the world is devoid of mental properties. This premise is accepted by most physicalists, and it goes back to the seminal text in Galileo's Assayer (Galileo, 1623). It is such a premise that leads to the hard problem (Chalmers, 1996). Yet if we accept such a premise, we must then confront the fact that the mind is some property of neural activity. This is consistent with the role of neuroscience as a future mindscience. But if the world is devoid of mental properties and if neural networks are part of the world, how can neural networks produce mental properties? The conclusion denies the premises, namely that the world is devoid of mental property (a similar argument led Galen Strawson to embrace panpsychism; see Strawson, 2006). Suggesting to identity theorists such as Place and Smart that there are mental properties in the world, only that all of them are neural (which, of course, is not to say vice versa, that all neural properties are mental), is rather confusing since it implies that being neural is, per se, something special, which it is not. In the end there seems no way out. The only possibility could be the refusal of mental properties, which is the eliminativist stance. In fact, if there were no mental properties, neural activity would not need any special property and thus could continue to belong to the physical world. Unfortunately in this way, one only dismisses the explanandum instead of actually explaining it. The very assumption that neural activity has some kind of special property which is not shared by the physical world leads to the aforementioned contradictions. Phenomenological Adequacy Any scientific approach to the mind cannot avoid providing an explanation of the nature and the origin of mental content. So far neuroscience has scored very 11</page><page sequence="12">Manzotti &amp; Moderato low in this respect by suggesting a brute force identity between neural activity and mental content. By brute force identity we refer to the fact that, as far as we know, there is nothing in the physical description of neural activity that would lead to expect the appearance of mental properties. This is simply a restatement of Chalmers' hard problem. Furthermore, it is a brute force identity because, as far as we know, most properties of neural activity are not shared by phenomenal experience and vice versa (Chalmers, 1996; Stubenberg, 1998; Tononi 2008; Wright, 2008). Thus, the identity is imposed rather than observed. In the grip of theoretical commitments, scientists are capable of saying almost everything: They have no free will, they do not exist, they have no emotions, they have no mind, and their mental properties are identical with the properties of their neurons. Yet, it is only too easy to point out that the properties of the healthy and active neuronal networks are nothing like the properties of our mental life. Neural activity does not resemble in any way either our conscious experience or our mental activity. And yet many neuroscientists, to square the neural circle, often do ask the scientific community to believe that the properties of neural activity are identical to those of mental life. Or if they seem different now, to believe that eventually they will be shown to be the same once research methods improve. An example of this stance is offered by Paul and Patricia Churchland, who have long tried to defend a strongly eliminativist view (Churchland, 1986; Churchland &amp; Churchland, 2002). For instance, Patricia Churchland stated that "I am a materialist and hence believe that the mind is the brain" (Churchland, 1986, p. ix). They maintain that in the long run every mental concept will be substituted by a corresponding neural concept. To them, the mentalistic language is no more than a useless vestige of a pre-scientific world. This stance has yet to be verified. To many, the eliminativist stance is not credible. For example, Leopold Stubenberg appealed to the principle of phenomenal adequacy: I will reject everything that does not square with what I take to be the phenomenal data. . . ."So much the worse for phenomenology" is not a viable option for one who adheres to the principle to phenomenal adequacy. The phenomenology is that which the theory of consciousness is supposed to illuminate. If a theory requires us to disregard the deliverances of phenomenology then it is not the theory I seek. (Stubenberg, 1998, p. 36) On a similar note, Clyde Hardin concluded that "phenomenology must be the arbiter of adequacy" (Hardin, 2008, p. 153). The same point has been made by countless other authors who simply find it impossible to accept that mental properties are one and the same with the properties of neural networks. So far, any brute force attempt at reducing the former to the latter has failed utterly. If you compare what is observed by neuroscience - spikes, frequencies, bursts, BOLD signals - to what is experienced by a subject - feelings, emotions, goals, thoughts - it seems there is some deep chasm between the two sets. 12</page><page sequence="13">Is Neuroscience Adequate as the Forthcoming "Mindscience"? This is not a minor issue. It articulates into many further apparently unsolvable issues that do not seem reducible to neuronal properties. Among the most troublesome ones, the problem of unity, the problem of representation, the problem of time, and the problem of phenomenal judgment are conspicuous. A few words about each are useful. The problem of unity refers to the difference between neural activity, which is scattered in time and space through the cortex, and phenomenal experience, which has perceptual unity. Consider that color, movement, form, edges, and features are processed in different parts of the brain (Bayne, 2009; Cleeremans, 2003; McKeefiy &amp; Zeki 1997; Zeki, 2003). How do we perceive an object as a unity of color, movement, and form? Neuroscience is looking for a binding mechanism that - by means of synchronization, broadcasting, or information integration - could integrate all these otherwise separate processes (Cleeremans 2003; Engel &amp; Singer, 2001; Roskies, 1999; Tononi, 2008; Treisman, 1998). Up to now, no convincing answer has been provided. The problem of representation is only apparently simple (Bickhard, 1998; Fodor, 1981; Putnam, 1988; Rey, 1998; Searle, 1992; Tye, 1990). In short, it goes as follows. If the perceiving subject is nothing but the brain, why does the perceiving subject not perceive neural activity instead of the external world? The canonical solution is that neural activity represents the external world. Yet, using the word "representation" does not explain anything. It only provides a shorthand to address the mysterious fact that we experience the outside world by means of neural activity. How does representation articulate in physical terms? The problem of time has many facets. Some are related to perception and other with motor control and voluntary actions (Lee, 2007; Libet, 2004; Manzotti, 2009; Mauk &amp; Buonomano, 2004; Van Rullen &amp; Thorpe, 2001). The problem springs from the discrepancy between the time when neural activity takes place and the time when mental content appears to be available (Libet, 1981). It is not simply a matter of delay, either linear or nonlinear. Rather, mental content seems to be spread over discrete amounts of time that do not easily match their neural counterparts (Bartels &amp; Zeki, 2004). The issue is made thornier by the troublesome notion of the present instant, which is "instantaneous" for Newton, a point in the space-time continuum for Einstein, a discrete bud for quantum mechanics, a temporal window of integration among trains of spikes for neuroscience, and a phenomenal present full of mental content for the subject (Lyre, 2008). The last issue - the paradox of phenomenal judgment - is slightly more technical than the previous three, but only in its formulation. Basically, it stems out of the apparent incommensurability between subjective experience and higher- order experience (Chalmers, 1996). The conundrum runs this way. Consider phenomenal qualities. They are the foundation of our experience of the world. Yet they cannot be straightforwardly translated into thoughts since thoughts, like language, do not have places for qualities as such. For instance, consider an agent capable of distinguishing between red and green stimuli. To explain both its behavior and its beliefs there is no need to introduce anything like either subjective qualities or phenomenal content. However, from the first-person perspective we 13</page><page sequence="14">Manzotti &amp; Moderato know that the roots of our knowledge of the world lie in the phenomenal subjective qualities of it. The fact is that, up to now, no one has been able to propose any bridging principle that could explain why the neural properties should give rise to most of the experienced properties of the mind. Neuroscience is expected to be able to do so in the future. However, it has not done so up to now, and there is no evidence it will do so in the future. The (Empirically Undemonstrated) Thesis of the Minimally Sufficient Neural Substrate Most neuroscientists assume that, whether practically possible, a healthy brain in a vat would have the same content as a real brain in a body connected with the environment. This assumption is hypothetical; it has never been tested empirically and could be wrong. Cristof Koch clearly fleshes out the gist of most neuroscientific approaches by stating that "The goal [of neuroscience in respect to consciousness] is to discover the minimal set of neuronal events and mechanisms jointly sufficient for a specific conscious percept" (Koch, 2004, p. 16). This is even a narrower claim than N2: Not only the brain as a whole determines the mind, but parts of the mind are determined by parts of the brain. There is a one to one correspondence between mental units and neural activities. Furthermore, there must be a set of neural events sufficient for a specific phenomenal content (Crick &amp; Koch, 1990). Yet, so far this hypothesis has never been empirically demonstrated. Just to be clear, what is at stake is not whether neural activity is necessary but whether there is a given neural activity which is either sufficient for or identical with a given phenomenal experience - and this ought to hold true for all mental content. The thesis that "for every conscious state, there is a minimal neural substrate that is nomically sufficient (as a matter of natural law) for its occurrence" has been labeled the "thesis of the minimally sufficient neural substrate" by Alva Noë and Evan Thompson (Noë &amp; Thompson, 2002, p. 4). Of course, such a thesis does not conflict with the obvious fact that human brains need to develop in real environments and are the results of their individual histories. The historical dependency on development holds for most biological subsystems. For instance, muscles and bones need gravity and exercise in order to develop properly. But, once developed, they are sufficient to deliver their output, so to speak. They need gravity and weight in order to develop, but when ready, muscles are sufficient to produce a mechanical force as a result of the contraction of myofibrils. Many neuroscientists hold that the experiences of the body with the environment are necessary for the development of consciousness, but a knowledge of neurological changes wrought by a developmental history does not shed light on the cognitive systems underlying consciousness (see summary in Adams &amp; Aizawa, 2001, 2008). Similarly, many neuroscientists hold that consciousness is produced by the nervous system in the same manner that strength is produced by muscles - neural activity and consciousness having the same relation as myofibrils and 14</page><page sequence="15">Is Neuroscience Adequate as the Forthcoming "Mindscience"? strength. This tension between constitutive aspects and contingent causes is something we will address at greater length below. Because of the abovementioned thesis, neuroscience focuses on the localization of a neural correlate of consciousness (NCC). Yet, so far, there is neither evidence that an NCC exists, nor any clear notion of what an NCC would look like (Block, 1996; Frith, et. al., 1999; Rees, et. al., 2002; Tononi &amp; Koch, 2008). NCC-oriented approaches are plagued by three kinds of problems (Chalmers, 2000; Hohwy, 2009; Noë &amp; Thompson, 2004). The first two are empirical and the last is more theoretical. First, even if we could point at a certain neural activity whenever we have a phenomenal experience, how could we be sure that the same neural activity would be associated with consciousness in every possible condition? Second, there is no theory explaining why a certain electrochemical activity should produce phenomenal experience. Third, the properties of neural activities are dramatically different from those of perception. Notwithstanding a recent gold rush for the neural correlates of consciousness (Koch, 2004; Metzinger, 2000; Velmans &amp; Schneider 2006), there is no consensus as to where to locate a sufficient NCC of consciousness (Chalmers, 2000; Noë &amp; Thompson, 2004). Here, we emphasize a fact that is obvious for many, namely that a relevant NCC has to be sufficient. The attribute of sufficiency of neural activity is the real acid test. A necessary NCC is neither so difficult to be located nor so helpful. There are plenty of possibilities for NCCs in humans: extended reticular- thalamic activation systems (Edelman, 1989), re-entrant loops in thalamocortical system (Edelman, 1989), neural assemblies bound by NMDA (Flohr, 1995), higher level of activations at dedicated perceptual areas (Zeki &amp; Bartels, 1999), dorsal prefrontal and parietal areas (Rees, et. al., 2002), and many others. They have been proposed as sufficient NCCs, but they were unable to pass the test of sufficiency and thus have been downgraded to simple necessary NCCs. Rather surprisingly, this repetitive series of failures has not shaken the belief in the existence of a sufficient NCC. Conceptually, a sufficient NCC has to be expected once you believe in the premise of sufficiency. Yet, it is the existence of the sufficient NCC that should justify the premise of sufficiency and not the other way round. Once more neuroscience is begging the question. In order to show that a certain neural activity is sufficient for conscious experience, scientists have to show that if such neural activities were to happen anywhere, those activities should invariably produce conscious experience. So, if such neural activities could be replicated in vitro, a corresponding phenomenal experience should occur. This inescapable conclusion seems hardly plausible, yet this is the brain-in-a-vat scenario that many authors find so convincing and plausible. However, our pre-theoretical intuitions are not the point. What has to be stressed is that, although many scientists boldly claim there is plenty of evidence showing that "the entire brain is clearly sufficient to give rise to consciousness" (Koch, 2004, p. 16), there is none. So far, the "central plank of modern materialism - the supposition that consciousness supervenes on the brain" (Prinz, 2000, p. 425) is surprisingly poorly supported by experimental evidence. 15</page><page sequence="16">Manzotti &amp; Moderato Empirical evidence shows that neural activity in human subjects is often associated with consciousness and that certain neural activities possess a higher correlation. In order to make the big step and demonstrate their sufficiency, it should be shown that either a brain or a subset of brain matter undergoing certain states invariably produces consciousness. Besides being beyond current scientific testability, this is probably untrue. Many scholars wonder whether a brain, which has never had a contact with the world, would have mental content if it were a molecular duplicate of a real subject's brain. This is a thought experiment whose outcome is obviously unknown to everyone. Its expected outcome, however commonsensical, is not a sound evidence for a theory of consciousness. Simply to assert that the two brains are the same begs the question. The point to be discovered is whether two molecularly identical brains have identical minds. The intuition that two molecularly identical brains would undergo the same mental processes cannot be used to support the thesis that a brain or a subset of brain matter undergoing certain states is sufficient to produce consciousness. Finally, we need to mention one further problem related with sufficiency. Not only is there no proof that any neural activity is sufficient for consciousness, but neither is there any proof that it is necessary. The thesis of sufficiency encourages an unjustified neural chauvinism or bio-prejudice (an example of unabashed bio- prejudice is offered by Revonsuo, 2006). In other words, why should the relevant activity be produced by biological neurons only? Could the activity not be produced by some other physical system (such as a computer or a robot)? Here, we are agnostic as to the possibility of consciousness in systems made of nonbiological material (Manzotti, 2007). The Lack of Mind-Brain Bridging Laws If the mind is not identical with neural activity, there should be some kind of explanation of when, why, and how neural activity brings mental content into existence. For instance, is it possible to produce pain in an artificial neural network? What is missing? What is pain in neural terms? These are answers that any tentative science of the mind must attempt to outline. So far, neuroscience is not even trying to do this. In the past, it mostly tried to debunk them claiming they were ill-posed problems. For instance, some have suggested that pain is a subjective notion whose physical existence is a meaningless category mistake. This suggestion is no longer acceptable. If a discipline is proposing itself as the new mindscience, it must pinpoint the physical conditions that bring the mind into existence. In order to define the mechanisms that generate a specific conscious experience, we need "to understand the conditions that determine what kind of consciousness a system has" (Tononi, 2004, p. 1). Even if it were possible to identify a neural correlate of consciousness, why should a specific physical process lead to the occurrence of a specific phenomenal experience? On the basis of which law? Giulio Tononi attempted at providing an answer to such questions on the basis of a measure of a still hypothetical fundamental property of information (Tononi, 2004). However, even Tononi admitted that, at present, there is no way to 16</page><page sequence="17">Is Neuroscience Adequate as the Forthcoming "Mindscience"? explain why a certain pattern of activations should lead to a particular phenomenal content. Currently, there are no psychophysical laws bridging the gap between physical and mental processes. In short, NI, N2, and N3 imply the existence of a law having the following form: Menial content = F (neural activity) On this view F represents a law expressing a correspondence between neural activity and mental content. By this we simply stress that once it is assumed that the mind can be explained just looking inside the brain, there must be some law explaining how the mind is produced by the activity of the brain. The point is that, until now, there is no law of that kind. If there is, we are unaware of it. If anything like F were available, it would be straightforward to define a sufficient NCC. For instance, the sufficient NCC of an individual's conscious percept of red, Cred, would be the neural activity Nred occurring in the brain, such that Crea = F (Nred). So far F is nowhere to be seen. Currently no neuroscientist is able to identify what F could be. Of course, eventually it could turn out that consciousness is an epiphenomenal phenomenon. We ought not to judge a theory on the basis of our intuitions about the epiphenomenal nature of consciousness. Yet, this is something that should be acknowledged openly by the proponents of these views. The Mereological Fallacy Is the brain the subject? The brain is a part of the subject. The mind is something the subject either has or is identical with. Are we not confusing the whole with one of its parts? Due to the vagueness and intrinsic difficulty of talking about the brain, we are often tempted to reduce the mind to some identifiable physical system. As a result we are often tempted to reduce the subject as a whole to some simpler subsystem. This is an example of the "mereological fallacy" in which a part of a problem is identified as the problem as a whole (Bennett &amp; Hacker, 2003). The brain is not the whole subject. Thus, they argue, it is fallacious to suppose that the brain does all manner of things. The fallacy consists in inflating the conception of the brain by assigning to it powers and activities that are normally reserved to subjects. For instance, consider this description of an experiment targeted to measure neural correlates of conscious decision: Because brain activity. . .consistently preceded the conscious decision, it has been argued that the brain had already unconsciously made a decision to move even before the subject became aware of it. (Siong Soon, et. al., 2008, p. 543) It looks as if the brain makes a decision that eventually the subject takes into consideration. It is as if the brain could be another subject inside the conscious one. Clearly there is some kind of tension between the whole (the subject) and one of its parts (the brain). 17</page><page sequence="18">Manzotti &amp; Moderato The mereological fallacy can be used to debunk other common mistakes that identify the mind as a whole with some minor aspect of it. For instance, it is true that often conscious agents are autonomous agents. However, are we sure that an autonomous agent is necessarily an agent with a mind? Are we not we conflating the whole (the mind) with a part (the capacity of being autonomous)? Similar arguments suggest a more cautious approach for other capacities and aspects presented as sufficient for conscious experience: autonomy, embodiment, situatedness, resilience, and so on. Whether or not consciousness can be reduced to certain capacities or features that are often correlated with the existence of a conscious agent is, to say the least, unclear. Along these lines, Koch and Tononi maintained that consciousness does not require many of the skills usually associated with the mind: Remarkably, consciousness does not seem to require many of the things we associate most deeply with being human: emotions, memory, self-reflection, language, sensing the world, and acting in it. (Koch &amp; Tononi, 2008, p. 50) The issue is controversial. Most scholars would probably argue against such a view - more prominently those that associate conscious agency with the capacity either to integrate cognitive skills (Baars, 1988; Haikonen, 2003; Shanahan, 2005) or to be autonomous, resilient, and embodied (Bongard, et. al., 2006), or situated (Manzotti, 2006; Noë, 2004). The Fallacy of Code Interpretation It is not uncommon, in reading the literature on the brain, to find statements suggesting that the brain makes use of neural codes to interpret information in terms of mental content (Averbeck, et. al., 2006; Bialek, et. al., 1991; Gallese, 2000; Haynes, 2009; Howard, et. al., 2009; Kamitani &amp; Tong, 2005; Schnupp &amp; Carr, 2009). This terminology reflects a rather Cartesian viewpoint. Worse, it is a confused terminology. There are at least two shortcomings. This first one derives from the fact that a code is a rule of correspondence between one set of symbols and another set of symbols. For instance, a simple code is that used by computers until 2000: ASCII code. According to ASCII there is a rule of correspondence between binary digits and alphanumeric characters. For instance, the binary digit "00100000" corresponds to the letter "A," the digit "00100001" to the letter "B," and so on. So, a code needs two sets of entities. In the case of mental content, the very idea of a neural code that refers to the proper mental content is likely to endorse a dualistic view, which is worrying. Assuming the existence of two distinct sets of separate entities (the code vs. the abysmal set of mental contents) suggests at least some kind of epistemic dualism. All considered, adding a code does not solve the problem of the mind. Furthermore, there is no place where such mental content could conceivably be located. In the case of the ASCII code there are screens and printers where the data, stored inside a computer memory, are displayed to show alphanumeric 18</page><page sequence="19">Is Neuroscience Adequate as the Forthcoming "Mindscience"? characters. In the case of a brain, where should the neural code be translated into the corresponding mental content? And how? The second shortcoming arises from the semantic nature of the notion of code. Consider again the ASCII code. The example works because somewhere there are beings that give meaning to symbols. The code is a rule of correspondence between two sets of symbols. There is nothing physical there. As long as computers are concerned there is no need to use ASCII code. Bits are just bits. They are not even bits. They are just electric levels inside circuits. There is no need to introduce the notion of code. Computers simply control electric switching. The same holds for neural activity. It is not a code and it does not use codes. A code is a manner of speech very useful to refer to certain physical systems such as computers that are tightly coupled with our own semantic capabilities. Human beings have codes. Using codes, human beings can interpret a set of symbols (a sentence in French) into another set of symbols (a sentence in Italian). However, the point at stake is that codes are semantic devices and thus they require semantic agents. To sum up, a code requires a semantic agent, which is what we had to explain from the start. Invoking neural codes to justify the emergence of the mind out of the brain is a case of circularity. There is a difference between a code as a rule of correspondence between symbols and a code as the conceptual metaphor used to refer to a mechanical pairing of some kind, however complex. For instance, notwithstanding the widespread usage, DNA is not a code. DNA is a molecule that, in the right biochemical environment, allows certain reactions with other molecules in a very reliable way. Of course, it is acceptable to say that DNA embeds a code translating sequences of nucleotides into proteins as long as it is clear that this terminology is no more than a metaphor. To be a code, DNA should have semantic capabilities representing the relations between two set of entities. Neither molecules nor brain have any semantic capabilities, as far as we know. Whenever natural or artificial systems embed complex and reliable causal relations between sets of events or things, it is easy to resort to the metaphor of code. It is an example of surviving anthropomorphism and, to a certain extent, another case of the mereological fallacy. We attribute to the part - the brain, the property of the whole - the human person. Cartesian Materialism Does the brain play the same role as the soul in the Cartesian philosophy? Did neuroscience unconsciously adopt the dualistic world view? A rather surprising outcome of current neuroscience is the reappearance of dualism disguised either as emergence or as the existence of multiple levels of reality: "Brain imaging tools have lent undeserved legitimacy to ill-conceived, mentalistic notions within psychology" (Thompson, 2008, p. 137). Teed Rockwell nicknamed this dualism in disguise "Cartesian materialism" (Rockwell, 2005). He pointed out that 19</page><page sequence="20">Manzotti &amp; Moderato Cartesian materialism is the claim that the mind supervenes on nothing physical except the brain. . . .The basic dogma of Cartesian Materialism is that only neural activity in the cranium is functionally essential for the emergence of the mind. (Rockwell, 2005, p. 12) Cartesian materialism gives to the brain the same burden substance dualism gave to the soul. Several authors have adopted a dualistic approach that is contrary to their alleged aims. For instance, Atti Revonsuo conceived a "phenomenal level" (Revonsuo, 2006, p. xix) that runs afoul of its heralded goal to explain consciousness as a biological phenomenon. Similarly, recent authors in the business of inferring mental content out of brain activities keep lapsing into a dualistic language, given that they have to assume a mental level opposed to the purely physical one (Haynes &amp; Rees, 2006; Kay, et. al., 2008; Thirion, et. al. 2006). Since Dewey's time there has been some suspicion as to whether the mind can be reduced to the properties of the brain: "Too often. . .the older dualism of soul and body has been replaced by that of the brain and the rest of the body" (Dewey, 1916/1966, p. 336). As we have seen, Cartesian materialism amounts more or less to N 1 and N2, which are widely popular in neuroscience. However, there are many other physical subsystems that can be taken into consideration as foundations for the brain, such as the body or the body plus the environment. According to Bennett and Hacker (2003) a new mutant form of dualism is taking hold inside neuroscience: Sherrington and his pupils Eccles and Penfield cleaved to a form of dualism in their reflections on the relationship between their neurological discoveries and human perceptual and cognitive capacities. Their successors rejected the dualism - quite rightly. But the predicates which dualists ascribe to the immaterial mind, the third generation of brain neuroscientists applied unreflectively to the brain instead. (Bennett &amp; Hacker, 2003, p. 72) And yet, such new reincarnations of dualism suffer from all of the problems of the previous ones. Cartesian materialism falls into either epiphenomenalism or causal conflict among different levels of reality. This was not always the case. For instance, neither behaviorism nor functionalism, for all they were lacking, could be accused of being dualist. Both tried to avoid redundancy in their ontology as well as in their epistemology. So far, neuroscience has not done either. Commonsensical Premises Lurking in the Underbelly of Neuroscience Laymen's confidence in the forthcoming explanatory power of neuroscience ought not to be taken as empirical evidence. More often than not, some unjustified assumptions are backed up by commonsensical reasons rather than theoretical arguments. As to the wide acceptance that neuroscience received as a future mindscience, it is worthwhile to list those prejudices that promote the idea that the mind is somehow inside the brain. Below are three of the most common prejudices. 20</page><page sequence="21">Is Neuroscience Adequate as the Forthcoming "Mindscience"? Perceptual center of gravity. Our eyes, our ears, our mouth, and our nose are all centered in the skull. This fact gives a powerful feeling of being where our senses are centered (i.e., inside the skull). However, such feeling is no more authoritative than the feeling that our planet cannot rotate since we always feel to be standing up. In fact, our brain could be located somewhere else without any sensible difference with respect to our conscious experience (Dennett, 1978). Social recognition. When we look at someone, it is convenient to identify that someone with her/his body. Analogously, we feel that others identify us with our body. Children learn to recognize themselves in a mirror (Robinson, et. al., 1990; Staller &amp; Sekuler, 1976). Yet what they recognize is their body, not themselves. What about the use of an avatar in a virtual reality system? Would we not identify with the avatar after a sufficiently long period of adaptation? Confusion between necessity and sufficiency. Since the body is a necessary part of the subject, it cannot be absent from our considerations. Whenever there is a subject, there is the body of the subject. This is not a proof that the subject is identical either to her/his body or to a part of it. Rather, it is a proof (by induction) that the body is necessary for the subject. We should not derive unwarranted conclusion out of this simple fact. For instance, there are no examples of environment-less bodies (brain-in-a-vat), so we do not really know whether a body is sufficient to host a conscious subject: Brain-in-vat cases have always been seriously underdescribed. Until the scenario is much better fleshed out, we can't say what the brain's intentional contents would be. Simply to assert that they are the same as yours begs the question. (Lycan, 2001, p. 34) Vanilla Embodiment of the Mind How seriously are embodiment and situatedness taken? Are they taken to be constitutive elements or simply contingent causes of neuronal activity? Many neuroscientists deny that the mind is nothing but what the brain does. Yet, it is often held that cognition is situated and embodied. It is also often held that the mind results from development, upbringing, environmental influences, and social interactions. However, from our viewpoint these statements confuse constitutive factors and contingent causes. Many authors have stressed the importance of the environment for the subject's development. The subject is the result of many factors external to the body. Many authors have stressed that cognition is extended in many respects. To make a computation we use a pencil and some paper. Aren't they a true extension of our cognitive processes, as in Clark and Chalmers' extended mind (Clark, 2008; Clark &amp; Chalmers, 1998)? To walk, our body needs the pull of gravity against the floor to thrust the leg forward. To walk we take advantage of many morphological tricks that simplify an otherwise awful task of computing complex limb trajectory in space (Pfeifer &amp; Bongard, 2006). 21</page><page sequence="22">Manzotti &amp; Moderato Nobody believes that either the mind or the brain does not take advantage of being embodied and situated during development. It is also reasonable to suppose that some kind of frequent feedback between the brain and the world is necessary to maintain the standard state of awareness. And nobody would question the contribution that these factors, external to the nervous system, play in shaping the brain. However, this does not mean that the interplay among these factors is constitutive of the mind. Consider this analogy regarding a source of energy and temperature. Temperature is the average movement of molecules. Without a source of energy a body cannot reach a given temperature. The energy must be provided in some form - gravitational, chemical, nuclear, or electromagnetic. Once you reach a certain temperature, the source of energy is no longer constitutive of the movement of molecules. The source of energy caused a rise in the temperature, but is different from it. In the case of the mind, all listed factors are causes of a certain development of the brain, yet they are not constitutive. Furthermore, they are contingent causes - namely causes whose occurrence is neither sufficient nor necessary. In fact, the acid test to understand the difference between constitutive principles and contingent causes is the following: A constitutive principle is at least necessary, whereas a contingent cause is not. Consider the case of temperature. The contingent cause could be either oxidation or nuclear decay. No matter what it was, we obtain a warmed up material afterwards. On the other hand, movement of molecules is constitutive of temperature (in this particular case, it is even more than constitutive, being identical with it). Now consider the case of the brain. Looking at an external visual stimulus, say a tree, triggers some neuronal activity in an individual's visual cortex. Yet, according to neuroscience, once the activity is taking place, the visual stimulus could be set aside and the cortex directly stimulated. Would the same mental content still occur? If the answer is positive, the tree is a contingent cause; otherwise, you assume the tree is a constitutive principle. And if you accept either NI, or N2, or at least N3, you must answer positively. But if you take the external stimulus to be a contingent cause of brain activity, it must be a contingent cause of the mind too. And a contingent cause cannot be part of what it is a cause of. According to the view advocated by most neuroscientists, whatever the mind is, it has to be internal to the brain. So the alleged situatedness heralded by some neuroscientists is no more than a case of vanilla embodiment. In short, there is real concern about a conceptual confusion in neuroscience between cause, arising externally, and the constitutive effect of such a cause, arising internally. The internal constitutive effect cannot then be taken as itself a cause of something else. If Not Neuroscience, What Will the Foreseeable "Mindscience" Be? Notwithstanding its trumpeted explicatory power, so far neuroscience is not a satisfactory mindscience. As far as we know, it may not be any better in the future, either. 22</page><page sequence="23">Is Neuroscience Adequate as the Forthcoming "Mindscience"? Although psychology may have fallen short of its many promises, neuroscience is not likely to take its place very soon. It could do so in the media and in the quest for grants and funds. But based on the analysis presented here, it is unlikely that it could do that in a serious theoretical and experimental way. This will not hinder the historical and political ascendancy of neuroscience as the leading discipline in the next decade. As to the mind, neuroscience will play a role similar to that held by computationalism or by artificial intelligence in the 1970s and in the 1980s. For lack of a better theory, scientists will keep proposing models and endorsing theoretical landscapes inside the central nervous system, collecting data, and carrying on experiments. But this should not be taken as a criticism of neuroscience as such. It isn't. Neuroscience is gaining an increasing momentum and it is addressing terrific problems. Yet the problems addressed in neuroscience are only indirectly related to the mind. Of course, there is a more intimate connection between neurons and our thoughts than between bones and thoughts. To a certain extent, bones and all other parts of our body are only indirectly related with our mind. To flesh out a true science of the mind, the point at stake is whether neurons, and what they do, are all there is to know. Is the mind nothing but what the brain does? It is sometimes maintained that we cannot understand the mind without understanding the brain. But why this should be necessarily so? At most, it could be held that we hope to gain a better understanding of the mind by understanding the brain. As a matter of fact, it could be perfectly possible that understanding the mind does not require understanding the brain. For instance, we can understand a C++ program without knowing anything about its electronic implementation in our computer. We could even ignore which brand our computer is. It is the old functionalist thesis. At present, it is unknown whether digging into the neural machinery will provide a better understanding of, let us say, phenomenal experience. It could turn out that neurons are just the wrong physical basis for phenomenal experience. Maybe they are neither necessary nor sufficient. And this is true not only for a functional view of phenomena. To quote a much-used analogy, feathers are neither necessary nor sufficient for flying. There are birds with feathers that cannot fly and animals without feathers that can. Thus, we can understand flight without studying birds, and we can understand temperature without dissecting cellular tissues. As is so often the case in science, it may happen that the ideas of researchers rest on intuition and common sense, not exactly the most rigorous criteria demanded by scientific hypotheses. Only a few researchers have recently taken a critical look at the implicit assumptions for neuroscience with relation to the study of the mind. Yet, the situation for the view encouraged by neuroscience is worrying because it has become so widely embraced by the scientific community and has limited scientific evidence to back it up. How could a theory so long on speculation and so short on hard facts, hinging on nothing more than intuition, be embraced by so many? Passed down through the literature from one generation to the next, the idea that the mind has to be secreted by the brain is closer to a religious belief than a scientific theory. 23</page><page sequence="24">Manzotti &amp; Moderato If the reader is not convinced that neuroscience is endorsing such a neurocentric view of the brain, we would like to quote at length Alfred N. Whitehead: When you are criticizing the philosophy of an epoch, do not chiefly direct your attention to those intellectual positions which its exponents feel it necessary explicitly to defend. There will be some fundamental assumptions which adherents of all the variant systems within the epoch unconsciously presuppose. Such assumptions appear so obvious that people do not know that they are assuming because no other way of putting things has ever occurred to them. (Whitehead, 1925, p. 48) We wonder whether one of those hypotheses could be that neuroscience is doomed to become the true science of the mind. Once more, it is worth stressing that a negative answer to the identity between the brain and the mind does not necessarily imply an anti-physicalist stance. Neurons are not the only option for a physicalist. What we have stressed since the onset of this paper is that the nervous system is not necessarily the physical substrate to the mind. There are other possibilities that should be considered unless proven wrong. As researchers struggle to find some answers, a few have switched their attention from the neurons to the processes between neurons and the external environment, looking for alternative physical processes more extended than those embedded in neurons alone. Is this an anti-scientific turn? In our view, it would be unfair to so maintain as long as the quest remains inside the boundary of physical explanations. References Adams, D., &amp; Aizawa, K. (2008). The bounds of cognition. Singapore: Blackwell. Adams, F., &amp; Aizawa, K. (2001). The bounds of cognition. Philosophical Psychology , 14, 43-64. Aleksander, I. (2001). The self 'out there'. Nature , 413 , 23. Armstrong, D. M. (1968). A materialist theory of mind. London: Routledge &amp; Kegan Paul. Averbeck, B. B., Latham, R E., &amp; Alexander, P. (2006). Neural correlations, population coding and computation. Nature Reviews Neuroscience , 7, 358-366. Baars, B. J. (1988). A cognitive theory of consciousness. Cambridge, MA: Cambridge University Press. Bartels, A., &amp; Zeki, S. (2004). The chronoarchitecture of the human brain - natural viewing conditions reveal a time-based anatomy of the brain. Neurolmage, 22, 419-433. Bayne, T. (2009). The unity of consciousness. Oxford: Oxford University Press. BBC (2010). Vegetative state patients can respond to questions. Retrieved 3 Feb 2010 from http://news.bbc.co.Uk/2/hi/health/8497148.stm. Bennett, C. M., Baird, A. A., Miller, M. B., &amp; Wolford, G (2009). Neural correlates of interspecies perspective taking in the post-mortem Atlantic Salmon: An argument for multiple comparisons correction. 15th Annual Meeting of the Organization for Human Brain Mapping, San Francisco, CA. 24</page><page sequence="25">Is Neuroscience Adequate as the Forthcoming "Mindscience"? Bennett, M. R., &amp; Hacker, P. M. S. (2003). Philosophical foundations of neuroscience. Maiden, MA: Blackwell. Bennett, C. M., Wolford, G L., &amp; Miller, M. (2009). The principled control of false positives in neuroimaging. Social Cognitive and Affective Neuroscience , 4 , 417-422. Bialek, W., Rieke, F., de Ruyter Van Steveninck, R. R., &amp; Warland, D. (1991). Reading a neural code. Science , 252, 1854-1857. Bickhard, M. H. (1998). Levels of representationality. Journal of Experimental and Theoretical Artificial Intelligence, 10, 179-215. Block, N. J. (1996). How can we find the neural correlate of consciousness? Trends in Neurosciences , 19, 456-459. Bongard, J., Zykov, V., &amp; Lipson, H. (2006). Resilient machines through continuous self- modeling. Science, 314, 1118-1121. Chalmers, D. J. (1994). On implementing a computation. Minds and Machines, 4, 402-491. Chalmers, D. J. (1996). The conscious mind: In search of a fundamental theory. New York: Oxford University Press. Chalmers, D. J. (2000). What is a neural correlate of consciousness? In T. Metzinger (Ed.), Neural correlates of consciousness (pp. 18-39). Cambridge, MA: MIT Press. Changeux, J. P. (1983). L'homme neuronal. Paris: Linraire Artheme Fayard. Churchland, P. S. (1986). Neurophilosophy : Toward a unified science of the mind-brain. Cambridge, MA: MIT Press. Churchland, P. S., &amp; Churchland, P. M. (2002). Neural worlds and real worlds. Nature Reviews Neuroscience, 3, 903-907. Clark, A. (2008). Supersizing the mind. Oxford: Oxford University Press. Clark, A., &amp; Chalmers, D. (1998).The extended mind. Analysis, 58, 10-23. Cleeremans, A. (2003). The unity of consciousness: Binding, integration, and dissociation. Oxford: Oxford University Press. Crick, F. (1994). The astonishing hypothesis : The scientific search for the soul. New York: Touchstone. Crick, F., &amp; Koch, C. (1990). Toward a neurobiological theory of consciousness. Seminars in Neuroscience, 2, 263-295. Crick, F., &amp; Koch, C. (2003). A framework for consciousness. Nature Neuroscience, 6, 119-126. Dennett, D. C. (1978). Brainstorms: Philosophical essays on mind and psychology. Montgomery, AL: Bradford Books. Dewey, J. (1916/1966). Democracy and education: An introduction to the philosophy of education. New York: Free Press. Edelman, G M. (1989). The remembered present: A biological theory of consciousness. New York: Basic Books. Edelman, Q M. (2004). Wider than the sky: The phenomenal gift of consciousness. New Haven, CT: Yale University Press. Engel, A. K., &amp; Singer, W. (2001). Temporal binding and the neural correlates of sensory awareness. Trends in Cognitive Sciences, 5, 16-25. Faux, S. F. (2002). Cognitive neuroscience from a behavioral perspective: A critique of chasing ghosts with Geiger counters. The Behavior Analyst, 25, 161-173. Flohr, H. (1995). Sensations and brain processes. Behavioral Brain Research, 71, 157-161. Fodor, J. A. (1981). Representations : Philosophical essays on the foundations of cognitive science. Cambridge, MA: MIT Press. Frith, C., Perry, R., &amp; Lumer, E. (1999). The neural correlates of conscious experience: An experimental framework. Trends in Cognitive Sciences, 3, 105-114. 25</page><page sequence="26">Manzotti &amp; Moderato Gallese, V. (2000). The inner sense of action. Journal of Consciousness Studies , 7, 23-40. Galilei, G.. (1623). Il Saggiatore. Haikonen, P. O. (2003). The cognitive approach to conscious machine. London: Imprint Academic. Hardin, C. L. (1993). Color for philosophers: Unweaving the rainbow . Indianapolis, IN: Hackett. Hardin, C. L. (2008). Color qualities and the physical world. In E. Wright (Ed.), The case for qualia (pp. 143-154). Cambridge, MA: MIT Press. Harnad, S. (2000). Correlation vs. causality: How/why the mind/body problem is hard. Journal of Consciousness Studies , 7, 54-6 1 . Haynes, J.-D. (2009). Decoding visual consciousness from human brain signals. Trends in Cognitive Sciences, 13, 194-202. Haynes, J.-D., &amp; Rees, G. (2005). Predicting the stream of consciousness from activity in human visual cortex. Current Biology, 15, 1301-1307. Haynes, J.-D., &amp; Rees, G. (2006). Decoding mental states from brain activity in humans. Nature Reviews Neuroscience, 7, 523-534. Haynes, J.-D., Sakai, K., Rees, G, Gilbert, S., Frith, C., &amp; Passingham, R. E. (2007). Reading hidden intentions in the human brain. Current Biology, 17, 323-328. Hohwy, J. (2009). The neural correlates of consciousness: New experimental approaches needed? Consciousness and Cognition , 18, 428-438. Honderich, T. (2006). Radical externalism. Journal of Consciousness Studies, 13, 3-13. Howard, J. D., Plailly, J., Grueschow, M., Haynes, J.-D., &amp; Gottfried, J. A. (2009). Odor quality coding and categorization in human posterior piriform cortex. Nature Neuroscience, 12, 932-940. Jackson, F. (1996). The primary quality view of color. Nous, 30, 199-219. James, W. (1902/2002). Varieties of religious experience. New York: Routledge. Kamitani, Y., &amp; Tong, F. (2005). Decoding the visual and subjective contents of the human brain. Nature Neuroscience, 8, 679-685. Kay, K. N., Naselaris, T., Prenger, R. L., &amp; Gallant, J. L. (2008). Identifying natural images from human brain activity. Nature, 452, 352-355. Kim, J. (1995). Dretske's qualia externalism. Philosophical Issues, 7, 159-165. Kim, J. (1993). Supervenience and mind. Cambridge, MA: Cambridge University Press. Koch, C. (2004). The quest for consciousness : A neurobiological approach. Englewood, CO: Roberts &amp; Company Publishers. Koch, C., &amp; Tononi, G. (2008). Can machines be conscious? IEEE Spectrum, 47-51. Krekelberg, B., Boynton, G. M., &amp; van Wezel, R. J. (2006). Adaptation: From single cells to BOLD signals. Trends in Neurosciences, 29, 250-256. Kurthen, M., Grunwald, T., &amp; Elger, C. E. (1998). Will there be a neuroscientific theory of consciousness? Trends in Cognitive Sciences, 2, 229-234. Lamme, V. A. F. (2006). Towards a true neural stance on consciousness. Trends in Cognitive Sciences, 10, 494-501. Lee, G. (2007). Consciousness in a space-time world. Philosophical Perspectives, 27, 341- 374. Legrenzi, P., &amp; Umiltà, C. (2009). Neuro-mania. Il cervello non spiega chi siamo. Bologna: Il Mulino. Libet, B. (1981). The experimental evidence for subjective referral of a sensory experience backwards in time. Philosophy of Science, 48, 182-197. Libet, B. (2004). Mind time: The temporal factor in consciousness. Cambridge, MA: Harvard University Press. 26</page><page sequence="27">Is Neuroscience Adequate as the Forthcoming "Mindscience"? Logothetis, N. K. (2001). Neurophysiological investigation of the basis of the fMRI signal. Nature , 412, 150-157. Logothetis, N. K. (2008). What we can do and what we cannot do with fMRI. Nature , 453 , 869-878. Lycan, W. G (2001). The case for phenomenal externalism. In J. E. Tomberlin (Ed.), Philosophical perspectives. Vol. 15: Metaphysics (pp. 17-36). Atascadero: Ridgeview Publishing. Lyre, H. (2008). Time in philosophy of physics: The central issues. Physics and Philosophy , 1, 1-23. Manzotti, R. (2006). An alternative process view of conscious perception. Journal of Consciousness Studies , 13 , 45-79. Manzotti, R. (2006). Consciousness and existence as a process. Mind and Matter , 4 , 7-43. Manzotti, R. (2007). Towards artificial consciousness. APA Newsletter on Philosophy and Computers , 7, 12-15. Manzotti, R. (2009). No time, no wholes: A temporal and causal-oriented approach to the ontology of wholes. Axiomathes , 19 , 193-214. Manzotti, R, &amp; Moderato, R (2008). Il ritorno del fantasma nella macchina. Sistemi Intelligenti , 20 , 335-340. Mauk, M. D., &amp; Buonomano D. V. (2004). The neural basis of temporal processing. Annual Review of Neuroscience, 27 , 307-340. Melzack, R. (2001). Pain and the neuromatrix in the brain. Journal of Dental Education , 65, 1378-1382. Mendola, J. (2008). Anti-externalism. Oxford: Oxford University Press. Metzinger, T. (2000). Neural correlates of consciousness : Empirical and conceptual questions. Cambridge, MA: MIT Press. Noë, A. (2004). Action in perception. Cambridge, MA: MIT Press. Noë, A., &amp; Thompson, E. (Eds.). (2002). Vision and mind: Selected readings in the philosophy of perception. Cambridge, MA: MIT Press. Noë, A., &amp; Thompson, E. (2004). Are there neural correlates of consciousness? Journal of Consciousness Studies, 11, 3-28. Nunez, P. (2010). Brain , mind, and the structure of reality. Oxford: Oxford University Press. Pfeifer, R., &amp; Bongard, J. (2006). How the body shapes the way we think : A new view of intelligence. New York: Bradford Books. Place, U. T. (1956). Is consciousness a brain process? British Journal of Psychology, 47, 44-50. Prinz, J. (2000). The ins and outs of consciousness. Brain and Mind, 1, 245-256. Putnam, H. (1988). Representation and reality. Cambridge, MA: MIT Press. Rees, G, Kreiman, G , &amp; Koch, C. (2002). Neural correlates of consciousness in humans. Nature Reviews, 3, 261-270. Revonsuo, A. (2006). Inner presence: Consciousness as a biological phenomenon. Cambridge MA: MIT Press. Rey, G (1998). A narrow representationalist account of qualitative experience. Philosophical Perspectives, 12, 435-457. Robbins, P., &amp; Aydede, M. (Eds.). (2009). The Cambridge handbook of situated cognition. Cambridge: Cambridge University Press. Robinson, J. A., Connell, S., Mckenzie, B. E., &amp; Day, R. H. (1990). Do infants use their own images to locate objects reflected in mirrors? Child Development, 61, 1558-1568. Rockwell, T. (2005). Neither ghost nor brain. Cambridge, MA: MIT Press. Roskies, A. L. (1999). The binding problem. Neuron, 24, 7-9. 27</page><page sequence="28">Manzotti &amp; Moderato Ryle, G.. (1949). The concept of mind. London: Hutchinson. Schnupp, J. W. H., &amp; Carr, C. E. (2009). On hearing with more than one ear: Lessons from evolution. Nature Neuroscience , 12, 692-697. Searle, J. R. (1992). The rediscovery of the mind. Cambridge, MA: MIT Press. Shanahan, M. R (2005). Global access, embodiment, and the conscious subject. Journal of Consciousness Studies , 12, 46-66. Shoemaker, S. (1982). The inverted spectrum. The Journal of Philosophy, 81, 357-381. Silberstein, M. (2002). Reduction, emergence, and explanation. In R Machamer &amp; M. Silberstein (Eds.), The Blackwell guide to the philosophy of science (pp. 80-107). Oxford: Basil Blackwell. Siong Soon, C., Brass, M., Heinze, H.-J., &amp; Haynes, J.-D., (2008). Unconscious determinants of free will in humans. Nature Neuroscience, 11, 543-546. Staller, J., &amp; Sekuler, R. (1976). Mirror-image confusions in adult and children: A non perceptual explanation. The American Journal of Psychology, 89, 253-268. Strawson, G. (2006). Does physicalism entail panpsychism? Journal of Consciousness Studies, 13, 3-31. Stubenberg, L. (1998). Consciousness and qualia. Amsterdam: John Benjamins. Thirion, B., Duchesnay, E., Hubbard, E., Dubois, J., Poline, J.-B., Lebihan, D., &amp; Dehaene, S. (2006). Inverse retinotopy: Inferring the visual content of images from brain activation patterns. Neuroimage, 33, 1104-1116. Thompson, T. (2008). Self-awareness: Behavior analysis and neuroscience. The Behavior Analyst, 31, 137-144. Tonneau, F. (2004). Consciousness outside the head. Behavior and Philosophy, 32, 97-123. Tononi, G. (2004). An information integration theory of consciousness. BMC Neuroscience, 5, 1-22. Tononi, G. (2008). Consciousness as integrated information: A provisional Manifesto. Biological Bullettin, 215, 216-242. Tononi, G., &amp; Koch, C. (2008). The neural correlate of consciousness: An update. Annals oj the New York Academy of Sciences, 1124, 239-261 . Treisman, A. (1998). The binding problem. Current Opinion in Neurobiology, 6, 171-178. Trimble, M. R. (2007). The soul in the brain: The cerebral basis of language, art, and belief Baltimore: John Hopkins University Press. Tye, M. (1990). Representational theory of pains and their phenomenal character. Philosophical Perspectives , 9, 223-239. Uttal, W. R. (2001). The new phrenology: The limits of localizing cognitive processes in the brain. Boston, MA: MIT Press. Uttal, W. R. (2004). Dualism: The original sin of cognitivism. Mahwah, NJ: Lawrence Erlbaum Associates. Van Rullen, R., &amp; Thorpe, S. J. (2001). The time course of visual processing: from early perception to decision making. Journal of Cognitive Neuroscience, 13, 454-461. Velmans, M., &amp; Schneider, S. (Eds.). (2006). The Blackwell companion to consciousness. London: Blackwell. Whitehead, A. N. (1925). Science and the modern world. New York: Free Press. Wright, E. (Ed.) (2008). The case for qualia. Cambridge, MA: MIT Press. Zeki, S. (1980). The representation of colours in the cerebral cortex. Nature, 284, 412-465. Zeki, S. (1983). Colour coding in the cerebral cortex: The reaction of cells in monkey visual cortex to wavelengths and colours. Neuroscience, 9, 741-765. Zeki, S. (2001). Localization and globalization in conscious vision. Annual Review of Neuroscience, 24, 57-86. 28</page><page sequence="29">Is Neuroscience Adequate as the Forthcoming "Mindscience"? Zeki, S. (2002). Neural concept formation and art: Dante, Michelangelo, Wagner. Journal of Consciousness Studies , 9, 53-76. Zeki, S. (2003). The disunity of consciousness. Trends in Cognitive Sciences , 7, 214-218. Zeki, S., &amp; Bartels, A. (1999). Toward a theory of visual consciousness. Consciousness and Cognition , 8 , 225-259. 29</page></plain_text>
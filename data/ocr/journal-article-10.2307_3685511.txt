<plain_text><page sequence="1">Why and How to Take the Fruit and Leave the Chaff Ellen Spolsky The Nun's Priest, concluding his tale to the Canterbury pilgrims, and apprehensive that it might be dismissed as a worthless "folly," cites the authority of Saint Paul against this potential error: But ye that holden this tale a folye As of a fox, or of a cok and hen, Taketh the moralitee, goode men. For Saint Paul saith that al that writen is To our doctrine it is ywrit, ywis: Taketh the fruit, and lat the chaf be stille. Adumbrating a hermeneutic of threshing and winnowing, he maintains that moral teaching is available from all stories, but only when they are properly worked. Six hundred years later, in 1979, Gerald Graff, speaking of Moby Dick, also promises nourishment: The truth or falsity of the "information" or the seemingly factual content of propositions stated or implied is unimportant when we are reading a literary work. When we read the command, "Call me Ishmael," the fact that there never was any such person as Ishmael makes no difference. And the novel would not be a better novel if there really were such a person. But does it follow that because the pseudo-informational propositions in literary works make no truth-claims, there are no truth- claims in literature at all? ....If you chose sentences like "call me Ishmael" or "Slowly wading through the meadows of brit, the Pequod still held her way north-eastward towards the island of Java," you will end up deciding that literary propositions are merely fictive imitations of genuine statements. But Moby Dick also includes sentences like this: "For as this appalling ocean surrounds the verdant land, so in the soul of man there lies one insular Tahiti, full of peace and joy, but encompassed by all the horrors of the half known life." If you take this kind of example into your reckoning, you may have to reopen the question. (154-5) So readers must apparently still be warned not to miss the good stuff. But if there is such a danger, we might ask, why do writers continue to couch expressions of truth within "fictive imitations of genuine statements?" SubStance # 94/95, 2001 177</page><page sequence="2">178 Ellen Spolsky Why can't they just say what they mean so that readers won't have to distinguish the fruit from the chaff, won't risk failure? The power of fiction to lead us to these insular Tahitis, then, would not need perpetually to be reasserted, and the processes of threshing and winnowing would not need to be learned. The question of why authors don't just say what they mean arises regularly in beginning literature classes, and has also arisen as part of the neo-Darwinist debate about the adaptive function of story-telling in general, and of fictions in particular. Leda Cosmides and John Tooby in "Consider the Source: The Evolution of Adaptations for Decoupling and Meta- representations," for example, recognize the value of fictions as hypothetical scenarios or improvisations, but raise the question of how the positive consequences of imagining fictional situations might be protected from the negative effects of the circulation of disinformation (fiction) in the system. Although most people would agree that a large part of what it means to be a thinking animal is being able to make judgments of various strengths and at varying levels of consciousness about the reliability of information, it isn't at all clear how we do it. In an attempt to describe the underlying structural adaptations on which such judgments might be based, Cosmides and Tooby hypothesize evolved cognitive mechanisms including "scope regulators" or operators, which "regulate the migration of information among the subcomponents of the human cognitive architecture" (5). They suggest that these operators allow us to carry out inferential operations on information that has been "decoupled" or marked as a "metarepresentation," that is, as "unevaluated or [of] suspended truth value" (10). Although it is reasonable to assume that evolved adaptations of the brain are prior to and necessary to higher-level processes such as inference, the paths are as yet uncharted that we hope will eventually indicate the connections between at least these three things: a hypothesized evolved structure in the brain, the automatic and repetitive work it does--often called an algorithm or a mechanism--and observable higher-level capabilities. A problem arises here that is common to all attempts to move backward from the complexities of human behavior to their material foundations, indeed to all theoretical beginnings. As we have learned from historians and philosophers of science, a new theory or model is often developed by means of borrowed terms used at first with the avowed and valued imprecision of analogy. Richard Boyd uses the term "metaphor" to express the important tentativeness of the use of such borrowed vocabulary. The metaphor, in his view, allows a progressive refinement of the emerging theory by indicating the directions further research might take. SubStance # 94/95, 2001</page><page sequence="3">The Fruit and the Chaff 179 The danger, of course, is that the new theory will find itself unwittingly committed to unnecessary or even misleading assumptions that arrived with the imported vocabulary and concepts. Since there is no choice but to begin somewhere-that is, with borrowed concepts that seem suitable-it is methodologically important to remain aware of the provisional nature of borrowed terminology, and to interrogate it. This is a timely warning for our investigation of the adaptive uses of story-telling. Because interpretive theory has been the subject of such intense theorizing in the last thirty years, and since so much of that intensity derives from its interactions with linguistics, anthropology, psychology, and philosophy, I am optimistic about the possibilities of continued interdisciplinary dialogue, especially as we now add evolutionary biology to the cognitive mix. Thinking of how this project might be extended, however, I stumble upon the set of terms brought into play by Cosmides and Tooby in the article mentioned above, some of which pull in a different direction than that of the vocabulary and concepts developed in contemporary interpretive theory. My own performance here (that is, my own bracketing of their adopted terminology), might well be called "metarepresentational." One might even say that I am "decoupling" them while their status is in doubt, thus demonstrating their validity. It is precisely not their validity, however, that I am either questioning or affirming; nor do I doubt that humans make good use of their ability to bracket slices of discourse. What I do want to question is the fit of these terms within the project of building a theory of the use of fictional narrative. My point is, rather, that the terms "decoupling," "meta- representation," and "scope operators," seem in crucial ways incompatible with some of the most important insights of neo-Darwinian argument. In order to make progress in the investigation of fictional narrative, we need, I will propose, to understand not the disconnections, but the connections between our uses of differently weighted hypotheticals. For a start, I would hope my use of "bracketing" within a scholarly essay to be understood as a demonstration that this practice is by no means exclusive to productions classified as "fiction," but is part of the behavioral repertoire needed for much of what we consider thinking. I will assert then, as a correction to my own use above, that it is not a theory of fictional narrative that is needed, but a theory of the adaptive use of narrative. One of the most damaging decouplings, I will claim, is the assumption that narratives can or should be sorted into fictional and true, or non-fictional. We certainly do categorize narratives, and need to, as I will discuss below, but not into those two categories. SubStance # 94/95, 2001</page><page sequence="4">180 Ellen Spolsky The term "decoupling," as it seems to be used by Cosmides and Tooby, applies to algorithms, and the term "metarepresentation," to the gradient along which people arrange their commitment to the truth of stories or to parts of them. The hypothesis, then, would be that the first enables the second: because our brains have evolved a decoupling mechanism, we can distinguish fact from fiction and use the latter productively. The problem is, however, that nothing we now know about the distinctions people make between kinds of truth (and they surely make such distinctions) could be accomplished at the level at which an automatic mechanism could evolve and/or function. The behavioral evidence as well as evidence of linguistic usage in and out of narrative contexts suggest, rather, that the processes by which we protect ourselves from misinformation a) don't work reliably enough to suggest that they are automatic, and b) all seem to be culturally dependent in ways that evolved adaptations could not be. Not only do the fallibility and context-dependence of our judgments about the relative reliability of different parts of any narrative make it unlikely that the work is done by an "upstream," evolved adaptation, but the evolutionary argument itself suggests that it would actually be maladaptive if the making of such distinctions were automatic and decontextualized. In discourse and narrative, the distinctions between what is "fit" or appropriate and what is not is decided at the pragmatic, not at the neurological level. The nature of narrative itself argues that an automatic decoupler could not operate at the behavioral level at which narratives are understood and analogized to the life experiences of their audiences, in any of the ways we currently understand that interpretive process. The literary sources with which I began this essay are one kind of evidence that the audiences of narratives do not reliably distinguish, mark, or bracket the valuable, true parts of stories and discard the less valuable parts. On the other hand, although audiences often fail at this task, they don't always fail at it, and, as the Nun's Priest's admonition implies, they can be taught to do better. Graff suggests that the primary reason the process of sorting cannot be automated is that narratives are heterogeneous. Their surface features do not include clear markers distinguishing the true from the not true or from the mistakenly believed or the not-yet-established. These must be inferred. An algorithm, however, cannot work on the output of inferential processes. The structure that performs an algorithm can evolve and work only in a reliable context, or in a context in which the variations in context are reliably arranged along a limited continuum.' Furthermore, since it is an advantage to be able to reinterpret semantic meaning that may have been false or misleading in one SubStance # 94/95, 2001</page><page sequence="5">The Fruit and the Chaff 181 context, as true and helpful in another, and since the reverse is true as well (we need to be able to recognize when old truths begin to mislead), it would actually be counterproductive if the algorithms underlying narrative judgments were decouplers. I will ultimately claim that narratives are themselves the processes that human beings have evolved to understand, express and meet the need for revised and revisable behavior in an unstable world. It is not, however, the truth or falsehood of stories, but their indirection that is crucial to their usefulness. The indirections of narratives, I will argue, are themselves not only not the problem, they are the solution, on the condition, of course, that we learn how to take the fruit and leave the chaff. They allow us to be flexible in the face of the new, and flexibility is by definition the most valuable survival mechanism. In other words, stories do "say what is meant" in the clearest and most direct way possible under the complex circumstances of human life. But that's the conclusion. The argument about borrowed terminology that I will sketch out here begins with the claim that the apparent paradox of truth-telling fictions is an empty one when considered not only from the perspective of interpretive theory, but also from the perspective of the evolutionary biological argument it assumes.2 It, and the inference from it (that the errors or untruths of fiction must or can be labeled and regulated) quickly derail the investigation of the evolutionary function of narratives. I would propose, instead, that the foundational cognitive process by which human beings launch their transformations of narratives so that they can be used constructively is precisely not decoupling or disconnection, but connection. These couplings are provided by a set of learned elaborations on the evolved, general-issue cognitive capacities, one of which is the capacity for analogy, and it is these procedures-based on flexible categorization and often in direct conflict with inferential processes-that provide the bridge between stories and lived experience. Surely one of the crucial lessons of Darwinian thinking is that what counted on the Pleistocene savanna was not truth, but "fitness," or appropriateness in a context. Truth, of course, often "fits" very well; it may be just what is needed. Where can water be found? Is it potable? It might be thought that the best adaptation would be when truth and appropriateness are close to the same thing. But this turns out to be too simple a hypothesis: SubStance # 94/95, 2001</page><page sequence="6">182 Ellen Spolsky truth and fitness may come into alignment only indirectly, as they do, for example, in narrative. Other evidence that truth and fitness are not always productively aligned may be glimpsed in the discussion about the origins of altruism, where it has been hypothesized that the ability to fool oneself about one's own motives may well be adaptive. Hypocrisy and self-delusion, in these arguments, are part of the necessary equipment for living in social groups.3 And since it is adaptive success that counts (with the proviso that it cannot be assumed that whatever IS is necessarily adaptive), then truth standards and "fitness" are not so much opposed to each other as, in principle, disjunct and only unreliably commensurable. When they relate to each other, they do so indirectly. As theorists in several fields have recently been demonstrating, indirection is often the best way of accomplishing a goal, and often the only way. The divergence between truth and fitness has been fruitfully pursued in natural language philosophy, for example, in the wake of J. L Austin's demonstration of the relative uselessness of a truth standard in the description of sentences such as "pass the salt" or "I bet you sixpence it will rain tomorrow." It is more important, he argues, to judge whether an utterance is "the right or proper thing...in these circumstances, to this audience, for these purposes and with these intentions" (145).4 Furthermore, it's not just a matter of how we do things with words. Richard Dawkins's view of what he calls the "extended phenotype" argues, in parallel to Austin, that indirection, or "genetic action at a distance" (229) is often how life achieves its aims. The convergence of Austin and Dawkins is a result of their perception that the conventional categorizations of their disciplines were impeding its progress. For Austin, neither words nor sentences function (i.e., make meaning) independently; both depend on their fit within a context. Similarly for Dawkins, the boundaries of what biologists have conventionally considered an organism impede the understanding of biological function, since that function can only be understood within a context. Both these thinkers echo the conclusion of literary theorists who have argued, as I did above, that the distinction between fiction and non- fiction is a misleading way to categorize narrative texts (see Paul Hernadi's article in this issue). These views of function and meaning as context-sensitive overlap the specifically biological concept of functionalism argued by bio-physicist Robert Rosen, and are at variance with computational models based on how machines work. In Rosen's view, the distinction between hardware and software implicit in Cosmides and Tooby's assumption that the hardware of SubStance # 94/95, 2001</page><page sequence="7">The Fruit and the Chaff 183 human minds would be confused (would propagate errors) if the software (input) included errors, implies an untenable theory of what life itself is. In Rosen's view, because the genotype and the phenotype cannot be absolutely separated, life processes are not well modeled by physics, where the lack of such absolute boundaries would be disastrous (112). To benefit maximally from a Darwinian way of thinking, it is necessary to make full use of the power of the idea of indirection and the flexibility it contains, within the larger assumption that the adaptive success of organisms is the same as their fit in variable contexts. From their different vantage points, then, literary scholars, philosophers of language, and biologists have been demonstrating the advantage of rethinking questions that may originally occur to us as questions of truth, so that we understand them as questions of relatively advantageous categorization. In this view, a categorization is not itself true or false, but may be useful or not to the project of displaying the relationship of a unit to its context. Thus, the goal of understanding the fit between an organism and its niche may be met by a reinterpretation of the boundaries of the unit itself, as in Dawkins, or by understanding its categorization description as contingent on function, not form, as in Austin. Indeed, a robust awareness of the necessity of theoretical redescription produces a methodological adaptation analogous to the adaptation of an organism itself in a changed environment. Cosmides and Tooby are clearly committed to the centrality of improvisation within a context: Arguably, one central and distinguishing innovation in human evolution has been the dramatic increase in the use of contingent information for the regulation of improvised behavior that is successfully tailored to local conditions....For situation-specific, appropriately tailored improvisation, the organism only needs information to be applicable or "true" temporarily, locally, or contingently [in which case] a vastly enlarged universe of context- dependent information becomes potentially available to be employed in the successful regulation of behavior. This tremendously enlarged universe of information can be used to fuel the identification of an immensely more varied set of advantageous behaviors than other species employ, giving human life its distinctive complexity, variety and relative success.(1,2) In other words, even if we could somehow get "enough" truth, the sum of the true things we would know would never provide sufficient grounds for behavior, since unpredictable variation and change would likely outpace knowledge. What we have evolved, however, are ways of filling in the blanks between the variously secure pieces of information that we do have, so that we can anticipate or guess how the bits we perceive, experience, remember, SubStance # 94/95, 2001</page><page sequence="8">184 Ellen Spolsky imagine, infer, deduce, and dream, might fit together. This use of "fit" is not a pun, but the extension of a non-technical term that serendipitously overlaps Darwin's technical usage. Things that fit into a pattern, and the Darwinian concept of traits that confer "fitness," share the important component of being judged only within a context, i.e., the impossibility of saying something fits or "is fit" without knowing what it fits or is fit for. These constructed patterns are stories or narratives, or, to put it the other way round, a narrative is a conflation of all kinds of facts of the matter mixed in with inferences and hypotheses that may be true, along with blatant untruths. When Red Riding Hood sets out for her grandmother's house, the story includes the "truth" that grandmothers are two generations older than their granddaughters, are often widowed and living alone, are often looked after (especially when ill in bed) by daughters or daughters-in-law who may not live with them, and that little daughters can help do their mothers' errands, but cannot fight wolves unaided. These various truths are explicit or implicit in the story, along with the indifferent matters of whether there ever was a little girl of this name, and whether her cloak was red, and the obvious untruth that little girls who have been eaten by wolves can be cut out of wolves' stomachs by fast-acting hunters. And once upon a time, very close to the beginning of human social life, someone discovered that these fictions, these heterogeneous mixes with a plot line that asserted causality, and implications about future behavior, were more useful than a few secure but unconnected truth bites. It is apparently something like this mix that Cosmides and Tooby are thinking of when they categorize some "data sets" as metarepresentation (6), borrowing Alan Leslie's term from his work on the development of pretending in young children. Yet they underestimate the damage done to the usefulness of the term by their correct recognition that "'false' inputs incorporate many elements that are true or informative" (24). The problem is not just that the distinctions between true and false are opaque, i.e., need to be inferred (see Leslie's usage, 197), but that the distinction itself is undependably and variously relevant. And that is because it is their relevance, not their truth or falsity that needs to be inferred. Indeed, it is precisely at this point that their argument becomes less sure-footedly evolutionary and infected by standards that they themselves have correctly recognized as irrelevant. The "naive realist" position (described as an evolutionarily early brain state) very soon becomes complicated when the brain recognizes apparently conflicting information. Minds must now not just know things, but, in this SubStance # 94/95, 2001</page><page sequence="9">The Fruit and the Chaff 185 argument, also store them with a label that distinguishes them from more or less trustworthy information. Here, Ibelieve, the levels of description become confused, and downstream capabilities are described as automatic (upstream) processes. Surely once the mind is able to recognize anomalies (as opposed to simple differences) and thus to worry about relative reliability, it can no longer be functioning at an automatic level. Looking closely at the language Cosmides and Tooby use to describe the acquisition of new information, we can see that two separate kinds of arguments are actually being made here as if they were the same: "When new information is produced that renders old information obsolete, the old information is updated, overwritten, forgotten or discarded" (5). The first two of these metaphors (updated, overwritten) imply that the system can distinguish what is merely new information from information that renders old information useless. But how is this distinction made? It is in principle impossible to know, in a computational model, whether a new piece of information redescribes something already stored or describes something new; all that can be known about a bit of data is that it is the same or different from data already stored. For information to be updated or overwritten, a judgment must be made.5 The last two metaphors (old information is "forgotten or discarded"), however, do indeed describe processes that may happen automatically: "if not used or primed after a given period of time, they fade and are discarded" (6). Recent connectionist theories of mind would confirm that nothing special needs to be done with information (synaptic connections) that is (are) not used. Yet Cosmides and Tooby now postulate "criteria indicating that they (the bits of information/synapses) merit long-term storage, or warrant being treated as architecturally true" (6). Here a gap opens that can only be filled by judgments, although not necessarily conscious judgments. Thus, where they begin the search for the criteria whereby the system will "purge itself" of its "volatile" or dangerous fictions, the argument is led away from its own neo-evolutionary premises, in which fitness, not truth, is the relevant standard, and into a search for the algorithms that will presumably protect the organism from itself in as-yet metaphorical ways, although the use of the terms "merit" and "warrant" already suggests that an algorithm will not suffice. Here, then, the notion of decoupling is referred to several times as one of a set of scope-limiting procedures, though the idea is little more than a place holder: "Without decoupling, a fiction would be stored as a reality" (24). But to say this is simply to repeat Cosmides and Tooby's worry that narratives may be stored in a way that leaves them free to recombine, SubStance # 94/95, 2001</page><page sequence="10">186 Ellen Spolsky i.e., illegitimately authorizes them.And of course, they are right, this is indeed what often happens, although it is not the whole story. In this argument, any specificity that the notion of decoupling may have comes from analogy with the various scope operators used in semantics to describe structural relationships within sentences. Failing greater specificity (of the kind perhaps given by Terry Parsons in his Non-Existent Objects), however, this hypothesis remains unconvincing, although I think I can see where its proponents want it to lead. The analogy proposes a process- "decoupling"-that brackets or labels different parts of narratives, and that process might be as automatic as those aspects of grammar that assign different truth values to different parts of sentences. Here again, however, there is a clash between borrowed terms and the new context. Formal semanticists use the notion of "scope operators" most productively within a compositionally based (non-contextual) approach to truth-conditional aspects of meaning. If narratives are to earn their keep, however, it can only be in terms of their usefulness (fit) within cultural contexts, and this is indeed how literary theorists understand their power. To try to describe how we cope with the non-truths of fiction, then, with an assumption that crucial decisions are made automatically, and by way of a theory that isn't built to consider their contexts, is to begin the discussion facing in the wrong direction. It is certainly true, however, that the different levels of commitment that may be expressed by a speaker are often exploited in novels. Thus, while "Once there was a little girl named Red Riding Hood" can be said simply to lie, the same cannot be said about the opening sentences of George Eliot's Middlemarch, in which the character of the heroine is introduced: Miss Brooke had that kind of beauty which seems to be thrown into relief by poor dress. Her hand and wrist were so finely formed that she could wear sleeves not less bare of style than those in which the Blessed Virgin appeared to Italian painters... Here the author exploits precisely the possibilities of differentiating levels of belief in order to smuggle in, as it were, the assertion that once upon a time there was a woman named Miss Brooke. The magic is done, however, by the presupposition that arises from a name appearing in the subject position of a sentence, not by a scope or modal operator. Syntactically and semantically, the sentence suggests many references to which the speaker is less than committed: "that kind of beauty which seems to be;" the Blessed Virgin "appeared to Italian painters;" and the reference to the mother of SubStance # 94/95, 2001</page><page sequence="11">The Fruit and the Chaff 187 Jesus under her most unconvincing name of "Virgin." Buried by all this, the assertion made by casting a fictional character as the subject of the sentence goes virtually unnoticed. If we know (as we do) that there is no such person as Miss Brooke, we know it from the genre of the text, not from the syntax. In a novel or a play, to predicate something about a name is to create a character. To command of a hearer: "Call me Ishmael" is to slip in the creation of the character while the hearer is distracted by the associations of the name. The way we deal with the heterogeneity of truths in these narratives is much more likely to be well described by pragmatic rules and genre conventions than by scope operators. The theory we are after needs to take into account that many perfectly normal people do not deal with this heterogeneity well, do not learn what they might from narratives, and do, apparently, learn from stories to behave in self-destructive and tragic ways. Many people seem, quite normally, not to have understood, in good time, what is or isn't true, what does or doesn't have what consequences. One can think not only of King Lear and his daughters, but of the conflict faced by a young man who needs (according to one of his cultural stories) to drink a lot of beer of an evening, even though, according to another story, he needs to drive his date safely home. If only there were an evolved mechanism that would inform the fellow that the first story is a local, cultural fiction, and the second a matter of fact. If only there were an evolved mechanism that would prevent his date from feeling "fat" because her body image is only a cultural narrative illustrated by Barbie dolls and fashion magazines. Or that would convince her to buckle her seatbelt even if it creases her clothes. Cosmides and Tooby's paper suggests a complex computational model of "how humans process fictional worlds without confusing their environments and inhabitants with the real world" (36). But the evidence is that humans do confuse the two frequently, subject, as they are, to powerful stories and their powerful interpreters. We are often instructed by models of behavior who have lived only in their author's heads, i.e., fictional characters, including the heroes and heroines of communal myths. Thus we see that even when a fiction or a legend or local history is clearly labeled as such, that label itself is just one more datum from which inferences can be drawn. The labels themselves could be labeled, in an infinite regress.6 Furthermore, beyond recognizing that fictions indeed circulate with impunity, the theory that will describe how narratives can still be adaptive even though people are frequently misled by them will benefit from the recognition not only that we learn from them, but that we may be taught by others how to learn from them. This is an important indirection, because it SubStance # 94/95, 2001</page><page sequence="12">188 Ellen Spolsky allows the emergence into the theoretical field of issues of authority and power that surely complicate processes that might otherwise function on the simpler basis of self-interest. The importance of authority figures who determine both the texts to be interpreted and the method of interpretation within social groups can now be considered as evidence in any consideration of how narratives work. It may be that leaders are identified as such precisely because they have attained the position within the group that allows them to invoke or induce group behavior on the basis of narratives, even when the behavior is not, or not obviously, useful to the individual. We call these "narratives ideologies"-that is, stories that make sense of a group's past and present experience in a useable way. Crucially, when we are talking about them as aspects of brain function, ideologies are not structurally different from plans for a picnic, proverbs, or Shakespearean plays. The advantage of considering group ideologies as narratives on the same footing as plans, gnomic wisdom, or the high cultural texts of visionary poets, is that their inclusion allows us to recognize that in the real world, fictions, even lies, are often entirely functional for groups, or, as Michel Foucault has so powerfully argued, for certain members of groups. Our category of narrative, then, cannot exclude them, and our description of it cannot stand clear of the functions of deception, nor of the argument these functions mount against the presence of a decoupler. In short, when the category of narrative is described with realistic breadth and complexity, and when the borders between fiction and non-fiction are recognized as unstable and not always useful, it is hard to see how an evolved algorithm could reliably deal with the conflicting stories that the real and overwhelmingly complex world presents. If any further argument were needed, we might consider the ubiquity of attempts at censorship, which itself argues that those who have the physical power to attempt the control of the dispersion and interpretations of stories don't trust an evolved internal decoupler to monitor how people sort the useful stuff from the dysfunctional. Or perhaps (and this would make a different kind of argument) they feel that the decoupler can itself be neutralized or colonized by imposed standards. The frequent failures of attempts at censorship testify to the difficulty of stopping the productivity of a text on the grounds of its truthfulness, when it is, somehow, useful. If we had evolved such a mechanism, as we have, for example, evolved the ability to understand and use grammatical negativity, then why would people disagree so enormously about the truth of stories? Why, as Napoleon marveled, would men be willing to die for little pieces of ribbon? SubStance # 94/95, 2001</page><page sequence="13">The Fruit and the Chaff 189 That willingness returns me to my own point of departure, making unavoidable the surmise that Chaucer at the end of the fourteenth century and Graff at the end of the twentieth were right to suspect that people still need instruction in how to manage the connections between narratives and life. All people need and use stories, but the evidence suggests that the ability to produce and understand narratives adaptively is not distributed evenly throughout a society. For better or worse, just as a society will have stronger hunters whose greater success may compensate for others' deficiencies, and gatherers who can sort out the medicinal from the poisonous herbs, social groups have storytellers and interpreters-poets and priests-who produce and interpret the group's narratives in ways that make them useful, although they may be differently useful to different segments of the society. This uneven distribution of talent and power in story-telling might help explain why large bodies of stories may be revered and preserved throughout generations, often with great care for accurate transmission, and how these stories differ from those that arise and disappear in popular culture, and which many people dismiss as not serious. From this more complex view of story-telling, we can again ask, what is adaptive about the production and reception of narratives that consist of complex imbrications of inferred, imagined, and assumed material (some of the last three actually false, even misleading), along with several kinds of truth, (facts of the matter, including whose authority counts, inherited traditions that may no longer be functional, etc.). It remains to be explained how constructed narrative allows prediction on the basis of past experience, and in the face of perceptual intake (data from the world) that is often novel, always uncategorized, underorganized, not clearly marked as to reliability (in fact, often mismarked, as when an authority figure is a purveyor of not entirely true information), usually missing apparently key bits of information, and also containing unhelpful repetition. What theory will account for the lumpiness of any single story, as well as the agglomeration of stories and their variable authority, which we call ideologies, and for the simultaneous claims of conflicting stories or ideologies, as well as the variable motives and competencies of interpreters? Because the categorization criteria of what counts as fiction are so fuzzy (Spolsky and Schauber ch. 2), literary theorists have come to believe that if literary texts are different from other narratives, it isn't because one is fictional and the other isn't. If I have to decide how to judge the assertion that "Once SubStance # 94/95, 2001</page><page sequence="14">190 Ellen Spolsky upon a time there was a little girl named Red Riding Hood," or the command to "Call me Ishmael," I have to use the same equipment I use to judge the salesman's assurances that my new water heater will outlast the house. Experience, in both cases, helps, and recognizing the genre of certain speeches is gained by experience. The ability to recognize a feature of a text as contributing to a judgment about its genre isn't specific to understanding texts that are considered literary, but is part of the cognitive apparatus of categorization. A category judgment is made when structural features of text are recognized. The formulaic beginning we recognize as a feature of a fairy tale is thus not functionally different from one feature of generic exchanges with salespeople, according to which the quality of the merchandise is exaggerated. Either of these cues gives you a hint about the category of speech genre you're dealing with, which in turn suggests interpretations of parts of the whole. In the dynamic of this hermeneutic circle, one is always free to revise a judgment in the light of other information, and this is the state of all semantic knowledge, not just narratives: it is all more or less permanently open to reconsideration in the light of new information, while at the same time being more or less resistant to reconsideration on the basis of its relative entrenchment or interconnectedness (see Wimsatt). We make do, it seems, without a foolproof mechanism for distinguishing between categories of texts, just as we make do without foolproof mechanisms for distinguishing truth from untruth. Even when they arrive labeled, texts can fool us into thinking they contain either more or less truth than they perhaps do. Functionalism, the evolutionary perspective argues, is the real test, although this is not the end of the story. Even if we accept the importance of functionalist factors, there is often a serious time lag between accepting a story as provisionally functional, using it to make plans or decisions, and understanding, in the fullness of time, how those decisions play out. This is most glaringly obvious, for example, in the differently useful stories or ideologies learned by children within families, and which, for better or worse, guide their behavior as adults twenty years later. The plots of a large number of Shakespeare's tragedies reproduce precisely the situation in which parents pull their children, to everyone's detriment, into old stories. In Hamlet, for example, both Polonius and the old King Hamlet cause the deaths of their sons by involving them in retrospective stories of honor and revenge. Romeo and Juliet are caught between older people who are committed to the power of the story of the feud between the Montagues and the Capulets. It has been suggested that the function of these stories is at least in part to encourage young adults to disagree with or to deceive the SubStance # 94/95, 2001</page><page sequence="15">The Fruit and the Chaff 191 parents they love, since they are going to be ill-equipped for the world a generation on, if they don't know how to sort and reject some of what they've been taught.7 It is thus the nature of language itself, and of narratives, that neither the formal features of language nor the most probable semantic meanings of words can reliably be connected to their function without a consideration of context.8 This is true at all levels, from the ambiguities of syntax to the possibilities of irony, any one of which would scuttle the work of discrimination if the job were to separate fact from fiction. This is as true of proverbial wisdom as of complex works of imagination.And once it is agreed that aspects of the context determine the scope or applicability of parts of a sentence or a story, the possibility that the surface structure will predict the usefulness of parts or of the whole now and in the future becomes even more remote. The significance of any part of a language text, then, from a sentence to a story, is so densely interwoven a construct as to reduce to virtually nil the possibility that the work of disassembly and labeling could be done usefully and reliably by an evolved algorithm. The last argument against the usefulness of the metaphor of decoupling is that in its derivation from the computational metaphor of mind, it misdescribes the complexity of the job, not only, as has already been argued, because an evolved algorithm cannot function when the surface form does not reliably determine the function of the unit within the whole, but also because it overlooks the interactivity of human processing, thereby missing the multi-directionality of the processes of interpretation. In short, one couldn't know what to decouple until some interpretation had already been done, and that interpretation usually begins with a genre judgment about the text. Each such judgment is based on earlier experience. We may well initiate a category judgment by identifying the grossest structural features of an object or a text, say, the fact that it starts with "Once upon a time..." But there is nothing about the opening line of Moby Dick ("Call me Ishmael") that formally distinguishes it from a non-fictional command. We know it is a fictional invitation because of a whole range of things we know about books and narrators, none of which could be built into an algorithm. And once we decide that the heavy tome is fictional (even if it indeed has whole chapters on whaling techniques) we remain open to revising that judgment, as we read, until we settle into a use for the text, as Graff suggests. And that may not be for years. We don't want a model of decoupling because we don't want a model wherein consideration of bits and pieces learned from a universal and presumed adaptive behavior (i.e., the construction of narratives) are blocked SubStance # 94/95, 2001</page><page sequence="16">192 Ellen Spolsky from use in cognition, and at more than one point Cosmides and Tooby recognize this. We want, instead, a theory in which whatever we've got can be used and reused as needed. Furthermore, we don't need to label bits or limit their scope, because the larger theory of "fitness" will do that: what isn't useful will, by definition, not be used, and if a fiction or a lie is useful, it will be used. The remaining questions are, how will these heterogeneous narratives be used, and what will they be used for? A fair amount of work has already been done suggesting how basic cognitive processes are elaborated for both the production and the understanding of narratives. I have argued, for example, that we have apparently evolved the ability to perceive and construct patterns on the basis of three separable, but densely interconnected processes that can be labeled as categorization, inference, and analogy. All of these processes are recursive, or generative, in principle ad infinitum (Schauber and Spolsky, 189). Furthermore, as human, rather than machine processes, they interact in a continually self-adjusting dynamic whereby any one part of the system may be responsive in a compensatory way to the outputs (even the excesses) of another. Thus, the cognitive powers of inference are not free to propagate errors throughout the system, because existing categorizations and analogies will keep them in check. We know that a "reductio ad absurdum" is absurd because we can reject the usefulness of the product of formally correct inferences by observing the lack of fit with other relevant information. In Lisa Zunshine's example of Swift's Modest Proposal in this issue, the "error" or lie introduced early on indeed generates a logical proposal to eat one- year-old children. But the outrageousness of the categorization of human children as food acts as the clue that Swift couldn't really mean it. Of course, for other reasons, not everyone at the time of publication read the clue properly. So while we see that categorization and analogy can help interpreters keep tabs on the differences between situations-the contexts of stories-so that the applicability of the kind of information offered can be judged, the process is certainly not fool-proof. Nevertheless, the complexity, redundancy, and responsiveness in the system mean that even a single individual approaches any interpretive task as if Marvin Minsky's metaphor of the society of mind was literally true. Thus, culturally established categories set conventions of appropriateness or fitness that counterbalance the propagation of errors that might occur from runaway inference, just as inference checks unchecked analogy. I suggest that it is these highly practiced and context-dependent homeostatic controls that are the regulators we need to sort out the variously connected and conflicting narratives around us. SubStance # 94/95, 2001</page><page sequence="17">The Fruit and the Chaff 193 Judgments will be either stronger or weaker, depending, for example, on how much conflicting information must or may be accounted for. The fact that it is often desirable to be able to make reliably strong and clear judgments doesn't mean it is always possible to do so. Genre categorizations are crucial discourse-level regulators. The Nun's Priest tells us a fable of a philosophical cock and a braggart fox. What we know about beast fables tells us not to stop looking for nourishment from the story even though we know that animals don't really speak Middle English. The editor of a farm journal, however, would rightly be suspicious of the conclusions of an article on predatory foxes that included as evidence the words of a cock describing his abduction and escape. History writing, taxi-cab chatter, and movie reviews are also genres that contain narrative elements and mixtures of fact and fiction.9 The early and crucial contribution of Mervis and Rosch was the demonstration that human categorization, unlike machine matching, is fuzzy, but not arbitrary: "A category exists whenever two or more distinguishable objects or events are treated equivalently" (89). This "inaccuracy" is not, Rosch had made clear earlier, a systemic failure, but is crucial to all thought, which is always and in principle a fudging of distinctions. When the goal is "to provide maximum information with the least cognitive effort...it is to the organism's advantage not to differentiate one stimulus from others when that differentiation is irrelevant to the purposes at hand" (28-29). And an organism is always attuned to "the purposes at hand." As descriptions of analogy, both schema and frame theories seem to catch the phenomenological feel of the way some stimuli call up whole patterns of form and content (Arbib and Hesse). Ray Jackendoff's preference model suggests a formalism for the description of fuzzy categorization.10 Connectionist theories, at the neurological level, suggest how these schemata might be constructed by the interaction of genetically encoded developmental programs and sensory input. Syntactic and semantic theories, even dream theories, all bid to describe our production of new functional connections. Mark Turner and Gilles Fauconnier's theory of cognitive blending describes the reuse of old information of almost any kind (syntactic, visual, kinesic) as a powerful strategy of integrating new information or solving new problems. If the revised categorization, blend, or transformation works well, the new blend may "catch on," perhaps as a "meme," and may spread, with modification (Sperber). Much work remains to be done. It is not, however, too early to hypothesize how narratives are the solution, not the problem, by further SubStance # 94/95, 2001</page><page sequence="18">194 Ellen Spolsky specification of the notion of indirection. How are indirect processes-at all levels of description, from the intracellular to the metaphysical-just what is needed to keep open the possibilities of recategorization, reinferencing, and blending? Indirection is the word I use here because it is the most neutral of all formulations describing the inescapable context-dependence of life processes. It is an abstraction intended to describe both brain processes and theoretical models of complex systems in which the move from one state to the next is not logically entailed or biologically necessary, but neither is it random. The hypotheses for both language and heredity arrive on parallel tracks: no language string can be unambiguously and uniquely linked to anything in the world with more than a probability, and no genotype can unambiguously and uniquely predict or produce a specific phenotype with anything more than a probability. Crucially, this is not just a temporary situation resulting from our still being in the early stages of description of human language and descent. On the contrary, the permanent possibility of alternatives makes constant reference to the context unavoidable, and it is this necessity of reference to context that constitutes the indirection. Since contexts of course cannot be fully controlled by those who must operate within them, it is precisely the possibility of alternative behaviors that makes survival possible. To put it another way, the necessity of constant reference to the context is itself a way of insuring that an organism will stay in touch with changing demands, so that its evolved adaptability can function. At the same time, while full predictability would build in fatal inflexibilities, there are also times when survival depends on fast and reliable decision-making (get out of the way of that approaching wild animal) in which indirections can be fatal time-wasters. How do we balance the need for fast, thoughtless responses, especially to danger, and the need to remain open to new contingencies? For one thing, "we" don't do this individually, we do it as a species, or more likely, as a cultural group. Since the survival of the species doesn't depend on the survival of every individual, we learn from the mistakes of others. An individual mistaken categorization (say, eating poisonous mushrooms) may be a reasonable price to pay for the evolved flexibility of categorization that allows a group to identify a previously unexploited source of food. Similarly, in language, we need to be able to express new information, new ideas, new combinations of old ideas, with the language we have already learned, and in ways that are immediately understandable, although not always immediately understandable to everyone in the group. The language of metaphor, rhetorical troping, or blending, is, on this account, the reuse of old material SubStance # 94/95, 2001</page><page sequence="19">The Fruit and the Chaff 195 in a new context, allowing language to take us places we haven't been, but need to explore. Some parts of the society may go first, scouting out the land and sending back reports. Thus Virginia Woolf's innovative novels, misunderstood by many of her contemporary readers, can now be taught to undergraduates. Similarly, as we grope toward a description of the function of narratives, we naturally try out vocabulary developed in other fields. Such success as our species has had, and undoubtedly our failures as well, have depended on keeping alive the recombinatory power of the human mind, on line, open for business and ready to invent, in spite of the contingent, relative, or possibly absolute falsity of some of the information therein. Am I telling you anything new when I tell you that human life is lived on the edge? Rather than a model of how humans are evolved to keep themselves unconfused, what we have now is a model of how, given certain kinds of information in certain circumstances, some people can take advantage of their innate abilities to improvise and understand revisionary narratives adapted for new circumstances. The usefulness of narrative, then, is not in its production of any one moral or another; it's in the constant possibility of drawing new inferences from the old texts. We can reject old stories as false, even if they once were true, and we learn that we can do it not so much from the morals of the stories themselves as from the way the stories are told and interpreted. It is their very indirection, their inventive, tropological, and previously unexperienced ways of presenting themselves that train us in flexible thinking. Indeed we have been badgered by our teachers to do this- from Jesus to Gerald Graff." A large amount of the work of literary theory can be understood as investigating the possibility that the experiences of narrative-both as hearers and storytellers-provides practice in repatterning, recategorizing, reinferencing and reanalogizing. We are on our way to describing why we need and how we have developed story-telling cultures as a way to keep our minds open. One last look at the two teachers of literature with whom I began. The Nun's Priest tells us to take the fruit and leave the chaff, these lines following his own comment on his story, just a line earlier: "one must never trust flattery." But within the tale itself, the cock had just proposed his own moral: "he who blinks when he should see will never thrive." The fox himself proposed a third: "bad luck to he who speaks when he should hold his peace." The story itself, it turns out, has at least these morals, and that's not counting St. Paul's moral, i.e., "all fictions can teach." It's just as well then, that Chaucer's priest didn't simply describe what he considered the chaff, and the fruit. To have done so would have been to attempt to limit the tale's SubStance # 94/95, 2001</page><page sequence="20">196 Ellen Spolsky productivity. Chaucer thus produced two animals, a clerical narrator, and St. Paul, each of whom learned and/or taught something different within the same story. And, of course, each could have learned more than one lesson, too. Graff also fails to point a clear moral; his "insular Tahiti" is, of course, a metaphor, but for what? However, his not specifying is not an evasion. Were he to interpret it, he would be limiting it to what he understands it to mean, short-circuiting the very process of production that literary texts engage us in. The whole point, however, of presenting narratives that are generative rather than limited is not only to let every reader take his or her own fruit (and perhaps to take it differently on the next reading), but precisely to teach us that very generativity we need to counterbalance the rigidities that life so often requires of us. It is the indirection of the way language means that underwrites the unlimited and permanent possibility of recategorization, and the open-endedness of inference and analogy that allow narratives to be reinterpreted by new readers in new situations. Ad infinitum. Bar-Ilan University Ramat-Gan, Israel Notes 1. I use the term algorithm here as Daniel Dennett describes the algorithms of evolution: "individually mindless steps succeeding each other without the help of any intelligent supervision" (59). Adaptations surely can react to variations in the environment, such as the way a bird's wing reacts to air currents or a fish's gill to the amount of oxygen in the water. The variations here, however, are definitively describable, which the cultural contexts in which narrative must work are not. 2. Cosmides and Tooby set this paradox as a straw man: "What could possibly be useful [about] fictive, counterfactual, or imagined worlds - that is, about false or indeterminate information" (14)? 3. R.H. Frank (Passions within Reason) argues that "really" wanting to help others is the best way to convince others of your altruism and thus to provoke their reciprocal cooperation. The earlier Alexander-Trivers hypothesis, summarized by Nesse and Lloyd in Barkow, Cosmides, and Tooby, The Adapted Mind: Evolutionary Psychology and the Generation of Culture (603ff), describes the basis on which the most successful behavior is said to result from self-delusion. 4. Even Austin, however, didn't sufficiently understand the felicity of fictions. Austin in fact advanced a theory something like a theory of decoupling, claiming that in poetry or on stage, "the normal conditions of reference may be suspended....Walt Whitman does not seriously incite the eagle of liberty to soar" (104). This claim, however, as was eventually shown, was inconsistent with Austin's own theory. In short, just as "Can you reach the salt?" does not ask a question, so Whitman doesn't incite the eagle. Both, however, have other designs on their addressees, designs that need to be inferred. This indirection, i.e., the need for inference it evokes, was exactly what Austin argued for all language, so it was odd that he should have missed the persistence of the phenomenon in literary texts. SubStance # 94/95, 2001</page><page sequence="21">The Fruit and the Chaff 197 5. There is an ambiguity in their use of the passive "is overwritten" that suppresses the subject. A human computer user can decide to overwrite or delete, and instructs the machine to do so, but a machine cannot make that decision. Fading, on the other hand, being a biological process, is apparently a reaction to neglect rather than to a judgment, but further knowledge may show that anthropomorphic distinction to be unfounded; that is, disuse may turn out to have an active component. 6. The process of relabeling is subject to historical pressure, of course. Assertions that were at one time considered reliable because they were taught by priests, for example, may now be labeled false for precisely the same reason. 7. Renee Garfinkle, personal communication. 8. One might return to E.D. Hirsch, Jr., Validity in Interpretation, for an early argument of the claim that meaning is always only probable meaning. These claims were argued further in the work of the French and American deconstructionists. Again, here, see Culler. 9. M.M. Bakhtin's essay on speech genres has been influential. 10. Ellen Schauber and I (1986) described how Jackendoff's formalism (1983 and 1987) works well to describe literary genres. His preference model represents a category judgment as an analogical judgment built from an open-ended series of matches between the necessary and the typical, gradient and non-gradient conditions or features of stored tokens and objects or ideas in the environment. The preference model comes about as close as is going to be possible to an algorithm for analogy. Spolsky 1993 discusses analogy and genre change, and Spolsky 2001 discusses categorization and change in specific cultural contexts. 11. Chaucer's reference to St. Paul recalls a long tradition of religious teaching in which the text to be interpreted and the principles of its explication are taught together. Jesus's exhortations to his flock ("He that hath ears to hear let him hear" (Mark 4:9) continued the Jewish tradition of Talmud Torah. The development of a hermeneutic and the dissemination of it throughout the community is exemplified by the 13 modes of Rabbi Ishmael, developed in the first half of the second century CE, which are still printed in Jewish prayer books, meant to be read daily. Works Cited Arbib, Michael and Mary B. Hesse. The Construction of Reality. Cambridge, England: Cambridge University Press, 1986. Austin, J. L. How to Do Things with Words. Oxford: Oxford University Press, 1965. Bakhtin, Mikhail. Speech Genres and Other Late Essays. Ed. Caryl Emerson and Michael Holmquist. Trans. Vern W. McGee. Austin: University of Texas Press, 1986. Barkow, Jerome H., Leda Cosmides, and John Tooby. The Adapted Mind: Evolutionary Psychology and the Generation of Culture. Oxford: Oxford University Press, 1992. Boyd, Richard. "Metaphor and Theory Change: What is 'Metaphor' a Metaphor for?" Metaphor and Thought. Ed. Andrew Ortony. Cambridge: Cambridge University Press, 1979. Pp.356-408. Cosmides, Leda, and John Tooby. "Consider the Source: The Evolution of Adaptations for Decoupling and Metarepresentations." Metarepresentations: A Multidisciplinary Perspective. Ed. Dan Sperber. Vancouver Studies in Cognitive Science. Oxford andNew York: Oxford University Press, 2000. Culler, Jonathan. On Deconstruction. Ithaca: Comell University Press, 1982. Dawkins, Richard. The Extended Phenotype: The Long Reach of the Gene. Oxford: Oxford University Press, 1982. SubStance # 94/95, 2001</page><page sequence="22">198 Ellen Spolsky Dennett, Daniel C. Darwin's Dangerous Idea. New York: Simon and Schuster, 1995. Emerson, C., and M. Holquist, eds. Bakhtin, Mikhail. Speech Genres and Other Late Essays. Trans. V.W. McGee. Austin: University of Texas Press, 1986. Fauconnier, Gilles, and Mark Turner. "Conceptual Integration Networks." Cognitive Science 22.2 (1998): 133-87. Graff, Gerald. Literature against Itself: Literary Ideas in Modern Society. Chicago: University of Chicago Press, 1979. Jackendoff, Ray. Semantics and Cognition. Cambridge: MIT Press, 1983. Leslie, Alan M. "Pretending and believing: issues in the theory of ToMM." Cognition on Cognition, ed. Jacques Mehler and Susana Franck. Cambridge, MA: MIT Press, 1995. Mervis, Carolyn B., and Eleanor Rosch. "Categorization of Natural Objects." Annual Review of Psychology 1981 32 (1981): 89-115. Minsky, Marvin. The Society of Mind. New York: Simon and Schuster, 1985. Parsons, Terence. Nonexistent Objects. New Haven: Yale University Press, 1980. Robinson, F.N., ed. The Works of Geoffrey Chaucer. 2nd ed. Cambridge, MA: Harvard University Press, 1957. Rosch, Eleanor. "Principles of Categorization." Cognition and Categorization. Eds. Barbara B. Lloyd and Eleanor Rosch. Hillsdale, NJ: Erlbaum, 1978. Rosen, Robert. Essays on Life Itself. New York: Columbia University Press, 2000. Rubin, David C. Memory in Oral Traditions: The Cognitive Psychology of Epic, Ballads, and Counting-out Rhymes. New York: Oxford University Press, 1995. Schauber, Ellen, and Ellen Spolsky. The Bounds of Interpretation: Linguistic Theory and Literary Text. Stanford, CA.: Stanford University Press, 1986. Sperber, Daniel. Explaining Culture: A Naturalistic Approach. Oxford: Blackwell, 1996. Spolsky, Ellen. Gaps in Nature: Literary Interpretation and the Modular Mind. Albany, NY: SUNY Press, 1993. - . Satisfying Skepticism: Embodied Knowledge in the Early Modern World. Aldershot, Hants and Burlington VT: Ashgate, 2001. Wimsatt, William C. "Developmental Constraints, Generative Entrenchment, and the Innate- Acquired Distinction." Integrating Scientific Disciplines. Ed. W. Bechtel. Dordrecht: Martinus-Nijhoff, 1986. SubStance # 94/95, 2001</page></plain_text>
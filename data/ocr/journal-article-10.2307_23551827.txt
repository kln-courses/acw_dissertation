<plain_text><page sequence="1">THE SO-CALLED COGNITIVE OPTIMUM AND THE COST OF RELIGIOUS CONCEPTS1 Gregory D. Allés 1. Introduction When I try to explain to people who specialize in cognitive science and psychology basic positions in the cognitive scientific study of reli gion, they often reply, "That doesn't work." Now, I am willing to con cede that their negative reactions may result from my own inability to explain these positions adequately. I am also willing to entertain the notion that these people are not sufficiently competent to judge. They seem knowledgeable and bright enough to me, but perhaps my confidence in their abilities is excessive. Here, however, I want to entertain another possibility, namely, the possibility that my interlocutors may in fact be right. They certainly know considerably more about cognitive science and psychology than I do. And I want to entertain that possibility with regard to a question on which there is no little difference of opinion among those who study religion from the point of view of cognitive science. That question is the cost of religious concepts. The focal point of my inquiiy is Pascal Boyer's claim that religious concepts occupy a cognitive optimum, which some have taken to calling moderately costly (e.g., Whitehouse 2004: 17-47). In his ground-breaking book, The Naturalness of Religious Ideas, Boyer (1994: 121) put it this way: Religious concepts could not be acquired, and more radically could sim ply not be represented, if their ontological assumptions did not confirm an important background of intuitive principles. At the same time, they 1 Earlier versions of this essay were presented at the meeting of the North American Association for the Study of Religion at San Antonio, Texas, in November 2004, and the Nineteenth Congress for the Internationa] Association for the History of Religions at Tokyo, Japan, in March 2005. Thanks to Ric Peters, Anders Lisdorf, and Luther Martin for written critiques and encouragement. I am also grateful to my colleague, Peter Bradley, who has given me access to the Inquiry website on cognitive science that he helped develop while a post-doctoral fellow at Washington University in St. Louis. None of the people named are responsible for any errors I may have made, nor should they in any way be associated with the unnamed persons in my opening paragraph. © Koninklijke Brill NV, Leiden, 2006 Method &amp; Theory in the Study of Religion Also available online - www.brill.nl 18, 325-350</page><page sequence="2">326 GREGORY D. ALLES would not be the object of any attention if they did not contain some principles that are simply ruled out by intuitive expectations. One can therefore assume that certain combinations of intuitive and counterintu itive claims constitute a cognitive optimum, in which a concept is both learnable and nonnatural. By the time I am finished, I hope to have given cause to doubt whether this notion of a cognitive optimum is tenable. I also hope to have sketched out ('in a preliminary fashion') the requirements for a model that makes it nonetheless possible to retain what seem to me to be Boyer's important contributions. Before turning to that task, however, it seems prudent to offer first a brief sketch of the basic mental archi tecture that my comments will presuppose. Otherwise, we risk talking past each other, as too often happens in academic discussions. 2. Feedback and Reflection In principle I subscribe to a theory of identity according to which men tal processes are identical with neurophysiological events.2 In practice, however, the limits of current knowledge make it unfeasible to start with neurophysiology for anything more than a rudimentary account of mental functioning (for attempts, see Anderson et al. 2004: 1053 1057: Crick and Koch 2003). So the sketch that follows is unashamedly functional. That is, it will identify mental structures according to their functions and without regard to their neurophysiological bases.3 But while I adopt this procedure, I want to add two qualifications. First, I 2 To be more precise—and this should become clear by the end of the paragraph— I hold the position that every mental event is at the same time a physical event in the brain, but I do not hold the position that for every type of mental event there is one and only one type of physical event that occurs in the brain. It is conceivable, and perhaps likely, given the way that different parts of the brain take over functions after strokes, that similar mental events may correlate with different types of physical events in the brain. 3 I take it as self-evident that defining the components of mental processing in terms of their functions is fundamentally different from offering functionalist expla nations in the sense in which, for example, a Malinowskian might explain why people pray by appealing to the relief of anxiety. In some circles, however, the word "function" has become such a scare word—because of its connections with functionalist explanations—that it is probably worthwhile to point out the difference. Nor do I mean to take a stand one way or another on functionalism as a theory of mental states, as opposed most blatantly to either behaviorism or physicalism (paradigmatically, Putnam 1980). I find much to agree with in qualia-based objections to pure functionalism (e.g., Block 1980, 1997), but the discussion here can afford to ignore the issue.</page><page sequence="3">THE COST OF RELIGIOUS CONCEPTS 327 fully expect that a better understanding of human neurophysiology will require changes in anyone's current conceptualization of the archi tecture of the human mind. Second, and equally important, a better understanding of human neurophysiology will not make a functional account obsolete. We know from computer science that different hard ware can run the same software, although perhaps with differing degrees of efficiency. We also know that human brains, while similar, differ from one another in some respects. Whether an investigator is prima rily interested in the neurophysiology of the brain or the functional architecture of the mind may always depend to some extent on the questions being addressed. I begin by following the lead of Justin Barrett (2004, citing Sperber 1997, who uses different terminology) and distinguishing between two kinds of mental functioning, nonreflective and reflective. Reflective mental processing involves active, conscious attention. Nonreflective mental processing does not. I readily concede that identifying these two levels, nonreflective and reflective, hardly accounts for the complexity of human mental processing. Indeed, it begs a number of thorny questions. One begins to see what those questions might be if one considers an illustration that David Armstrong (1980: 59) introduced into the literature: What are we to make of the mental experiences of a long-distance truck driver who manages to drive all night but, on arriving home, apparently has no memory of much of the road over which he has driven? I take it that such experiences are fairly common— I have certainly had them—but it is not at all clear just what we are to make of them (Armstrong 1997; Dretske 1997; Lycan 1997; Rosenthal 1997). Present purposes do not, however, require us to address this conundrum. Instead, I want to identify only one more level of mental processing, a level that I will call "perceptual." Perceptual processing comprises all those processes by which the brain takes primary input from the senses and formulates it into an organized representation of the world. Studies of visual representation show that this processing is quite complex in its own right. A classic example concerns the modu larity of the "what" and "where" visual pathways. But that complex ity will not concern us here. It will be enough simply to identify these three levels of processing—perceptual, nonreflective, and reflective— and make a couple of points about them. As noted long ago (Fodor 1983), these three levels of mental processing are open to the operation of feedback mechanisms to differing degrees. Take a familiar example: two lines of equal length whose endpoints are arrows pointing in opposite directions, inward and outward. All</page><page sequence="4">328 GREGORY D. ALLES human beings with an unimpaired visual apparatus seem to see these lines as being of different length. By measuring them with a ruler, we can determine that, for all practical purposes, their length is identical. But even after making this determination, we still see the lines as differing in length. In other words, perceptual processing is much less susceptible to correction through feedback than reflective processing is. It is enough here simply to add that nonreflective processing stands somewhere between perceptual and reflective processing in terms of its openness to correction. Here is another way to express these relationships. Greater openness to feedback in higher-order processing implies greater, but hardly com plete, freedom from the algorithms that govern lower-order processing.4 Reliance upon algorithms allows perceptual processing to achieve results with speed and a minimum of mental exertion. By contrast, the relative, but hardly complete, absence of algorithms and the greater variability of representational possibilities available to reflective processing means that it is slower and more costly in terms of mental effort. It makes up for these disadvantages, however, by being capable of reaching higher degrees of accuracy, subtlety, and abstraction. At the same time, it permits greater levels of disagreement about results before we begin simply to doubt another person's mental competence. Nevertheless, it would be a mistake to consider the relatively less constrained, slower operations of reflective processing to be any less natural than the more constrained, faster operations of perceptual or nonreflective processing. Evolution seems to have selected reflective processing as the mecha nism by which the brain assesses, corrects, and refines the results of perceptual and nonreflective processing in cases where the results of prior processing seem unreliable, as when, upon seeing a mirage, one comes to the conclusion that it is probably not a likely source of water.5 This account of mental architecture is deliberately minimalist. Its aim has simply been to clarify the vocabulary that I will use in what follows. Even so, it may allow us to create some order where a certain amount of chaos has previously reigned. Without always saying so, different the orists in the cognitive study of religions have focused their attention on different levels of mental processing. For example, Stewart Guthrie (1993) has been fascinated by the tendency of the perceptual system to 4 I remain non-committal to the precise form that these algorithms may take. 5 One finds this "just-so story" in, for example, Armstrong 1997. Conscious attention also has other benefits, for example, benefits in the area of learning.</page><page sequence="5">THE COST OF RELIGIOUS CONCEPTS 329 identify faces.6 It is virtually impossible not to see some configurations of shapes—consider the colon-hyphen-parenthesis figure of email fame [ :-) ]—as a human face. Guthrie has also discussed cases of nonreflective misidentification corrected by reflective processing, for example, his famous example of the mistaking a distant rock in the woods for a bear. But he has been less clear about the levels of processing to which he assigns religion, asserting rather vaguely that religion—which he defines as systematic anthropomorphism—somehow emerges from such perceptual and nonreflective processes. By contrast, Boyer has focused on the algorithms of nonreflective processing ("cognitive constraints") and the limited ability of reflective concepts to break away from those algorithms. Harvey Whitehouse (1995, 2000, 2004) has taken yet a third position. He has tended to place religious concepts on the reflective level and see them as capable of a great deal of variability, difference, and sophistication, despite the dominance of algorithms at lower levels of processing. Given the focus on different levels of mental processing, it comes as no suiprise that these thinkers differ significantly about the cost of religious concepts. 3. The So-Called Cognitive Optimum Let us now turn to Boyer's notion of a cognitive optimum, which Whitehouse (2004: 17-35) also accepts, although he rejects it as an ade quate description of religious concepts. In The Naturalness of Religious Ideas Boyer wanted to explain why certain kinds of concepts, such as ghosts and supernatural beings, tend to recur across time and space when they could not be attributed to cultural transmission. He did so by claiming that the mind/brain tends to favor certain kinds of nonreflective con cepts, namely, minimally counterintuitive ones. "Intuitive" is a technical term here, and it can be misleading. On Boyer's view concepts are intuitive to the extent that they conform to the ordinary constraints of folk physics, biology, and psychology—in the language of the previous section, to the algorithms that constrain the nonreflective processing of physical objects, living objects, and objects to which we assign men tal states ("theory of mind"). Concepts are counterintuitive when they 6 His insistence that perception is always "perception-as" would seem, how ever, to require refinement in terms of Dretske's (1997) distinction between "thing awareness" and "fact-awareness." In Dretske's example one can be thing-aware of an armadillo and not perceive it as an armadillo (not be fact-aware that it is an armadillo).</page><page sequence="6">330 GREGORY D. ALLES violate those constraints, and they are minimally counterintuitive when they violate only a limited number of them.7 To the extent that these concepts are nonreflective, they should be distinguished from both the primary perceptions about which Guthrie tends to speak—faces in clouds, on Kool-aide mugs, and in sets of punctuation marks—as well as from the reflective conceptions on which Whitehouse tends to concentrate. For Boyer, nonreflective, minimally counterintuitive con cepts constitute, in the words of the opening quote, a cognitive optimum. If such concepts were not counterintuitive, they would not attract attention and so they would not be passed down. But if they were too counterintuitive, they would be too difficult to retain in memory and so would be lost. Some experimental evidence is consistent with Boyer's analysis. For example, through story tasks Justin Barrett (1998) along with F. C. Keil (Barrett &amp; Keil 1996) has shown that people whose reflective religious concepts are very counterintuitive operate on a nonreflective level with religious concepts that are less so. Scott Atran (2002: 100-107) has shown that lacing narratives with a moderate number of counterintu itive elements contributes to their memorability. But such results hardly establish minimal counterintuitiveness as a cognitive optimum. For example, Barrett only demonstrates a tendency for nonreflective concepts to be less counterintuitive than reflective concepts that are very counterintuitive. To establish minimal counterintuitiveness as the cognitive optimum for nonreflective concepts, he also needs to show a similar trend in the opposite direction: namely, that nonreflective concepts tend to be more counterintuitive than reflective concepts which are thoroughly intuitive. Otherwise, we might just as well establish intuitiveness as the optimum for nonreflective concepts, and explain minimally intu itive concepts in terms of constraints on the mind's ability to reframe maximally counterintuitive reflective concepts. Atran actually intends his work as a moderate critique of Boyer. According to him, the mind/brain does not favor minimally counter intuitive concepts per se. Rather, it favors memories that contain a few 7 To the best of my knowledge, people who speak this way generally work with three vague classes: intuitive, minimally counterintuitive, and maximally counter intuitive. They have not provided any instruments for measuring counterintuitive ness that would allow us to compare actual degrees of counterintuitiveness and so to determine which set of minimally counterintuitive traits approximates the opti mum counterintuitive value, e.g., an invisible supernatural being who hears at great distances or one who does not.</page><page sequence="7">THE COST OF RELIGIOUS CONCEPTS 331 minimally counterintuitive traces. But by itself this contention hardly supports even a soft form of Boyer's position. There are many diffe rent techniques for improving recall, and many of them do not involve counterintuitive concepts. Consider the classic example of the prodi gious memory accomplishments of long-distance runners in the labo ratory, who were able to recall long strings of numbers by schematizing them in terms of running statistics (Chase and Ericcson 1981, 1982; Ericsson, Chase, and Faloon 1980). The memory effects of a modest number of counterintuitive concepts need to be examined in the con text of all devices that improve human memory. Only if one can demon strate, first, that counterintuitiveness defines a distinct class of memory aid rather than a particular instance of more general means for assist ing memory, and second, that counterintuitiveness is more effective than most if not all other memory aids, do we begin to approach the estab lishment of minimal counterintuitiveness as a cognitive optimum for remembered, nonreflective concepts. Along with suggestive but hardly conclusive experimental evidence, however, there are problems with Boyer's notion of a cognitive opti mum. To start with, it seems to be prima facie false. For if it were true, people would not normally ascribe the properties of folk physics, biology, and psychology to the multitude of ordinary objects in their worlds, except when they were consciously reflecting on them. It should then be quite normal to see people nonreflectively attempting to walk through walls or fly through the air without mechanical assistance, to say nothing about the dangers of encountering nonreflective drivers on the road. It is true that both nonreflective and reflective processing may ascribe properties to objects either by mistake or through hyperactiv ity (cf. Barrett 2000), as when my dog mistakes blowing leaves for squir rels or when I say my car has a mind of its own. But taken in the context of the continuous mental processing of the world, these would seem to be relatively rare and exceptional cases. We readily correct them or identify them as metaphorical, and once that correction or identification is made, it takes little or no mental energy to maintain those positions. By contrast, if minimal counterintuitiveness were actu ally the cognitive optimum, it should take a great deal of mental effort to do so. Indeed, implicit in the very notions of folk physics, biology, and psychology is the assumption that intuitiveness defines the cognitive optimum, that it is the ordinary result of nonreflective mental processing and that the ascription of counterintuitive properties is somehow excep tional. Otherwise we would not be able to talk about minimal coun terintuitive properties as violating folk constraints.</page><page sequence="8">332 GREGORY D. ALLES Initial impressions may, of course, be mistaken, but in this case I think that prima facie hesitations point to real problems. Consider Boyer's (1994: 121) claim, quoted above, that if concepts were not counterin tuitive, "they would not be the object of any attention." In Naturalness he simply cites as evidence the way in which religious concepts attract attention among anthropological subjects (1994: 51, 53). Elsewhere (Boyer 2001: 109-111), he notes the way in which infants' eyes are drawn to objects on a display screen that seem to violate the princi ples of folk physics (also implicit in 1994: 105). But to deduce from such evidence the broader claim that concepts that are not counterin tuitive would not attract attention is to commit a logical error. It is one thing to say that counterintuitive traits attract attention; it is quite another to say that in the absence of counterintuitive traits objects or concepts would not attract any attention. That second claim—Boyer's claim—is just wrong, if not to say bizarre.8 8 One might argue that the claim I have quoted is simply an incautious state ment, and that on a more charitable reading Boyer simply wants to argue that religious concepts are by definition counterintuitive, and because they are coun terintuitive they attract attention and therefore survive. But apart from making Boyer's statement "If religious concepts were not counterintuitive" empty (because there could be no religious concepts that were not counterintuitive), this reading does not change the argument. One still needs to show that minimally counterin tuitive concepts occupy an optimal point in cognition. In other words, one still needs to show (a) that counterintuitiveness has some sort of competitive advantage among all the other characteristics that make concepts attractive, and (b) that hav ing attracted attention, minimally counterintuitive concepts survive and are trans mitted at a much higher rate than other concepts. Note that if the issue concerns the acquisition, retention, and transmission of concepts strictly speaking, experiments which show that stories with minimally coun terintuitive concepts are more easily recalled than stories without them do not demonstrate that counterintuitive concepts constitute a cognitive optimum. It may be the case that one will remember a story about a being with a lion's body and a woman's head and that poses questions (a sphinx) better than a story about a lion or about a woman. That does not mean, however, that it is easier to remem ber the concept sphinx than the concept lion or woman, that one will in fact pre fer to use the concept sphinx instead of the concept lion or woman, or that one will attribute greater truth value to the concept sphinx than to the concepts lion and woman. The same applies, mutatis mutandis, to the concept of a being with a human body, gigantic wings, and a blindingly bright appearance (an angel) in com parison with a person or a bird. Presumably, in most cases people will prefer to activate the concepts lion, woman, person, and bird rather than the concepts sphinx or angel, and they will have no particular difficulty in doing so, despite the fact that these concepts are not counterintuitive. I do recognize that there are in fact sub-optimal cognitively preferred positions from which the brain finds it extremely difficult to depart, even when reflective processing demonstrates convincingly that these positions are not in fact correct. But counterintuitive concepts, such as a car with a mind of its own (Chitty Chitty</page><page sequence="9">THE COST OF RELIGIOUS CONCEPTS 333 For example, the eyes of air-traffic controllers are drawn to unidentified aircraft on their display screens, but that is hardly because these marks are counterintuitive. Consider, too, the cocktail-party scenario that is often used to demonstrate the presence of background mental process ing. You are engaged in a conversation at a party. Suddenly you hear your name mentioned in another part of the room, and your attention shifts to the linguistic stream in which your name appeared. Your name clearly attracts attention; indeed, it may attract so much attention that you need to ask your conversation partner to repeat what she has just said. But that is hardly because your name contradicts intuitive assump tions. There seems litde point in multiplying examples. It seems that one important function of reflective processing is to deal with cognitive problems, and that one source of such problems is the appearance of unexpected, counterintuitive traits. But such traits are only one of many possible features that might attract attention. As a result, the ability of counterintuitive concepts to attract attention is hardly sufficient to sit uate them at a cognitive optimum. The fit between counterintuitive - ness and attracting attention is not specific enough. But that is not the only problem. The suggestion that concepts sur vive simply because they attract attention is too simple. I am hardly in a position to give an authoritative account of the processes by which concepts attract attention and survive, but I must give some sugges tions in order to clarify what I mean. I expect that others could phrase my suggestions better. To make those suggestions, I want to borrow terms—perhaps loosely— from a cognitive architecture known as ACT-R, the latest version in a series of symbolist models of cognition—now with subsymbolic and neu rophysiological components—that John Anderson began to develop in the 1970s (http://act-r.psy.cmu.edu/publications, among many others, cf. Anderson 1976, 1982, Anderson et al. 2004; "perhaps loosely," because I do not claim to be proficient in this type of analysis). Fundamental to the ACT series of models is a distinction between two types of content, "chunks" or facts and procedures, stored in two types Bang Bang), are not very good examples of such cognitive positions. Very much better, it seems to me, are some experiments done to show that human beings do not always favor decisions made in accordance with the dictates of rational choice. These experiments have shown that even scholars who insist that people do make decisions in accordance with the dictates of rational choice nevertheless strongly tend, in certain circumstances, to violate those dictates. Of course, when that is pointed out to them, they want to go back and correct their errors, but the errors will tend to recur (Thaler, 137-138).</page><page sequence="10">334 GREGORY D. ALLES of memory, declarative and procedural. More recent versions also provide for perceptual input, or better, perceptual uptake. In the context of problem-solving—which, following Allen Newell (1980), Anderson (1982: 372) takes to be "a fundamental category of cogni tion"—but in other contexts as well—perceptual processes feed data into various buffers, which determine what data to pass on. In other words, the buffers transform some input into uptake. Roughly simulta neously, other buffers retrieve chunks or what we might call concepts from memory. Which chunks they retrieve—in our language, which concepts attract attention—depends upon the activation levels of the various concepts.9 Here is where Boyer's claims enter the picture. The way cognitive theorists of religion usually talk about costliness, it would seem that counterintuitiveness would in fact decrease a con cept's activation level. That is because an increase in cost decreases the probability of activation, and counterintuitiveness, even minimal coun terintuitiveness, is generally seen as more costly than intuitiveness. But for the sake of argument, let us grant that it actually increases the probability that the retrieval buffer will call a concept. That is simply another way of saying that a concept which is counterintuitive attracts greater attention. This concession would require us to add a "coun terintuitiveness coefficient" to the standard formula for the activation weights of what we are here calling concepts. Furthermore, in keeping with the theory that minimal counterintuitiveness defines the cognitive optimum, this coefficient should not be a constant but an upside-down U-shaped function of counterintuitiveness, whose apex occurs at the point of minimal counterintuitiveness.10 True, this would be a significant modification of the theory, but we might justify making it by pointing out that those who employ ACT-R have limited their attention to intu itive concepts, so that they have had no cause to take counterintu itiveness into account. What is the result of all this? Have we produced a model in which minimal counterintuitiveness defines the cognitive optimum? Not at all. 9 B(t) = logoff - tj)'d (Taatgen and Anderson 2002: 130). 10 As an alternative, one might suggest that this shape is unnecessary, because maximally counterintuitive concepts are unable to be stored in memory and so incapable of being recalled. (I suspect, in fact, that the kinds of inabilities to for mulate concepts that Boyer explores under the heading "maximally counterintu itive" have somehow to do with structural instabilities of neural, i.e., connectionist, networks, although I am in no position to offer an account of how this is the case.) Even if we adopted that alternative, however, the result of the critique would be the same.</page><page sequence="11">THE COST OF RELIGIOUS CONCEPTS 335 I take it that empirical research has demonstrated fairly convincingly that activation levels correlate with the frequency with which a con cept has been called as well as with the nearness in time in which it has been called. This makes intuitive sense. We find it easier to recall concepts that we use frequently or have encountered in the recent past, but more challenging to recall concepts that we encounter infrequently or have last encountered in the distant past. For example, in reading about ACT-R, I experienced a sudden urge to call my daughter for a quick refresher course in logarithms; the last time I can remember hav ing thought about them was an introductory calculus class that I took in 1974—thirty-one years ago. Furthermore, the frequency with which we use a concept depends in turn upon the successful application of that concept, since successful applications are themselves written into declarative memory and so increase a concept's activation weight." What all this implies is quite straightforward: the magnitude of any counterintuitiveness coefficient would have to be tremendous if it were to override the strength of repeated successful application. This seems unlikely, however, because theories of learning have done very well without considering counterintuitiveness at all. Now, as a matter of theoretical interest it is possible to develop any number of models of cognitive activity. I think it would be quite inter esting to write a computer simulation of cognitive activity in which minimal counterintuitiveness defined the cognitive optimum and set it running. It would be particularly interesting if that simulation included instructions to guide the movement of a robot through space. Writing such a simulation is, unfortunately, quite beyond my current abilities, although I would certainly be willing to collaborate in such an endeavor. In any case, I would be very interested in the results. Naturally, I am willing to be convinced by evidence to the contrary, but I think that the results of such a simulation would diverge significantly—saliently?— from the statements and behavior that we actually observe in human beings. In any case, the upshot of this discussion is that concepts do not survive because they attract attention. If they attract attention, the mind attempts to use them. If it uses them successfully and repeatedly, they survive in memory. All this is prior to their successful transmission. If my criticism is right, why does it sound so convincing to scholars of religious studies to say that minimal counterintuitiveness defines a 11 As my logarithm example shows, other factors besides successful usage deter mine the frequency with which we use concepts. Studying languages, I had very little use for mathematics, including logarithms.</page><page sequence="12">336 GREGORY D. ALLES cognitive optimum? The reason, I think, is that these scholars have concentrated on religious concepts, without thinking about what the implications would be for human cognitive activity more generally. (This was not, of course, Boyer's intention.) In other words, they have embraced a special theory of religious concepts. This, however, is like saying that the counterintuitiveness effect only occurs in the case of religious con cepts that happen to be successful. It simply begs the question. What we need is not a special theory of religious concepts. It is a general theory of how human beings come to use the concepts that they do, and one that has as one of its results the consequence that, with vary ing probabilities, human beings use religious concepts. Simply making minimal counterintuitiveness a cognitive optimum will not do. 4. The Cost of Religious Concepts I have no intention of trying to develop such a general theory in what remains of this essay. Instead, I want to reflect on the cost of religious concepts as an entree into formulating what such a model might look like. As already noted, those who have contributed to the cognitive scientific study of religion differ considerably on the cost of religious concepts. For Pascal Boyer the cost of religious concepts is moderate. Cognitive costliness makes concepts attractive, but it also makes them more difficult to remember. As a result, the cognitive optimum is moderately costly concepts, that is, minimally counterintuitive ones. Harvey Whitehouse concedes that minimal counterintuitiveness defines the cognitive optimum, but he insists, as does Illka Pyysiâinen (2001), that most religious concepts are rather more costly. That is why the transmission of reli gious views requires an elaborate mnemonic apparatus, based in either episodic or semantic memory (but apparently not in the interaction of both). At the other extreme stands Stewart Guthrie, somewhat over looked in recent years. Guthrie suggests that religious concepts prevail because they are in fact the least costly. To use his compelling image: when walking in the woods, it is better to mistake a rock for a bear than vice versa. In other words, it is less costly to postulate animal and human agency where none exists than to overlook cases where such agency does exist. Furthermore, Guthrie insists that many features which others identify as counterintuitive are in fact quite intuitive. People encounter—at least, early people who were prey as well as predator routinely encountered—so-called violations of folk physics such as</page><page sequence="13">THE COST OF RELIGIOUS CONCEPTS 337 invisibility, movement through an apparently impenetrable mass, and the defiance of gravity. They encountered them in the forms of camouflage, a predatory strike from a tangled mass of brush, and a leaping or aerial attack. The first point to make about a model that takes the cost of reli gious concepts seriously is one that is implicit in both Boyer's and Whitehouse's accounts but that should be made explicit and the subject of analysis. The mind/brain is no cheapskate. That is, it is not possible to determine the fate of concepts simply by determining which concept costs least. Mental processing does not always prefer the least costly concepts. That should be apparent to anyone who has participated in a rigorous higher education. The concepts of organic chemistry—nomen clature, reactions, and so on—are not the easiest concepts in the world to learn, but people still learn and teach them, at least some people do. So if we are to take the notion of cost seriously, we should set it in the context where it properly belongs, one in which costs and gains are compared. In other words, we might think of mental processing as seeking to maximize conceptual profit. The most basic formula in this regard is simply arithmetical: profit equals gain minus cost. This for mula may seem better suited to economic than to cognitive activity, but there is some precedent for applying it to the latter, too. For exam ple, it provides the basis for the formula in the ACT-R cognitive archi tecture that defines which "production rules" the mind will attempt to implement. In AGT-R the choice of production rule is determined by expected outcome, which consists of the product of the expected gain times the estimated probability that the application of the rule will prove successful, minus the estimated cost of implementing the pro duction rule.12 To the extent that this model is correct, the mind/brain will not simply prefer concepts that have a specific cost, such as min imally counterintuitive ones. Nor will it prefer concepts that maximize revenue, that is, total conceptual benefit. Rather, it will prefer concepts that seem to have the best chance of maximizing conceptual profit. So perhaps the disagreement over the cost of religious concepts has a very real basis: we cannot model correlate the production, retention, and transmission of religious concepts according to their with a specific range of costs, whether moderate or maximal, because these properties may remain relatively constant while the costs of such concepts vary. Expected outcome = PP G - CP + noise (Taatgen and Anderson 2002: 130).</page><page sequence="14">338 GREGORY D. ALLES A second point recapitulates the conclusion of the previous section, but it is worth restating: a model based upon maximizing conceptual profit should not be a special model of religious concepts but a model of human cognitive activity in general that accounts for the existence of religious concepts, however we decide to define those concepts. At the moment I am willing to grant that counterintuitiveness is a dis tinctive feature of at least an important class of such concepts, although I am also inclined to side with Whitehouse and Pyysiàinen in the claim that many religious concepts are not minimally counterintuitive but rather dramatically violate the algorithms of folk physics, biology, and psychology. Be that as it may, the model needs to explain why the mind/brain finds it profitable to employ concepts with varying degrees of counterintuitiveness in some cases but not others. Third, the model should be probabilistic, because the degree to which people maintain religious concepts varies. A model that predicts that in certain circumstances the mind/brain either will or will not adopt religious concepts simply will not do. Instead, it should predict the like lihood that the mind/brain will employ certain concepts, such as min imally counterintuitive ones. Note, too, that probability factors need to extend over a rather large range. Ideally, the model needs to account for the differing degrees (a) to which the same individual uses religious concepts, (b) to which people in the same culture use religious con cepts, and (c) to which different cultures around the world rely upon religious concepts. It should go without saying that these probabilities should be specific and testable. That is a very tall order. Fourth, the model should take into account that reflective processing has the capacity to perform more labor-intensive, slower conceptual tasks than non-reflective processing. As a result, reflective processing is capable of diverging from the algorithms that direct non-reflective pro cessing to a greater degree. To put it in the terms ordinarily used in these discussions, it should yield the result that reflective concepts are capable of being more counterintuitive than non-reflective ones.13 There are probably a number of ways to achieve this result. One is—in terms of ACT-R—to look at the "wiring" of the buffers that are responsible for bringing uptake, concepts, and procedures to reflective processing and see whether there are by-pass routes that directly connect different 13 This holds for non-religious concepts as well. My father, an aerospace engi neer, could explain in detail the structural integrity of airplanes. Nevertheless, he once shared with me that sitting in an airplane and watching the wing flop up and down going down the runway, he was still amazed that it did not break.</page><page sequence="15">THE COST OF RELIGIOUS CONCEPTS 339 modules without going through the buffers (conceded in Anderson et al. 2004: 1057). Another is to analyze connectionist networks at the sub symbolic level to see whether it makes sense to postulate varying con nection weights for reflective and non-reflective processing. A third might be to suggest that reflective processing has greater access to mem ory of specific items, while non-reflective processing depends to a much greater degree on regularization rules. I readily concede that these sug gestions are simply wild guesses on my part. I give them to illustrate what I mean, not to indicate directions for research. Fifth, in calculating gains and losses the model needs to take into account more than formal properties of concepts such as counterintu itiveness. It also needs to take into account, for example, people's expe riences of the world (sensory input and uptake), the actions they attempt to perform, and the consequences of those actions, as well as the acti vation costs associated with the frequency or remoteness of a concept's retrieval. This point needs a little explaining. Following an epidemiological approach to conceptual transmission, Boyer makes the survival of concepts dependent upon formal properties which increase the likelihood of their transmission. Even within the bounds of a conceptual epidemiology, this is not sufficient, for epi demiology teaches us about microbes that transmit so successfully and rapidly but with such devastating consequences for their hosts that their spread is very limited. That is a good thing, too. Otherwise, outbreaks of diseases like Ebola and the Marburg virus would not be contained but extremely widespread. So even granting an epidemiological per spective, it seems impossible, in assessing the cost of concepts, not to take into account the consequences of their operation upon their hosts. Take, for example, a group of human beings who suddenly acquired the conviction that, whenever they encountered a precipitous drop, they could fly. If they proceeded immediately to act upon that conviction, they would not be likely to last very long nor to transmit that concept to many other people. The simple fact that such a conviction is min imally counterintuitive would seem to be somewhat beside the point. What would be more salient would be the number of precipitous drops that they encountered in a day. They have the best chance for surviving and transmitting their conviction if they live in a land without precip itous drops. (In terms of studying the epidemiology of concepts and their consequences, the conviction that one is immune to bullets fired in battle is a more interesting case, partly because the result of injury or death is not certain, and partly because there is some empirical data about people who have held just such a conviction.)</page><page sequence="16">340 GREGORY D. ALLES I have, however, serious doubts about whether an epidemiological approach to conceptual transmission is entirely satisfactory. Concepts are not computer viruses. Unlike genes and viruses, virtual or real, they do not simply replicate on their own. Nor do they remain invariantly resident in memory until they are passed on to the next person, a process that may involve a time lag of as much as a generation or more. It may be that, once acquired, concepts never entirely disappear, but their strength certainly decays predictably if it is not reinforced. Several factors contribute to this reinforcement, but self-replication on the part of the concept is not one of them. Rather, the strength of a concept—I am thinking of activation weights here—increases every time a person retrieves the concept in an attempt to perform a cognitive or behavioral task. It increases even more if the retrieval of the concept results in the successful completion of the task. It also increases as the result of explicit instruction and correction from other people. More interestingly, it increases when it conforms to observation even in the absence of instruction and correction. (I have in mind observations of how other people use words [Taatgen and Anderson 2002].) It may actually be the case that the interaction of these factors yields certain formal properties. For example, in an article that I have mined primarily for its concise statement of equations, Niels Taatgen and John Anderson (2002) argue that the distinction between irregular and reg ular verbs in English and similar distinctions in other languages, as well as the developmental trajectory by which children learn to use them, reflects the operation of the mind as it attempts to retrieve words in accordance with procedural rules. That leads me to wonder—speculatively, of course—whether "God" is not rather like an irregular verb. (The analogy is very loose). Consider the question that Justin Barrett, Rebekah Richert, and Amanda Driesenga (2001) explore: What kinds of knowledge do chil dren believe different beings possess? We might construct the following scenario. Children learn various words—"cat," "mother," "God"—and learn to associate the property "knowledge" with these words. (Use a connectionist model for this.) At first they store these words as indi vidual chunks in declarative memory. But in time and with experience they learn a rule: IF the question concerns knowledge AND if animal or person THEN knowledge. The class "animal or person" includes the elements (cat, mother, God}, but it also permits extrapolation of the rule to new elements. Through further observation and interaction, however, the child becomes aware of various exceptions to this rule: cat does not know X, mother does not know Y. At first it stores these</page><page sequence="17">THE COST OF RELIGIOUS CONCEPTS 341 exceptions as individual memory chunks but later, in accordance with set procedures, it also learns a rule that regularizes them. {God}, how ever, is something of an odd fish. Although the word "God" is useful for performing several cognitive operations, the child never has occasion to observe anything specific about God's knowledge. So the child remains uncertain whether God's knowledge has limits or not. It may be tempted to apply the regularization rule, but with time it also observes that its uncertainty is shared by the broader speech community. So it continues to store the chunk "God" in declarative memory with the property "knowledge pimits unknown]," and eventually it calls this chunk con sistently, rather than a regularization rule (algorithm), when it is con sciously attending to questions of God's knowledge (perhaps not, however, during nonreflective processing). The result is that, similar to what one finds for learning irregular verbs, the graphs for "learning" about God's knowledge in Barrett, Richert, and Driesenga (2001) display a U-shaped curve. Understand that I am not claiming that this scenario is correct, although at the moment I rather like it. I rehearse it simply to illus trate how the concept "God" with the counterintuitive property "knowl edge pimits unknown]" could arise as an artefact of the complex processes by which the mind processes data, rather than as a result of the mind's preference for specific kinds of concepts, namely, minimally counterin tuitive ones.14 As a result, our model needs to take into account more factors than simply the formal nature of counterintuitive concepts. 5. Costs and Gains I have suggested that a model of religious concepts should meet five requirements: 1. It should make success and failure of concepts a function of the mind's attempt to maximize conceptual profit. 2. It should apply to all concepts, not just religious concepts. 3. It should be probabilistic. 4. It should account for the way religious concepts—and others— vary with nonreflective and reflective processing, such as more or less counterintuitiveness. 14 A "harder" argument would of course point out that, unlike the model which makes the mind prefer minimally counterintuitive concepts, this model can account for the U-shape of the learning curve.</page><page sequence="18">342 GREGORY D. ALLES 5. It should not depend solely upon the formal properties of con cepts, such as counterintuitiveness, to explain their retention and transmission. Scholars of religious studies are accustomed to eye-balling data in the held and then developing theories to account for what they observe. In dealing with the costs and gains of religious concepts, they may need to abandon that procedure. Specifically, they may need to postpone making applications to real-world data. That is because the correlations that need examination are ones that require computer simulation and testing in a laboratory under controlled cir cumstances. Indeed, we need to acknowledge the serious possibility that it may never be feasible on these bases to formulate full, specihc explanations for religious concepts as we hnd them in the held, for the simple reason that it may not be possible to determine such things as activation weights and the full contents of conceptual stores outside a laboratory setting. That does not mean that these factors do not operate in the real world. It just means that our knowledge is not hne-grained enough that we can make detailed analyses and predictions about real-world situations on the basis of the processes that we know are operative. If that prospect seems unsatisfactory, perhaps the dissatisfaction indicates that scholars of religious studies really want to study religions in other ways and should move on. However that may be, I am in no position actually to formulate a model that meets the requirements that I outlined in the previous sec tion. An initial stab at an equation might produce something like this: Ur = Wr(G[ + Ge) - (Cj + Ce)r where R is the concept ("representation") under consideration, U is the conceptual profit ("utility"), G is the gain, C is the estimated cost, and W is a weighting coefficient which reflects the estimated probability of success in achieving G. I ("internal") and Ε ("external") are simply reminders that costs and gains cannot be computed in terms of coun terintuitiveness alone. I would fully expect that any actual model would replace them with a more detailed and accurate accounting of gains and costs. The actual choice of a concept Rx might then be defined— inadequately by the equation: Ρ r«x = η l y-1 J</page><page sequence="19">THE COST OF RELIGIOUS CONCEPTS 343 where P is probability and n the number of potentially active concepts stored in memory. At least this equation might work well enough for probabilities that approximate 0.5 (50 %). Studies (e.g., Kahneman and Twersky 2000) show that in economic decision-making probabilities that approach 0 and 1 tend to "snap" to those values, and that may be the case here, too in economic decision-making have revealed, however, that people's preferences do not always follow precisely the predictions of such mathematical formula (e.g., Kahneman and Tversky 2000). It might be the case that given a choice between a concept R1 with util ity of 99 on some scale and concept R2 with utility 1 on the same scale, the mind will choose R1 more than 99 % of time. But to these equations I want to add some very strong caveats. Anyone who can recall in a rudimentary fashion studying natural sciences in high school, and perhaps even in elementary school, will remember that, while it is possible to multiply, say, feet by pounds (to produce the unit foot-pounds), one can neither add pounds to feet nor subtract them from feet, or vice versa. Quantities to be added and sub tracted need to be quantities of the same unit of measure. So what I have written above is not yet an equation. I have not specified the units in which to measure gains and costs. This is indeed a real prob lem for which I have no solution to offer at the moment. Economists use money as the standard measure of value. That makes it easy, at least until they try to measure certain non-monetary values, such as love or justice, in monetary terms.15 In AGT-R costs are measured in units of time: how long it takes the brain to retrieve and apply a chunk from declarative memory and execute a procedure. It may even be possible simply to sidestep this difficulty altogether: the equation above is an example of a Bayesian equation, and I have been told that in the Bayesian equations used in decision theory units of measure are not an issue. In that any case, if this problem can be solved, two con sequences follow. First, in studying religious concepts we have tended to talk about cost in terms of counterintuitiveness, but an alternative model might require us to measure costs in terms of processing time. Through clever experiments it might be possible to determine whether access time for, say, minimally counterintuitive concepts is any greater than access time for intuitive concepts. I suspect that, for concepts which 15 Deirdre McCloskey (2003) has in fact suggested that such values cannot simply be included in an aggregate value equation (cf. also 2004).</page><page sequence="20">344 GREGORY D. ALLES a person has already learned, there may not be much difference. In that case the cost of religious concepts would not be much different from the cost of other concepts. We may—or may not—need other explanations besides costliness for the kinds of concepts that Boyer refers to as maximally counterintuitive, such as a god who turned into a refrigerator on Tuesdays (see n. 10). Second, we might need a com plex model, if not two separate models altogether. One component would deal with the use of concepts by the mind/brain, another would deal with the impact of concepts on the person's ability not to survive but to transmit them. (For example, a concept that carries with it the instruction that under no circumstances should it ever be communi cated to another being would seem less likely to spread, regardless of its impact on survival—unless, of course, the person holding the con cept found it impossible to follow the instruction.) Even granting that we can make such equations work, all we will have given is two equations. It is true that equations can count as a model in some respects. Think of Newton's famous f = ma or his analy sis of velocity as the first and acceleration as the second derivative of an equation which expresses distance traversed as a function of time. In cognitive science, however, it is customary for equations to assume places inside larger models, such as models inspired by generative lin guistics and computer programming. In the course of revising prepar ing this essay for publication I found myself drawn to the ACT-R model developed by John Anderson and others, but I should be frank about the reasons why. Starting with an interest in economics, I set out to see whether economic models could be helpful in analyzing cognitive processes. I discovered in ACT-R a very developed model which made use of a basic economic formula concerning costs and gains. But ACT R is not the only model for mental processing available. Others include SOAR, 4CAPS, and EPIC, none of which I have explored in detail.16 As I understand it, ACT-R has certain advantages in terms of com bining symbolic modeling with neural network modeling (sub-symbolic 16 SOAR is a cognitive architecture developed from the ideas of Allen Newell (e.g., Newell 1990; Rosenbloom, Laird and Newell 1993; recent bibliography at http://winter.eecs.umich.edu/soarwiki/Soar_Publications). Its basic working princi ple reads, "All decisions are made through the combination of relevant knowledge at run-time. In Soar, every decision is based on the current interpretation of sen sory data, the contents of working memory created by prior problem solving, and any relevant knowledge retrieved from long-term memory. Decisions are never pre compiled into uninterruptible sequences" (http://sitemaker.umich.edu/soar). 4CAPS, short for Cortical Capacity-Constrained Collaborative Activation-based Production</page><page sequence="21">THE COST OF RELIGIOUS CONCEPTS 345 processing). But in the absence of agreement about cognitive modeling among people who do that sort of modeling for a living, it would be very rash for someone like me to settle on ACT-R for impressionistic reasons. A final caveat concerns what I have here been calling concepts. Is this in fact the right term to use? It may turn out that, at the level of cognidve analysis, "concept" is really not a natural-kind thing in terms of which we should develop our analyses. Let me invoke ACT-R one last time to illustrate what I mean. As already mentioned, this architecture makes a fundamental distinction between "chunks" stored in declara tive memory and procedures stored in procedural memory. It then rec ognizes the achievements of connectionist modeling by "deconstructing" (not in a Derridean sense) chunks into neural networks. What we call a concept would seem to resemble a chunk more than a procedure. Indeed, those familiar with ACT-R should already have objected to the equations above because they most resemble the equations in ACT R that apply to retrieving procedures from procedural memory, not chunks from declarative memory.17 So prima facie there are serious problems—and I agree. But the point I want to make here is that, in addition to that problem with equations, we need to decide what we mean by the term "religious concept" (for an older discussion, see Anderson 1981). Into what cognitive language—and how—should we translate it? I do not mean to underestimate the costs involved in pursuing the path that my five requirements identify. It may be that many people simply take a less arduous path and leave it at that. But if we want to pursue cognitive models of religions, this path strikes me as having a couple of broad advantages over the notion that religious concepts reside at a "cognitive optimum," and to my mind these advantages outweigh the costs. For one thing, this path recognizes that the claims associated with religions, while not exactly abnormal, are not exactly cognitively Systems, is an attempt to model, on the basis of evidence provided by 1MRI tech niques, the relationship between brain activation and cognitive processes (see http://coglab.psy.cmu.edu/project_10modeling4CAPS.htm). EPIC (Executive Process/Interactive Control) is an attempt to develop a model of "human infor mation processing that accurately accounts for the detailed timing of human perceptual, cognitive, and motor activity" (http://www.eecs.umich.edu/~kieras/epic. html; Meyer and Kieras 1997; bibliographies at http://www.eecs.umich. edu/~kieras/epic.html and http://www.umich.edu/~bcalab/documents/index.html). 17 Pi = ! (Anderson et al. 2004: 1042). 1 + e-(Ai-t)/M</page><page sequence="22">346 GREGORY D. ALLES optimal in the ordinary sense of the word, either. There is too much disagreement about religion for that to be the case. Indeed, to suggest that religion occupies a cognitive optimum may be a latent—or not so latent (cf. Barrett 2004)—form of religious apologetics. At the same time, the cognitive-optimum model seems to commit us to a Tylorean model of what religion is.18 I certainly have no objection to people adopting this model for their research, but I also do not think that reli gion is one of those things for which we can have one right definition, (Smith 1998: 281) nor do I think "religious concept" is a natural-kind term. For that reason, a general model that explains the existence of religious concepts conceived in a Tylorean fashion but that also explains the existence of religious concepts conceived in other fashions strikes me as preferable. To develop such a model we need to abandon the notion that minimal counterintuitiveness defines a cognitive optimum and strive instead to understand religious concepts in the context of a more general model of human conceptualization. McDaniel College Westminster, MD 21157 U.S.A. Addendum, August 2006 (A) In the time since I drafted this article, my colleague in philosophy, Peter Bradley, has taught me to frame the problem of the cognitive optimum in the language of prepositional attitudes. Briefly, concepts as they are used by the mind involve at least two aspects: conceptual con tent and attitudes. It is sufficient here to say that conceptual content refers to the meaning of concepts. Attitudes express standpoints which minds take with respect to concepts. For example, consider the con cept [God] or rather the more specific concept [God exists]. As the following list illustrates, the conceptual content [God exists] can be asso ciated with a variety of attitudes: 18 Tylorean models define religion in terms of souls, gods, spirits, and the like. The most popular neo-Tylorean definition of religion is that of Melford Spiro: reli gion is "an institution consisting of culturally patterned interaction with culturally postulated superhuman beings" (Spiro 1966: 96). The over-arching success of the ory of mind in elucidating religious concepts largely results from making this Tylorean move. If religion were defined differently, theory of mind would not be so successful at all.</page><page sequence="23">THE COST OF RELIGIOUS CONCEPTS 347 I believe I doubt I hope I deny ^ that [God exists] I know I suspect One problem with the theory of the cognitive optimum is that it operates with an impoverished model of concepts: it ignores attitudes and focuses entirely on conceptual content, specifically, what makes conceptual content memorable. But as the so-called Mickey Mouse problem illustrates, religion also involves the adoption of certain atti tudes, and in this it is hardly unique. Most other uses of concepts do, too. To date, however, the cognitive study of religion has theorized attitudes insufficiently; it is perhaps more accurate to say that it has hardly theorized them at all. Just what makes human minds adopt specific attitudes remains, so far as I know, an open question, but at the very least it would seem to require more than memorability to explain the adoption of the attitude "I believe" with regard to the con cept [God exists]. Including attitudes in the discussion would compli cate the ACT-R analysis of calling procedures and weights that the body of my text discusses, but it is not incompatible with it. As a professional philosopher who concentrates on cognitive science, Bradley can formulate these ideas much more precisely than I, and with much greater knowledge of the literature on propositional atti tudes as well as the pitfalls connected with them. I have urged him to do so in print. If he does, he will of course deserve full credit for the position. I deserve whatever opprobrium comes from invoking it pre maturely. (B) It might also be possible to extend the parenthetical suggestion made in footnote 10 to a higher level than the sub-symbolic by suggesting that the cognitive-optimum theory makes a mistake in theorizing con cepts when it appeals to scalar degree of counterintuitivity, for example, in the terms "minimally counterintuitive" and "maximally counterintu itive" and the arguments over whether religious concepts are the former or the latter. The examples of maximally counterintuitive concepts that Boyer (2001) gives would seem to be specific examples of a more general memory effect, namely, the effects of conceptual coherence on the reten tion of concepts. Conceptual coherence is a major theme of the "theory theory" of concepts.</page><page sequence="24">348 GREGORY D. ALLES To put it briefly, the mind easily retains concepts which are coher ent; it retains only with difficulty concepts which are incoherent. (Perhaps the reasons for that memory effect, along with what makes for coherence and incoherence, may be sought in the structural characteristics of sub symbolic networks.) To be sure, without a developed view of what causes coherence, "coherent" and "incoherent" may seem like nothing more than synonyms for "easily memorable" and "memorable with difficulty," the effects that need explanation. But changing the terms does have one advantage: it allows us to raise the question of whether the effects that Boyer associates with maximal counterintuitiveness, namely, difficulty of retention, are properly identified. For example, in a seminal study advancing the theory theory of con cepts, Murphy and Medin write, in a manner reminiscent of Boyer's maximally counterintuitive categories, "a category consisting of striped things that have more than one leg, and that weigh between 11 and 240 kg... does not seem sensible or cohesive" (431). That category may not be cohesive (sc. coherent), but so far as I can see, there is nothing counterintuitive about it. Indeed, it is not even empty. I am no biologist, but I suspect that it includes baby zebras along with rather large striped chairs and sofas. Given a little friendly tweaking of the upper weight limit, say to 500 kg., it would even include all adult zebras as well as perhaps oddly painted concert grand pianos. That leads me to wonder whether it might be possible to define reli gious concepts etically as "empty concepts [that] are fully coherent" (ibid.) and toward which people adopt certain attitudes. I recognize, however, that counterintuitiveness probably provides a less contentious basis for defining religious concepts than "fully coherent empty con cepts." So for now I will only contend that rather than trying to iden tify some optimal level of counterintuitiveness in religious concepts, it might make more sense to say that concepts are religious just in case they are fully coherent, exhibit counterintuitive features, and are the object of certain as yet unidentified and understudied attitudes. To this I should add two qualifications. First, this definition is clumsy. It may be unnecessary to specify that religious concepts be coherent, for that requirement only selects which concepts are likely to survive long enough that we want to classify them. Second, if science ever manages to demonstrate regularities that are counterintuitive, that is, that violate the presumptions of folk physics, biology, and psychology— and I see no reason in principle why it could not—then the definition above creates problems for demarcating science from religion. That</page><page sequence="25">THE COST OF RELIGIOUS CONCEPTS 349 difficulty may well require us to turn to take religious concepts as some thing like "fully coherent empty concepts." References Anderson, John R. (1976). Language, Memory, and Thought. Hillsdale, N.J.: Lawrence Erlbaum Associates. — (1981). Concepts, propositions, and schemata: What are the cognitive units?" In J. Flowers (ed.), Nebraska Symposium on Motivation, 121-162. Lincoln, Nebraska: University of Nebraska Press. — (1982). Acquisition of cognitive skill. Psychological Review 89, no. 4: 369-406. Anderson, John R., et al. (2004). An integrated theory of the mind. Psychological Review 111, no. 4 (October): 1036-1060. Armstrong, D. M. (1980). The Nature of Mind, and Other Essays. St. Lucia, Queensland: University of Queensland Press. — (1997). What is consciousness? In Ned Block, Owen Flanagan &amp; Giiven Giizeldere (eds.), The Nature of Consciousness: Philosophical Debates, 721-728. Cambridge, Mass.: MIT Press. Atran, Scott (2002). In Gods We Trust: The Evolutionary Landscape of Religion. Oxford: Oxford University Press. Barrett, Justin L. (1998). Cognitive constraints on Hindu concepts of the divine. Journal for the Scientific Study of Religion "il, no. 4: 608-619. — (2000). Exploring the natural foundations of religion. Trends in Cognitive Sciences 4: 29-34. — (2004). Why Would Anyone Believe in God? Walnut Creek, Calif.: AltaMira Press. Barrett, Justin L. &amp; F., C. Keil (1996). Anthropomorphism and god concepts: Conceptualizing a non-natural entity. Cognitive Psychology 31: 219-247. Barrett, Justin L., Rebekah A. Richert &amp; Amanda Driesenga (2001). God's beliefs versus mother's: The development of nonhuman agent concepts. Child Development 72, no. 1 (January/February): 50-65. Block, Ned (1980). Troubles with functionalism. In Ned Block (ed.), Readings in Philosophy of Psychology, 1: 267-305. Cambridge, Mass.: Harvard University Press. — (1997). Inverted earth." In Ned Block, Owen Flanagan &amp; Giiven Giizeldere (eds.), The Nature of Consciousness: Philosophical Debates, 677-693. Cambridge, Mass.: MIT Press. Boyer, Pascal (1994). The Naturalness of Religious Ideas: A Cognitive Theory of Religion. Berkeley: University of California Press. — (2001). Religion Explained: The Evolutionary Origin of Religious Thought. New York: Basic Books. Chase, W. G. &amp; K. Anders Ericsson (1981). Skilled memory. In: J. R. Anderson (ed.), Cognitive Skills and Their Acquisition, 141-189. Hillsdale: Lawrence Erlbaum Associates. — (1982). Skill and working memory. In G. H. Bower (ed.), The Psychology of Learning and Motivation, 16: 1-58. New York: Academic Press. Crick, Francis, and Christof Koch (2003). A Framework for Consciousness Nature Neuroscience 6, no. 2 (February): 119-126. Dretske, Fred (1997). Conscious experience. In Ned Block, Owen Flanagan, &amp; Giiven Giizeldere (eds.), The Nature of Consciousness: Philosophical Debates, 773 788. Cambridge, Mass.: MIT Press. Ericsson, K. Anders, William G. Chase &amp; Steve Faloon (1980). Acquisition of a memory skill. Science 208, no. 4448 (June): 1181-1182.</page><page sequence="26">350 GREGORY D. ALLES Fodor, Jerry A. (1983). Modularity of Mind: An Essay on Faculty Psychology. Cambridge, Mass.: MIT Press. Guthrie, Stewart E. (1993). Faces in the Clouds: A Mew Theory of Religion. New York: Oxford University Press. Kahneman, Daniel, and Amos Tversky (ed.) (2000). Choices, Values, and Frames. Cambridge: Cambridge University Press. Lycan, William G. (1997). Consciousness as internal monitoring. In Ned Block, Owen Flanagan, &amp; Güven Güzeldere (eds.), The Mature of Consciousness : Philosophical Debates, 755-771. Cambridge, Mass.: MIT Press. McCloskey, Deirdre (2003). Bourgeois virtue: The pagan and theological virtues. Keynote Address, Religion, Economics, and Culture Sessions, Society of the Scientific Study of Religion, Norfolk, Virginia, October 25. — (2004). Dear Prudence, you're overrated. Times Higher Education Supplement 1622 (January 9): 26. Meyer, D. E., and D. E. Kieras (1997). A Computational Theory of Executive Control Processes and Human Multiple-Task Performance. Part 1. Basic Mechanisms. Part 2. Accounts of Psychological Refractory-Period Phenomena. Psychological Review 104: 3-65, 749-791. Murphy, Gregory L., &amp; Douglas L. Medin (1999). The Role of Theories in Conceptual Coherence. In Eric Margolis and Stephen Laurence (eds.), Concepts: Core Readings, 425-458. Cambridge, Mass.: MIT Press. Newell, Allen (1980). Reasoning, problem solving, and decision processes: The prob lem space as a fundamental category." In Raymond S. Nickerson (ed.), Attention and Peformance VIII. Hillsdale: Lawrence Erlbaum Associates. — (1990). Unified Theories of Cognition. Cambridge, Mass.: Harvard University Press. Putnam, Hillary (1980). The nature of mental states. In Ned Block (ed.), Readings in Philosophy of Psychology, 1: 223-231. Cambridge, Mass.: Harvard University Press. Pyysiâinen, Ilkka (2001). How Religion Works: Towards a Mew Cognitive Science of Religion. Leiden: E. J. Brill. Rosenbloom, Paul S., John E. Laird, &amp; Allen Newell (1993). The Soar Papers: Research on Integrated Intelligence. Cambridge, Mass.: MIT Press. Rosenthal, David M. (1997). A theory of consciousness. In Ned Block, Owen Flanagan, &amp; Güven Güzeldere (eds.), The Mature of Consciousness: Philosophical Debates, 729-753. Cambridge, Mass.: MIT Press. Smith, Jonathan Z. (1998). Religion, Religions, Religious. In Mark C. Taylor (ed.), Critical Terms for Religious Studies, 269-284. Chicago: University of Chicago Press. Sperber, Dan (1997). Intuitive and reflective beliefs. Mind and Language 12: 67-83. Taatgen, Niels A., &amp; John R. Anderson (2002). Why do children learn to say 'broke'? A model of learning the past tense without feedback. Cognition 86 (2002): 123-155. Thaler, Richard H. (1991). Quasi-Rational Economics. New York: Russell Sage Foundation. Whitehouse, Harvey (1995). Inside the Cult: Religious Innovation and Transmission in Papua Mew Guinea. New York: Oxford University Press. — (2000). Arguments and Icons: Divergent Modes of Religiosity. New York: Oxford University Press. — (2004). Modes of Religiosity: A Cognitive Theory of Religious Transmission. Walnut Creek, Calif.: AltaMira Press.</page></plain_text>
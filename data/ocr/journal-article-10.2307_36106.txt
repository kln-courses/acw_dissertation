<plain_text><page sequence="1">Proc. R. Soc. Lond. B 230, 279-292 (1987) Printed in Great Britain The evolution of visual processing and the construction of seeing systems BY G. A. HORRIDGE, F.R.S. Research School of Biological Sciences, P.O. Box 475, Canberra, A.C.T. 2601, Australia (Received 6 November 1986) This paper is concerned with the evolution of visual mechanisms and the possibility of copying their principles at different levels of sophistication. It is an old question how the complex interaction between eye and brain evolved when each needs the other as a test-bed for successive improvements. I propose that the primitive mechanism for the separation of stationary objects relies on their relative movement against a back- ground, normally caused by the animal's own movement. Apparently insects and many lower animals use little more than this for negotiating through a three-dimensional world, making adequate responses to indi- vidual objects which they 'see' without a cortical system or even without a large brain. In the development of higher animals such as birds or man, additional circuits store memories of the forms of objects that have been frequently inspected from all angles or handled. Simple visual systems, however, are tuned to a feature of the world by which objects separate themselves by movement relative to the eye. In making simple artificial visual systems which 'see', as distinct from merely projecting the image, it is more hopeful to copy the 'ambient' vision of lower animals than the cortical systems of birds or mammals. INTRODUCTION From a study of situations in which insects give visual responses to objects it was recently proposed that the visual separation of objects by insects depends upon the relative motion of the object against background when the insect moves (Horridge i977, 1986). That mechanism requires no fast computer with a sophis- ticated memory of the shapes of common objects to distinguish the angular bearing of a relative motion and to identify a discrepancy in the flow field as the outline of an object. By expressing the problem of object recognition by an array of neurons in this way, we are saying that in the insect visual system there are neurons which immediately interpret the relative motion against background as the separateness of an object, whether or not the background appears to move. Within this limited framework of insect vision, these neurons would therefore 'see' the object as distinct in itself, but would not see it as we do. By the word 'see' I imply a behavioural or neuronal signal which indicates that the distinctness of the object is discriminated from its surroundings in the two-dimensional image on the retina. A neuron sensitive to relative motion serving this visual behaviour, would require no cortex or memory bank to recognize the distinctness of an object [ 279 ]</page><page sequence="2">G. A. Horridge by acute form vision. Moreover, within the restricted range of insect self-motion such as walking, flight and the landing response, an array of such neurons with medium-sized fields could give a coarse spatial and temporal representation of the three-dimensional world in space around the insect, without other mechanisms such as accommodation, binocular vision or memory of the shapes of common objects. Neurons with suggestive features to encode relative motion have already been recorded in insect optic lobes (Collett &amp; King 1975 ; Honegger 1980) and lower vertebrates (see below). The time is now ripe for the forging of conceptual links between work on a variety of other visual systems, including the effort to construct artificial systems, and the work on insects is a convenient introduction to a new theory of the evolution of visual processing. For an earlier discussion, see Gregory (1974, P. 60). THE EVOLUTION OF VISUAL PROCESSING Widening the survey of eyes to other invertebrates and lower vertebrates reveals that vision has evolved repeatedly in numerous groups of animals which do not necessarily have a complex nervous system. By their visual responses these animals clearly demonstrate that they 'see', but the simplest examples have nothing that we could call object vision. The shell-closure reflex of barnacles is an example of 'seeing' the approach of a potential predator that casts its shadow on a few photoreceptors measuring intensity change. We have many artificial systems which open doors or detect burglars at this level of complexity. The next level is the detection of a moving contrast by a stationary eye: some molluscs, e.g. scallops and giant clams are of this type. Even at this level there are many types of eyes with large numbers of receptors and optical systems that suggest that they approach optimum resolution as limited by diffraction, and have maximum sensitivity to axial rays by utilizing long rods of dense visual pigment. Beyond this stage, several groups of animals that move have evolved a variety of visual mechanisms which prevent collisions, detect the direction of a distant movement, and pursue prey or mates. Eyes serving this level of complexity have a sampling array of many receptors looking in different directions on adjacent optical axes; an arrangement which can be achieved in an eye like a camera with many light-sensitive grains behind a single lens, or by a compound eye with a separate optical axis for each lens, as in insects and crustaceans. Motion detection is the characteristic of these eyes, and it is this level of complexity, without a large brain behind the eye, where there is now scope for copying the processing mechanisms of these eyes into artificial systems with available technology. Human technology is evolving along the same path, in that our cameras have excellent resolution but as yet no brains at all. On this theory, eyes with arrays of receptors having narrow fields of view were progressively elaborated because the detection of the direction of the least movement of a moving contrast with noisy receptors requires many simultaneous correlations (Reichardt 196 ) between many adjacent receptor pairs. They evolved as sampling arrays with optimum optics to detect motion relative to the eye, not because they could resolve the details in the panorama, but because at first they 280</page><page sequence="3">Evolution of seeing systems lacked the central nervous mechanism to do that. Quite complicated retinas in lower animals, e.g. Cubomedusae, scallops, and fan-worms, with regular close arrays of receptors, are unlikely to have a projection of the outside world upon a brain, or produce a reconstituted picture as we have. With more advanced visual processing, jumping spiders, praying mantids and snakes have diffraction-limited eyes backed by a nervous system that can coordinate a strike at a prey. Eyes over this wide range of structure detect motion of potential prey remarkably well, and possibly the design of the eye is optimized for motion detection (and therefore for a combination of spatial and temporal resolution) not for resolving stationary images (contra Snyder et al. I977). Most arthropods that have appropriate behavioural responses (and have been tested) respond to angular movements that are more than an order of magnitude smaller than the interommatidial angle. In fact, low threshold for angular motion seems to be very widespread in motion perception systems, even in the peripheral vision of man (Foster et al. 1981). Besides seeing the direction of a motion, many lower animals such as arthropods, some polychaetes and some molluscs, with brains at this level of complexity, respond to the direction of a steady light, and sometimes to the direction of a selected colour, but efforts to reveal any sort of form vision have failed. Nevertheless, some of these animals move freely as if they see separate and discrete objects in a three-dimensional world. VISION BY MOTION PERCEPTION A freely-moving animal, with eyes that detect the angular bearing and direction of motion of a moving contrast immediately finds itself with new problems and possibilities introduced by its own motion. When it turns or moves forward on a straight course, all surrounding contrasts move relative to the eye. Because locomotion is irregular and mainly horizontal, most of this induced motion is in the horizontal plane and is not entirely predictable from the motor output. Therefore, to see a movement while it moves, the animal must cancel the horizontal motion of the background at least in some of the neurons with fields that respond to motion. But as it moves, the apparent background motion differs at different angles to the line of motion. Therefore, the background must be subtracted region by region. When turning in the horizontal plane, however, it need only subtract the motion of the whole surround together, along the equator. Because of the irregularity of all locomotion, the visual system must cancel or ignore all movement of the background in each region, not just that part caused by its own motor output. In agreement with this limitation, we find that eye motion (e.g. in the crab) is usually compensated more by visual feedback (Horridge &amp; Sandeman I964) than by proprioceptive feedback (Varju &amp; Sandeman 1982). These requirements can be met by neurons with medium sized fields which subtract the average horizontal motion of contrasts in each field from a local motion of contrasts within the field. Such neurons are known in insects (Horn &amp; Rowell 1968; Palka 1969; Collett &amp; King 1975; Egelhaaf 1985). Another way for the neuron to ignore the background motion is to adapt to the general motion in the field while remaining sensitive to a local change in the motion within the field. 281</page><page sequence="4">G. A. Horridge Again, such neurons have been described in insects (Horn &amp; Rowell I968; Honegger 1978; Maddess &amp; Laughlin 1985). With such neurons, a primitive animal can cruise along having cancelled the visual effect of its own motion but it still sees local relative motions. These hypothetical neurons provide a limited visual system that is relevant to the construction of artificial visual systems that will separate out the objects in a three-dimensional scene as distinct from projecting their image from one plane to another within the nervous system. We are now saying that discontinuities in the flow field are automatically detected and separated into objects in three-dimensional space by an appropriately evolved but relatively simple set of neurons detecting relative motion against background motion. The primitive animal with this system will not see the discontinuities as an object as we do because it has no equipment to handle or see a wide variety of objects and build up memories of their forms. Of course, the visual system will also have other neurons, with other field properties, that serve other tasks at other times. Detection of range from self-motion A flying insect with forward velocity v detects the induced angular motion of a stationary contrasting object which appears to move in the horizontal plane across the eye. Actually the insect has information about the bearing relative to the midline, measured as 0, and the apparent angular velocity dO/dt of the object. Then, as shown by Nakayama &amp; Loomis (1974): dO/dt (0) = (v sin )/x, (1) where x is the range of the object and (0) refers to the dependence on the object. Therefore, if the speed of locomotion, v, is known or assumed, the angular velocity across the eye gives an inverse measure of the range of an object, if the insect flies on a straight course. Theoretical models for the measurement of angular velocity are reviewed by Buchner (1984). Freely moving animals turn as they move, and the eye can never be perfectly stabilized. At all times, therefore, the angular velocity of the whole visual field must be cancelled out by subtracting average background motion, or, better, by subtracting the angular velocity seen directly in front. Large-field motion- detecting neurons which might do this are known in insects and on this theory they should be inhibitory to small-field units (Egelhaaf I985). Also the frontal pole appears to be the region of the eye which controls turning in free flight (Collett 1980). When there is a background at a distance nx behind the object, it will have an apparent angular velocity, given by d6/dt (B) = (v sin O)/nx, (2) where (B) refers to the dependence on the background. So, the angular velocity of the object relative (R) to background is dO/dt(R) = v sin 0 (1 -1/n)/x, (3) For example, if n = 2, the relative angular velocity will be half of the absolute angular velocity of the object. Small-field motion-sensitive neurons, having 282</page><page sequence="5">Evolution of seeing systems inhibitory surrounds also sensitive to motion, would be ideal for detecting the angular bearing and strength of a parallax signal, but they can measure the range of an object only if the background is far away (large n). If they assume the background to be at infinity, the range is over-estimated. This argument shows that parallax cannot be relied upon for the estimation of range by a flying insect that must avoid a collision or land on an object because the background would be at an uncertain distance. Time to contact When there is a planar array of objects directly in front, the absolute measurement of the time to contact, from 0 and dO/dt, is less ambiguous and requires only angle-labelled neurons with medium sized fields sensitive to local velocity on the retina. Time to contact is given by t = x/v = sin O/(dO/dt) from (1), (4) and when 0 is small, 0/t = dO/dt. So time to contact depends only on the way that the image moves at each point on the retina. More complex hard-wired detectors of an expanding scene (looming units) would be more effective for measuring the time to contact than simple directional velocity detectors. This type of mechanism has been inferred in flies (Wagner 1982), in birds (Lee &amp; Reddish 1981) and man (Lee &amp; Young 1985) but the 'looming' neurons have not yet been found. Because much insect behaviour, such as the landing response and the escape response, depends on motion-measurement by the visual system, it would not be unreasonable to think of the insect's visual world as a time-to-contact at each angle on the eye. Whereas we see angle-labelled moving contrasts, the fly would see angle-labelled anticipated collisions, or time-to-reach-gokl in each direction. Compromise in the field size In the array of sampling stations, every photoreceptor and neuron on the path to the brain has a 'field' which is defined as the distribution of sensitivity to change in intensity, to motion, etc., within its own segment of the visual scene. Each neuron is a transmitting line which does not convey independent information about the position of the contrast within its field. Therefore the direction of a contrast is labelled more accurately by having smaller fields and more of them. But if fields are too small their sensitivity is low on an absolute scale; increasing sensitivities requires that they must be summed in larger groups. A field is optimized when it is matched to the stimuli that are most significant in survival; at present we do not understand this relationship for motion perception units organized into antagonistic regions or with local adaptation. When the effect of head rotation is eliminated, equation (1) implies that an angle-labelled neuron can measure dO/dt in one direction, i.e. the bearing 0 relative to the eye is labelled by choice of neurons, ambiguity of 0 depends on field separation and size, and angular velocity at that angle is signalled by the impulse frequency. Given a set of detectors which are observing the same moving stimulus, to overcome the aperture problem (Marr 1982, p. 166), the insect will know the 283</page><page sequence="6">G. A. Horridge directions and approximate times to contact of about half as many objects in front of it as it has neurons with separate fields. The 'half' comes from the Nyquist criterion for separating sampling points in an array, i.e. there must be fields which fall between the objects as well as those which respond. At one extreme, if a wide-field neuron is sensitive to any motion discrepancy in the animal's whole visual field, it can detect one object but does not know its direction relative to the eye. To detect several objects simultaneously requires about twice as many neuron fields (plus one) as there are objects. By progressively increasing the number of neurons sensitive to relative motion, the visual processing system can slowly evolve in complexity from seeing only one outstanding object at a time against total background, towards a system that detects the times to contact of different objects in separate directions by line-labelling them in separate neurons with moderate sized fields. Once the neurons that detect relative motion have evolved in conjunction with locomotion, any number of additional hard-wired circuits can be added as outputs of the visual system, to deal with specific elements of behaviour. Examples are alerting neurons, detectors of looming, neurons for turning towards or away from large discrepancies in the flow field with particularly significant features such as colour, flicker or contrast. None of this requires an inbuilt memory that would recognize previously familiar objects, although memory circuits can also be progressively superimposed upon the motion system. Such a visual processing system can progressively evolve in complexity without, in the intermediate stages, necessarily recognizing objects with the help of a memory. Bees and other Hymenoptera, however, provide evidence that a memory for patterns is so superimposed upon motion detectors in some insects. Insects may have two systems, for motion and for colour, in parallel. The comparative study of eyes and optic lobe complexity in a variety of insects and crustaceans is consistent with this progressive elaboration. Object vision by natural systems Once we take this approach, it is easy to find evidence for the idea that many visual systems have not evolved much beyond the ability to separate the direction of a discontinuity in the visual flow field. A quick survey of visual behaviour in animals such as fish, reptiles, insects and molluscs shows that relative motion appears to be the essential stimulus to elicit visual responses, and animals which themselves move must discount the motion of the background and extract the relative motion by appropriate neuron fields. Many lower animals, especially flying insects, behave as if they see objects around them against a background, and peering mantids respond especially well to motion discontinuities caused by objects in the visual flow field (Horridge I986). This mechanism of detecting objects is likely to be colour blind because motion detection is frequently colour blind (Srinivasan 1985). The current limitation of our knowledge of object vision in lower animals is set by the limited stimulus situations used in the experimental tests, not by the animals. In most previous work the effect of background is not mentioned and frequently a flat two-dimensional visual stimulus has been used. When the animal, or a neuron recorded in it, responds to a homogeneously moving 284</page><page sequence="7">Evolution of seeing systems contrast, the flat stimulus is not providing the test to which the visual system may be adapted. Only slowly each field of endeavour related to this topic is getting away from the idea that parallax is the relative movement of objects that have already been discriminated. The simpler view is that objects are first separated by their relative motion and then, with the progressive evolution or development of a memory of shapes, form vision progressively evolves or develops. Memory in the visual channels could evolve or develop first as a persistence of the signal that a relative movement has occurred in a particular direction. We have some evidence of pattern memory in insects and crustaceans, most obviously in bees. In development, as in evolution, the system slowly grows. In human babies, information about range and depth from motion appears crudely in the first month, but binocular vision and other ways of estimating range appear only at about four months (Yonas &amp; Granrud I985). We are aware that for ourselves the discrepancies in the flow field, as cues to three-dimensional structure, are visual imperatives, and are very rapidly processed unconsciously in human vision. Our ability to play fast cricket or table-tennis depends on such mechanisms, which are faster than our form vision. In studies of human binocular vision, however, it has been possible to combine separate successive stationary images at the two eyes to produce perceived motion, and this has drawn attention away from studies of the more rapid detection of motion by single eyes. In studies of vision of lower animals the test stimulus has usually been a contrasting shape drawn on a flat two-dimensional screen. To a simple visual system that recognizes only the independent existence of an object by relative motion, flat pictures are a poor stimulus, effective only when they move relative to the eye. Even advanced animals like dogs and cats are not very interested in photographs. In studies of vision in the housefly by Reichardt &amp; Poggio (1979) and others in Tiibingen, however, the appropriate stimulus was used: a moving dot figure on a moving dot background. From the behavioural response the basic mechanism discussed here was inferred, that horizontal background motion is subtracted from each local motion (Egelhaaf I985) so that at least one object separates itself from background. To this we now add the idea that when the eye moves, the ego-motion within a three-dimensional world creates 'objects' which the brain would otherwise know nothing about. This proposal that insects 'see' objects entirely by motion relative to each other and to the eye (Horridge 1977, 1986) is compatible with a wide variety of observations. For example, the praying mantis, locusts and other insects sway or 'peer' in circumstances when they are estimating the relative distances of nearby objects - perhaps indeed when they are 'seeing' the objects at all. The peering is an erratic horizontal movement, not stereotyped, in keeping with the idea that a mechanism originally adapted for normal locomotion would suit any non-stereotyped motion. In studies of neurons within the visual system of higher animals such as cats or monkeys, the eye is usually fixed and the stimulus is presented on a flat screen. True, the stimulus is usually a moving bar or a flickering spot, but in most studies the stimulus is a single event on a featureless background, and is not designed to 285</page><page sequence="8">G. A. Horridge pick out the neurons that would detect objects by relative motion against background. Only recently, in cat cortex (Hammond &amp; Smith I982), cat superior colliculus and pigeon optic tectum, more appropriate stimulus situations have been introduced (see below). Computer vision An alliance between studies of neurons and of artifical vision has been at work for three decades. Initially, work on several vertebrates, including fish, birds, amphibia and mammals had demonstrated the widespread centre-surround organ- ization of the fields of ganglion cells of the vertebrate retina. The arrangement of an on-centre and an off-surround means that the ganglion cell gives a response to a small flash or dark spot or to a moving contrasting edge but not to general changes in illumination. Later it was found that neurons in the cat's visual cortex are sensitive to the movement of edges and bars in their visual field. Ganglion cells with centre-surround fields can be grouped together to excite neurons that are edge or bar detectors (Hubel &amp; Wiesel 1962, but see Stone (I983) for alternative mechanisms). Apparently the vertebrate visual cortical pathway works by sum- mation of centre-surround units, with much additional complexity and some argument about whether pure summation must be supplemented by inhibition or by more complex parallel processing. By eliminating the redundancy in the intensity, the centre-surround arrangement is a particularly convenient coding unit for later building a central representation of an edge or a shape. Therefore, it was argued, we should design computerized visual systems on these principles so that they will detect the edges of objects and thereby take the first essential step for 'seeing' (see, for example, Marr 1982). Unfortunately, it was not so simple to 'see' objects by this route. An enormous expenditure of time and computer power has gone into the efforts, but a 'flat' scene contains too many ambiguities to be resolved into objects without other information about shapes, textures and shadows. The problem is not only in the transmission of the image! The major problem is 'seeing' or understanding the image. There are two types of clue missing. First, juvenile animals with a maturing visual cortex are able to 'handle' objects and educate their own brains in the correspondences between shape, shading, texture, colour, hardness, and apparent changes in shape upon rotation. Animals which do this - especially cat and monkey, but for some objects even fish - have visual systems in which centre- surround visual fields are projected to a representation on their optic tectur or visual cortex. So far the image is not 'seen': it has simply been transmitted to be ready to be 'seen'. The missing clues, that resolve the ambiguities in a two- dimensional scene into objects, are supplied partly by learning. The other and more reliable clues about objects are provided by the relative motion that is generated by the animal's own motion. As Helmholtz (i866) described, the scene separates itself into objects, and therefore objects can be known to be discrete. A flat pattern of random dots containing a group of dots that move in accordance with the movement of a single eye generates a three dimensional illusion in man (Rogers &amp; Graham 1979). The ability to detect the angular bearing of a parallax is inseparable from the array of neurons that do the job. Seeing 286</page><page sequence="9">Evolution of seeing systems parallax is effectively 'seeing' objects at different depths with separate sets of neurons with different but definable properties as described below for the cat colliculus. Similarly, the set of neurons which detects an outline of equal relative velocities is the set that defines the outline of an object which moves as a whole. Parallax, in general, is reliable as an indicator of object separation. The importance of being right way up In the natural world of trees or grasses, most of the edges are vertical, so the primitive eye is adapted to see discrepancies in the flow field in the horizontal plane. There appear to be examples of vision which depend on horizontal but not vertical parallax; the fly, for example. The system is remarkably economical, but there is an additional condition. To perform at all, the fly must be able to stay the right way up, and, in common with most animals with eyes, it has a very strong righting reflex. The dorsal light reflex and special gravity reflexes that keep eyes in their normal posture, as in crabs, make it possible to economize by limiting parallax to the horizontal. Builders of robot hands, however, at present rely on rotations to move the hand, but if the hand could stay the right way up its guidance by its own eye (on a finger) could be simplified. Neurons which detect relative motion The situation in insects is covered in Horridge (1986). Compared to cat and monkey, neurons sensitive to directional motion are surprisingly common in the retina and optic tectum of lower vertebrates, especially amphibia and fish. In addition, feature-detectors for more sophisticated stimuli can be found in the retina and especially in the optic tectum of these animals. Moreover, specific behaviour such as fleeing or feeding can be linked to particular feature detectors. Comparison with insects is tempting; we find similar mechanisms for similar natural situations, although most of the known neurons are inadequately des- cribed. In contrast to mammalian cortical cells, the vertebrate tectal units might have been acceptable to Muller (I852) or Hering (I86i) as updated versions of 'given' or 'nativistic' (i.e. hard-wired) elements. Toad optic tectum Detailed descriptions of the neuron types (Ewert 1982) show a variety of motion-sensitive and feature detectors that have functional explanations. As an example, toads respond in two ways to small black shapes that move. An object which is elongated (a) in the direction of movement is interpreted as prey, one that is elongated (b) perpendicular to its line of movement causes the toad to flee. In the thalamus/pretectal region there were neurons with fields 40-50? diameter responding to stimulus (b) above. In the optic tectum there were units of field 27? diameter activated by stimulus (a) above, other neurons were inhibited by stimulus (b) (Ewert &amp; Wietersheim I974). Together with small field neurons that code direction more accurately, this system is a good candidate for the control of the feeding/flight choice in toad behaviour. The point is that the early visual processing appears to be based upon a foundation of motion detection. 287</page><page sequence="10">288 G. A. Horridge Avian optic rectum Birds may face many of the same visual processing problems as the larger fast-flying insectzs. They avoid collision, chase prey or mates, land on a twig, etc., with a lmechahism that must combine speed of response, minimum weight and a nimechanism that fits the characteristics of the environmental scenes. Several st udies of the optic tectum, mainly of the pigeon, show that a large proportion of the neurons are motion-sensitive with centre-surround organization, and therefore selective for relative motion. Recently Frost &amp; Nakayama ( 983) described neurons of the pigeon optic teetum which are inhibited by in-phase motion of a small object against background but facilitated by anti-phase motion. The inhibitory surround is very large and the response is only broadly tuned to the direction of the movement. These details (few others are given) suggest that these neurons detect relative motion of objects caused by the animal's own motion. 7he mammalian colliculus The superior colliculus of mammals is a primitive centre of the brain which corresponds to the optic tectum of lower vertebrates, with a projection from the eyes. In evolution the teetum is older than the cortex and appears to be responsible for the ability of mammals that are apparently blind, after lesions in the visual cortex, to operate as if they localize objects (Weiskrantz 1978). The colliculus is the place to look for neurons that separate objects by their relative motions and thereby inform the cortex of their individuality, direction and range. In a particularly relevant study, Mandl (I985) recently found, deep in the superior colliculus of the cat, a class of neurons which are tuned to relative velocity. The stimulus was a moving spot seen on the background of a moving striped pattern. The response peaked at a certain relative velocity irrespective of how the relative velocity was made up from the motion of the spot and of the background (often around 20? s-1). Clearly, a number of such neurons, tuned to different relative velocities, would divide up the different relative motions seen at a particular angle to the eye as an animal moves relative to boundaries at different depths. Expressed another way, the different amplitudes of parallax seen at different depths are line-labelled by groups of neurons tuned to different relative velocities. Another neuron type in the cat superior colliculus (Mandl I985) is tuned to the velocity of motion of an object irrespective of the motion of the background. A class of such neurons tuned to different velocities would be able to group together edges moving at the same absolute angular velocity, and during the animal's own motion, clusters of them would indicate the absolute range of nearby objects, irrespective of background. Focal and ambient vision In mammals the 'focal' visual system (Trevarthen 1968; Diamond &amp; Hall 1969) is distinguished as high-resolution (i.e. small fields), local, foveal, colour-coded and object-identifying; it evokes conscious images in man (Schneider 969). In contrast the 'ambient' system is peripheral, global, colour blind, motion sensitive, localizes</page><page sequence="11">Evolution of seeing systems objects in space and is less obviously conscious in man. With qualification, the 'focal' system can be localized in the cat to the X cell projection (with some Y cells) from the retina to the lateral geniculate and then to the striate cortex, while the 'ambient' system is the projection of W cells (with some Y cells) from the retina to the superior colliculus, which persists after lesions of the striate cortex and is correlated with loss of discriminations of local pattern (Hughes 1982). In primates, the behaviour after ablation of the striate cortex is even more obviously limited to the ambient system (Keating &amp; Dineen 1982). In lower mammals, the 'focal' system is less well-developed, less evolved I should say. For example, in the rabbit a large fraction of the retinal ganglion cells are motion-sensitive and send a branch to the superior colliculus. A full account can be found in Stone (i983). Human vision Ability to direct the gaze We have the ability to fixate our gaze upon the background and see the relative motion of an object in the foreground, or alternatively to shift the fixation to the foreground so that the background now moves in the opposite direction for the same head movement. Fixation means that we can rotate our eye as we move our head sideways. The separation of objects by parallax does not depend on the ability to direct the gaze, and many of the animals mentioned in this paper do not have a fovea or this additional facility, which is therefore not relevant (contra Mandl 1985). Resolution and ambiguity of location On its input side, there can be a high resolution for relative motion at each point in a neuron's field but its output indicates only that the stimulus is somewhere in the field. Quite large fields are common deep in the optic lobes of insects or crustaceans. These large fields must contribute to the explanation of how objects persist in vision although they move on the retina. Neurons downstream cannot recover the location within that field without reference back to the periphery e.g. by shifting to the fovea. Therefore memory of detailed location by local circuits is essential because neurons that build up the central representation necessarily have medium-sized fields and time constants or they could not be integrative. This line of thought suggests that the detail in the objects and in the whole visual world that we 'see' is continuously coming out of local memory circuits, just as the appreciation of objects via the motion-detecting system also depends on memories of their three-dimensional shapes. We not only create the objects that we see, we also fill in the detail from memories of previous visual examinations. In fast reading, for example, we evoke the letters and even whole words from memory. In seeing moving objects, illusions or dreams, we can see them sharply as they are pulled out of short-term memory, by a process which (for moving dots) Foster et al. (1981) called 'disambiguating'. Escaping anthropomorphic convictions To the central problem of human visual perception since Bishop Berkeley's ( 709) essay - how much is innate and how much is learnt - we can now add the 289</page><page sequence="12">290 G. A. Horridge broad finding that some systems in naive newborn animals, and in lower vertebrates and insects that clearly 'see', have 'nativistic' (hard-wired) neurons that are mainly motion-sensitive and fit the term 'ambient vision' as applied to mammals with cortical lesions. Added to this in the cortex (but not necessarily in the striate cortex) is a cognitive, constructive, and learnt system which generates our consciously visual world -Helmholtz's 'unconscious inference'. When the nativistic system transmits a familiar shape to the cortex via an appropriate cluster of neurons, do we suppose that a cluster of local cortical memory neurons recognize it like a number in bingo ? Yes, I think we must, tentatively, in order to explain visual dreams and visual illusions. The same mechanism explains why moving objects appear sharp (contra Burr et al. I986) and incidentally why conscious vision takes so long to process. Such theories help us to generate the necessary expectations of the functions of local cortical neurons despite the circularity of the explanation. Without these expectations, the appropriate experiments are impossible to divine. If memory is so significant, as empiricist philosophers have also stressed, then contra Marr (I982), copying the X cell transmission to the cortex is not a hopeful way to synthesize artificial vision. When we look at a flat visual image and see a three-dimensional object, we are pulling the form of it out of memory circuits. No wonder that visual illusions are easily generated. This creation of 'objects' being so, it is no wonder that we do not know how to instruct a computer to do the same. On the other hand, we can never know what lower animals actually 'see', but it is clear from their behaviour towards objects that relative motion and parallax puts form vision into their nervous systems by a simple but effective mechanism. The 'visual cliff' response of naive newborn animals also suggests 'hard-wired' systems that detect range even without recognition. To copy these systems, a way forward would be to analyse this earlier stage in the evolution or development of form vision, and use the principles of object vision derived from relative motion. CONCLUSION That motion perception is a fundamental visual dimension has progressively become apparent only this century as the alternative view has faded that motion is the memory of the change in position over time of an already separated object. To illustrate the shift in basic perspective needed, may I quote from the concluding remarks in the review of visual processing of motion by Nakayama (1985); 'it appears that the pick-up of motion information is beneficial for a wide variety of tasks. This includes a role in reconstructing the third dimension, segmenting the image, driving eye movements, eliciting attention, encoding self-motion, mediating size constancy, and detecting moving objects.' My own emphasis goes much further, to say that in evolution and in ontogeny of visual processing, relative motion is the first cue whereby objects are distinguished at all, and the whole system of recognition of objects and their discrimination is superimposed later upon the motion-processing system. The word 'later' here implies three senses, in evolution, in ontogeny and during visual processing. Motion information is not 'beneficial' to other tasks: it is primary in my view. If objects as</page><page sequence="13">Evolution of seeing systems we see them are plucked from memory, it is a misplaced effort to make machines to abstract objects from stationary two-dimensional pictures. REFERENCES Berkeley, G. 1709 Essay toward a new theory of vision. In The works of George Berkeley, Bishop of Cloyne (ed. A. A. Luce &amp; T. E. Jessop), vol. 1, pp. 143-239. Toronto: Nelson. Buchner, E. 1984 Behavioural analysis of spatial vision in insects. In Photoreception and vision in invertebrates (ed. M. A. Ali), pp. 561-621. London and New York: Plenum Press. Burr, D. C., Ross, J. &amp; Morrone, M. C. I986 Seeing objects in motion. Proc. R. Soc. Lond. B 227, 249-265. Collett, T. S. I980 Some operating rules for the optomotor system of a hoverfly during voluntary flight. J. comp. Physiol. 138, 271-282. Collett, T. S. &amp; King, A. J. 1975 Vision during flight. In The compound eye and vision of insects (ed. G. A. Horridge), pp. 437-468. Oxford University Press. Diamond, I. T. &amp; Hall, W. C. I969 Evolution of neocortex. Science, Wash. 164, 251-262. Egelhaaf, M. I985 On the neuronal basis of figure-ground discrimination by relative motion in the visual system of the fly. Biol. Cybern. 52, 123-140 (part I), 195-209 (part II), 267-280 (part III). Ewert, J. P. I982 Neuronal basis of configurational prey selection in the common toad. In Analysis of visual behaviour (ed. D. J. Ingle, M. A. Goodale &amp; R.. . W. Mansfield), pp. 7-45. Cambridge, Massachusetts: M.I.T. Press. Ewert, J. P. &amp; Wietersheim, A. von 1974 Musterauswertung durch Tectum und Thalamus/Praetectum-neurone im visuellen System der Krote Bufo bufo (L). J. comp. Physiol. 92, 131-148. Foster, D. H., Thorson, J., McIlwain, J. T. &amp; Biederman-Thorson, M. I98I The fine-grain movement illusion: a perceptual probe of neuronal connectivity in the human visual system. Vision Res. 21, 1123-1128. Frost, B. J. &amp; Nakayama, K. 1983 Single visual neurons code opposing motion independent of direction. Science, Wash. 220, 744-745. Gregory, R. L. 1974 Concepts and mechanisms of perception. (669 pages.) London: Duckworth &amp; Co. Hammond, P. &amp; Smith, A. T. I982 On the sensitivity of complex cells in feline striate cortex to relative motion. Expl Brain Res. 47, 457-460. Helmholtz, H. von I866 Handbuch des Physiologischen Optik. Hamburg: Voss. (Transl. J. P. C. Southall 1924; reprinted 1962. New York: Dover Publ.) Hering, E. I86I Beitrdge zur Physiologie, vol. 1. Leipzig: Engelmann. Honegger, H. W. 1978 Sustained and transient responding units in the medulla of the cricket, Gryllus campestris. J. comp. Physiol. 125, 259-266. Honegger, H. W. I980 Receptive fields of sustained medulla neurons in cricket. J. comp. Physiol. 136, 191-201. Horn, G. &amp; Rowell, C. H. F. 1968 Medium and long-term changes in the behaviour of visual neurones in the tritocerebrum of locusts. J. exp. Biol. 50, 723-732. Horridge, G. A. I977 Insects which turn and look. Endeavour (N.s.) 1, 7-17. Horridge, G. A. 1986 A theory of insect vision: velocity parallax. Proc. R. Soc. Lond. B229, 23-27. Horridge, G. A. &amp; Sandeman, D. C. 1964 Nervous control of optokinetic responses in the crab Carcinus. Proc. R. Soc. Lond. B 161, 216-246. Hubel, D. H. &amp; Wiesel, T. N. I962 Receptive fields, binocular interaction and functional architecture in the cat's visual cortex. J. Physiol., Lond. 160, 106-154. Hughes, C. 1982 Search for the neural mechanisms essential to basic figural synthesis in the cat. In Analysis of visual behaviour (ed. D. J. Ingle, M. A. Goodale &amp; R. J. W. Mansfield), pp. 771-800. Cambridge, Massachusetts: M.I.T. Press. Keating, E. G. &amp; Dineen, J. 1982 Visuomotor transforms of the primate tectum. In Analysis of visual behaviour (ed. D. J. Ingle, M. A. Goodale &amp; R. J. W. Mansfield), pp. 335-365. Cambridge, Massachusetts: M.I.T. Press. 291</page><page sequence="14">292 G. A. Horridge Lee, D. N. &amp; Reddish, P. E. 1981 Plummeting gannets: a paradigm of ecological optics. Nature, Lond. 293, 293-294. Lee, D. N. &amp; Young, D. S. I985 Visual timing of interceptive action. In Brain mechanisms and spatial vision (ed. D. J. Ingle, M. Jeannerod &amp; D. N. Lee), pp. 1-30. Nato ASI Series, no. 21. Dordrecht: Martinus Nijhoff. Maddess, T. &amp; Laughlin, S. B. 1985 Adaptation of the motion-sensitive neuron H1 is generated locally and governed by contrast frequency. Proc. R. Soc. Lond. B 225, 251-275. Mandl, G. 1985 Responses of visual cells in cat superior colliculus to relative pattern movement. Vision Res. 25, 267-281. Marr, D. I982 Vision. San Francisco: Freeman. Muller, J. I852 Elements of physiology (transl. W. Baly), New York: Levitt. Nakayama, K. I985 Biological image motion processing: a review. Vision Res. 25, 625-660. Nakayama, K. &amp; Loomis, J. M. 1974 Optical velocity patterns, velocity sensitive neurons and space perception: a hypothesis. Perception 3, 63-80. Palka, J. I969 Discrimination between movements of eye and object by visual interneurones of crickets. J. exp. Biol. 50, 723-732. Reichardt, W. 1961 Autocorrelation, a principle for the evaluation of sensory information by the central nervous system. In Principles of sensory communication (ed. W. A. Rosenblith), pp. 303-317. New York: Wiley. Reichardt, W. &amp; Poggio, T. 1979 Figure-ground discrimination by relative movement in the visual system of the fly. Part 1. Experimental results. Biol. Cybern. 35, 81-100. Rogers, B. J. &amp; Graham, M. E. 1979 Motion parallax as an independent cue for depth perception. Perception 8, 125-134. Schneider, G. E. 1969 Two visual systems. Science, Wash. 163, 895-902. Snyder, A. W., Stavenga, D. G. &amp; Laughlin, S. B. I977 Spatial information capacity of compound eyes. J. comp. Physiol. 116, 183-207. Srinivasan, M. V. 1985 Shouldn't directional movement detection necessarily be' colour-blind'. Vision Res. 25, 997-1000. Stone, J. 1983 Parallel processing in the visual system. New York: Plenum Press. Trevarthen, C. B. I968 Two mechanisms of vision in primates. Psychol. Forsch. 31, 299-337. Varju, D. &amp; Sandeman, D. C. 1982 Eye movement of the crab Leptograpsus variegatus elicited by imposed leg movements. J. exp. Biol. 98, 151-173. Wagner, H. 1982 Flow-field variables trigger landing in flies. Nature, Lond. 297, 147-148. Weiskrantz, L. 1978 Some aspects of visual capacity in monkeys and man followng striate cortex lesions. Archs ital. Biol. 16, 318-323. Yonas, A. &amp; Granrud, C. E. 1985 The development of sensitivity to kinetic, binocular and pictorial depth information in human infants. In Brain mechanisms and spatial vision (ed. D. J. Ingle, M. Jeannerod &amp; D. N. Lee), pp. 113-146. Nato ASI Series, no. 21. Dordrecht: Martinus Nijhoff.</page></plain_text>
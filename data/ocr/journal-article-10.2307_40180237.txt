<plain_text><page sequence="1">^£ Journal of Logic, Language, and Information 9: 447-466, 2000. aa&lt;-j ^^ © 2000 Kluwer Academic Publishers. Printed in the Netherlands. Beyond the Turing Test JOSE HERNANDEZ-ORALLO Departament de Sistemes Informatics i Computacid, Universitat Politecnica de Valencia, Cami'de Vera, s/n, E-46022 Valencia, Spain E-mail: jorallo @ dsic. upv. es (Received 1 June 1999; in final form 15 April 2000) Abstract The main factor of intelligence is defined as the ability to comprehend, formalising this ability with the help of new constructs based on descriptional complexity. The result is a compre- hension test, or C-test, which is exclusively defined in computational terms. Due to its absolute and non-anthropomorphic character, it is equally applicable to both humans and non-humans. Moreover, it correlates with classical psychometric tests, thus establishing the first firm connection between information theoretical notions and traditional IQ tests. The Turing Test is compared with the C-test and the combination of the two is questioned. In consequence, the idea of using the Turing Test as a practical test of intelligence should be surpassed, and substituted by computational and factorial tests of different cognitive abilities, a much more useful approach for artificial intelligence progress and for many other intriguing questions that present themselves beyond the Turing Test. Key words: ATs anthropomorphism, comprehension, descriptional complexity, inductive Inference, measurement of intelligence, psychometrics, Turing test 1. Introduction Turing realised that only machines with very special self-modifying programs could eventually pass the test he had just devised (Turing, 1950). The ability to learn new functions for which the machine had not explicitly been programmed has since then been recognised as a necessary condition for a machine to be con- sidered intelligent. Accordingly, the relationships between AI, IQ tests, inductive inference, learning, and descriptional complexity soon began to be discovered and, in many cases, formalised. Many early works in AI dealt with the relation between IQ tests and AI (Simon and Kotovsky, 1963; Evans, 1963). The association between AI and inductive infer- ence was taken on by Solomonoff (1957), leading him to the independent discovery of descriptional complexity (also known nowadays as algorithmic information or Kolmogorov complexity), and the formalisation of inductive inference under this complexity (Solomonoff, 1964, 1978). Since intelligence tests occasionally require the extrapolation of an effective sequence, the connection between inductive infer- ence and IQ tests was frequently alluded to (Gold, 1967; Blum and Blum, 1975). In particular, the idea of "measuring machine power-intelligence as the scope of the class of inferable functions" is suggested for the first time (Blum and Blum,</page><page sequence="2">448 J. HERNANDEZ-ORALLO 1975). Nonetheless, it is not until Chaitin's challenge to "develop formal defini- tions of intelligence and measures of its various components" (Chaitin, 1982), that the proposal of measuring intelligence by the use of descriptional complexity is explicitly solicited. The problem of extrapolating a sequence (i.e., sequential inductive inference) has been clarified and formalised under descriptional complexity. See, e.g., So- lomonoff (1978), Zvonkin and Levin (1970), and Li and Vitanyi (1997). However, the evaluation of inductive abilities (a notably different problem) has not been successfully addressed to date, at least in the way Chaitin suggested. As expected, many of the technical tools and results that will be used in the following are bor- rowed from Kolmogorov complexity, but some new constructs will be introduced in order to make the evaluation feasible and to make it meaningful. The motivation for such an evaluation is a first step in the construction of a scientific measure of intelligence, which should be compliant with the following assumed requirements: non-Boolean, factorial, non-anthropomorphic, computa- tional and meaningful. As will be discussed in later sections, despite the philo- sophical and enlightening virtues of the TT, when implemented, it has various drawbacks. First, it is difficult to gauge, it is not factorial, it is absolutely anthro- pomorphic, it is informal and it does not give an objective meaning to the word "intelligence." On the contrary, IQ tests provided by psychometrics (Spearman, 1904; Neisser et al., 1996; Eysenck, 1979) are non-Boolean and factorial. However, psychometrics has neglected (or failed) to incorporate the last three requirements, which, in fact, are highly related. Psychometrics, as the science of measuring hu- man intelligence, is anthropomorphic by definition. The factorial approach has not provided much insight, and no meaning can be extracted from "intelligence is what is measured by intelligence (IQ) tests." I realise that any definition is arbitrary, but it would be qualitatively better if the exercises that compose the tests were related to or derived from computational concepts. In this paper, a test for one of the main factors of intelligence (comprehension ability) is introduced, according to the five prerequisites mentioned above. I would like to point out that the test is exclusively based on concepts which are derived from the notion of the Turing machine. The paper is organised as follows. The next section introduces some necessary tools which will be used in the rest of the paper. It will also provide a descrip- tion of some technical difficulties which are solved in the subsequent sections. In particular, Section 3 formalises the initially vague notion of comprehension in information-theoretical terms. Section 4 deals with its measurement by solving the "subjectivity objection" under the notion of unquestionability and by ordering the difficulty of instances. This allows for the construction of a comprehension test (C- test). Section 5 presents the results of applying the C-test to humans and compares it with psychometrical tests. Its applicability to AI is discussed. Section 6 stud- ies the measurement of other factors (knowledge applicability, contextualisation, knowledge construction) under the same conditions that the C-test was devised</page><page sequence="3">BEYOND THE TURING TEST 449 with. The TT is re-examined in Section 7 and compared with the C-Test. The final section concludes with the claim of a new science of intelligence that would make it feasible to answer many new and fascinating questions which lie ahead. 2. Preliminaries and Technical Problems Let us choose any finite alphabet E composed of symbols (if not specified, E = {0, 1}). A string or object is any element from E*, with • being the composition operator, which is usually omitted. We define a sample space 5n consisting of all finite strings and infinite sequences over E, i.e., S% = E* U E00. By (a, b) we denote a standard recursive bijective encoding of a and b, such that there is a one- to-one correspondence between (a, b) and each pair (a, b). Note that this usually takes more bits than a • b. The empty string is denoted by e. The term l(x) denotes the length or size of x in bits and log n will always denote the binary logarithm of n. For every string y composed of/ symbols, we denote the symbols from position n to position m by yn ..m if 1 &lt; n &lt; m &lt; I. Otherwise it is undefined. With y.jn&gt; yn.., and yk9 we denote yXmM9 ynj(y), and ykmtk, respectively. If y has infinite length, yKmm denotes the infinite sequence jn..oo- Given any string jc, we denote by x-d = X)j(X)-d the prefix of x with length l(x) - d, i.e., the string x without its last d elements. The complexity of an object can be measured in many ways, one of which is its degree of randomness, which turns out to be essentially equal to its shortest de- scription (Kolmogorov, 1965). Descriptional Complexity, now commonly referred to as Kolmogorov complexity, was independently introduced by Solomonoff, Kolmogorov and Chaitin to formalise this idea, and it has been gradually recog- nised as a key issue in statistics, computer science, AI, epistemology and cognitive science (Li and Vitanyi, 1997; Gammerman and Vovk, 1999). However, the algorithmic prefix version of descriptional complexity, usually denoted by K(x) is unsuitable for our purposes because it is not monotone on pre- fixes, i.e., K(xy) can be less than K(x). K(x) is problematic for prediction in the continuous case (see, e.g., Vitdny and Li, 1997), but, more importantly, the use of 2~K(x) ^ a probability prior would imply that the probability of the sequence 0" to be followed by a 0 is greater if n = n0 = 1010thanifn = n\ = 141568756142169, which is quite counterintuitive because no &lt; n\. To avoid these problems, we shall work with monotone machines. There are slightly different definitions of monotone machines (Solomonoff, 1964; Levin, 1973; Schnorr, 1973). We follow Li and Vit£nyi (1997): DEFINITION 1. A Monotone Machine f} is a Turing machine with a one-way read-only input tape, some work tapes, and a one-way write-only output tape. The input tape contains a one-way infinite sequence of 0's and l's and initially the input head scans the leftmost bit. The output tape is written one symbol in E at a time, and the output is defined as the finite binary sequence on the output tape</page><page sequence="4">450 J. HERNANDEZ-ORALLO if the machine halts, and the possibly infinite sequence appearing on the output tape in a never-ending process if the machine does not halt at all. For a (possibly infinite) sequence x, we write fi(p) = x if p outputs x after reading p and no more. (Machine fi either halts or computes forever without reading additional input). DEFINITION 2. The Monotone Complexity of an object x given y on £, with fi being a monotone machine, is defined as: Kmfi(x\y) = min{/(p) : 0((p, y)) =xco, co e 5E}. p The monotone complexity of an object x is denoted by Kmp(x) = Kmp(x\e). There is an additively optimal monotone machine U such that there exists an independent constant c such that for any other monotone machine ft and for all x Kmu(x) &lt; Kmp(x) + c. If we select this machine U as a reference machine, the subscript can be dropped, thus assuming only constant errors. Kolmogorov Complexity and the monotone variant Km also constitute an absolute and object- ive criterion of complexity, and they are independent (up to a constant term) of the descriptional mechanism fi due to the invariance theorem. The relationship between monotone complexity and other variants of Kolmogorov complexity is of logarithmic additive terms (see, e.g., Li and Vitdnyi, 1997). Occam's razor, which states that "given two alternative explanations, choose the simplest one," was formalised under descriptional complexity by Solomonoff (1964), approximated by Rissanen in 1978 under the name "Minimum Descrip- tion Length" principle (MDL), finally re-formulated in its current one part code (Rissanen, 1996; Barron et al., 1998). In Vit£nyi and Li (1997) it is shown that under some reasonable assumptions on the fi - probability of correctly extrapolating a sequence, a fixed-length y extrapolation from x maximises ii(y\x) iff it minimizes Km(xy) - Km(x). In other words, this difference, which is always positive since Km is monotone, states that the shorter that the description of xy wit. x is (i.e., the less novel y is), the better the prediction is. From here, a compression/prediction test based on Chaitin's proposal (Chaitin, 1982) seems to be easily applicable. However, there are many technical reasons that explain why such an intriguing proposal has not yet been implemented: 1. K(x) and Km(x) are not computable. If a compression test is constructed, how do we know whether the subject's answer is a hit? 2. There can be different alternative plausible descriptions. In other words, there may exist a / such that Km{xyf) = Km(xy) + c with c being a very small constant. 3. Despite the invariance theorem, the constant involved is relevant, and there is no reason to prefer one descriptional system over another. 4. The test would finally measure the ability of compression, but, as will be argued in the following section, this differs slightly from the ability of comprehension, the main factor of intelligence that is to be measured.</page><page sequence="5">BEYOND THE TURING TEST 45 1 The first problem can be solved by incorporating time into the definition of Km. The most appropriate way to weight the space and time execution of a program, the formula LTp(px) = l(px) + log r^ (/?*), where r is the number of steps the machine has taken until x is printed, was introduced by Levin in the seventies* (see, e.g., Levin, 1973). The corresponding complexity, denoted by Kt (see, e.g., Li and Vitdnyi, 1997) is a very practical alternative to K, because as well as avoiding intractable descriptions, it is computable. Moreover, it better accounts for the idea of simplicity, and Occam's razor should be better formalised under this variant. Let us parametrise the definition of r in the following way: Tp(p)[..ri\ is defined as the time or machine steps such that the first n symbols of the definite output are placed at the beginning of the output tape. Consider also *p(p)[n..m] = rp(p)[..m] - rp(p)[..n - 1]. In the same way, LTp(p)[n..m] = l(p) + log rfi(p)[n.jn] and LTfi(p)[..n] = l(p) + log rfi(p)[.ji\: Then, the next variant comes directly and is a parametrisation of Kt: DEFINITION 3. The k-Projectable Length-Time Complexity of an object x given y on a monotone machine f$ is defined as: Ktmkfi(x\y) = min{L7&gt;((/&gt;, y))[..l(x)] - l(y) '.ScoeS* l(co) &gt; k s.t. P({p, y)) = xco)}. p Since LTp({p, y)) takes the length of y into consideration, this must be corrected by the term - l(y). It is trivial to see that Ktm° is the corresponding monotone notion to Kt. Definition 3 will serve as a starting point for facing the other three unsolved problems (2, 3, 4). In fact, we first require distinguishing what com- prehending is (problem 4), which is addressed in the following section, and in Section 4 we shall address how to measure the comprehension ability (problems 2 and 3). 3. Formalising Comprehension To comprehend is to understand the inner mechanism of a given evidence by constructing a plausible model of it. In some way, comprehension is stricter than inductive learning in terms of justification, because comprehension usually requires that the subject be able to explain the concept to others. In the case of infinite concepts, this explanation is only possible if the subject has a finite description of the concept. Consequently, comprehension could be understood in terms of identification. However, if a concept is finite, like most everyday concepts, both notions diverge significantly. A short finite concept can be easily identified by its extensional description, which has no insight and which has surely not identified any mechanism or pattern from it, if the evidence ever had one. This is an age-old * Intuitively, every algorithm must invest some effort either in time or demanding/essaying new information, in a relation which approximates the function LT.</page><page sequence="6">452 J. HERNANDEZ-ORALLO question in logic, where comprehension means the connotation of a term, opposed to its denotation or extension. Hence, an extensional description (by enumeration) has no connotation and consequently requires no comprehension at all. On the contrary, an intensional description (by comprehension) may have not discovered the right meaning or real mechanism of the evidence, but at least it has a chance of having discovered the right one. There is a fundamental feature that determines this difference, known as the comprehension requirement, namely that the thing being defined cannot appear in the definition, which is also one of the four laws of definition, according to meth- odology (Bochenski, 1965). Ancient and modern teachers have used it whenever they ask their pupils whether they have comprehended a concept. This is one of the oldest evaluation criteria ever used and a premise with which the pioneer of the psychometric approach, Binet, designed his first tests to avoid "rote learning." At first sight, Kolmogorov complexity seems sufficient to distinguish exten- sional descriptions from intensional ones. However, the ideal MDL principle, which chooses the shortest description for a given concept x, does not ensure that the description is intensional. In the vast majority of cases, the data is not compressible, and the MDL principle gives the void hypothesis plus the data itself as a set of exceptions. This most extensional description gives no hint about the comprehension of that data. Even in the rare cases where the data is compressible, a short description does not ensure that all the data is described intensionally; there could be a part that is highly compressed while another part is quoted as an exception. Example 1. Given the sequence ln, where up to m bits have been set to 0 by using pattern p. The MDL principle will give a sequence of \n plus the excep- tions as the most plausible hypothesis, and will predict 1, because it minimizes Km(xy) - Km(x). The zeros will be considered as noise (not explained) until the cost of quoting the exceptions exceeds the cost of p. In fact, it is easy to see that this problem only happens for relatively short sequences, because, if there is a pattern, there is always a value of n from which the use the pattern begins to be simpler than to quote the exceptions. One may argue, that for short sequences, exceptions would simply be allowed or not, depending on the purpose of the inductive technique: prediction or explanation, respectively. However, we will see that this is not easy. The MDL principle avoids this problem by finding a compromise between the length of the hypothesis plus the length of exceptions, since "it is difficult to find a valid mathematical way to force a sensible division of the information at hand in a meaningful part and a meaningless part" (Vitdnyi and Li, 1997). Koppel intro- duced the notion of sophistication with the goal of distinguishing the structural part of an object (Koppel, 1987) from its data (or non-compressible part of it). However, it can "disguise" a general effective interpreter as fictitious pattern and leave a great amount of real pattern as data. Thus, a different approach is required to distinguish</page><page sequence="7">BEYOND THE TURING TEST 453 whether a description has exceptions (partially or totally extensional) or whether is composed exclusively of pattern (it is all structure or fully intensional). One positive result of this paper is that it is possible to distinguish pattern from data, at least to the extent of discerning the part of a description which is used for all the data to the limit (the structure). Let us introduce the necessary constructs for this mathematisation: DEFINITION 4. A description pf is m-equivalent in the limit to a description p for a monotone machine &lt;/&gt; iff 3n e IN, n &gt; 0 and 3z e 7L such that &lt;/&gt; (p')n+z..n+z+m = 0(p)n..n+m- Note that if l(&lt;t&gt;(p)nJ = s &lt; m then the subscript is not well defined and the descriptions are not m-equivalent (they would be s -equivalent). In what follows, m is the "match," n is the "shift" and z is the "phase." Informally, two descriptions are m-equivalent in the limit if there is an "alignment" point from which their predictions match at least m symbols. DEFINITION 5. A description p is an m-fully Projectable Description of jc given y on a monotone machine &lt;/&gt; iff -*3p' with &lt;f&gt;((p', y))..m&gt; ^ #((/?, y))..mf such that (p\ y) is m-equivalent in the limit to {p, y) with shift n and phase z and n + z &lt; l(x)andLT((p\ ;y))[n+z..n+z+m'] &lt; LT((p, y))[n..n+m'] with m' = l(x)+m. The concept is more insightful for m = oo. In this case, we would read that an oo-fully projectable description of x cannot have a simpler description which is different from p and which at the same time is oo-equivalent in the limit. Note that LT is used instead of / and only applied to the first chunk of length m! where p' and p begin to be equivalent. The reason for introducing a parameter m in both definitions is because it is impossible to effectively know whether two sequences are equivalent up to the infinite. In practice, the highest goal we can aim for is that m be the greatest number possible. Example 2. Given the evidence "3, 12, 21, 30, 102, 111, 120" (properly codi- fied into a binary sequence) we can consider several projectable descriptions. For instance, DY = "3, 12, 21, 30, 102, 111, 120 and 1 forever" is not fully projectable because there exists a shorter description "1 forever" which is equivalent in the limit. In the same way, D2 = "Start with number 3. The following three numbers are obtained by adding 9 to the preceding one. Continue with number 102. The following numbers are obtained by adding 9 to the preceding one" is not fully projectable because there exists a shorter description "Start with number 3. The fol- lowing numbers are obtained by adding 9 to the preceding one" which is equivalent in the limit. On the contrary, the description D3 = "numbers whose digits in decimal representation amount to 3 ordered" is fully projectable. Similarly, the description D4 = "repeat 3, 12, 21, 30, 102, 1 1 1, 120 forever" is fully projectable (unless there is a way to compress the rote pattern). Finally, the following description is also</page><page sequence="8">454 J. HERNANDEZ-ORALLO fully projectable D5 = "the y values of a polynomial y = P(x)" where P is a polynomial such that P(l) = 3, P(2) = 12, . . . , P(7) = 120. Although D4 and D5 may seem counterintuitive, it should be realised that a fully projectable description simply formalises the idea of explanation (and not yet the comprehension requirement): it describes the evidence, it accounts for all of it (there are no exceptions because it is fully projectable) and it can be related (ex- plained) to others (because of the use of LT, descriptions which are extremely time consuming are avoided). Hence, D4, whether we like it or not, is an explanation for the evidence. For the moment, we can define a new variant of descriptional complexity: DEFINITION 6. The m-Explanatory Complexity of an object x given v on a monotone machine f$ is defined as: Etfi(x\y) = nun {L7&gt;((p, y»[../(*)] - l(y) such that p is an m -fully projectable description of x given v}. The string y, which we have carried along, represents the context or previous knowledge where the explanation must be applied. In the same way as is done with Km and the MDL principle, we can denote with SED(x\ y) the Simplest (in LT terms) oo-Explanatory Description for x given y, i.e., the first simplest fully projectable description (in lexicographic order) for x given v. Logically, l(SED(x\y)) = Et(x\y). However, we still have that for most strings, SED(x) will be just the rote de- scription "repeat x forever" which does not follow the comprehension requirement. A first idea to avoid this phenomenon is to force the description to be shorter than the data and to say that the data has no comprehensive explanation if this is not the case.* However, most everyday data is not compressible and it is still comprehended. Another approach is the idea of reinforcement or cross-validation. For instance, if we remove the last element of the previous series, i.e., "3, 12, 21, 30, 102, 111," it is not very likely that D4 and D5 be produced; however D3 can still be generated. In general, DEFINITION 7 (Stability). A string x is s-stable on the right given v in the descriptional system 0 iff Vi, 1 &lt; i &lt; s : SEDp(x^\y) = SEDfi(x\y). In other words, a string x is s-stable on the right if taking s elements from the right, it still has the same best explanation. These s elements, if given a pos- teriori, are considered reinforcement or confirmation, and, if given a priori, are * A different approach is the notion of exception, studied and formalised in Hern£ndez-Orallo and Minaya-Collado (1998) and Hernfcidez-Orallo and Garcfa-Varea (1998).</page><page sequence="9">BEYOND THE TURING TEST 455 considered redundancy or hints to help to find the explanation. Consequently, although rote learning can be trickily used to make an extensional description fully projectable, stability (like reinforcement or cross-validation) is a methodo- logical criterion which can be used to avoid this phenomenon. Both conditions (fully-projectableness and stability) are necessary. Example 3. Consider the sequence x = VOV with i and j being random and independent. Imagine that the description p = "print 1 forever except from position i + 1" is selected as the shortest description for x and stability is defined in terms of MDL instead of SED. Under these conditions p would be j -stable. On the contrary, this does not happen with SED because p cannot be fully projectable, since there exists a different description p' = "print 1 forever" which is simpler and equivalent to p from position i + 1. There is still another reason to support the previous notion of comprehension as an ontological principle. Why must we avoid rote learning? Why must we anticipate? Why do children innately find more complex patterns than the minimal description (Marcus et al., 1999)? This search for more informative and explanatory hypo- theses instead of the shortest ones may lead to fantasy, but this is not dangerous provided that the system can interact with the world in order to refute some of these hypotheses (Harman, 1965). This informativeness or investment in the hypotheses was advocated by Popper for the scientific method (Popper, 1962), and as we have seen, it is equally applicable for cognition. Even if we make the very strong as- sumption of Occam's razor, i.e., things in nature are not unnecessarily complex, the previous rationale is justified by the fact that, just as every incompressible string has compressible substrings, most compressible strings have incompressible substrings, because there comes a point where the string is so short that it is not worth compressing. If the evidence is presented incrementally, it is better to invest in more informative or general hypotheses instead of finding the optimal one for each chunk, which in the end will not turn out to be part of the whole description of the whole evidence. This rationale leads to the next theorem: THEOREM 1. For every monotone machine /?, there exists a constant c which depends exclusively on f$ such that for every string x of length n with SED(x) = s and l(s) = m such that m &lt; n, and for every partition x = yz such that l(y) &lt; m - c, SED(y) is not equivalent in the limit with s. Proof Consider any string x and SED(x) = s with l(s) = m such that m &lt; n. Take any prefix y such that l(y) &lt; m - c. Consider the description py = "print y for ever" with l(py) = l(y) + d &lt; m - c + d, this constant d being the space which is required for coding "print .. for ever." Since the computational cost of py is linear, say kr • /(jc), it is sufficient to choose c &gt; d + log/:' to ensure that the description py is shorter than s. Jointly, LTp(py)[..l(x)] = l(p(y)) + log(/:' • /(jc)) &lt; m - c + d + log it' + log/(jc) &lt;m- d - log/:' + d + log/:' + log/(jc) = m + log /(jc) &lt; LTp(s)[..l(x)] since l(s) = m and x cannot be printed in less than</page><page sequence="10">456 J. HERNANDEZ-ORALLO l(x) steps. Obviously, LTp(SED(y))[..l(x)] &lt; LTp(py)[J(x)] because SED is the simplest explanation in LT terms. From here, we finally have that SED(y) is simpler (in LT terms) than s. Consequently, s and SED(y) cannot be equivalent in the limit because s = SED(x) is fully projectable and, by definition, there cannot exist a description with less LT equivalent in the limit. □ Although the result is still worse for the MDL principle, as shown in Example 1, the theorem seems to also discredit SED. However, if we demand stability this does not happen, because py would not be stable. The idea of stability or cross-validation is then supported by the previous theorem. In fact, it is an innate aesthetic preference in the explanations that human beings generate. Why does answer 23 seem better to the series "3,7,11,15,19, ..." than answer 3? Why is 23 the "correct" solution in IQ tests? In Hofstadter's words, "it would be nice if we could define intelligence in some other way than 'that which gets the same meaning out of a sequence of symbols as we do"' (Hofstadter, 1979). Despite the fact that hardly any definition can completely grasp the intuitive notion that generates it, the arguments provided in this section allow us to state that SED descriptions which are stable formalise the notion that comprehension has taken place. The following section is devoted to ensuring that the descriptions get the same meaning from a sequence. It also discusses how to measure the difficulty of an instance. 4. Testing Comprehension Ability Theoretically, there are two ways to know whether a system's operation is com- pliant with certain requirements: by inspecting its code (or program) or by testing its behaviour. In general, for complex systems, as has been finally recognised in software engineering, verification must be experimental in practice, by means of sets of tests. However, it is an open and difficult problem to devise a complete specification of intelligence, mainly because it depends on a consensus on the abilities that an intelligent system should have. Nonetheless, it is currently possible to distinguish certain abilities that are fundamental for intelligence. A verification of intelligence behaviour should begin with these fundamental traits and gradually add more diverse (factorial) exercises in order to make the test set more robust. Traditionally, comprehending is recognised as the most important trait of intelli- gence, and we have formalised it in a computational framework. This allows for the construction of exercises for a test which are selected theoretically rather than experimentally. This does not mean that they are necessarily more representative, but at least we know exactly what is measured, quite unlike psychometrics. However, if we intend to measure comprehensibility there are still two ques- tions to solve. First, we must design unquestionable exercises, in order to avoid the "subjectivity objection" of IQ tests. Secondly, we require an absolute referent of comprehension difficulty in order to give a non-Boolean score which is inde-</page><page sequence="11">BEYOND THE TURING TEST 457 pendent to the mean ability of the subjects or society who have taken the test before. With respect to the notion of unquestionability, psychometrics has striven to show that it is not absurd to talk about the "correct" solution, at least if by "correct" we mean the prediction of the simplest comprehensive answer. Its rationale is that if the great majority matches some solution it is because there are not alternative explanations of similar complexity, and, consequently, it is the most plausible one. However, this assertion is made from a very subjective and informal point of view. At first glance, it seems that given some data x of length n, we can still modify any explanation p with the addendum "Execute p but print aT every m symbols that are printed beginning from n -f 1." This alternative explanation would be com- prehensive for the data but would differ from p in the limit. It would only be a little longer and this would depend on the descriptional machine used.* To avoid these problems in an implementation of a test, the following constructions are sufficient: DEFINITION 8 (Plausibility). A fully projectable description p for a string x given y is (c, d)-plausible on the right in a monotone machine ft iff Vi, 0 &lt; i &lt; d : L7/,(S£D/J(j:.I-|y))[../(x-l-)] + c&gt; LTfi(p\y)[.Mx^)l Intuitively, a description is (c, d)-plausible if it is at most c bits longer (in LT terms) than the best explanation for x, and this holds even if we remove up to d elements from the right of x. DEFINITION 9 (Unquestionability). A fully projectable description p for x is (c, dyunquestionable in a monotone machine fi iff it is (c, d)-plausible and there does not exist another (c, d)-plausible description p1 for x. This is a more restrictive condition as c and d are greater. In order to still obtain some unquestionable descriptions we must make the strings larger. However, as we shall see below, if c and d are tuned conveniently for a concrete descriptional mech- anism, the tests can still be composed of short strings x such that their SEDp(x) is (c, d)-unquestionable. The second question was to ascertain the difficulty of each problem, in or- der to be able to give a test set of exercises of different comprehensibility. The idea is to relate this difficulty to the complexity of the simplest (in LT terms) explanation (i.e., Et) and the explicitness of the description wit. the data. To do this, we adapt the definition of potential (Li and Vitinyi, 1997) and the notion of k-compressibility to the corresponding notion of comprehensibility: DEFINITION 10. A string x is k-incomprehensible given y, denoted by incomp(x\y), in a descriptional system f$ iff k is the least positive integer number such that: Ktmp(SEDp(x\y)\(x, y)) &lt;k- logZ(jc). * This is a very difficult problem which can be addressed by recognising the addendum as a non-reinforced part (an exception). This has been done in Hern&amp;idez-Orallo (2000) for uni- versal (constructive) representations, but it is not easy to extend the framework to any universal representations (Herndndez-Orallo and Minaya-Collado, 1998).</page><page sequence="12">458 J. HERNANDEZ-ORALLO The use of the factor log l(x) is to compensate the fact that x must be printed and, therefore, for all x we have Et(x) &gt; log/(jc). E.g., consider a string x of length 256 and y = e, with Et(x) = 50; its comprehensibility is k- 7. Definition 10 measures the difficulty of finding SED(x\y) from x and y, be- cause descriptions of the form "repeat x forever" for xn have a high absolute Et value (to quote x) but low relative complexity (w.r.t. (jc, y)). Now a generic test of the ability of comprehension can be constructed by generating a series of strings of gradual comprehensibility. Unquestionability is achieved by providing "redundant" information up to a limit, because, otherwise, the problems would be much too long. However, there must be sufficient support to not distort its difficulty. In other words, when the subject finds the solution, it should be sure that he/she/it has found it. For instance, given the series "a, c, c, a, c, c, c, a, c, c, c, c, a, . . . " it seems logical to expect that the series would follow "c, c, c, c, c, a, c, . . . ," so it is redundant to present more than the necessary symbols, but less would make the answer questionable. We can finally obtain the degree of intelligence (comprehensibility factor) of a given system as the value which results from applying the following test: DEFINITION 11 (C-Test). Let us select a descriptional system* p which is sufficiently expressive and impartial, and which is composed of an alphabet of symbols Sip and a set of operations 0^. These operations manipulate these symbols, and they have a corresponding cost (or length). We provide (or programme) the alphabet, operations and cost to S. Depending on the expected intelligence of a system we select a sufficiently wide range I..K of difficulty. For each k = I..K, we randomly choose p sequences xk-p which are k-incomprehensible, (c, d)-plausible, (c, d)-unquestionable and s-stable with s &gt; r, r being the number of redundant symbols (or hints) of each exercise. The questions are the K • p sequences without their s - r elements (jc_'£+r)). We give them to S and we ask for the following element according to the best explanation that S is able to construct with Qp and 0^. We leave 5 a fixed time t and we record its answers: guess(S, **J+r+1). The result of this test of comprehensibility (or C-test) is measured as: /(S)= £ f. 53«r[^+1,«««5(5,jc^+1)] k=\..K i=\..p the function hit is usually measured as hit[a, b] = 1 if a = b and 0 otherwise (neg- ative values could be used to penalise errors). The value e is simply for weighting the difficult questions (e = 0 means that all have the same weight). * From now, we shall deal with any type of descriptional system since any machine can be "wrapped" into a monotone machine or, alternatively, monotone complexity can be computed on non-monotone machines by providing the length of the input string in an additional input tape.</page><page sequence="13">BEYOND THE TURING TEST 459 In an informal way, the test measures the ability of finding the best explanation for sequences of increasing comprehensibility in a fixed time.* The relevance of the time given and the weighting e of the difficult exercises is still an open question. I would be in favor of either including (logarithmically) the time in the resulting value I(S) or fixing a high time and penalising wrong results with a negative value of hit [a, b] (blank answers with a zero value). However, this would create problems if you would ever want to measure two different things: the intelligence of a subject and the speed of the subject. 5. Measurement of Pretended Intelligent Systems The preceding test is applicable to any system whose degree of intelligence is questioned. The test can be used for humans, animals, computers, extraterrestrial beings and any combination of these by appropriately selecting the descriptional system and the rest of parameters of the test. Although Definition 11 evaluates a single ability, there are still many ways to devise a specific test. An implementation of the test is described in Herndndez- Orallo and Minaya-Collado (1998). The abstract state machine which was used is not monotone, but this difference is not relevant due to the stability condition. A variety of strings of different comprehensibility in that machine were generated. Although the set of fc -potent numbers of length at most n can be computed in polynomial time in n (see a proof in Li and Vitdnyi, 1997), the cost of O(nk) forces the use of heuristics. In the same way, m fully-projectable descriptions were checked up to a given length limit m. Finally, a sieve was applied in order to obtain only (c, d)-plausible, (c, d)-unquestionable and s-stable sequences. The creation of the test took several days in all. The same work presents the results** of applying the test to 65 subjects from the species Homo Sapiens Sapiens aged between 14 and 32 years (jointly with a classic test of intelligence, the European IQ Test). The correlation between both tests was 0.77. This value does justify a further more exhaustive study on larger groups and several variations derived from Definition 11. Another remarkable experimental result shown in Figure 1 is that the relation between the hit ratio (the percentage of subjects that gave the right answer) and ^-incomprehensibility is direct, which suggests that comprehensibility really estimates the difficulty of each string. * One relevant feature of the test is that, although the subject is supposed to have a partic- ular universal descriptional system &lt;j&gt;s with a particular background knowledge (life experience) fly, it is given a descriptional system 0 over it, which highly minimises the influence of the dif- ference between the computations performed by &lt;ps and another subject &lt;f&gt;t, i.e., the difference between Ets(x\(Bs, P)) and Ett(x\(Bt,P)). This makes it possible for the notions of plausibility and unquestionability to be similar for both subjects. ** For more information about the experimental setup, methodology, questionnaire, sub- jects, times, etc., consult Hernandez-Orallo and Minaya-Collado (1998). The web page http://www.dsic.upv.es/~jorallo/itests/ includes an up-to-date summary of results and an archive of past and on-going tests.</page><page sequence="14">460 J. HERNANDEZ-ORALLO Figure 1. Relation between hit ratio and fc -incomprehensibility. Logically, the C-tests cannot be expected to substitute contrasted and widely used IQ tests for the moment. Nonetheless, this could be a starting point towards a theoretical foundation of psychometrics which is free from the Homo Sapiens as a reference. However, it is not human intelligence but non-human intelligence which ur- gently needs to be measured. A formal declaration of what is expected from an intelligent system should allow for two important things: to derive more intelli- gent systems from a more concrete specification and, secondly, to evaluate them. Definition 1 1 provides a first step for both, since a detailed scale for measuring the progress (in one intelligence factor) of generic systems in AI can help to establish the first one. As any other field of science, a great advance in a discipline occurs when one of its topics can be measured in an effective and justified way. Just as aeronautics needs altimeters and speedometers, AI requires measurements of different factors of intelligence. Nowadays, the initial aim of making general systems is still represented by two subfields of AI: automated reasoning and machine learning. Automated theorem provers are able to solve complex problems from different fields of mathematics. The great advance of automated deduction over the last two decades can be mainly attributed to the existence of sets of problems for comparing different systems. These sets have evolved and grown to huge and complete libraries of theorem proving problems, such as TPTP (Suttner and Sutcliffe, 1998). Machine learning is also taking a more experimental character and different systems (from different paradigms) are evaluated according to classical (toy) problems in the literature rather than exclusively accepting the results for classes of problems which are theoretically expected to occur. In my opinion, experimental test sets should also be automatically generated or at least accompanied by a theoretical measurement about the complexity of each exercise. This complexity could be obtained by adapting the previous notions to several representational languages.</page><page sequence="15">BEYOND THE TURING TEST 46 1 6. Factorisation During the XXth century, psychometrics strove to differentiate between back- ground knowledge (either evolutionary-acquired or life-acquired) and "liquid intelligence" (or individual adaptability). Accordingly, exercises from IQ tests are strictly selected to avoid the influence of background knowledge in order to be fool- proof to "idiots savants." Even with this restriction, there are still many knowledge- independent abilities (or factors) to measure. Some factors usually found in psychological tests are "verbal ability," "visual ability," "calculation/deductive ability," etc. The C-test measures one factor, which could empirically be identified with the g factor or liquid intelligence. There are more partially independent factors which could be measured by using extensions of the framework presented in the previous section. For instance, other inductive abilities, such as knowledge applic- ability, contextualisation and knowledge construction ability, can be measured in the following way: - Knowledge Applicability (or "crystallized intelligence"): a background know- ledge B and a set of unquestionable (with or without B) sequences jc/ are provided such that incomp(Xi\B) = incomp(x{) - u but still SED(xt\B) = SED(xt). The difference in performance between cases with B and without B is recorded. This test would actually measure the application of the back- ground knowledge depending on two parameters: the complexity of B and the usefulness of B, measured by u. - Contextualisation: it is measured in a way similar to knowledge applicability but different contexts B\, B2, . . . , Bj are supplied with different sequences xiyt such that incomp(Xij\Bt) = incomp(xit) - u. This multiplicity of back- ground knowledge (a new parameter T) distinguishes this factor from the previous one. - Knowledge Construction (or learning from precedents): a set of sequences jc/ is provided such that there exists a common knowledge or context B (now not given) and a constant u such that for incomp(Xi\B) &lt; incomp(x{) - u. A significant increase in performance must take place between the first sequence and the later sequences. The parameters are the same as the first case, the complexity of B and the constant u. It is obvious that these three factors should correlate with the comprehension abil- ity. Other non-inductive factors, especially deductive abilities, are seemingly easier to measure because there is no problem of unquestionability. It is expected that ana- logical and abductive abilities* can be shown to be closely connected to inductive and deductive abilities both theoretically and experimentally. Inductive abilities, especially knowledge applicability, may also be correlated with deductive abilities * See an attempt to measure them in Hern£ndez-Orallo and Minaya-Collado (1998).</page><page sequence="16">462 J. HERNANDEZ-ORALLO (any hypothesis must be checked deductively) and these may also correlate with the idea of congruence or coherence, since it has been shown to be theoretically equivalent to constraint satisfaction (Thagard, 1989). To show experimental correlations (especially for non-human and/or non-adult subjects), the presentation of the test must change slightly. The exercises should be given one by one and, after each guess, the subject must be given the correct answer (rewards and penalties can be used instead). This has two advantages: there is no need for the subject to understand natural language (or any language) in order to explain the purpose of the test to the subject, and there is no need to tell which factor or purpose is to be measured in each part of the test. There is also one disadvantage, deductive problems should be posed in terms of "learn to solve" or "learn to prove" in a way similar to that used by Solomonoff (1957) suggested with simple problems of arithmetic. Properly, this problem is not prediction but classi- fying, i.e., to know which elements could be "theorems" (class true) in that model. In this sense, it would be interesting to evaluate non-sequential induction, where an unordered set of elements is given as evidence, in the way that Solomonoff has recently formalised (Solomonoff, 1999). In fact, non-sequential induction would be more related to deductive ability while sequential induction would be more related to calculation ability. Some other factors are more related to intentionality than intensionality and general intelligence. These are reactivity, pro-activity and interactivity, that could eventually be measured by modifying the C-test. This could be done by adopting notions from Query Learning paradigms (Angluin, 1988) or by using interactive Turing machines. However, not every factor will be meaningful for intelligence. Factors like "playing chess well" are much too specific to be robust to background knowledge. Other factors will result in being highly correlated (experimentally or theoretically) to other more distinct factors. The influence of the description^ mechanism should also be studied for each factor. In the end, the matter at issue is then to refine and extend the previous notions in order to make factorial and grounded tests of intelligence, knowing exactly what is measured. This is an urgent and fascinating task for AI. 7. The C-test and the Turing Test The imitation game was conceived by Turing to dissipate the doubts about pos- sibly non-human intelligent beings. He left no place for human exclusivism and transcendentalism: intelligence can be evaluated by a solely behavioural test. Un- fortunately, instead of recognising this as his most important contribution, the test is still considered "a goal" in AI. Nonetheless, this view has been responded to by many authors, whose criticism is that the TT provides little information on to what intelligence really is; it is just a test of humanness (Fostel, 1993), that, in fact, if applied to human beings, yields many paradoxes. The result of applying</page><page sequence="17">BEYOND THE TURING TEST 463 it to ourselves is a recursive trap which is unable to answer the question of how intelligent the Homo Sapiens is. There have been unsuccessful attempts to correct the two main problems of the Turing Test for measuring intelligence: its informal character and its anthro- pocentrism. There is still a third problem, which is the need for several intelligent "judges" and a "referent" to implement the test. The self-reference question arises again: Who is the first intelligent being to start the game? These and other problems are incarnated in short-time versions of the TT, such as the Loebner Prize, which usually awards the participant who has devised the system which is better able to cheat the judges. Furthermore, there is no way of knowing who is cheating, the system or its designer. However, if fairly played (and for long), the imitation game is a hard examina- tion for any intended intelligent system. It is extremely difficult to behave like an average human being of this epoch (it is even difficult for some human beings). For a non-human-contextualised being, it would be required to comprehend the complex behaviour of human beings of these times, their evolution-acquired traits, their language, their culture, their limitations, etc. It is much easier then to try to cheat the judges. On the contrary, the C-tests, as they have been presented, are necessary (at least to obtain a minimum value of 7(5)) but not sufficient (other important factors should be measured as well). It has already been suggested that both kinds of tests (TT and factorial) could be combined in order to give a more accurate intelligence test, because "if is this posing of puzzles in arbitrary domains that is the hardest part of the Turing Test, and a part that no program has yet passed" (Shapiro, 1992). The motivation for such a combination is quite the same reason why IQ-tests are used jointly with an interview in post selections and for other evaluation purposes. However, the interview just shows that the questionnaire is incomplete or that the abilities that are measured in the interview are less related to intellect. In my opinion, the TT should be celebrated as an extremely valuable philo- sophical exercise about the behavioural character of intelligence. For practical purposes, though, it will be necessary to implement progressively more accurate computational tests of different cognitive abilities. 8. Conclusions Turing devised a way of distinguishing intelligent beings from non-intelligent ones without solving the problem of what intelligence is. In fact, an imitation game is the only way to make sense from such an apparent paradox. However, in practice, this approach has numerous limitations and problems which make it useless for application in AI. Experience has shown that it is difficult to develop non-human intelligence without a computational formalisation of the problem we are trying to solve.</page><page sequence="18">464 J. HERNANDEZ-ORALLO It is high time to address the fundamental problem: what intelligence is. This paper presents a tiny first step along this line. A formalisation of one of the main factors of intelligence, the g factor or liquid intelligence is defined computationally. This definition has been used to develop an intelligence test, which is very different from the TT and which is in compliance with classical IQ tests. Like the latter, it distinguishes acquired knowledge from liquid intelligence. More importantly, the C-Test, unlike the TT and IQ tests, is not anthropomorphic. The factor is defined as the ability to find comprehensive explanations, and thus is meaningful. This makes it philosophically acceptable: intelligence is what allows us to comprehend the world. Sooner or later we need to face the fact that computers will come closer and closer to human intelligence. Once this milestone of AI has been achieved, it will be absolutely necessary to have an objective measure of intelligence, in order to solve the incipient technical and ethical problems that could be derived from that point. The paradigm presented in this paper allows for the projection of the measurement of intelligence beyond human intelligence. Once beyond the TT, many more interesting questions present themselves. How many independent computational factors does human intelligence have? How in- telligent is the Homo Sapiens? Which factors make a chimpanzee significantly different from the Homo Sapiens? How intelligent can machines be with the current computational power? Psychometrics, Anthropology, Zoology and AI have only partially dealt with some of these questions. Only a science of intelligence which is grounded in theoretical computer science and information theory could answer these questions thoroughly. Acknowledgements I am much obliged to the main inspirers of this work, G. Chaitin and D. Hofstadter, for their encouraging comments, especially during 1997 when the main ideas were taking shape. Since then, the work has matured with the help of many collabora- tions and suggestions: K. Araque, R. Barreiro, R. Beneyto, N.T. Crook, E. Fueyo, I. Garcia, E. Hernandez, J.M. Lorente, N. Minaya, I. Soto and P. Thagard. Finally, I am especially grateful to the referees of this special issue for their justifiably incisive comments and numerous corrections on an earlier version of this paper. References Angluin, D., 1988, "Queries and concept learning" Machine Learning 2, 319-342. Barron, A., Rissanen, J., and Yu, B., 1998, The minimum description length principle in coding and modeling," IEEE Transactions on Information Theory 44, 2743-2760. Bien, Z., Kim Y.T., and Yang, S.H., 1998, "How to measure the machine intelligence quotient (MIQ): Two methods and applications," pp. 03.15-03.22 in World Automation Congress (WAC), Albuquerque, NM: TSI Press.</page><page sequence="19">BEYOND THE TURING TEST 465 Blum, L. and Blum, M., 1975, "Towards a mathematical theory of inductive inference," Information and Control 28,125-155. Bochenski, J.M., 1965, The Methods of Contemporary Thought, Dordrecht: D. Reidel. Bradford P.G. and Wollowski, M., 1995, "A formalization of the Turing test (The Turing test as an interactive proof system)," SIGART Bulletin 6, 10. Chaitin, G.J., 1982, "Godel's theorem and information," International Journal of Theoretical Physics 21, 941-954. Chandrasekaran, B., 1990, "What kind of information processing is intelligence?" pp. 14-46 in Foundations of AI: A Source Book, D. Partridge and Y. Wilks, eds., Cambridge: Cambridge University Press. Evans, T.G., 1963, "A heuristic program to solve geometric analogy problems," Ph.D. Thesis, MIT, Cambridge, MA. Also in Minsky, M., ed., 1968, Semantic Information Processing, Cambridge, MA: MIT Press. Eysenck, H.J., 1979, The Structure and Measurement of Intelligence, Berlin: Springer- Verlag. Fostel, G., 1993, "The Turing test is for the birds," SIGART Bulletin 4, 7-8. Gammerman, A. and Vovk, V., eds., 1999, Special Issue on Kolmogorov Complexity, The Computer Journal 42. Gold, E.M., 1967, "Language identification in the limit," Information &amp; Control 10, 447-474. Harman, G., 1965, "The inference to the best explanation," Philosophical Review 74, 88-95. Hamad, S., 1992, 'The Turing test is not a trick: Turing indistinguishability is a scientific criterion," SIGART Bulletin 3. 9-10. Herken, R., 1994, The Universal Turing Machine: A Half-Century Survey, 2nd edn., Oxford: Oxford University Press. Hern£ndez-Orallo, J., 2000, "Constructive reinforcement learning," International Journal of Intelli- gent Systems 15, 241-264. Herndndez-Orallo, J. and Garcia- Varea, I., 1998, "Explanatory and creative alternatives to the MDL principle," pp. 17-19 in Proceedings of the International Conference on Model Based Reasoning (MBR'98), Pavia, 1998, S. Rini and G. Poletti, eds., University of Pavia, Italy. Also to appear in Foundations of Science. Herna'ndez-Orallo, J. and Minaya-Collado, N., 1998, "A formal definition of intelligence based on an intensional variant of Kolmogorov complexity," pp. 146-163 in Proceedings of the International Symposium of Engineers of Intelligent Systems (EIS'98), Tenerife, Spain. ICSC Academic Press. Hofstadter, D.R., 1979, Godel, Escher, Bach. An Eternal Golden Braid, New York: Basic Books. Johnson, W.L., 1992, "Needed: A new test of intelligence," SIGART Bulletin 3, 7-9. Kolmogorov, A.N., 1965, "Three approaches to the quantitative definition of information," Problems Information Transmission 1, 1-7. Koppel, M., 1987, "Complexity, depth, and sophistication," Complex Systems 1, 1087-1091. Larsson, J.E., 1993, "The Turing test misunderstood," SIGART Bulletin 4, 10. Levin, L.A., 1973, "Universal search problems," Problems Information Transmission 9, 265-266. Li, M. and Vitinyi, P., 1997, An Introduction to Kolmogorov Complexity and Its Applications, 2nd edn., Berlin: Springer- Verlag. Marcus, G.F., Vijayan, S., Bandi Rao, S., and Vishton, P.M., 1998, "Rule learning by seven-month- old infants," Science 283, 77-80. Millican, P.J.R. and Clark, A., eds., 1996, Machines and Thought. The Legacy of Alan Turing, Vol. I, Oxford: Clarendon Press. Neisser, U., Boodoo, G., Bouchard, T.J., Boykin, A.W., Brody, N., Ceci, S.J., Halpem, D.F., Lochlin, J.C., Perloff, R., Sternberg, R.J., and Urbina, S., 1996, "Intelligence: Knowns and unknowns," American Psychologist 51, 77-101. Popper, K.R., 1962, Conjectures and Refutations: The Growth of Scientific Knowledge, New York: Basic Books.</page><page sequence="20">466 J. HERNANDEZ-ORALLO Preston, B., 1991, "AI, anthropocentrism, and the evolution of * intelligence'," Minds and Machines 1, 259-277. Rissanen, J., 1996, "Fisher information and stochastic complexity" IEEE Transactions on Informa- tion Theory TT-42, 40-47. Schnorr, C.P., 1973, "Process complexity and effective random tests," Journal of Computer and Systems Sciences 7, 376-388. Shapiro, S.C., 1992, "The Turing test and The Economist," SIGART Bulletin 3, 10-1 1. Shieber, S.M., 1994, "Lessons from a restricted Turing test," Communications of the ACM 37, 70-78. Simon H. and Kotovsky, K., 1963, "Human acquisition of concepts for sequential patterns," Psychological Review 70, 534-46. Solomonoff, R.J., 1957, "An inductive inference machine," pp. 56-62 in IRE Convention Record, Section on Information Theory, Part 2, New York: Institute of Radio Engineers. Solomonoff, R.J., 1964, "A formal theory of inductive inference," Information &amp; Control 7, 1-22, March, 224-254, June. Solomonoff, R.J., 1978, "Complexity-based induction sytems: Comparisons and convergence theor- ems " IEEE Transactions on Information Theory IT-24, 422-438. Solomonoff, R.J., 1997, "The discovery of algorithmic probability," Journal of Computer and System Sciences 55, 73-88. Solomonoff, R.J., 1999, "Two kinds of probabilistic induction," The Computer Journal 42, 256-259 (Special Issue on "Kolmogorov Complexity"). Spearman, C, 1904, "'General Intelligence' objectively determined and measured," American Journal of Psychology 15, 201-293. Sternberg, R.J., 1977, Intelligence, Information Processing, and Analogical Reasoning, New York: John Wiley &amp; Sons. Sternberg, R.J. and Detterman, D.K., 1986, What is Intelligence? Contemporary Viewpoints on Its Nature and Definition, Norwood, NJ: Ablex. Stonier, T, 1992, Beyond Information. The Natural History of Intelligence, Berlin: Springer- Verlag. Suttner, C.B. and Sutcliffe, G., 1998, "The TPTP problem library: CNF release vl.2.1," Journal of Automated Reasoning 21, 177-203. Thagard, P., 1989, "Explanatory coherence," Behavioural and Brain Sciences 12, 435-502. The Economist (Editorial), 1992, "Artificial stupidity," The Economist, 324, no. 7770, August 1, p. 14. Turing, A.M., 1936, "On computable numbers with an application to the Entscheidungsproblem" Proceedings London Mathematical Society, Series 2 42, 230-265. Correction, 1937, Ibid. 43, 544-546. Turing, A.M., 1950, "Computing machinery and intelligence," Mind 59, 433-460. Valiant, L., 1984, "A theory of the learnable," Communications of the ACM 27, 1 134-1 142. Vitinyi, P. and Li, M., 1997, "On prediction by data compression," pp. 14-30 in Proceedings 9th European Conference on Machine Learning, M. van Someren and G. Widmer, eds., LNAI, Vol. 1224, Berlin: Springer- Verlag. Watanabe, S., 1972, "Pattern recognition as information compression," pp. 31-60 in Frontiers of Pattern Recognition, S. Watanabe, ed., New York: Academic Press. Zvonkin, A.K. and Levin, L.A., 1970, 'The complexity of finite objects and the development of the concepts of information and randomness by means of the Theory of Algorithms," Russian Mathematical Surveys 25, 83-124.</page></plain_text>
<plain_text><page sequence="1">Science áf Society, Vol. 66, No. 2, Summer 2002, 228-255 V Forms of Physical Determination EFTICHIOS BITSAKIS ABSTRACT: Four forms of physical determination are presently known in physics: classical or mechanical determination, related to classical mechanics; dynamical determination, related to the relativistic theories of electromagnetism and gravitation; classi- cal statistical determination, related to classical statistical theo- ries; and quantum statistical determination, related to modern microphysics. The concept of interaction is a fundamental on- tological category, a moment of which is the causal relation; in- teraction is also local, taking place at finite velocities. Following the evolution of physical theories, it is possible to attest to the historicity of the concept of interaction and, accordingly, of the categories of interaction and determination. According to the Copenhagen School, causality and locality are incompatible with quantum mechanics. On the contrary, according to the point of view developed here, realism, causality and locality are simul- taneously compatible in the domain of microphysics. AND PHILOSOPHY INTERACT in a historically de- SCIENCE termined relation of opposition and unity. The scientific revo- lutions of the 20th century revived and renewed philosophy. Philosophy in turn contributed to the debates concerning the foun- dations of the sciences and especially of physics; it also added, more generally, to the epistemological analysis and interpretation of sci- entific theories. Physics was the revolutionary science par excellence of the first decades of the 20th century. Relativistic theories and quantum me- chanics revolutionized our conceptions of matter and energy, space and time, causality and chance. The debate continues in the present with new problems, new data, and new arguments. The problem of 228</page><page sequence="2">FORMS OF PHYSICAL DETERMINATION 229 causality has been central. Recent theoretical propositions and ex- periments have given the discussion a new impetus; "Histoire terminée, histoire interminable" as Louis Althusser might say. Three postulates of the classical theories have recently been called into question: realism, causality and locality. The determination of physical processes is realized by the mediation of the four presently known physical interactions: electromagnetic, strong, weak and gravi- tational. Newtonian physics was intuitively realistic. It also proposed that interactions are transmitted with an infinite velocity. This implies that between cause and effect there is no temporal hysteresis; that phenomena are instantaneous events. This is non-locality, Newtonian physics was therefore realistic, deterministic and non-local. Electro- magnetic theory and relativity, on the contrary, postulate that physi- cal interactions occur with finite velocity. For this reason, phenom- ena are now considered as processes realized in space and time, and characterized by an " épaisseur temporelle" a temporal hysteresis between cause and effect. The theories of Maxwell and Einstein - relativistic electromag- netism and relativistic gravitation - demonstrated the real content of physical interactions and, consequently, the concrete physical coun- terpart of the principle of causality in this domain. They also estab- lished the scientific status of the principle of locality. Consequently, classical field theories are realistic, deterministic and local theories. Quantum mechanics, in its turn, challenged these postulates. Quantum mechanics, and modern microphysics more generally, are incompatible, according to the adherents of the positivist and anti- realist interpretation, with the principle of realism. Microparticles are considered by this school to be simple potentialities, or even worse, simple mathematical forms. Neo-Pythagorism found a fertile ground in microphysics. More than that: the probabilistic character of quan- tum mechanics (QM) denoted, according to the Copenhagen Inter- pretation, the failure of causality and determinism. The debate about the character of QM began 73 years ago (1927, at the meetings of Como and Solvay) . According to more recent theo- retical and experimental research, even the principle of locality is not valid in physics. But then the deterministic order of nature becomes a subjective epiphenomenon. It is possible for the present to influ- ence the past, to telegraph to the past, to influence the future; it is possible to predict the future. Anti-physics, parapsychology and</page><page sequence="3">230 SCIENCE àf SOCIETY miracles are ail possible. Anti-realism, indeterminism and non-locality are considered by many physicists and philosophers as having been proved by developments in modern microphysics. Evidently, the very possibility of a rational understanding of the world is at stake (Jac- quard, 1994; Ortoli and Pharabond, 1984; Wilber, 1984; Science et Conscience, 1980). It may be useful to begin by drawing a careful distinction. Cau- sality and determinism are commonly treated as identical notions. There is, however, an essential difference between the two catego- ries: according to the principle of causality, there are causes in nature, and phenomena are produced by one or more of these causes. De- terminism, on the other hand, posits that phenomena are determined by their causes in a specific way. The different forms of determinism express the modalities under which this determination is realized. The law is the formal expression of the relations between cause (or causes) and effect. Positivism and Materialism: Opposed Conceptions of Nature For scientific realism (Bitsakis, 1993) the causal relation is ob- jective: it is an internal, necessary and genetic relation. Consequently, the categories of cause, causality, determinism and law have an on tic status: they express objective relations in nature and not only rela- tions between our "ideas," "perceptions," "data" (empiricism), or a priori forms of reason (Kant) . For scientific realism and materialism, these categories are ontological and not simply epistemic. Laws have a counterpart in nature. They have an ontic status, being at the same time subjective in their formulation (Lenin). They are historically relative; at the same time, they possess a historically determined objectivity. (Example: matter is constituted of atoms. This is an objective truth. At the same time, this truth is historically deter- mined and relative, as it concerns our specific knowledge of the atoms). If there is a relation of morphism between nature and our concepts and laws, this morphism concerns only a subset of the ele- ments of reality and the relations existing in nature. "Every determi- nation is negation," wrote Spinoza. Therefore, if the concept expresses that which is essential, it is always an impoverished representation of reality, or of the relation it represents. Consequently, contemporary realism can legitimately affirm that there are laws of nature, without</page><page sequence="4">FORMS OF PHYSICAL DETERMINATION 231 falling into a pre-critical ontologism. If the Universe is a totality, then interaction and mutual determination are elevated to the status of fundamental ontological categories. Cause and effect are, therefore, moments of the connection and the mutual determination of the "unbroken wholeness" (David Böhm) which is the Universe. According to Hume, on the contrary, there is no intrinsic neces- sity. It is senseless, he says, to define a cause by postulating that some- thing produces something else. There is no reason to suppose that everything must have a cause. The causal relation is simply reduced to a temporal order: if A, then B. Consequently, causal relations de- scribe regularities observed in nature, nothing more: "Should any one leave this instance and pretend to define a cause, by saying it is some- thing productive of another? It is evident that he would say nothing. For what does he mean by production?" (Hume, 1960, 77). Against this, one might argue that the simple identity of A and B reduces the causal relation to a tautology. The difference between cause and ef- fect and the emergence of the new are essential features of the causal relation. Hume's conception is part of a more general world view: it is il- legitimate, he affirms, to accept the existence of external objects as the source of our sense data: "By what arguments can it be proved that the perceptions of the mind must be caused by external objects different from them though resembling them? Experience is and must be entirely silent" (Hume, 1963, 119). However, experience is today eloquent. Physics, chemistry and physiology have falsified Hume: they have explained the processes through which the exter- nal object becomes an element of our consciousness. Positivism abandoned Kant in favor of Hume. There is no cause and effect in nature, declared Ernst Mach. Nature has only an indi- vidual existence. It simply is. According to Mach, there is no necessity other than the logical one. The distinguished physicist and philoso- pher was clear. Poincaré, in his turn, maintained that the internal harmony of the world is the only objective reality. The great mathema- tician was one of the eminent representatives of conventionalism. The different trends of contemporary empiricism developed, by using the language of "logic," the fundamental theses of classi- cal empiricism. Metaphysical propositions, maintained Carnap, are neither true, nor false. They are out of the domain of knowledge. The object of the philosophy of nature, he says, is the logical analy-</page><page sequence="5">232 SCIENCE &amp; SOCIETY sis of science. "Metaphysical" statements are devoid of theoretical meaning. Hume was right, according to Carnap, to deprive the causal re- lation of intrinsic necessity. Yet it is possible, he says, to introduce the concept of necessity, under the condition that its use does not go beyond the limits of modal logic and that one does not give it a "meta- physical" meaning. Concepts like the relation between cause and effect concern simply linguistic forms. Causal relation means, sim- ply, predictability. The existence of probabilistic laws, in particular, means the breakdown of determinism. Wittgenstein, from his per- spective, maintained that belief in the causal nexus is a superstition and that the law of causality is not a law, but a form of law (Mach, 1904; 1959; Carnap, n.d.; 1973; Wittgenstein, 1961). The ideas of positivism-empiricism found a fertile soil, especially in the domain of microphysics. The probabilistic character of its laws was the starting point of an anti-realist and indeterministic current that developed in the 1930s, and has not yet lost its audience. By this route, the particularities of microphysics, blended with empiricist, idealistic and spiritualist prejudices, produced an enormous litera- ture, having indeterminism as its common denominator (Bitsakis, 1988a; 1983). Mechanistic Determinism and Its Limits Before going on to QM, we must discuss the two classical forms of determination. Mechanistic (or Laplacian) determinism constitutes one of the principal aspects of the mechanistic world view. Its elaboration is connected with the development of the sciences, especially mechan- ics, in the 17th and following centuries. For classical mechanics the values of the parameters characteriz- ing the state of a particle are determined for any given moment, if one knows their values in a given initial moment. Consequently, the motion of the particle is strictly determined from its initial state and the physical interactions involved. So, the probability of prevision of its state in a subsequent moment is equal to unity. Classical mechan- ics was thus intrinsically determinist. Moreover, in contradiction with the (false) principle of action- at-a-dis tance, classical physics accepted the separability of physical</page><page sequence="6">FORMS OF PHYSICAL DETERMINATION 233 systems. In fact, however, the postulated non-locality of interactions entails non-separability. Consequently, the separability tacitly ac- cepted by classical physics was incompatible with the notion of action- at-a-dis tance. (We will see later the importance of this problem.) Classical physics also accepted the concept that measurement does not disturb the state of a system. Consequently, the ensemble of the observables defining a state were mutually compatible. In this way, classical physics held that it is (in principle) possible to measure all the variables defining the state of a particle and to define this state rigorously. This theoretical possibility constituted the foundation of mechanistic determinism. Realism, determinism and non-locality constituted the foundations of classical mechanics. Let us now try to see the logical aspect of the problem. Non- perturbation and compatibility of the variables mean that the system conserves its identity during measurement. Compatibility of the vari- ables, on the other side, implies compatibility of the ensemble of propositions concerning the system. This implies, in turn, that the structure of the propositions concerning a classical system is Bool- ean. But the Boolean structure is the structure of formal logic, that is to say, of the logic of identity. This logic concords with the mecha- nistic conception of nature.1 A necessary condition for a theory to be deterministic is that its logic is Boolean. However, this condition is not sufficient. A neces- sary and sufficient condition for a Boolean system with finite degrees of freedom to be deterministic is its atomicity. The atomicity of a logic and determinism are equivalent (Kronfli, 1970, 395; 1971, 141). But atomicity is but another expression for the conservation of identity, that is to say, for the absence of production of new elements of real- ity. The postulates of classical mechanics constitute a realm of abstract beings (Galilean particles), conserving their identity forever. 1 The English mathematician George Boole was a seminal thinker of the mid-19th century. In "The Laws of Thought, on Which are Found the Mathematical Theories of Logic and Probabilities" (1854), he showed the close relationship between mathematical and logi- cal structures. In 1936 Birkhoff and von Neumann showed that some of the "weirdness" of QM, especially the superposition principle, entails a modification in logic by replac- ing the Boolean lattice of classical propositions by a non-Boolean lattice of quantum propo- sitions. More recently, Hans Reichenbach, P. Février before the war, and J. M. Jauch, C. Piron, K. Hubner, S. Gudder, T. Brody and many other physicists, philosophers and mathematicians have produced an enormous number of papers and books contributing to the clarification of many logical and physical aspects of QM and, at the same time to the development of logic.</page><page sequence="7">234 SCIENCE àf SOCIETY What is the philosophical meaning of the logical aspect of classi- cal determinism? The logic of identity means that the system conserves its identity during measurement and motion; that, therefore, noth- ing new is produced. The mechanistic model claimed universal va- lidity. According to classical physics, even probabilistic laws were re- ducible to deterministic ones, via the introduction of supplementary variables (the classical hidden variables). In this way chance was ex- cluded from nature: it was considered to be a product of partial knowl- edge, i.e., a subjective category. Fatalism was the inevitable conclu- sion of the mechanistic-Laplacian form of determination. Mechanistic determinism presupposes an ensemble of ideali- zations. But real systems do not respect these idealizations; so, quite apart from the fictitious character of compact atoms and instanta- neous interactions, even in classical mechanics it is impossible to measure exactly the position and the momentum of a particle. More concretely: according to F. Bopp, it is not possible to observe ex- actly a particle's position in phase space. Therefore, the object of research is an ensemble of particles representing all possible states of the single particle we are examining. This virtual ensemble is a statistical ensemble (Bopp, 1957). It should be added that it is not just a question of the possibility of observing a particle's position in phase space; the state possesses objectively a fine structure of sto- chastic character, determined by the interactions of the particle with its milieu. Also, according to Max Born, uncertainties in the initial conditions result in the fact that the predictions of classical mechan- ics do not concern a precise trajectory, but an ensemble of trajec- tories given by a probabilistic distribution. According to Born it is reasonable to formulate classical mechanics as a statistical theory (Born, 1955; 1959). Consequently, the most "deterministic" disci- pline reveals an inherently stochastic character. This shows the in- herent link between chance and necessity, which transcends the irreducible antithesis of the rigid schema of formal logic. The mod- ern concept of deterministic chaos expresses the dialectical anti- thesis between chance and necessity. For Einstein, the real laws of nature are not linear. The theories of Born and Bopp constitute a first indication that the "paradise of simplicity" of the linear laws of mechanics is only an idealized approxi- mation of the laws governing real material particles. Alternatively, in 1892 Henri Poincaré proved that certain mechanical systems whose</page><page sequence="8">FORMS OF PHYSICAL DETERMINATION 235 evolution is governed by Hamilton's equations could display chaotic motion. More recently, E. N. Lorenz (1963) found that a set of three coupled, first-order, non-linear differential equations can lead to chaotic trajectories. Since then, new phenomena and new concepts and formalisms have entered the realm of science: chaos, catastro- phes, fractals, etc. Chaotic behavior is the result of a system's sensitive dependence on initial conditions. "Mathematically, all non-linear dynamical sys- tems with more than two degrees of freedom, i.e., especially biologi- cal, meteorological or economic models, can display chaos and, there- fore, become unpredictable over longer time scales." Chaos denotes a state of disorder and irregularity. However, chaos is not the formal negation of determinism. The concept of deterministic chaos expresses a dialectical unity of opposites. According to H. G. Schuster, "deter- ministic chaos denotes the irregular or chaotic motion that is gener- ated by non-linear systems whose dynamical laws uniquely determine the time evolution of a state of the system from a knowledge of its previous history" (Schuster, 1989). Chaotic behavior is not the result of external sources of noise. It is the result of the property of non-linear systems of separating ini- tially close trajectories exponentially in a bounded region of phase space. The initial order is transformed into its opposite. At the same time, chaos shrinks to order. The concept of strange attractors ex- presses the fact that sufficiently close trajectories are attracted asymp- totically for long enough times. Strange attractors, in their turn, are sensitive to initial conditions. The theories of catastrophes and fractals appeared in the same period as chaos theories. They describe phenomena of movement, evolution, change, creation and destruction of forms. Catastrophe theory is, at the same time, a theory of morphogenesis. Catastro- phes, Arnold says, "are abrupt changes arising as a sudden response of a system to a smooth change in external conditions." This theory is applied to a large class of phenomena - physical, biological, geo- logical, etc. Fractals are complicated forms that tend toward mini- mal surface, volume, etc. The attractor belongs to the category of fractals. The three theories share formal and essential similarities: they concern complicated non-linear systems. They describe phenomena of movement, evolution, change, catastrophe and creation of forms.</page><page sequence="9">236 SCIENCE àf SOCIETY They presuppose causal relations that transcend simple, linear cau- sality (Arnold, 1986; Schuster, 1989; Thorn, 1974). But we must now examine a new form of determination. The Dynamical Form of Determinism Mechanistic determinism is valid at a certain level of abstrac- tion, for phenomena of rather macroscopic order (motion, colli- sion, diffusion of rigid bodies, etc). However, even in these cases, non-mechanical phenomena (for example, heat) are generated. On the other hand, the concept of force, foundation of mechanics and of the mechanistic form of determination, has been a mystery for phys- ics. The fictitious nature of this concept was demonstrated by the rela- tivistic theories. The passage from macroscopic physics to the study of microscopic realities and phenomena brought out the limits of the mechanistic conception. In fact, the development of electromagnetism proved that there are not only coulombian "forces" (forces propagated on the straight line connecting two particles) . There are also forces perpendicular to this line. And, most important, forces (that is to say, interactions) are not propagated with infinite velocity. Consequently, determina- tion is not instantaneous: phenomena are processes realized in space and time, and therefore possess an "épaisseur temporelle." But there is more: electromagnetic waves are emitted and absorbed. They con- stitute a new form of reality, incompatible with mechanism. The same would be established later for gravitational waves, as well as for weak and strong interactions. We therefore have processes of creation and destruction of forms of matter. The laws of radiation oriented research to the more profound structures of matter. The field was the new reality, inde- pendent of its source, possessing qualitative characteristics and propagating at a finite velocity. This reality, that of electromagnetic waves, is the agent of a new form of determination - the dynami- cal - which is different from mechanistic determination in crucial respects. With the electromagnetism of Maxwell, its relativistic generali- zation, and Einstein's theory of gravitation, interaction became a fundamental concept of physics possessing concrete forms and con- stituting a new reality, incompatible with the mechanistic paradigm.</page><page sequence="10">FORMS OF PHYSICAL DETERMINATION 237 Interaction, causality and determinism thus became correlated in an intrinsic way (Bitsakis, 1997). During the first decades of the 19th century, the quantal nature of micro-entities was not manifest. However, the regularities and laws of statistical ensembles (laws of gases, laws of chemistry) indicated the existence of atoms. These phenomena, where chance plays an essential role, constituted, on the macroscopic level, the background of a new form of determinism: dynamical determinism, valid for elec- tromagnetism and gravitation. In fact, on the macroscopic level, the stochastic character of elec- tromagnetic and gravitational phenomena disappears. A great statis- tical ensemble of such micro-phenomena results in the negation of their individuality. The dialectical negation of chance appears as a dynamical law, with a probability of prevision equal to unity. However, the certainty of prevision is the only common feature shared by the mechanistic and dynamical forms of determinism. And it is interesting to note that the majority of physicists, even of phi- losophers, do not discern the essential difference between these forms. Thus, they continue to confound dynamical and mechanistic determinism. In fact, dynamical determinism presupposes: a) the concept of field, i.e., of a reality possessing qualitative characteristics, contrary to the material points of Newtonian physics whose only attribute is mass; b) finite velocity of physical interactions, i.e., that phenomena are evolutionary processes in space-time (locality) ; c) the creation and destruction of particles (photons, gravitons); d) existence of an internal structure of the atom and more generally of matter, which presupposes the interplay of interactions, forms of matter emerging from the most profound structures of matter. The fact that the prob- ability of prevision is equal to unity is due to the concrete realization of the dialectics of chance and necessity (Bitsakis, 1983). The invariance of the laws of mechanics under a Galilean trans- formation is the formal aspect of their objectivity for small velocities. The physical counterpart of this restricted objectivity is the idealized mechanistic world. The laws of electromagnetism, by contrast, are not invariant for this group of transformations. The hidden cause of this asymmetry is the finite velocity of electromagnetic interactions. The relativistic laws of electromagnetism and gravitation are, as is well known, invariant for another group, the group of Lorentz. This more</page><page sequence="11">238 SCIENCE àf SOCIETY general objectivity presupposes a revolution concerning the funda- mental concepts of physics (mass, energy, space intervals, time, etc.). Invariance is an essential attribute of the laws of physics, because these laws are independent of the system of reference and acquire a status of objectivity and universality. This formal invariance entails invariance of the physical quantities involved. But relativistic objec- tivity is stronger than its classical counterpart, because it concerns a greater class of phenomena and, above all, real phenomena gener- ated by real and not fictitious interactions. With electromagnetism and the relativistic theories, a new con- cept entered the realm of physics: the concept of locality. Because the velocity of physical interactions is finite, a particle A cannot in- fluence a particle B instantaneously. Phenomena are, accordingly, not instantaneous transformations. They are evolutionary processes in space-time. Locality and causality constitute the foundation for elaboration of a rational world view. Locality is a central concept of relativistic physics. The four cur- rently known interactions, mediated by photons, gravitons, gluons and intermediate bosons, respect locality, which is inscribed in the formalism of relativity. It is, consequently, legitimate to conclude that our universe is objective (realism), deterministic and local. Knowledge of relativistic phenomena revealed the gnoseological and ontological limits of the mechanistic universe. Absolute space and time, mutually independent, were the products of abstraction from their real properties. For relativity space and time constitute a four-dimensional continuum, the form of which is determined by the distribution of matter. In this dynamic universe phenomena are re- alized in the interior of the light cone. The locality of material pro- cesses is inscribed in the relativistic formalism. The temporal order for causally connected phenomena, on the other hand, is absolute and in accordance with the irreversibility of real processes in nature. Consequently, the deterministic character of events is intrinsically related to the unique sense of the flow of time. The arrow of time depicts the deterministic and local character of electromagnetic and gravitational phenomena. Real physical phenomena are irreversible. Irreversibility deter- mines the unique direction of the arrow of time. In this sense we speak about physical, cosmological, geological, biological, etc, arrows. These denominations express a unique fact: we are not in a Euclidean, non-</page><page sequence="12">FORMS OF PHYSICAL DETERMINATION 239 local universe, but in a universe where local interactions mediate causal relations and determine the direction of time. Time is mean- ingless when conceived as independent of movement and transfor- mation, as both Aristotle and Engels anticipated. Time is not the universal abstract of mechanistic physics. It is local, intrinsically re- lated to the irreversible processes realized in nature (Belinfante, 1975; Prigogine, 1982). In this way, space, time, matter, interactions, move- ment and determination constitute a coherent totality. Dynamical determinism is the characteristic form of macroscopic relativistic phenomena (Bitsakis, 1983; Davis, 1974; Fer, 1977; Prigogine, 1968). However, to this point we have not approached the real nature of microphysical phenomena. At the dynamical determinist level, quantification of interactions has proved that the continuity of the macroscopic level is an epiphenomenon - that chance is essential. The question arises, however: are probabilistic phenomena incom- patible with causality, locality and determination? Classical Statistical Determination Classical field theories (relativistic electromagnetism and gravi- tation) deal in fact with statistical ensembles of stochastic phenom- ena. Their formalism, however, presupposes the continuity of the field. Similarly, the new form of determination, proper to these theo- ries, presupposes continuity of interactions. This situation is explained - as already noted - by the fact that on the macroscopic level mi- croscopic chance is transformed into necessity. However, it is well known that even in classical physics there are laws where chance is "on the surface" and plays an essential role. The kinetic theory of gases, classical thermodynamics, etc., would be im- possible without a probabilistic formalism. Now these theories treat microscopic systems as material points, deprived of specific qualities. The validity of the mechanistic form of determinism was, consequently, one of the premises of classical statistical physics. A classical state is represented by a non-dispersive probabilistic measure. Statistical states, on the other side, are represented by proba- bilistic measures in phase space. However, in the classical frame, a state with statistical dispersions is considered to be an incomplete description of the system. Consequently, it would in principle be possible to define a dispersion-free state by the introduction of a</page><page sequence="13">240 SCIENCE àf SOCIETY number of supplementary variables. By this method classical proba- bilistic laws were considered to be reducible to deterministic ones. The category of chance was relegated to the status of a subjective, non-essential category. Conclusion: the existence of statistical laws has not been considered to be incompatible with Laplacian deter- minism or, more generally, with the mechanistic paradigm. Quantum Statistical Determinism Classical statistics was unable to bring to light the dialectical rela- tion between chance and necessity. Necessity dominated the mecha- nistic universe. Quantum physics accomplished this step. Paul Langevin was one of the first to formulate the new concept of quantum statisti- cal determinism (Langevin, 1964). The emergence of the new continent of quantum physics began with the discovery of the quantification of the electromagnetic inter- action (1900), the discovery of the first radioactive elements and the first theories of the structure of the atom, that is to say, with the dis- covery of a level of organization of matter more fundamental than the macroscopic one. The emergence of the new science also pre- supposed the development of electromagnetism and related tech- nologies, the technology of spectroscopy, advanced techniques of chemical analysis and certain branches of modern mathematics. We have noted above that the structure of the propositions con- cerning a classical system is Boolean, and that this fact is a conse- quence of: a) the compatibility of all the variables defining the state of the system; and b) the conservation of its identity during measure- ment. The distributive identity, valid in classical mechanics, is a dif- ferent expression of the compatibility of the variables and the con- servation of the identity of the system. In quantum mechanics, by contrast, the distributive law is not valid; the superposition principle holds instead. What is the physical meaning of this difference from a logical point of view? This formal aspect is counterpart to the fact that the physical premises of the two mechanics are different. The non-Boolean struc- ture of QM is the consequence of: a) the existence of incompatible variables, and the resulting validity of the inequalities of Heisenberg; b) the validity of the superposition principle; c) the probabilistic character of this discipline. How are the above specificities related</page><page sequence="14">FORMS OF PHYSICAL DETERMINATION 241 to (so-called) indeterminism? I will try to show that the difference between the two mechanics lies in the fact that the principle of iden- tity - foundation of the mechanistic conception and the correspond- ing formal logic - is not in general valid in QM. In QM perturba- tion results in the creation of new elements of reality by a process of passage from potentiality to actuality. Now a new form of determin- ism is manifested: quantum statistical determinism. All these are alien to the mechanistic paradigm. Let us take the inequalities of Heisenberg: It is impossible, ac- cording to Heisenberg, to measure for the same system two conju- gated variables (for example the position and the momentum of a particle) with an arbitrary degree of accuracy. I note, first, that the postulate according to which these inequalities put an upper limit on the simultaneous knowledge of two conjugated variables has been challenged by many physicists. Nevertheless, let us accept this con- cept for the moment. How might it be possible to interpret it? One interpretation, given by Heisenberg himself, is the opera- tionalist one: the apparatus perturbs the system, because of the finite character of the quantum of action. In this way it destroys the infor- mation concerning the conjugated variable. This interpretation ac- cepts, implicitly, that the two variables actually exist prior to the measurement. But this assertion contradicts the "principle" of non- existence of non-observed quantities, formulated by Pauli and by Heisenberg himself. The logical inconsistency of the orthodox interpretation is not confined to this contradiction. Because, according to a second inter- pretation that we may call ontological, quantum particles are "wave packets" and, therefore, present an extension in space and in the val- ues of the momentum as well. The Heisenberg inequalities are sup- posed to translate this uncertainty inherent in the wave packet, i.e., in the individual particle. This interpretation conforms with the domi- nant single-system interpretation of the Copenhagen School. However, what is the physical meaning of the concept of the wave packet? This concept was introduced by de Broglie and was also used by Schrödinger in the first period of QM. From a didactic point of view, de Broglie writes, it was very useful to use this image, "mais il n'est pas sûr qu'elle correspond à la réalité" (de Broglie, 1953, 31- 32). Also, according to Schrödinger, it is impossible to represent the particle adequately as a wave packet (Schrödinger, 1952). However,</page><page sequence="15">242 SCIENCE äf SOCIETY according to the dominant interpretation, the wave packet is a physi- cal object (although unobservable!). This has not prevented Bohr from asserting that a particle is not a centaur of a double nature and to give an agnostic response on the basis of his principle of comple- mentarity (Bitsakis, 1992). The orthodox interpretation is incoherent. Now, according to Paul Langevin and to Gaston Bachelard, the cause of the "indeter- minacy" is determinate: it is the quantification of the interactions. On the basis of this physical fact, it is possible to give a statistical in- terpretation to the Heisenberg inequalities. In fact, it is legitimate to assert that the inequalities concern not the individual particle, but a statistical ensemble of identical particles, being in the "same" quan- tum state. Because of the interactions of the particles with their envi- ronment, or with the measuring apparatus, the conjugated variables manifest statistical dispersions, expressed by the inequalities. So, the existence of these inequalities is not an argument against the validity of determinism in microphysics: the causes of the phenomena exist and are generally known, and the causes determine quantum me- chanical phenomena. Quantum statistical determinism is a new form of determination expressing the general frame of the laws of the microphysical level (Bitsakis, 1976). If one accepts the principle of complementarity (Bohr) , then it is possible to have a "causal" or a spatio-temporal description, but not both at once. The two descriptions, and more generally the comple- mentary descriptions, attributes or physical quantities, are "mutually exclusive." In spite ofthat, quantum mechanical description is consid- ered complete by the orthodox school (the most complete possible). The Copenhagen Interpretation, more generally, has been accepted even by some eminent physicists who considered themselves to be Marxists. This is, for example, the case of L. Rosenfeld and V. Fock. Both of them considered complementarity as a dialectical "principle." A first objection to the Copenhagen Interpretation concerns "completeness." Physicists in practice use spatio-temporal data to compute dynamical outcomes, without taking into consideration the restrictions imposed by the complementarity principle. A second and more important objection concerns the mechanistic spirit implicit in the orthodox interpretation: Even if it were possible to know ex- actly the position and momentum of a particle, even then it would in general be impossible to predict with certainty the outcome of a</page><page sequence="16">FORMS OF PHYSICAL DETERMINATION 243 measurement, which results in the creation of a new state. This phe- nomenon (the so-called reduction of the wave packet) is in fact a transformation of the system. It is not a linear phenomenon and it is impossible to predict it with certainty on the basis of mechanical data. Thus we have arrived at the second argument of the positivist school. According to the classical forms of determination, the same causes produce the same effects (Newton) . Yet it is well known that in nature, as well as in the case of certain types of measurement, from one initial state it is possible to obtain more than one final state, yielding a certain probability distribution. For the orthodox school, the probabi- listic character of QM is proof that nature does not respect the prin- ciple of causality. Let us, however, examine this issue more concretely. According to John von Neumann, two forms of evolution of a quantum state exist: a) the "causal" (i.e., deterministic), if there is no perturbation of the system; b) the "non-causal" evolution, induced by the measurement, which in general results in more than one state, transforming a pure state into a mixture of different states. In spite of the knowledge of the "cause" (interaction with the apparatus) the transformation is considered a-causal (i.e., indeterminate). More than that: according to this interpretation, the transformation of the quan- tum system (the reduction of the so-called wave packet) is impossible. The system and the apparatus constitute, Bohr maintains, a unique and non-analyzable whole, and they continue to oscillate between the possible states through all eternity. Only the intervention of an ob- server (of a consciousness) can provoke the "reduction of the wave packet" and create a proper state (von Neumann, 1955). However, because of his intervention, the observer will become part of the whole system and will lose his magical power to effect "reduction." This is the crucial point of the failure of the orthodox school and of its in- determinism. The sarcastic paradox of Schrödinger's Cat illustrates the impasse of the single-system interpretation (Schrödinger, 1935). The indeterministic interpretation, instead of recognizing the in- capability of the existing linear formalism to describe a non-linear phenomenon of transformation, introduces, without finding even an artificial way out, the consciousness of the observer, which has nothing to do with the phenomenon. The Schrödinger's Cat story depicts, in a humorous way, the impasse of this interpretation and its subjectivistic outcome. In the epoch of the nearly exclusive domination of the posi- tivist school, no model of realistic description was available. Today such</page><page sequence="17">244 SCIENCE &amp; SOCIETY models exist, which, introducing supplementary variables, describe the so-called reduction of the wave packet as an irreversible and dissipative phenomenon, of finite duration (Gisin and Piron, 1981). Even in the epoch of domination of the orthodox school, there were physicists who defended realism and determinism. Schrödinger, for example, in a 1952 paper, criticized the dominant mysterious, "fit and jerk theory" for its jumplike transitions from one energy level to another, and formulated the hope that the wave equations "could be expected to describe any changes of this kind as slow and actually describable processes" (Schrödinger, 1952). In another paper of the same period Schrödinger writes: if a newcomer to quantum mechan- ics "asks for instance whether the state transitions in the atom that accompany the emission of a light quantum are instantaneous or whether they take time and pass through intermediate states, he is told that the question is meaningless and cannot be answered." Schrödinger recognized that he was "moving against the stream" (Schrödinger, 1954). Einstein also insisted that if we accept the in- stantaneous collapse we need a special mechanism of action at a dis- tance (Einstein, 1927; 1952). In the same period the first theories of hidden variables were formulated (Böhm, 1952; cf. Bitsakis, 1997). Böhm and Bub, in their turn, maintained that a theory of hidden variables can describe the "collapse" as a deterministic process (Böhm and Bub, 1966). What then is the physical meaning of the phenomenon (neither described nor explained) called "reduction of the wave packet"? A free particle moves in a "causal" (deterministic) way. The situ- ation changes radically if an apparatus breaks the idealized isolation of the particle: if a coupling is realized between the apparatus and the quantum system. Because ofthat, under given conditions, a quali- tative transformation of the system is possible. New elements of real- ity arise "from the background of the reality" (Hegel). The potenti- alities of the statistical ensemble become actual. These potentialities (the possible states and the corresponding probabilities) are condi- tioned by: a) the nature and state of the particle; b) the nature and state of the apparatus; c) the external conditions. Consequently, the transformation is causal and deterministic: modification of the con- ditions implies modification of the probability distribution. New states do not arise out of nothing. Their elements of reality appear as a result of the transformation of elements of reality of the</page><page sequence="18">FORMS OF PHYSICAL DETERMINATION 245 previous state; of the interaction between the particle and the appa- ratus. This case manifests, once more, the dialectical relation between the potential and the actual (the actual being, according to Aristotle, the measure of the potential) . These phenomena are irreversible and dissipative. They are processes in space-time and not instantaneous (or impossible) transitions. They are real physical phenomena and not fictitious "reductions" of a fictitious reality par excellence. Conse- quently, the state vector is not a logistic artifice. It is the measure of the potentialities of the statistical ensemble in a given set of external conditions. In an analogous way, the Hubert space to which the state vector belongs is not a space of real states, existing prior to measure- ment. It is a potential space: the space of the potential states of the ensemble in the given conditions (Bitsakis, 1985; 1988b). Based on this interpretation, it is reasonable to assert that the su- perposition principle, whose validity is a characteristic feature of QM, is the formal expression of the potentialities of the quantum ensembles. The "superposed" states are not real, contrary to what the single-system interpretation accepts (Bitsakis, 1991a). It is evident that the preced- ing phenomena are neither a-causal, nor indeterminate. The cause or causes, at least some of them, are known. On the basis of this knowl- edge it is possible to predict the possible states and the corresponding probabilities. Finally, as already noted, a modification of the relevant conditions results in a modification of the possible states and of the corresponding probabilities. I conclude that in QM a new form of de- terminism is valid: quantum statistical determinism (Bitsakis, 1976; 1988c). However, one might object: let us accept causality. What should be said about determinism? How can the same causes produce dif- ferent effects? For the positivist school, indeterminism is inherent in microphysics. Contrary to classical statistical physics, in quantum physics chance is the "essential," "non-reducible" manifestation of the nature of the ultimate constituents of matter. Yet, how have things evolved since Bohr and Heisenberg? Locality and Causality in Physics Relativistic theories, as already noted, are local theories, because they postulate finite velocity of physical interactions. QM, in its initial version, is a non-local theory. However, in accordance with the relativ-</page><page sequence="19">246 SCIENCE äf SOCIETY istic spirit of some of its creators (Einstein, de Broglie, Schrödinger, etc.) this fact was considered to be a necessary adjunct of the formal- ism, and the non-local version was seen as a first approximation to the real relativistic nature of microparticles. The quantum-relativistic theo- ries realized the connection between quantum phenomena and rela- tivistic locality. Quantum mechanics is an adequate theory of microphysical phenomena. Its predictions have never been experimentally falsified and the field of its applications is expanding with time. Yet the ques- tion of the completeness of its description has been posed from the beginning. Louis de Broglie was the first to formulate a deterministic version (1927) - the so-called theory of the double solution. In the Como Meeting of 1927, Einstein proved, with a thought experiment, the inconsistency of the single-system interpretation. Schrödinger, with his famous paradox (1935) demonstrated the subjectivism and the impasse of the orthodox interpretation. In the same year, Einstein, Podolsky and Rosen (EPR) formulated their "paradox," calling into question the complete character of the QM description. Without describing in detail the EPR experiment, its principle may be stated as follows: if two particles, A and B, have interacted in the past, then it is possible, by measuring an element of reality of A, to predict the value of the corresponding element of B, without making a measurement on it. QM, in its current formulation, can- not explain this correlation. For that reason, EPR argued, QM is not a complete theory (EPR, 1935). In his response, Bohr (Bohr, 1935) "refuted" the argument of EPR, by postulating his "principle of non-separability." According to this principle, the two particles continue to constitute a unique sys- tem, non-separable, even after their spatial separation. Their corre- lation is thus explained. Consequently, there is no paradox. The QM description is complete and definite, and the question of the hidden variables is non-existent. Now, what is the nature of the physical in- teractions ensuring the correlation between A and B, even after their spatial separation? Bohr was never clear on this crucial question. It is evident, however, that such interactions would have to be non-local and, therefore, in contradiction with the principle of relativity and relativistic locality. If Bohr were right, one would inevitably have to accept a mode of physical determination in accordance with Newtonian physics! (Bitsakis, 1990a).</page><page sequence="20">FORMS OF PHYSICAL DETERMINATION 247 Einstein never accepted the notion of non-separability. For him the real situation of particle B is independent of any measurement on A. He never accepted the claim that quantum theory is complete. If one insists on the opposite position, he writes in a letter to Max Born, one must accept that a measurement on A modifies brutally the physical reality of B. "Mon instinct scientifique se hérisse à cette idée" (Einstein, 1972). However, on the basis of relativistic locality, it would be possible to argue that the results of the measurements on A and B are corre- lated, because of the common history of the two particles, while the measurements themselves are not. In fact, during the time interval of the common genesis of the two particles, some elements of the reality of A are correlated with some corresponding elements of B. Consequently, the two particles are separated and at the same time "entangled." Then, if A realizes the element of reality AA, this does not imply that B realizes automatically (by telepathy?) the element A,B. It only has the possibility of realizing this value, if a suitable mea- surement is made (Bitsakis, 1996). Einstein always defended the realist position, as well as determin- ism and locality. The Copenhagen Interpretation is, for Einstein, equivalent to the abandonment of locality and the introduction of instantaneous interactions. It is, moreover, anti-realist and indeter- minist (Einstein, 1948; 1951; 1952; 1972). Yet, in the 1930s, with the exception of some "irreducible" real- ists, the general impression was that Einstein had been definitely beaten by Bohr. In the same period, von Neumann demonstrated his famous theorem, according to which nature does not respect causal- ity, at least on the microscopic level. After a long discussion, von Neumann concluded that "there are no ensembles which are free from dispersions." All ensembles have dispersions, "even homoge- neous ones." Consequently, "the decision is made and is against cau- sality." Moreover, there is no question of hidden parameters, because the dispersion's free states, which have to correspond to the "actual" states, do not exist (von Neumann, 1955, 308-325). von Neumann asserted that the present system of QM "would have to be objectively false, in order that another description of the elementary processes than the statistical one be possible" (von Neumann, 1955, 325). The demonstration of von Neumann was a rigorous mathemati- cal-logical one. He and Birkhoff also proved the non-classical struc-</page><page sequence="21">248 SCIENCE &amp; SOCIETY ture of the quantum-mechanical propositions (Birkhoff and von Neumann, 1936). Based on these demonstrations, combined with the epistemological analyses of Bohr, Heisenberg, and others, the quasi- totality of physicists concluded that the orthodox interpretation was the correct one, and that indeterminism is a characteristic inherent in microphysics. However, as is well known, in the 1950s the situation took an un- expected turn. David Böhm, who at that time was unaware of the theory of the double solution (1927), formulated a theory with hidden vari- ables which described the movement of quantum particles in a deter- ministic way (Böhm, 1952). In the frame of this theory, the probabili- ties became a necessity and not the manifestation of a supposed inherent lack of determinism. Yet, this deterministic theory was non-local. Since then, many theories with hidden variables were formulated (de Broglie, 1953; 1961). Also, the theorem of von Neumann was refuted (or contested) by de Broglie, Lande, J. S. Bell and other physicists (Bitsakis, 1997a, 1997b). However, many logicians were op- posed to the hypothesis of hidden variables, because in that case, according to their point of view, it would be necessary to embed the quantum lattice in a classical structure. Other logicians, on the con- trary, proved that this requirement was too restrictive, and that the theories with hidden variables concerned only Boolean subsets of the ensemble of propositions. Yet - the last argument to be considered here - hidden vari- ables, even if they exist, do not reveal themselves, since the theories reproduce the predictions of conventional QM. However, asj. S. Bell (1964) proved, a theory with hidden variables that aims in the spirit of EPR to restore causality and locality, ought, under certain condi- tions, to contradict the previsions of the existing QM (Bell, 1964; 1966). Thus, it should be possible to test the hidden variables theo- ries experimentally. Subsequently, many experiments were realized. Almost all of these were in favor of QM and against the inequalities of Bell. In light of this fact, we can note the following tendencies concerning the problem of realism, causality and locality in microphysics: a. Many physicists considered the falsification of the inequalities of Bell as a justification of the ideas of Bohr and as a confirmation of non-separability, in particular. So, the orthodox school was given a new impetus.</page><page sequence="22">FORMS OF PHYSICAL DETERMINATION 249 b. From the old school of de Broglie there emerged a new ten- dency (Böhm, Vigier) that tried to save realism and determinism. Böhm and Vigier were obliged to give up locality and to postulate the existence of superluminal interactions which, without transport- ing a signal, establish a causal connection between the EPR particles. By this postulate, the relativistic principle is not violated, since no transport of energy takes place. However, the nature of these inter- actions is unknown. Moreover, we must ask: how is it possible for a phase wave, not transporting energy, to induce observable effects? c. The third tendency tries to save realism and determinism, and also locality. According to certain protagonists of this tendency, the consequences of the Bell inequalities are not valid for every local theory. Consequently, experiments like those of Aspect do not con- stitute a refutation of relativistic locality (Angelidis, 1983). Also, ac- cording to de Broglie, Lochak and other writers, the physical premises of the Bell inequalities are not consistent with the nature of micro- particles. In fact, if the two ensembles of hidden variables postulated by Bell were considered as independent, we have here a classical condition which is not respected by QM. Consequently, the violation of the Bell inequalities was inevitable (de Broglie, 1974; de Broglie et al, 1976; Lochak, 1975). Also one can accept that some correla- tions between the two particles were established during their com- mon creation. Consequently, the elements of reality of the two par- ticles (potential or actual) are correlated, although the particles themselves are separated. Bell, on the basis of the principle of local- ity, considered it possible to factorize the state vectors of the particles. However, this is not possible because of the existing correlations. Con- sequently, the inequalities must be falsified (Bitsakis, 1985; 1997). Fi- nally, there exist local and deterministic models whose predictions are in accord with those of QM. These models are not affected by the falsification of the inequalities of Bell (Marshall, Santos and Selleri, 1983). The debate concerning locality has not come to an end. On the other side many opponents of the hidden variables theo- ries assert that such theories aim to restore Laplacian-mechanistic determinism in microphysics and represent, for that reason, a regres- sion. This argument is a product of ignorance and confusion. The hidden variables theorists presuppose that QM as presently consti- tuted is not a complete theory, and they propose a dynamical descrip- tion of certain microphysical phenomena. Yet, why must a hidden</page><page sequence="23">250 SCIENCE äf SOCIETY variables theory be deterministic in the dynamical sense of the term? Such a theory might well be probabilistic, on the condition that it introduces new variables and gives a description more complete than that of QM. Such theories can explain the results of the experiments of Aspect et al, without abandoning causality and locality (Selleri, 1982; 1985; 1986). Realism and determinism are premises for a realist analysis of the situation in QM. Locality is not such a premise. Nevertheless, local- ity is a relativistic requirement in conformity with the totality of the data of actual physics. Locality has, consequently, the status of a sci- entific concept. Non-separability, on the contrary, is an ad hoc hypoth- esis in contradiction with the principle of relativity. Consequently, it does not have the status of a scientific concept. The same holds for non-locality (Bitsakis, 1997; Selleri, 1990). Final Remarks I have tried to describe the different forms of physical determi- nation. Following the evolution of physical theories, we notice the emergence of new forms, more and more essential, which coincide with the great revolutions in the history of physics. A first conclusion is that the category of causality is a moment of the mutual connection and determination of phenomena. The funda- mental ontological category of interaction functions on another level, as a central concept of physical theories. A second fact concerns the historicity of the categories of causal- ity and determinism. These categories are not a priori; they are not conventions. They are elaborated as moments of the theorization of practice. Consequently the form and content of modes of determi- nation change throughout history. Moreover, this evolution does not concern only the gnoseological aspect of the problem. It concerns the ontological aspect also: as the forms of matter change, it is rea- sonable that the forms of determination also have a history in space and time. The identification of interactions with forces of infinite velocity corresponds to the mechanistic form of determinism. Engels, in his time, criticized this conception, and in particular argued against an anthropomorphic concept of force. The creation of the relativistic theories and the discovery of new forms of interaction proved that</page><page sequence="24">FORMS OF PHYSICAL DETERMINATION 251 phenomena are the outcome of deterministic and irreversible pro- cesses, of finite duration. Irreversibility gave a new content to the category of qualitative change. Consequently, the relativistic theories imply a dialectical conception of physical phenomena. The dynami- cal form showed, at the same time, the limits of mechanistic deter- minism. The prestige of the relativistic theories, and their wide range of applications, contributed to the reinforcement of the realist school against the different trends of conventionalism. Quantum mechanics, by contrast, was the starting point of the great wave of indeterminism. To understand the situation in QM we need the dialectics of chance and necessity. The laws of chance are not an argument against determinism, because chance is not the negation of causality and determination. It is the dialectical negation of necessity. Chance is transformed into necessity under appropri- ate conditions. In an inverse sense, it is possible to comprehend an ensemble of determinate events within a statistical law. Chance is an ontological and at the same time a gnoseological category. So it is quite legitimate to assert that in microphysics there exists a new form of determination: quantum statistical. At the same time it is reasonable to raise the possibility of an eventual reduction of quantum statistical determination to dynamical laws. Consequently, since hidden variables appear to be compatible with either form of determination, their existence remains an open question. However, a hidden variables theory has nothing to do with the restoration of mechanistic determinism. Also, it is not necessary to restore a dynamical form of determination. It is possible for theories with hidden variables to be probabilistic and at the same time to give a description more complete than that of the existing theory. The search for such theories is thus liberated from the constraints of dy- namical theory. It can be identified with the search for new determi- nations on the quantum or subquantum level. However, the quest for such theories has had as a result the ques- tioning of the validity of locality in microphysics. Two remarks on this subject are in order. First, causality and determinism are, as already noted, principles for every realist conception of nature. The evolu- tion of physics has demonstrated the range and diversity of their va- lidity. Locality, on the contrary, is not a realist principle. It is true that relativistic locality is consistent with the realist conception of phenom- ena as irreversible processes in space-time. However, realism is not</page><page sequence="25">252 SCIENCE à? SOCIETY associated with any particular form of locality. Today we are aware of the relativity of physical concepts. So, a particle with zero rest mass is material in the same sense as is a massive one. The only required "property" of matter, philosophically speaking, is to be a reality in- dependent of the subject. In an analogous way it is possible to accept a generalized locality, characterized by the existence of superluminal interactions. This is to some extent the position of Böhm and Vigier. The relativistic limit is not necessarily an upper limit for physical velocities. However, this generalized locality has nothing to do with the non-locality which, according to the Copenhagen interpretation, has been confirmed by recent experiments and, in particular, by the experiments of Aspect et ai Relativistic locality is for the moment in accord with the existence of a maximal velocity in nature, equal to that of light. There is, however, a growing body of experimental evi- dence showing that light itself can, in certain instances, have veloci- ties higher than the relativistic limit. Evidently, the eventual existence of superluminal interactions does not restore action-at-a-distance and the mechanistic paradigm. Eventual superluminal interactions will respect, in their turn, an enlarged form of locality. Finally, the objective of this paper has been, not to demonstrate that dialectics and dialectical materialism are "proved," or even that they are in accordance with modern physics. I have tried only to ana- lyze the different forms of physical determination in their historical sequence, and to bring to light their physical counterparts. If this constitutes a "test" for dialectics and if the witness of physics is in favor of dialectics, this means that we are in the presence of a concrete, regional dialectics. This fact would be an argument in favor of a de- terministic and dialectical conception of nature. However, this in no way means that dialectical materialism should be treated as a dogma or a religious creed. The choice between determinism and indeter- minism is not a problem of personal taste or apriori belief. It is im- posed by actual concrete knowledge and concerns the very founda- tions of nature. Department of Physics University of Athens K. Palaiologou 6 162 32 Byronas Greece</page><page sequence="26">FORMS OF PHYSICAL DETERMINATION 253 REFERENCES Arnold, Vladimir Igorevitch. 1986. Catastrophe Theory. Berlin: Springer-Verlag. Belinfante, F. J. 1975. Measurements and Time Reversal in Objective Quantum Theory. Oxford: Pereramon Press. Bell, John Stewart. 1964. Physics, 1, 195. . 1966. Review of Modern Physics, 38. Birkhoff, George, and lohn von Neumann. 1936. Annales of Mathematics, 37. Bitsakis, Eftichios. 1976. Le Problème du Déterminisme en Physique. Paris: Thèse d'Etat. . 1979a. "Sur le statut des lois physiques." La Pensée, 204, 61-89. . 1983. Physique et Matérialisme. Paris: Editions Sociales. . 1985. "Is it Possible to Save Causality and Locality in Quantum Mechan- ics?" Pp. 63-74 in Open Questions in Quantum Mechanics, ed. G. Tarozzi and A. von der Merwe. Dordrecht: Reidel. . 1988a. "For an Evolutionary Epistemology." Science àf Society, 51:4, 389-413. . 1988b. "A Generalisation of the EPR Criterion of Reality." Pp. 3-23 in Prob- lems in Quantum Physics, ed. L. Costro et al. Singapore: World Scientific. . 1988c. "Quantum Statistical Determinism." Foundations of Physics, 18, 331- 355. . 1990a. Une interprétation locale du paradoxe EPR." Annales de la Fondation Louis de Broçdie, 15, 35-57. . 1990b. "Locality, A New Enigma for Physics." Pp. 315-334 in Greek Studies for the Philosophy and History of Sciences, ed. P. Nicolacopoulos. Dordrecht: Kluwer. . 1991a. "The Physical Meaning of the Superposition Principle." Physics Es- says, 4, 124-133. . 1991b. "Mass, Matter and Enerev." Foundations of Physics, 21, 63-81. . 1992. "Complementarity, its Status and Function." Pp. 73-91 in Bell's Theo- rem and the Foundations of Modern Physics, ed. A. van de Merwe, et al. Singapore: World Scientific. . 1993. "Scientific Realism." Science àf Society, 57:2, 160-191. . 1996. "The Riddle of Locality: The EPR Paradox Revisited." Physics Essays, 9, 487-495. . 1997a. "On the Validity of Von Neumann's Theorem." In D. Giyev and R. S. Cohen, eds., Issues and Images in the Philosophy of Science. Dordrecht, Holland: Kluwer Academic Publishers. . 1997b. Le Nouveau Réalisme Scientifique. Paris: L'Harmattan. Böhm, David. 1952. Physical Review, 85, 166 and 188. Böhm, David, and Jeffrey Bub. 1966. "A Proposed Solution of the Measurement in Quantum Mechanics." Review of Modern Physics, 38, 453-464. Bohr, Niels. 1935. "Can Quantum-Mechanical Description of Reality Be Considered Complete?" Physical Review, 48, 696-702. Bopp, Fritz. 1957. "The Principles of the Statistical Equations of Motion in Quantum Theory." In Observation and Interpretation, éd. S. Körner. London: Butterworths. Broglie, Louis de. 1953. La physique quantique restera-t-elle indéterministe? Paris: Gauthier-Villars.</page><page sequence="27">254 SCIENCE &amp; SOCIETY . 1974. "Sur la réfutation du théorème de Bell." C. R. Ac. Sci. Paris. Série B. 278, 721-722. . 1976. Cahiers Fundamenta Scientiae, 55. . 1961 . Introduction à la nouvelle théorie des particules élémentaires de M.J. P. Vigier et ses collaborateurs. Paris: Gauthier-Villars. Carnap, Rudolf. 1979. Philosophy and Logical Syntax. Salónica: Egnatia. . 1973. Les fondements philosophiques de la Physique. Paris: Armand Colin. Davis, P. C. W. 1974. The Physics of Time Asymmetry. California: University of Califor- nia Press. EPR. Einstein, Podolsky, Rosen. 1935. "Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?". Physical Review, 47, 777-780. Einstein, Albert. 1948. Dialéctica, 2. . 1951. "Autobiographical Notes." Pp. 3-95 in Albert Einstein Philosopher- Scientist, ed. P. Schillp. New York: The Living Philosophers Library. . 1952. In Louis deBroglie, Physicien et Penseur, ed. André Georges. Paris: Albin Michel. Einstein, Albert, and Max Born. 1972. Correspondance, 1916-1925. Paris: Seuil. Engels, Friedrich. 1970. Ludwig Feuerbach et la fin de la philosophie classique allemande. Paris: Editions Sociales. Fer, François. 1973. Llrréversibilité. Paris: Gauthier-Villars. Gisin, Nicolas, and Constantin Piron. 1981. Letters Mathematical Physics, 5. Hume, David. 1960. A Treatise of Human Nature. Oxford: Clarenton Press. . 1963. Inquiry Concerning Human Understanding. Oxford: Clarendon Press. Jacquard, Albert. 1994. Science et croyances. Paris: Ecriture. Jauch, Joseph M. 1968. Foundations of Quantum Mechanics. London: Addison-Wesley. Kronfli, N. S. 1970. "Probabilistic Formulation of Classical Mechanics." International Journal of Theoretical Physics, 3, 503-507. . 1971. International Journal of Theoretical Physics, 4. Langevin, Paul. 1964. La Pensée et V Action. Paris: Editions Sociales. Lochak, Georges. 1975. "Paramètres Cachés et Probabilités Cachées." Cahiers Funda- menta Scientiae, 38, 1-20. Mach, Ernst. 1904. Mécanique. Paris: Hermann. . 1959. The Analysis of Sensations. New York: Dover. Marshall, Trevor, Emilio Santos, and Franco Selleri. 1983. Physics Letters, 98A. Ortoli, Sven, and Jean-Pierre Pharabond. 1984. Le cantique des quantiques. Paris: La Découverte. Piron, Constantin. 1976. Foundations of Quantum Physics. London: Benjamin. Prigogine, Ilya. 1968. Introduction à la Théorie des Processus Irréversibles. Paris: Dunod. . 1982. Physique, Temps et Devenir. Paris: Masson. Science et Conscience. Les deux lectures de l'univers. 1980. Paris: Stock. Selleri, Franco. 1982. Foundations of Physics, 12. . 1985. "Local Realistic Photon Models and EPR Type Experiments." Physics Letters, 108A, 197-202. . 1986. "Variable Photons Detection as an Explication of EPR Paradoxes." New York: New York Academy of Sciences. . 1990. Quantum Paradoxes and Physical Reality. Dordrecht: Kluwer.</page><page sequence="28">FORMS OF PHYSICAL DETERMINATION 255 Schuster, Heinz Georg. 1989. Deterministic Chaos. Weinheim: VCH. Schrödinffer, Erwin. 1935. Natunviss., 48. . 1952. "The Meaning of Wave Mechanics." Pp. 16-32 in Louis de Broglie, Physicien et Penseur, ed. André Georges. Paris: Albin Michel. . 1955. "The Philosophy of Experiment." Il Nuovo Cimento, 1:1, 2-15. Thorn, René. 1974. Modèles Mathématiques de la morphogenèse. Paris: Union Générale d'Editions. von Neumann, John. 1955. Mathematical Foundations of Quantum Mechanics. Prince- ton, New Jersey: Princeton University Press. Wilber, Ken, éd. 1984. Quantum Questions: Mystical Writings of the World's Great Physi- cists. Boulder Colorado: Shabala. Wittgenstein, Ludwig. 1961. Tractatus Logico-Philosophicus. London: Routledge and Kegan Paul.</page></plain_text>
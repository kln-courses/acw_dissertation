<plain_text><page sequence="1">The Statistician 33 (1984) 351-369 (? 1984 Institute of Statisticians Statistical Expert Systems: Design D. J. HAND Biometrics Unit, Institute of Psychiatry, De Crespigny Park, London SE5 8AF Abstract: This paper introduces the notion of expert systems for giving statistical advice. The place of such programs in the continuum of statistical software is examined, human cognitive processes involved in giving statistical advice are described, and a striking parallel between medical diagnosis and statistical consultancy is noted. Taking into account factors from a number of sources, an outline architecture of a statistical expert system is presented. Finally, issues of acceptability and accountability are discussed. l Introduction Expert systems have been variously defined: (i) From the British Computer Society's Committee of the Specialist Group on Expert Systems (February, 1983): An "Expert System" is regarded as the embodiment within a computer of a knowledge- based component, from an expert skill, in such a form that the system can offer intelligent advice or take an intelligent decision about a processing function. A desirable additional characteristic, which many would consider fundamental, is the capability of the system, on demand, to justify its own line of reasoning in a manner directly intelligible to the enquirer. The style adopted to attain these characteristics is rule-based programming. (ii) The same source also gives a less formal description: An "Expert System" is a computer program containing rules rather than the procedures and functions of conventional software. The rules express expert human knowledge in the relevant application. A common form of rule is IF condition THEN action or conclusion (e.g. IF symptoms are spots and temperature THEN maybe measles). Application of these programs include advisory systems, where the user consults the stored expertise (e.g. medical diagnosis), and decision making in or for a processing task (e.g. assisting the user exploit a complex software package). A vital feature of many "Expert Systems" is their ability to explain their reasoning, intelligibly to a human enquirer. This feature should become universal within such systems because it makes: (a) computers more fit for human usage; (b) programs easier to change and extend; (c) applications more independent of any particular machine. From the British Computer Society Specialist Group on Expert Systems Newsletter No. 4, October 1981 we have several suggestions: 351</page><page sequence="2">(iii) (Michie) Systems whose goal is to perform convincingly as advisory consultants, exhibiting human expertise in given domains with self-explanation of reasoning on demand. (iv) (Winston and Brown) Systems using a relatively small number of facts that have a rich interaction to solve problems in some domain in order to gain insight into the way people apply expertise, and to partially automate the problem solving task for real applications. (v) (Waterman) Systems that consist of a collection of antecedent consequent rules, a data base, and an executive. The rules are conditional statements that describe how to modify the data base when certain patterns are recognized. The executive performs the pattern matching, monitors data-base changes, selects and executes rules. These definitions give the general flavour of such systems, even if it is apparent that the details differ. Reasons for any differences may include the fact that different people have experience of developing such systems for different application areas. Thus, since the aim of this paper is to describe a particular type of computer program to be applied in a particular area, namely statistics, a useful starting point is a lightning survey of the range of types of computer program used for statistical work. I have found it convenient to divide these types into four groups, as shown in Figure 1. Section 2 of this paper considers these groups in detail. Here it suffices to note that the simplest group comprises such things as t-test programs to run on pocket calculators, while the most complex group consists of full expert systems, able to give advice on design and analysis as well as actually carrying out numerical manipulations. The possibility of a computer being able to advise a user what to do and then actually to do it raises the first question we must consider. Do we want a system to carry out automatic data analysis, or do we want it merely to give advice and let the user actually make the decisions? If the system can decide what it thinks is best in any particular situation, is there any need to appeal to the user's judgement- why not go straight ahead, carry out the analysis and present the user with the result: "Your new drug has no effect and I found this out using a method of analysis I thought best." We might term this the oracle approach. I have an uneasy feeling that many statistically naive users would welcome this approach- provided, that is, that the conclusion with which they were presented was the one they hoped to get! However, I strongly feel that the oracle approach is not a good idea. First, statistical expert systems contain statistical knowledge, not world knowledge. The system will not contain details of biology or psychology, or economics, or whatever. The only way it could contain such knowledge in addition to its statistical knowledge would be if it possessed the size and generality of the brains of several human experts together- a system we have not yet built. However, effective statistical work involves a subtle interplay between the two types of knowledge, the statistical and that of the domain of study. It is thus vital for there to be an opportunity for such interplay to occur and since the two sets are contained one in the program and one in the user it is vital for extensive communication to occur. We must all have had experiences, when advising clients or students, of the kind: "Oh! Your usage of the word 'variable' is different from mine." The second reason that an oracle is not a good approach is that a professional statistician would not be happy to use it. The statistician would like to weigh up the system's decisions and compare them with his own. This is directly analogous to the feelings of medical consultants when presented with medical diagnosis programs, a point we return to in depth below. The observations above implicitly introduce another issue which must be considered at the beginning. This is: for whom is the program intended? Who will use it? The discussion indicates the two extremes, namely the expert statistician and the statistically naive user. These two extremes require rather different properties from the system. The latter requires 352</page><page sequence="3">lengthy explanations and the facility to explain technical terms. The former can manage with briefer details but perhaps needs more in the way of justifications concerning why the system is making its recommendations. This and associated issues are discussed in detail in Hand (1985). Section 2 of this paper puts statistical expert systems in the context of other statistical software, showing how and why there are differences - what expert systems can do that other programs cannot. It is clearly of relevance to consider how human consultants approach their work, since this will suggest ideas for computer methods. We discuss this in section 3 before outlining a general design in section 4. In section 5, by way of conclusion, we discuss such issues as acceptability and responsibility. 2 Statistical software Figure 1 represents the range of complexity in statistical programs. The left-hand end represents the simplest and the right-hand end the most complex. The two left-hand blocks can be said to encode arithmetic and algebraic expertise. The programmer had to understand the technical details of the statistical methods in order to create the programs but it was not in fact necessary for him to understand the broader purpose of the analyses in terms of the uses to which they might be put and the conclusions which might be drawn from them. Furthermore the programs rely heavily on the good sense of the user to decide when it is appropriate to use them: one can score a nominal variable using the integers and then go ahead and calculate means, standard deviations, carry out t-tests and so on without so much as a murmur from the program. It is in this sense that the programs contain arithmetic expertise - give them the numbers and they can do the arithmetic. They are, however, pretty well devoid of statistical expertise: deciding when it is appropriate to use the numbers and drawing sensible conclusions from the results. In brief, simple programs for calculators and computers and complex packages for computers assume the user knows what he is doing. As far as complex packages go, at least, this assumption has two faces (see, for example, our work described in Smith, Lee, and Hand, 1983). I find it convenient to distinguish two types of package: those with which it is easy to get results and those with which it is difficult. At first glance one might think that the former is required - the idea, after all, is to get results, so why make it hard? The answer, and the distinction between the two types of package, is nicely demonstrated by a comparison of the MULTIVARIANCE package (Finn, 1977) and the SPSS package (Nie et al., 1975). The former is difficult to use unless one happens to be a professional statistician. It requires substantial effort being spent on the manual and even then its programs, being systems of numerical codes, are fairly opaque without great care and attention. Conversely, SPSS is simple to use. The basic manual is large but there is an introductory primer and once a grasp has been gained of its basic data structures and its keyword language then requesting analyses through it is simplicity itself. Too much so, in fact, for, as a colleague of mine remarked (about the MANOVA multivariate analysis program of SPSS): "Carrying out analyses is easy. Determining if they're the ones you intended to carry out is a different matter." The point is that SPSS makes it too easy for a naive user to misuse the methods. Thus the two faces of the assumption that the user knows what he's doing are first that the user knows enough to operate the program and second that he knows enough not to misuse it. It is the second which I regard as the more important - the first, if false, leads to no mistaken conclusions. It was such reasoning as this which led us to develop the BUMP interface to MULTIVARIANCE (described in Smith et al., 1983). The aim was to make access to MULTIVARIANCE easier for statistically naive researchers at the Institute and to begin to explore the possibility of preventing the more gross misuses of multivariate analysis. There 353</page><page sequence="4">Include both analysis and design 4F Simple package Complex package I nterface Expert system 1 2 3 4 Arithmetic and algebraic Statistical expertise expertise encoded encoded Fig. 1. Statistical software. was also a peripheral aim of teaching the users some of the terms and structures of such analyses. It would have been better to write an entire package and creating an interface is very much a second best. The reason was simply one of limited time and effort available. Some of the drawbacks of BUMP arose from this decision (for example, its severely restricted ability to give users guidance in understanding and interpreting results). But, equally, one of the major practical advantages also arose from it - namely the fact that the program was up and running within a year. BUMP interrogates the user using natural language questions, usually expecting Yes, No, or Don't Understand as answers. From this BUMP constructs a MULTIVARIANCE program, combines it with the data, and sends it off for processing. If the user says he doesn't understand, or requests help, the program has the facility for explaining technical terms. BUMP has provided us with valuable experience in such programs. One of the most encouraging conclusions to be drawn from it is the enthusiasm with which the naive users (mainly psychology and medical graduates) took to it. It is important at this point to insert a cautionary note, one which may allay some anxiety in the reader and a point which serves to distinguish systems like BUMP (be they interfaces or complete packages) from the full expert systems of the fourth module in Figure 1. BUMP was not designed to be used completely freely by the statistically naive. It was to be used only after consultation with one of the professional statisticians in our Unit, and after the type of design and analysis to be undertaken had been settled. The fact that BUMP's ability for detecting misuse was severely limited was thus not a great disadvantage. Such an ability is of much greater importance for systems intended to function with a greater degree of autonomy. BUMP was created for the same reason that computers are used in general - to free the human for more interesting tasks. Deciding on the form of design and analysis is interesting while actually writing the MULTIVARIANCE program is purely mechanical. BUMP automates the latter. One other point about BUMP is worthy of mention as it has implications below. Choosing to write merely an interface had the advantage that we knew what we were aiming at. We did not have to decide how best to represent the input information - we knew we had to encode it as card images in the form of a MULTIVARIANCE program. The shape and structure already existed, awaiting merely the numerical codes. Interfaces to existing programs and packages thus serve as an initial step in introducing statistical expertise into the computer. A program which asks "Is this variable an interval scale variable?" (which information requires world knowledge, not statistical knowledge) is demonstrating statistical expertise and not arithmetic expertise. A program which examines the data and warns "Point 3 seems to be an outlier. Do you want it eliminated from the 354</page><page sequence="5">analysis?" is demonstrating statistical expertise (although it uses arithmetic - and arithmetic expertise encoded by its author - in deciding to ask the question). This second example is crossing from block 3 to block 4 in Figure 1. Now the program is actually examining the data. Its input is coming from two sources: the user and the data itself. Our statistical expert system thus questions the user about his aims, examines the data, carries out the analyses, and by discussion with the user decides what else should be done. Figure 1 shows an additional attribute possessed by a full expert system but not by the other statistical software. This is that it contains statistical expertise about design as well as about analysis. Most of the existing packages are solely concerned with analysis - expecting the user to design the experiment, survey, etc. An expert system should be able to advise on both aspects. Before concluding this section it is perhaps worth remarking that for somebody who wants to explore the ideas above there is considerable scope for writing small programs for small computers which encode statistical expertise as well as arithmetic expertise (for example, a t-test program which checks the reasonableness of the assumptions). 3 The human approach Artificial intelligence research in general can be viewed from two perspectives (Hand, 1981a). Firstly, it can be seen as an effort to write computer programs which are able to perform functions which, in a human, would be said to require intelligence. This might be described as the "black box" approach: how the machine does it is not important, it is what it does that counts. No effort is made to model human cognitive processes. In contrast, the second perspective stresses the how, emphasizing as a primary aim the simulation of human processing structures. Some researchers feel that the surest avenue to the creation of artificial intelligence is through the second of these two perspectives. Hayes-Roth (1978, pp. 245-6) for example, says: "Human cognition can provide an inspiring model for the design of artificial knowledge systems.... In the long run, the most promising avenue of approach towards the development of artificial knowledge systems may be to investigate and model human cognition as closely as possible." Fox (1983) goes even further, suggesting: "Unless there is a compelling reason not to, systems should always be designed to process information in the same way that people do." He calls this the "Principle of Cognitive Emulation" (and remarks that it has also been called the Fourth Law of Robotics!). However, it seems to me that adopting an unreservedly anthropomorphic approach to artificial intelligence would be unwise. To do so would be to sacrifice any advantage that may be taken of any unique properties possessed by the computer. Computer chess provides a good illustration. Computers have an ability, far superior to that of humans, to examine a large number of potential moves. However, despite this superiority, computer programs to date are not as good as the best human chess players. The reason for this seems to be that humans, while not being able to examine as many moves as the computer, do have the ability to pick the most important ones to examine. Clearly these two abilities are in some sense com- plementary. Humans have some kind of facility for global synthesis not (yet) possessed by computer chess programs, and the latter can examine vast numbers of chess positions in an exhaustive (and error-free) way. That the former can go beyond the latter is obvious from the current man/machine chess rankings. That the latter can also go beyond the former is nicely illustrated by the following example from Michie (1982): 355</page><page sequence="6">"International Masters Berliner and Day were invited to demonstrate their skill against a move-perfect program for a particularly tricky sub-game of chess, the King-Queen-King- Rook ending. Except for a few special starting positions the Queen's side has a theoretical win against the Rook's side, and a strong Master can ordinarily be expected to win against any human opposition. Yet Berliner and Day found themselves unable to defeat the machine however many times they tried. The most upsetting feature, they complained, was their opponent's bizarre and counter-intuitive style, which bore no trace of the simplifying concepts which gave shape to human play." A second example of the unique properties of the computer is given by medicine. Human medical consultants are notoriously bad at combining prior probabilities with observations to yield posterior probabilities. Computers, of course, can do this both accurately and consistently. These two examples illustrate that man and computer have complementary kinds of abilities. It might be unnecessarily constraining to restrict one's computer approaches to modelling man. There is an additional point on this topic which is worth noting. Good models of the human way of solving problems might reasonably be expected to appeal more to people (as in the chess example above, and as in the contrast between statistical and expert systems approaches to medical diagnosis, discussed below). But they might equally be expected to make the same kinds of mistakes as humans. Our aim in a statistical expert system (where performance rather than verisimilitude of modelling is what counts) must be to minimize the number of errors. Despite all this my purpose here is not to go too deeply into this argument (further discussion of which is contained in Hand, 1984). Rather, my aim is to note the obvious importance of at least studying the way humans approach problems when we examine how we might program computers to approach them. (As we shall see, my proposed structure for statistical expert system uses both human and non-human ideas.) In this section we examine the problem solving methods used by consultant statisticians when selecting an appropriate statistical tool. Observation of consultant statisticians at work at the Institute of Psychiatry (see below) suggests a marked similarity between the way they decide which statistical methods to use in a research project and the way medical consultants arrive at their diagnosis. This is a useful observation since several studies have addressed the latter problem. Elstein et al. (1978, p. 4), for example, say: "Diagnostic problems are solved through a process of hypothesis generation and verification. Hypotheses are consistently generated early in a workup when only a very limited data-base has been obtained. While any early formulation may be revised or discarded if subsequent data fail to confirm it, there is a high probability that at least some of the formulations of experienced physicians will be correct." Similarly, Kassirer and Gorry (1978) say: "Detailed analysis of protocols of the participating clinicians shows that the clinicians tried various hypotheses as explanations of the patient's problem - hypotheses that 'fit' the case at hand more or less well. Piece by piece, they assembled the evidence for and against competing hypotheses until one hypothesis seemed clearly better. When findings seemed inconsistent with a hypothesis, they searched for an explanation for the inconsistency or they rejected the hypothesis in question." Szolovits and Pauker (1978), in a discussion of different approaches to medical diagnosis (with machine implementation in view), say: "An experienced physician can be pushed, in his domain of expertise, to give arbitrarily many complex potential explanations for a patient's condition. Especially in the teaching hospital environment with which we are most familiar, this serves the useful pedagogical purpose of discouraging pat answers from 356</page><page sequence="7">students. Because so many diagnostic possibilities appear to be available for the expert to consider, we suspect that the rapid generation and equally rapid modification or elimination of many explicit hypotheses plays a significant role in his reasoning." Finally, a bald statement expressing a similar opinion, not from a group studying how humans makes diagnoses but from experienced diagnosticians in psychiatry (Wing et al., 1974): cc... all investigation and diagnosis still properly starts with interviewing the patient and making a provisional diagnosis...". To summarize, these researchers seem to be saying that, presented with a sick patient and a multitude of potential diagnoses, a clinician will follow a hypothetico-deductive approach, choosing one or more diseases as potential candidates and then looking to see if any of them fits all the facts. In Simon's (1973) terms, this is the human way of transforming medical diagnosis from an ill-structured problem into a well-structured problem. Suggestions as to why such an approach is adopted are given by Elstein et al. (1978, p. 4): "Hypotheses serve as organising rubrics in working memory. They help to overcome limitations of memory capacity and serve to narrow the size of the problem space that must be searched for solution." And on p. 65: "The generation of hypotheses and utilization of a hypothetico-deductive method seem to be a nearly universal characteristic of human thinking in complex, poorly defined environments. Work in the psychology of memory and thinking has suggested why this is so: the problem must be represented cognitively in the mind of the problem solver. While rational problem solving is characterized by a high degree of adaptation of this representa- tion to the demands of the problem, there are limits to human capacity both in working memory and in respect to the number of operations that can be performed simultaneously ... The function of early hypotheses, therefore, is to limit the size of the space that must be searched for solutions to the problem. Some way of progressively constraining the size of the search space must be found or else a clinical workup could never end in the time that is available." This certainly seems a reasonable explanation of how humans go about medical diagnosis, as well as a convincing justification for why it is necessary. We shall give some examples later which illustrate why we believe it also matches statistical consultancy work. First, however, we examine the idea in a little more detail. We begin with the question of where the hypotheses come from in the first place. Again Kassirer and Gorry (1978): "At a time when the clinician was aware only of the age, sex, and presenting complaints of the patient, he often immediately introduced a hypothesis." And: "Hypotheses were most often activated by introduction of individual symptoms by the respondent but were also triggered by pairs or combinations of symptoms or by mention of a cause or a complication of a disease." They also say that conflicts between current hypotheses and new data caused new hypotheses to be generated. Pople (1982, p. 122) goes further than this: "One mark of an expert is his ability to formulate particularly appropriate differential diagnostic tasks on the basis of sometimes subtle hints in the patient record" and (p. 124): "What distinguishes an expert is his ability to sense important omissions in the data that can often be filled in simply by asking the right questions." Now let us translate all this into statistical consultancy terms by way of a hypothetical example. Suppose that a researcher has come to a statistician for advice. He begins by outlining the aims of his study. In the course of his explanation he might mention the word "groups". This word causes the statistician to hypothesize that an analysis of variance might be appropriate. This initial idea is tentative and subject to change. The client might be allowed to continue explaining the problem, but sooner or later the statistician begins asking his own questions. 25 357</page><page sequence="8">This is, of course, more efficient. Rather than waiting for the client to fill in the gaps in the conceptual structure in the statistician's mind - perhaps accidentally if the client has a poor grasp of statistical techniques-the statistician can ask questions focused on filling the gaps. If the responses make it clear that there is a contradiction between what the client is saying and the tentative model then the latter is rejected and some other adopted. Such switching will be more common in the early stages of a consultation. To begin to explore how well this basic idea matched statistical consultation sessions, I tape-recorded (with permission) a number of such sessions. (I initially tried to monitor my thought processes as I gave advice but this proved so hopelessly confusing that I had to abandon it.) Clearly the results of the taped sessions - and the inferences I drew from them - cannot in any way be regarded as rigorous. I wish to emphasize this: they are merely informal hypothesis generation exercises. To give the reader a feel for the results, I outline below some of the sessions. The general idea of hypothesis generation and testing seemed a reasonable explanation of the process of choosing a method, but with the proviso that it was never as clear or as obvious as the above quotations might seem to imply. Session 1 In all cases I asked the researcher to begin by stating his or her name and department so that I could subsequently identify the tape. This one began: "My name is LK and I'm studying for a PhD in the X Department, supervised by Y."' Even at this stage I was formulating some initial hypotheses. I had advised two or three PhD students from X supervised by Y in the recent past. I expected this to be an extremely complex multivariate psychophysiological experiment - and that multivariate analysis of variance techniques would probably be appropriate (perhaps using MULTIVARIANCE via BUMP). The student began to describe her work as a conditioning experiment involving 50 acquisition trials, 20 extinction trials and with two dependent variables (skin resistance and eyeblink rate) measured at each trial. These facts strengthened my feelings about the suitability of a multivariate analysis. Note that I had been thinking in terms of a repeated measures design. The possibility of a time series analysis did cross my mind, but my initial hypothesis (reinforced with my prior experience with studies of this type) was not shaken and stayed primary. As the description unfolded, it appeared that the design was not a simple bivariate repeated measures arrangement, but that there was also a complex pattern of psychological measurements made at each trial. However, we agreed to restrict the initial analyses to the bivariate data set, firstly to permit us to get a handle on the data and secondly so that she could begin to get a feel for the type of analysis to be undertaken and how to interpret the results. (This experiment illustrates one of the problems frequently encountered by consultant statisticians in our sort of environment: often the researchers collect far more data then they can-ever hope to analyse. And worse, all too often they have never given a thought to how some of it might be analysed or if it ever conceivably could be.) The between groups design for this study appeared to be quite straightforward, involving only three groups. The initial consultation ended at about this point. I had given her some general ideas of the kind of analysis which would be appropriate and had sent her away to prepare her data in a form suitable for the packages we had in mind. The fact that I was not involved with the design of the study (and that, possibly, no statistician was) is an obvious source of difficulties. A major reason is simply one of staff time. Clearly the study is quite complex and would have required more than a ten minute chat to produce a design. 358</page><page sequence="9">Session 2 This client was DC, an MPhil student, also from Department X. I asked him, as usual, to describe his study and he began by going into tremendous detail about the structure of the questionnaire he was using. How the items were grouped to form subscales, what the items were, and so on. As it turned out, all this was irrelevant to the hypotheses he wanted to test using the instrument. This sort of experience has motivated me to begin exploring alternative ways of conducting these interviews. For example, maybe my "describe your study" beginning is inappropriate (should I start: "What are you trying to find out?"). More probably, I should structure my interviews more rigorously. For example, I could try to impose some kind of hierarchy on the amount of detail the clients use to describe their studies (rather than relying on them to do it themselves). Session 3 The third recording also illustrates a misdirected attention to detail, though this one is less obvious and perhaps more understandable. The researcher here is CB, a Senior Registrar from a neighbouring hospital. He described the study very clearly and I am pleased to report that, having designed it himself, he was seeking advice before collecting the data. The study involved a comparison of three alternative treatments for hyperventilation syndrome, the three treatments being a relaxation programme, beta-blocker drug therapy, and simple reassurance. There were 20 randomly allocated subjects in- each group. The treatments were spread over a six month period, and CB explained the details of the administration pattern to me. Again I generated an early initial hypothesis that a multivariate repeated measures analysis might be appropriate. We had reached this point before CB revealed to me that he had seen my criticism of someone else's study where I had pointed out that it had such low power that it was a complete waste of time and money - not to mention any additional suffering caused to the patients. CB's reason in coiming to me was to avoid such a mistake himself. Since I had no technical knowledge of the particular syndrome CB was studying, I was unable to assess expected differences between means, standard deviations of means, and so on. All I could do in the circumstances was to explain the basis on which power calculations are made and despatch him to collect the necessary information from other studies (or to re-designate his study as a pilot). The point is, however, that we need not have gone into the details of his study at all for me to answer his question. Session 4 Several of the researchers whose sessions I taped produced and referred to tables of data they had collected. One or two referred to diagrams. For me as a human these posed no problems, but for an expert system there is a potential difficulty. Information in diagrammatic form can obviously make explaining a study a lot easier ("a picture is worth a thousand words") and I know that in my own case I explicitly conceptualize designs in diagrammatic form. That is, I often draw a geometric figure, for example, to represent the nesting and crossing structure of an experiment or the sequencing of a series of observations. Session 5 Analysing the tapes it is clear that, as with the medical consultants, I quickly formulated initial hypotheses, often based on very little concrete information (and often using general information, such as knowledge of the researcher's Department), and that usually the initial 359</page><page sequence="10">ideas were more or less correct. The case about to be described, however, is interesting because it was one of the exceptions. It took me a long time to see what the researcher was after. In such a case it is important to look at why the difficulty arose - it seems to be a lack of appreciation of statistical terminology and concepts on the part of the researcher. (At least, that is the biased view of myself, the statistician involved!) This subject was a junior medical doctor - a pertinent point because amongst the researchers I advise are two groups, one a set of medical grAduates and the other a set of psychology graduates, both at about the same level in their training and both conducting research projects of a comparable complexity. In general - though I stress that there are exceptions - the psychologists seem better able to cope with research methods than do the medical doctors. I assume that this has something to do with their earlier training; for example, whether a statistics course is a required component of their first degrees. In any case, it perhaps sheds a little light on the disparaging comments which have been expressed with some frequency of late concerning the level of statistical expertise evinced in medical journals (see, for example, Altman (1982) and the references cited therein). In what follows the subject is GA and the statistician is S. I have summarized the tape, using thoughts, words, or descriptions as I think most appropriate to convey the flavour of the conversation. GA: Introduced himself and began to describe his study. S: He's describing a scale, an ordinal scale. Not one but three scales? GA: "'One scale with three axes." S: Puzzling, this. Are we using the same words with different meanings? Questioning reveals that there seem to be three scales, all ordinal, and that they can be added to yield a single score. GA: "There are six variables in it." S: Coming out of the blue, this is something of a puzzle. A mistaken use of the word "variable", surely, since it doesn't seem to relate to anything earlier. GA: "I want to know how well this scale correlates." S: He is seeking a correlation between this total score and what? GA: With some prompting and translation says that he has another scale, a "predicted violence scale", also ordinal, independent of the earlier one. S: Presumably this is not "independent" in the statistical sense. Now there are two distinct scales: the predicted violence one and his earlier one. Unfortunately, questioning shows that he is not primarily interested in the correlation between these two scales. This is a clear example of a hypothesis failing. I try to match a discrimination approach to his problem (anyone familiar with Hand (1981b, 1982) will recognize that I often try to do this!): violence occurs or doesn't. But there seems to be no "not" group. Another hypothesis fails. But he did use the word correlation. GA: With continued questioning and in translation into statistical terminology he says that he wants to look at the distribution of violent incidents across the levels of the two predictor variables. S: So, what is needed is some kind of correlation measure or model to explore the relationship between the number of violent incidents and the two scales. In particular the question of whether the scales have any predictive power at all. Further probing reveals that this is correct. The researcher then went on to other aspects of the study. In retrospect, of course, the questions he wants to explore are obvious enough and when the summary is written down (and can, in a sense be seen in parallel, the earlier part of the interview with the latter) it does not look difficult. However, I hope the condensed narrative given above indicates the struggle I had. 360</page><page sequence="11">Session 6 Other problems cropped up which illustrate the necessity for some of the properties outlined in the preceding section. For example, the study in which the researchers began by saying they had observations on 152 subjects - and only much later, after a complicated model-fitting approach had been chosen, did it become apparent that due to missing data this was effectively reduced to 10, making such an approach infeasible. Backtracking is essential. These condensed descriptions should indicate that there is certainly some validity to the proposed hypothetico-deductive mechanism for human statisticians. I hope they also indicate some of the problems with which an expert system will have to cope. Many of the difficulties arise because these are different types of statistical consultation sessions. (i) The researcher may have a sophisticated grasp of statistics or a negligible grasp. (ii) The presenting problem may be trivial or complex. For example, the answer might be "a t-test" or a complex survey analysis design. The study might have many aspects. (iii) The session might be a one-off consultation or it might be part of a continuing chain. (iv) The problems may require non-standard methods. (Or they may require methods with which one is not very familiar.) (v) Different environments (e.g. industry, commerce, agriculture, medicine) have different types of problems. (vi) The copsultant may be under pressure of time. Does a snap answer have to be given, the statistician relying on the researcher to follow his instructions using a standard package? Or will the consultant be part of a team? It was noted in the discussion of session 2 above that the very fact of studying how I arrive at conclusions and give advice was generating suggestions for improving my approach. Certainly the study has caused me to look very carefully at the way I elicit information. By trying out various approaches in these informal taped sessions I hope to be able to formulate more detailed hypotheses for a properly designed experiment. Perhaps I should also remark here on some totally unexpected benefits of taping interviews. The first is that it seems to induce most people to make a special effort to be clear. A straightening of necktie, a clearing of throat, and a general careful structuring of thoughts and sentences was not an uncommon observation! (Though the presence of the recorder did confuse one or two at first.) The second benefit was that I went over the tapes again afterwards to study them to recall my thought processes while I was offering advice. In several cases this led to second thoughts about a better method of analysis. To some extent, of course, this reflects the time pressure and number of clients we have to cope with. When time permits, I have found that asking clients to prepare a short (say one page) description of their study, which I can read beforehand, can be of considerable help. (For example, it would presumably have helped me in session 5 above.) 4 A suggested design In this section I give an overview of a design for a statistical expert system, omitting the details so as to convey the important aspects of the overall structure. The design is based on considerations from a number of sources. Firstly, and most importantly of all, we must bear in mind the desirable features discussed in Hand (1985). Secondly, study of the way humans approach statistical consultancy work, as outlined in section 3, has suggested mechanisms for part of the design. Thirdly, observation of the way users responded to 361</page><page sequence="12">BUMP, and the comments and criticisms made concerning it and to what extent they made use of its various facilities, as well as studying the way researchers made use of other interactive programs have led to some of the features outlined below. It is generally recognized that one of the keys to effective artificial intelligence work lies in choosing an appropriate representation for the problem to be tackled or the domain to be described (Bobrow and Collins, 1975; Hand, 1981a). Basically this merely means that if we choose a suitable formalism or descriptive language - one well matched to our domain of interest - then tasks in that domain are made much easier. Let us take a trivial example to illustrate. There is a puzzle found in many elementary brain-teaser books which runs as follows. Take an ordinary eight by eight chessboard and mutilate it by removing two diagonally opposite corner squares. This leaves 62 squares. Now, given a set of 31 dominoes, each a rectangle of size two squares, can these dominoes be placed so as to completely cover the mutilated chessboard? There are a number of ways one could approach this problem. One could try lots of combinations of dominoes on the board. One could simulate that on an electronic computer, which would be faster. One could presumably come up with some description, some representation, of the problem such that an exhaustive enumeration of all possible positions was possible - and then one could try them all and see if any satisfied the requirements. It seems likely, however, that even on a computer this would take some time. At this point, if by any chance the reader has not come across this problem before, I suggest he covers up the remainder of the page and thinks about it for a few minutes. The objective is to find a way of describing the problem which renders the solution straightforward. One answer is to describe the problem not in terms of geometric configurations of the dominoes but in terms of the colours of the squares. Each domino must, by the very nature of a chessboard, cover one black and one white square. Thus, however they are configured the 31 dominoes will cover 31 black and 31 white squares. But opposite corners of a chessboard have the same colour. The 62 squares of the mutilated board thus do not divide equally into 31 black and 31 white. So the dominoes cannot cover them. This is obviously a trivial example, but it is an effective one. It illustrates the power of a good representation. We have already remarked that the problems encountered in writing BUMP were considerably eased because a representation had been chosen for us: a suitable representa- tion for the output of BUMP already existed in the pre-specified format of the MULTIVARIANCE language. (The algebraic and arithmetic representations for manipu- lating the numerical data already existed as part of MULTIVARIANCE and were irrelevant to us.) As far as a statistical problem goes, once it has been well-defined, extremely effective representations exist. For example, the various notations which have been suggested for experimental designs and analysis of variance or, ultimately, the mathematical equations themselves. Once the statistical tool has been chosen, in problem solving terms there is no longer any difficulty. Choosing the tool is, however, a different matter. For this there is no obvious formalism. The reader will perceive at this stage that our approach to a statistical expert system has two quite distinct components. One is concerned with choosing the statistical techniques (blocks 1 and 2 in Figure 2) and the other with using them (blocks 3 and 4 in Figure 2). The methodology we have adopted for the first of these components is the production system approach (Davis and King, 1977). Production system ideas seem first to have been introduced by Post (1943) as a general computational mechanism. They have since been adopted for use in a large number of expert systems where they seem particularly well suited to processing in ill-structured 362</page><page sequence="13">Pattern matching Bottom up Highly structured Interactive natural language _ production system interrogation processor processor identifying methods programs 1 of analysis 2 3 4 Storage Storage Fig. 2. A design. problem domains. They have also been considered as models of the way humans tackle such problems; as Newell and Simon (1972, pp. 803-4) in their classic work on human problem solving put it: "We confess to a strong premonition that the actual organization of human programs closely resembles the production system organization." A production system consists of a set of production rules, a database to which the rules are applied, and the executive mechanism for applying the rules to the data. Each rule typically has the general form. IF (logical conjunction of database items) THEN (Action) where "Action" may be a number of things but is typically to make some modification to the database. As an example of such a rule we might have IF (A is true and B is true) THEN (C is true). Or a more concrete statistical example: IF (require some summarizing average and the variable has an interval scale) THEN (Consider using the arithmetic mean) By stringing together a number of such rules deductions can be accomplished. Note that all interaction between rules occurs through the database. Items may be deposited in the database by a rule, as above. Or they may be deposited there as a result of a rule enquiring of the user. Returning to the statistical example above, the system may know that (Require some summarizing average) is true but not know if (the variable has an interval scale) is true. Examination of the rules and database may show that it cannot deduce the truth or falsity of this latter and in this case it will ask the user. The deductive process may proceed by either forward or backward chaining through the rules. In the forward case the left-hand sides of the rules are compared with the database and right-hand side actions taken when the rules are true (when they "fire", in technical terms). In the backward case if a fact is not already in the database, the system examines all those rules with the fact as their right-hand sides. Then it selects one (as described below) and examines its left hand side antecedents. If these are all true the truth of the right-hand side follows. If not, then the system searches for rules which have these new items as their right-hand sides. And so on. We have adopted this latter, goal-orientated approach for two basic reasons: Firstly, in this approach no complex method for selecting appropriate rules is usually needed. Often, simple precedence order in a uniform list of rules suffices. (In contrast, left-hand side driven systems require complicated "conflict resolution" strategies.) Secondly, as will be obvious from section 4, the backward chaining approach seems to have much in common with the way humans approach problems. This is very important since it makes the system's deductions easier to follow. To illustrate the ideas, we give an example from Waterman and Hayes-Roth (1978, pp. 10): Figure 3 displays the database and rule dictionary of a simple system. "The letters 363</page><page sequence="14">Database: B, C Rules: Rl. B and D and E ==&gt; F R2. D and G ==&gt; A R3. C and F ==&gt; A R4. C ==&gt; D R5. D ==&gt; E R6. A ==&gt; H Fig. 3. A simple example of a production system. represent database elements and are considered true if in the database. In this simple system, the action of firing a rule inserts the right-hand side letter into the database. "Assume the given premise is that 'H is true'. Since H is not in the database it must be deduced by backward chaining through the rules. The system first chooses rule 6 and attempts to show that A is true, since A implies H. Unfortunately A is not in the database and must itself be deduced. This can be attempted either through rule 2 or 3. Assume the system first tries rule 2. It must now show that both D and G are true. D is easy; it can be inferred from rule 4. G is another matter; nothing can be inferred about G since no rules contain G on. the right-hand side. The system now backs up and tries to infer A through rule 3. This time it succeeds since C is true and F can be inferred by showing that B, D and E are true. A causal chain has now been produced that proves the given premise 'H is true'." Production systems have a number of significant advantages over more conventional programming approaches for the method selection part of our system. Amongst these are: (i) They are fundamentally data driven. They respond in a very flexible manner to changes in the database. In principle any rule could fire at any time. It is not necessary to work out every possible route through the set of rules. (ii) The system is extremely modular. As a consequence it is easy to extend and modify: new rules can be added and old ones modified or deleted without being concerned that the entire program may crash. This property is vital. Statistics is a young and growing science and new methods are being developed all the time (often as a result of more conventional applications of the number crunching power of computers - in multivariate statistics and bootstrapping for example). (iii) An explanation facility can easily be added. Usually a simple mapping of the rules to natural language text displayed on the screen suffices. For example, in attempting to apply the above example of a statistical rule the system may ask of the user: "Is X an interval variable?" The user may not understand the reason for the question (we discuss below how the system responds if the user does not understand the question itself) and so may ask "Why?" A simple mapping from the above rule then produces "I know that you require some summarizing average. If also the variable has an interval scale, then the arithmetic mean may be appropriate." The overall design of our system, as described so far, is thus: (a) Generate some likely goal states (statistical methods) by a mechanism to be described below. Examples of such are: analysis of variance, sample size determination, time series analysis, survey design, and so on. (b) By backward chaining through the production system determine which are appropri- ate. (c) Having selected a statistical tool pass control to the next stage of the program (which will be block 3 in Figure 2). We now discuss the question of how goals are triggered. In the terminology of the human approach this is the question of how hypotheses are generated. Put bluntly the strategy is to analyse a concise natural language description of the study using simple pattern matching 364</page><page sequence="15">language processing method to detect key words or phrases (see, for example, Hand, 1984, chapter 3, or Tennant, 1981). As I remarked in section 4, I found that understanding the aims and statistical requirements of research projects was considerably eased if I asked for a short written description of the projects to be given to me beforehand. I usually asked for less than a page of double spaced typing. These, or equivalent descriptions will serve as inputs to the language processor. This will -simply scan the text searching for key words or phrases matching an internal dictionary of its own. These words and phrases will be used to trigger potential goal states. We envisage a hierarchy of activation - some goals are more likely to be the correct ones when certain words are given. Similarly, an activation network also seems an appropriate structure: methods closely related to activated methods are also examined (at a lower priority) as potential goals. To take an over-simplified example, if the input text contains the word "groups" then we might activate the goals below, where the numbers indicate their priority: analysis of variance (1) t-test (1) multivariate analysis of variance (2) analysis of covariance (2) Non-parametric group comparisons (2) X2-test (3) log-linear modelling (3) Clearly goals activated from several sources will have a correspondingly higher priority for examination by the production system. It is very important to remember that at this stage (which is block 1 in Figure 2) we are merely trying to generate hypotheses. Generating too many will not be disastrous, it will merely slow things down-a nice balance needs to be achieved. It is also worth remarking that the order of priority given to the goal states will depend on the frequency with which different kinds of problems are encountered. In an environment which handles only continuous variables presumably _2-test and log-linear modelling would receive a lower priority. It is clear that the system itself is in an ideal position to modify the priority levels as it acquires more experience, and so tune itself to its environment. In many cases a key word will trigger several goals. Thus it is necessary that once a goal has been confirmed by the production system other goals triggered by this goal's triggering word or phrase are de-activated. Once all triggering words and phrases have found satisfaction in suitable goals the production system enquires whether all of the user's aims have been covered. The best way to do this is for the system to present a summarizing list of its intended analyses. An example of a human doing this occurs at the end of session 5 in section 3. In view of the multiple objectives of even the smallest research project, this is clearly an important feature. Up to this point our discussion has been concerned with how the program selects a statistical tool. Once the tool has been chosen control passes to block 3 in Figure 2. This consists of a series of modules corresponding to the goal states of block 2. That is, there exists one module for each statistical method that can be identified by the production system. (In principle, at least. In fact one module may serve more than one goal state.) These modules are highly structured programs which interrogate the user in detail about the aims of the study. They build up, in the machine, formal representations of the analyses to be carried out or designs to be created. Thus, if an experiment is to be analysed the analysis of variance module might be called, and this will extract details of crossing and nesting of factors and so on. These modules act as preparatory interfaces to the processing modules, which actually carry out the analyses (though, as we discuss below, the processing modules are not passive number crunchers like most existing systems). 365</page><page sequence="16">Our program BUMP is a perfect illustration of such an interrogation module, although it functions in a rather different environment. BUMP is an interface to a multivariate analysis package. It interrogates the user about his experiment and constructs a formal description of the design in the form of a MULTIVARIANCE program. This is then passed to the numerical processor. The interrogation modules of the expert system can be written, like BUMP itself, using conventional programming techniques (simply because their domains and objectives are very highly structured). Like BUMP they can use menus and simple yes/no answers to questions. There is an important issue to be raised here. Despite what statistical cookbooks say, statistics is a complex interlocking structure, not a collection of isolated recipes. Thus in some ways the division of the right-hand side of the system into separate modules might be regarded as artificial. Separate modules for regression and analysis of variance might be more fruitfully coded as one, and why not then make these just special cases of a general linear model program, including log-linear models and so on? As far as the actual numerical processing routines go (block 4) this might be the best way. However, it seems that retaining distinct modules for block 3 will have advantages. Not least of these is that distinct modules will be easier to write and can be written by different people in parallel. The block 4 components were described above as being processing modules. They could be existing programs, such as SPSS, MULTIVARIANCE, GLIM or GENSTAT. This would save a considerable amount of programming effort. But it would also defeat to a large extent the purpose of the system. Remember that the system is to function as an expert statistician. A professional statistician does not discuss the aims of a study, carry out the analysis, and just send a listing to the researcher with no word of explanation or interpretation. Neither do we wish our system to do this. As noted in block 4 of Figure 2, our actual number manipulating modules are interactive. And this interaction should work both ways. The program should examine the data - not merely carry out the analysis. So, for example, if multicollinearity is encountered in a regression analysis the regression processor should point this out to the user (explaining what it means, if necessary) and suggest several solutions: perhaps deleting variables, ridge regression and principal components regression. Along with recommendations, of course. We have found this kind of facility immensely useful in an early small experimental regression package. The number processing modules deal with data of two kinds. There is the controlling information, specifying precisely what analysis to carry out. This comes from two sources: by interaction with the user ("Do you wish a hierarchical decomposition of the sum of squares?") and from examination of the data (the system detecting a lack of balance in the experiment - leading it to question the user as above). The second class of data is the numerical data itself. The raw data is input and undergoes various transformations as it works its way through the system under the direction of the controlling information. One cannot avoid a production line analogy and is reminded of UNIX's pipelines. There are a number of practical advantages to the structure outlined above. Amongst these is the natural dividing line between blocks 2 and 3. This means that two distinct teams can work on the system without worrying about each other. In the best of project software engineering traditions it is merely necessary that the interface between blocks 2 and 3 (i.e. the list of goal states for the production system) be clearly specified. Similar modularity advantages lie within block 3 itself, and to a lesser extent within block 4. Block 3 modules can be taken out and modified or rewritten without in any way harming the function of the rest of the system. There are two parts of Figure 2 to which we have not yet referred. These are those labelled "storage". Their use, and usefulness, should be self-evident. Most research projects 366</page><page sequence="17">are extended over time and require several, if not many, consultation sessions. (My own experience as a consultant reveals how irritating it can be for clients if they have to remind one of the details of their study at each session.) Thus the system must be able to store the results of its deliberations. Storage at the points we have chosen should be particularly straightforward. At the end of block 2 it is simply necessary to store the set of active goal states, and at the end of block 3 the highly structured instructions on the method to be applied. Temporarily stopping the dialogue at other points involves storing more informa- tion but is in principle straightforward. We referred above to an explanation facility. Experience with a small experimental regression package showed the following approach to be extremely effective. Whenever the system has asked the user a question or is awaiting a user response the user can divert the system's attention to an instruction module containing explanations and definitions of technical terms. In fact in our earlier system a command word called this module and the individual technical terms keyed access to their own explanatory definitions. Machine monitoring of the use of this facility would shed interesting light on the users' statistical weaknesses. This, then, is the overall structure. A simple template matching natural language processor triggers hypotheses which are refined by a backward chaining production system to a set of goal states. Command passes to appropriate members of a set of highly structured interactive interrogation modules which extract the details of the study. From here interactive numerical processing components take over and begin to manipulate the data. It is important to understand that at any stage the system can check model assumptions (from the data in so far as this is possible) and caution the user if appropriate. For example, if a t-test is carried out the user may be warned about the normality assumption. This feature of the system is an important one in distinguishing between it and more conventional data-analysis packages. It is in this feature that a large part of the statistical expertise resides. 7 Conclusion The system outlined above discusses the study with the researcher, recommends appropriate statistical tools, and carries out the analysis, telling the user what it is doing, why it is doing it, asking for guidance where appropriate, and checking any assumptions or restrictions with the user or against the data. The design is based on a number of considerations, including how humans give statistical advice, careful attention to desirable properties, the parallel of medical consultation, the particular special requirements of statistical work, and the weaknesses of currently available software. One common experience with medical expert systems has been superb performance in the research environments of their own problem domain - sometimes better even than human consultants - but severely degraded performance in the broader hospital environment. One reason for this "plateau effect" is thought to be the prior selection of cases which occurs in the research laboratory. More borderline and uncertain cases- even cases not suffering from the type of disease in question - occur in real consultancy sessions. We have taken note of this experience, which is why the system above is designed, right from the start, to handle the whole spectrum of statistical problems (though obviously not all capabilities will be implemented initially). It is an implicit part of the design above that it should be built in a consultancy environment and that its usability and usefulness should be constantly monitored. There remain some important issues which should at least be noted. One of the these is the acceptability of such systems. Once again, our medical colleagues have had much 367</page><page sequence="18">experience with attempts to computerize the diagnostic process. Most of this work has occurred in the form of statistical or pattern recognition approaches to diagnosis where, in the laboratory at least, considerable success has been achieved. Outside the laboratory, however, in the broader medical community they have stimulated little enthusiasm. In contrast to the pattern recognition type of approach, expert systems are claimed to have gained far greater support. How much this is due to the glamour of a new technology and how much to the more human ("user-friendly" and based on methods analogous to those thought to be used by man) approach of expert systems remains to be seen. Time will doubtless tell. This might seem to suggest that statistical expert systems will not encounter tremendous opposition from professional statisticians. However, the kind of statistical system outlined above goes beyond most medical systems described to date in that it is designed to communicate with statistically naive researchers. Typically, medical expert systems function through the intermediary of a medical consultant. Perhaps statisticians will only welcome such systems when they serve as advice-givers to professionals, and not if they speak directly to the researchers. Another important issue, and again one which has been raised in a medical context, is that of accountability. Wherein lies the blame if a consultant recommends some course of action on the advice of an expert system and the results turn out to be disastrous? (For example, through poorly designed or analysed clinical trials or social surveys.) In medicine the answer seems at present to be that the consultant is held to be responsible - the expert system was merely giving advice and the final decision was his. However, if a statistical expert system is used directly by a statistically naive researcher it is surely arguable that the responsibility lies with the creators of the system. These are problems which must be confronted, because I confidently predict that, whatever other changes occur, the face of statistical software will change substantially over the next decade as statistical expertise, in addition to arithmetic expertise, is integrated into the programs. Acknowledgements I would like to express my thanks to all those staff and students of the Institute of Psychiatry who permitted me to tape the consultancy sessions, some of which are described in section 3. References Altman, D. G. (1982). Statistics in medical journals, Statistics in Medicine, 1, 59-71. Bobrow, D. G. and Collins, A. (1975). Representation and Understanding. Academic Press, New York. Davis, R. and King, J. (1977). An overview of production systems. In Machine Intelligence 8, Ellis Horwood, Chichester, 300-32. Elstein, A. S., Shulman, L. S. and Sprafka, S. A. (1978). Medical Problem Solving: an Analysis of Clinical Reasoning, Harvard University Press, Cambridge, Mass. Finn, J. D. (1977). MULTIVARIANCE version VI. National Educational Resources, Chicago. Fox, J. (1983). The theory and practice of expert systems. British Computer Society Specialist Group on Expert Systems Newsletter No. 8 (May), 14-16. Hand, D. J. (1981a). Artificial Intelligence, Psychological Medicine, 11, 449-53. Hand, D. J. (1981b). Discrimination and Classification, John Wiley and Sons, Chichester. Hand, D. J. (1982). Kernel Discriminant Analysis, Research Studies Press, Letchworth. Hand, D. J. (1984). Artificial Intelligence and Psychiatry. To be published by Cambridge University Press. Hand, D. J. (1985). Statistical expert systems II: Necessary attributes. To appear in The Journal of Applied Statistics, 12. Hayes-Roth, B. (1978). Implications of human pattern processing for the design of artificial knowledge systems. In Pattern-Directed Inference Systems, ed. D. A. Waterman and F. Hayes-Roth, Academic Press, New York. 333-46. 368</page><page sequence="19">Kassirer, J. P. and Gorry, G. A. (1978). Clinical Problem Solving: a behavioural analysis. Ann. Int. Med., 89, 245-55. Michie, D. (1982). In defence of chess programming. British Computer Society Specialist Group on Expert Systems Newsletter No. 6, 17-18. Newell, A. and Simon, H. A. (1972). Human Problem Solving. Prentice-Hall, Englewood Cliffs, New Jersey. Nie, N. H., Hull, C. H., Jenkins, J. G., Steinbrenner, K., Bent, D. H. (1975). Statistical Packages for the Social Sciences. McGraw-Hill, New York. Pople, H. E., Jr. (1982). Heuristic methods for imposing structure on ill-structured problems: the structuring of medical diagnostics. In Artificial Intelligence in Medicine, ed. P. Szolovits, Westview Press, Boulder, Colorado, 119-90. Post, E. (1943). Formal reductions of the general combinatorial problem. American J. Math. 65, 197-268. Simon, H. A. (1973). The structure of ill-structured problems. Artificial Intelligence, 4, 181-201. Smith, A. M. R., Lee, L. S. and Hand, D. J. (1983). Interactive user-friendly interfaces to statistical packages. The Computer Journal, 26, 199-204. Szolovits, P. and Paulker, S. G. (1978). Categorical and probabilistic reasoning in medical diagnosis. Artificial Intelligence, 11, 115-44. Tennant, H. (1981). Natural Language Processing, Petrocelli Books, New York. Waterman, D. A. and Hayes-Roth, F. (1978). An overview of pattern-directed inference systems. In Pattern-Directed Inference Systems, Academic Press, New York, 3-22. Wing, J. K., Cooper, J. E. and Sartorius, N. (1974). Measurement and Classification of Psychiatric Symptoms. Cambridge University Press, Cambridge, England. 369</page></plain_text>
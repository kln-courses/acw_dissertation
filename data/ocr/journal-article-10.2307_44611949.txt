<plain_text><page sequence="1">951480 Teleoperation of Mobile Equipment - A Behavioral Cybernetic Analysis Thomas J. Smith, Christopher M. Keran, Eric J. Koehler, and Peter K. Mathison U.S. Bureau of Mines ABSTRACT Teleoperation of mobile equipment is attracting growing interest as a safe and viable technological means of allowing humans to perform work in hazardous environments without compromising safety and health. Relative to telemanipulation, which has been more intensively studied, mobile equipment teleoperation poses distinct operational challenges, because the mobile device must be navigated and controlled by the remote operator during dynamic interaction with often unpredictable terrain and sensory environments. This report evaluates this issue from the perspective of behavioral cybernetics, with a focus on the closed-loop control properties of behavioral performance and how and why such control may be compromised during teleoperation of mobile equipment. The conceptual paradigm adopted in the paper is to treat a mobile device during onboard operation as an exoskeleton, a structural and functional extension of the operator's own body. This approach has its origins in research on anthropomorphic machines, which first identified a series of critical human factors and engineering control principles required for effective teleoperation of mobile devices. The paper builds upon this concept with a review of the behavioral cybernetics of mobile equipment guidance from both human factors and control theory perspectives. The paper goes on to compare and contrast demands on behavioral control during onboard vehicular performance with those encountered during teleoperation of a mobile device. The analysis suggests that performance problems in the latter case are attributable to behavioral effects of perturbed sensory feedback inherent to teleoperation, coupled with the need for projective control of behavior for effective vehicular guidance. The last section provides support for this conclusion with a summary of findings from our research on loss of fidelity of behavioral control under both delay and spatial displacement in visual feedback. Finally, the report targets a series of research issues that must be addressed in order to both understand and abate performance problems with teleoperated mobile equipment. INTRODUCTION By obviating the need for direct operator interaction with physical and/or toxic chemical hazards, teleoperation of mobile equipment is attracting increasing interest as a safe and viable technological means of allowing humans to perform work in hazardous environments without compromising safety and health. Current application areas receiving the greatest attention include environmental remediation, mining, underwater work, and battlefield operations, all of which may require use of mobile equipment to perform work in close proximity to hazardous materials and/or conditions. During mobile equipment operation, the sine qua non of acceptable performance is that the vehicle be guided and controlled safely, accurately, and (in most operational contexts) efficiently. The routine and largely successful day to day operation of millions upon millions of mobile vehicles worldwide suggests that, for most people, proficiency in mobile equipment operation is a readily mastered, almost natural skill. Most of us are habituated to what by any measure must be recognized as one of the marvels of human performance in the modern world - the ongoing panorama on highways and byways of a constellation of large machines, some weighing many tons, hurtling to and fro often at high speeds in a smooth, coordinated, integrated fashion. Nevertheless, the apparently straightforward process of mobile vehicle operation rests upon a complex repertoire of behavioral control mechanisms. For acceptable vehicle guidance the operator must effectively control, through motor behavior, sensory feedback from major and auxiliary controls in the vehicle cab itself as well as from dynamic movements of the vehicle through its environment. These control demands may be exacerbated and confounded by additional demands on the behavioral control capabilities of the operator, such as social tracking of other passengers in the vehicle, or controlling auditory feedback from car radios or cellular telephones. Ultimately, all of this behavioral performance is directed at accurate, safe, and efficient dynamic guidance of the vehicle in relation to roadway features and obstacles, other vehicles, and pedestrians. 457</page><page sequence="2">In the case of teleoperation - involving remote rather than onboard control - of mobile equipment, demands on behavior for vehicle guidance and operation are fundamentally altered. Sensory feedback from direct operator interaction with cab controls and the cab environment is no longer available. Provision of sensory feedback from vehicle movement to the operator typically is mediated by a remote control computer, customarily as video-displayed visual feedback from remote cameras. Auditory and/or force feedback also may be provided - tactile and vestibular feedback typically are not. Major vehicle controls typically are actuated, not by steering wheel, accelerator, and brake, but by joystick. That is, relative to onboard control, sensory feedback during teleoperation control is reduced and perturbed in modality, quality, and quantity, and human-system compliance is disrupted, all of which place increased demands on behavioral control. Relative to telemanipulation, teleoperation of mobile equipment has been less intensively studied. For example, the Handbook of Industrial Robotics contains a chapter on teleoperator arm design, but no treatment of mobile equipment teleoperation [1]. In their review of teleoperation and telerobotics, Vertut and Coiffet [2] devote three chapters to telemanipulation, but only one to transporters and vehicles. Based on specified title, 111 references cited in this review deal explicitly with telemanipulation, whereas 41 deal with mobile robotic systems. Most of the references in the latter category are concerned with legged rather than wheeled mobile robots. Sheridan's [3] monograph on the role of supervisory control in teleoperation provides a more balanced treatment of both teleoperated mobile vehicles and telemanipulators. Indeed, a major impetus for development of supervisory control concepts and systems was the challenge of teleoperating mobile vehicles over large distances with substantial time delay. The growing market for remotely controlled mobile systems to deal with hazardous materials and conditions, as noted above, suggests that more scientific attention to human factors and human performance issues related to operation and use of such systems is warranted. Accordingly, a Telesciences and Telerobotics Session for the 25th International Conference on Environmental Systems was organized around the topic of teleoperation of mobile equipment. The session provided a series of practical and conceptual perspectives on mobile equipment teleoperation that illustrate the emerging significance of this area of telescience and telerobotic technology. This report and others in the session deal with human factors and engineering issues that pose a direct challenge to successful implementation of operationally effective systems. The purpose of this report is to evaluate mobile equipment teleoperation from the perspective of behavioral cybernetics, with a focus on the closed-loop control properties of behavioral performance and how and why such control may be compromised during teleoperation of mobile equipment. We assume that insight into performance issues and problems with mobile equipment teleoperation rests upon what is known about onboard performance with mobile equipment. Accordingly, subsequent sections of the report deal with: (1) a review of findings from studies of onboard performance with mobile equipment, from a behavioral cybernetic perspective; (2) a behavioral cybernetic analysis of mobile equipment teleoperation; and (3) a synopsis of empirical findings from our program of research on behavioral control under perturbed sensory feedback, that may provide insight into how and why performance is more compromised during remote as opposed to onboard control of mobile equipment. BEHAVIORAL CYBERNETICS OF MOBILE EQUIPMENT GUIDANCE Why is an acceptable level of skill and proficiency in mobile equipment guidance so readily achieved by so many people? We assume here that the answer to this question lies in an understanding of human-vehicle interaction as a behavioral cybernetic process that enables behavioral and vehicular performance to become tightly coupled or yoked in a feedback integrated fashion. The basic premise of behavioral cybernetics is that behavior is organized and integrated as a closed-loop, feedback-controlled process [4-9], based on movement control of feedback from sensory receptors (i.e., sensory feedback control). Behavioral guidance is achieved by referencing central nervous system activity caused by receptor self-stimulation (due to movement) to that caused by receptor activation due to environmental stimuli (originating with environmental design factors). Because muscle action also controls receptor interaction with environmental stimuli, both sources of sensory stimulation are directly controlled by the motor system. The use of movement to control sensory feedback links peripheral motorsensory activity with functioning of the central nervous system, and feedback integrates motor behavior, sensation, perception, and cognition. In both unaided and human-machine performance, motor control of sensory feedback forms the basis of tracking and controlling visual, kinesthetic, auditory, and tactile feedback, of integrating compound motorsensory operations, of social integration of behavior of interacting persons, of interrelating the use of language, speech, problem solving, and other cognitive operations with activity, of behavioral-physiological integration, and of both motorsensory and cognitive interaction with tools, machines, and complex automated systems [4] [9- 11]. The concept of behavior in all its variety as a feedback process comports with Adolph 's [12] thesis that all known biological systems are feedback controlled and feedback integrated. The premise that behavior is organized in terms of closed-loop links between sensory feedback (generated by environmental design factors) and sensory feedback control (mediated by motor behavioral mechanisms) implies that variability in behavioral performance should be critically influenced by design factors in the performance environment. This represents the thesis of context specificity in behavior and performance. A substantial body of empirical evidence supports the thesis [13]. Some of the strongest support is derived from studies of how and why interactive human- 458</page><page sequence="3">Figure 1. The motor vehicle as exoskeleton - concept diagram. machine performance is compromised by lack of compliance between behavioral control capabilities and sensory feedback from machine design factors [14][15]. During mobile equipment guidance, what design factors most critically influence human-vehicular performance? Subsections below address this question in relation to: (1) the concept of the motor vehicle as an exoskeleton; (2) human factors issues in mobile equipment control; (3) the role of projective control; and (4) systems control models of mobile equipment operation. THE MOTOR VEHICLE AS EXOSKELETON - To account for the ease and facility of onboard performance with mobile equipment, we assume that during the driving task the motor vehicle serves as an exoskeleton - a mechanical extension of the operator's own body, intimately coupled with and responsive to the operator's control behavior. This concept is illustrated in Figure 1. The diagram suggests that in terms of two of the most critical aspects of vehicular guidance, control of visual feedback (large eye) and of vehicular trajectory (steering wheel), the operator and vehicle comprise an integrated control system. A key premise of the concept, as the diagram suggests, is that the vehicular exoskeleton establishes a postural framework for the operators travel and manipulative movements, thereby determining the integration of these movements relative to projective control of the vehicle. Three important parameters of dynamic visual feedback from vehicle trajectory essential for effective vehicular guidance [16-18] also are shown in the figure: lateral error, heading angle, and path angle, relative to road line markings. One of the first systematic control system and human factors investigations of mechanical exoskeletons originated with Mosher's work some three decades ago on CAMs, or cybernetic anthropomorphous (human-like) machines [2][15] [19] [20]. The work defined a series of important human factors issues pertaining to human performance variability with tightly coupled human-machine systems, including: (1) need for compliant sensor, actuator, and effector designs for effective human-machine system integration; (2) guidance of interactive performance via behavioral feedback control mechanisms; (3) critical role of temporal and spatial feedback factors inhuman-system compliance and integrative control of robot movement; and (4) need for human- computer-robot integration arising out of use of computers to mediate control of telerobots. A major finding emerging from this work is that intimate human-machine coupling embodied in the exoskeleton concept cannot be achieved without tight spatial compliance between movements of the operator and those of the machine [21]22]. This finding forms part of a large body of evidence indicating that behavior is guided primarily in terms of compliance between the spatial organization of movements and the spatial attributes of sensory feedback controlled by those movements [4] [6] [8]. Some of the best evidence supporting the concept of the motor vehicle as exoskeleton is provided by studies of mobile equipment teleoperation (next section), showing the reduced spatiotemporal compliance, loss of functional integration, and consequent degradation in system performance that occurs when exchange of sensory feedback between operator and machine is reduced to a video display for visual feedback and a joystick for mobile equipment control. Support for the concept also is provided by studies of onboard vehicle operation, showing consistency between findings from empirical studies of driver performance and predictions of closed-loop models of steering control [18] [23-25]. Even more compelling are the observations of Druiy and Dawson [26] on driving a fork-lift truck. They show that times for moving the truck a given distance and stopping within different specified error bands are predicted by an equation similar to Fitts' law equating hand-arm movement time with index of difficulty. This finding suggests that the driver controls the truck as a direct mechanical extension of his/her own motorsensory system. HUMAN FACTORS ISSUES IN ONBOARD VEHICULAR CONTROL - Factors affecting human driving performance with motor vehicles have been reviewed by Biggs [27] and Hoffmann [18]. Broadly speaking, two broad categories of factors are addressed in these reviews: those pertaining to the design of the vehicle and the driving task, and those pertaining to the behavioral characteristics of the operator. The behavioral cybernetic perspective adopted here is to consider driving performance as a manifestation of the closed loop, feedback interactions between behavioral factors and system design factors [14][28],as illustrated in Figure 2. The figure depicts sensory feedback from vehicular design factors to the right under active control by behavior of the operator to the left [29]. Under dynamic performance conditions, design factors generate: (1) vestibular feedback from trajectory changes, accelerations, and decelerations of the vehicle; (2) force, vibration, and tactile feedback to the steering wheel and seat from contact of the vehicle with the road surface; (3) auditory feedback from engine, wind, and wheel noise and other sources; (4) visual feedback from extravehicular sources such as pedestrians, other vehicles, and/or roadway features and obstacles; and (5) visual feedback from the trajectory of the vehicle, perceived as path angle, heading angle, and lateral error displacements relative to road line markings (Figure 1). As shown in Figure 2, the operator senses and initiates motor behavior to control reactive, instrumental, and operational modes of sensory feedback from vehicle design factors [4] in order to guide vehicular performance. The 459</page><page sequence="4">с r . ! OPERATOR &gt; VEHICLE , , ^ ^ ^ I ^ Motor Adhttlv Motor Control of Sensory gmtwory ГчгНтгк i • Upper Limb Teedbacfc Rom Vahjgto ļ Rom Vehicle 1 ! • Lower Limb • Cab Enwronmert. ¡ ¡ ! - . . VtaíbilHy, &amp; Ottier ' • Vestibular ¡ ¡ * . Dashboard Foncions ļ . ^ ļ ¡ # Head • Seaing Funcione ¡ # vibration ¡ I ! |* I • Social Tracking | # Jacļjļe ¡ ! I • Vehicle Speed ! ^ ^ # Audtory ! i -Accelerator . Vehicular ^ ¡ -Brake Performance "► ^ # Víaual-Exiamhicular ¡ ' -GeerShHt ! 1 1 - Olher Vehicles ¡ - Roadway Features i ļ • Vehide Trajectory ¡ -Obstacles ¡ j -Steering Wheel . -Distracïons ■ I i ! • Visual-Vehicular I i . I Î, ļ - - Lateral Path Trajectory Displacement 1 ! Î, 1 ļ - Path Trajectory ! j Narvomfiylni 1 ¡ -Angu,, Muta. i ¡ • Receptor Activation- V ¡ i j Sensation р-гй»«. 11 ! Sensory Feedback From ¡ i , • Perception bv-Cab Peribrmance i ¡ I • F-ЛшЦ , j j • Cognition (Reactive, Instrumental, )ļ Operational Feedback) ¡ 1 1 1 1 ! ! Figure 2. Behavioral cybernetic model of onboard control of mobile equipment. same sensory feedback modes also are available from design features within the cab itself (i.e., steering wheel, brake and accelerator, seat, dashboard displays and controls, other displays and controls), which the operator senses and controls to guide in-cab performance. The primary objective of the operator's motor behavior in integrating both of these sources of sensory feedback is controlling vehicular speed and trajectory. However, other sensory feedback control demands, related to such functions as the cab environment, seating, social tracking of passengers, and/or other functions, may augment or distract from the primary control objective. Behavioral Factors - Which factors have the greatest influence on variability in driving performance? Despite extensive research, the literature offers no definitive answer to this question. Among behavioral factors, effects of fatigue on driver vigilance and safety long have been of concern [30] ; the review of extended workday research by Duchon and Smith [31] cites findings showing an elevated driver accident risk associated with working long hours. Another behavioral factor receiving close attention, in relation to both lateral and longitudinal control of a vehicle, is the visual feedback control capabilities of the operator. These encompass both steering reaction time to visual feedback, as well as visual perception of vehicle trajectory, roadway features and obstacles, and other vehicles. Relatively long time delays (1.5-2 sec) have been documented in lateral displacement steering responses to a perceived road obstacle [32], and to longitudinal displacement steering responses to changes in separation distance (headway) and relative velocity between lead and tailing vehicles during car following [18]. In the former case, the authors recommend that for safe operation, at least 3 sec be reserved for drivers to respond, by lateral displacement steering, to changes in the road environment [31]. Control of visual feedback by the driver during both lateral and longitudinal vehicular control tasks has been reviewed by Hoffmann [18], and by Biggs [27] from a theoretical perspective. Various eye movement studies suggest that both peripheral and foveal vision are employed during steering control; an interpretation of the findings is that peripheral vision is employed for monitoring lane position, other vehicles, and road signs, so that foveal vision may be employed for closer examination when necessary [33]. A number of studies support the conclusion that among the sources of visual feedback from vehicle trajectory shown in Figure 1, yaw or heading angle, yaw rate, and lateral displacement or error relative to road markings are most 460</page><page sequence="5">heavily relied upon for steering control purposes, a finding that accords with predictions from theoretical models of driver control [16-18]ģ For longitudinal control during car following, Hoffmann [18] concludes that control of both relative velocity and headway between lead and tailing vehicles is based upon visual feedback from either horizontal angular velocity of the lead vehicle (above threshold level), or changes in headway if angular velocity is below threshold. Design Factors - As with other types of performance [13] [14], evidence suggests that driving performance is specialized in terms of the interaction of behavioral factors discussed above with both vehicular and driving task design factors. Design of the driving task, manifest as the spatiotemporal profile of dynamic displacements between vehicle alignment and road markings (Figure 1), has a key influence on driving performance, with yaw angle and lateral error particularly important for trajectory control. A number of studies have identified vehicle response time (measured as exponential rise time), vehicle stability (measured as the degree of understeer or oversteer), steering gain, and steering force as vehicle design factors that can significantly influence lateral steering performance [18] [34]. Evidence points to vehicle response time as the most important single parameter for good handling [18], probably because it affects yaw rate upon which trajectory control relies. It appears that driver steering performance is best with a vehicle response time around 0.2 sec. Control of longitudinal driving performance is influenced by design of both the accelerator and braking systems [18]. Pedal angles, vehicle response to accelerator displacement, and accelerator or brake pedal force required per unit acceleration or deceleration are among the key design factors specified. Also, driver response time is affected by the physical layout of the brake relative to the accelerator. The foregoing synopsis of behavioral and design factors affecting driving performance is somewhat cursory for good reason. Compared with our (still incomplete) understanding of how behavioral and design factors interact to mediate onboard control of vehicular performance, understanding of the degree to which variability in teleoperation performance with mobile equipment may be influenced by these factors is minimal (next section). Furthermore, because of substantial differences between onboard and teleoperation performance contexts in terms of both behavioral demands and system design features, the degree to which findings cited above from research on onboard performance may be generalized to performance during teleoperation is open to question. Perturbed Visual Feedback Factors. There is one major category of design factors, not addressed in reports cited above, whose influence on onboard driving performance is likely, and whose pronounced effects on teleoperation performance with mobile equipment is unquestioned (next section). These are perturbed sensory feedback factors. Specifically, degradation, spatial displacement, and/or delay in visual feedback can profoundly disrupt vehicular control. The term "perturbed sensory feedback" refers to the introduction of some sort of displacement, transformation, and/or energy extreme in the spatial, temporal, and/or physical properties of one or more modalities of sensory input to the human operator across the interface. Perturbations in sensory feedback presented to the operator invariably arise as a consequence of system design features. In general, four major classes of perturbations in sensory feedback may be identified: (1) spatial transformations and/or displacements; (2) temporal delays; (3) changes in energy properties; and (4) modality conflicts. Perturbations in sensory feedback are pervasive to interactive systems generally and telerobotic systems in particular, in relation to design features and limitations of both hardware and software [15] [35-38]. Such perturbations lack compliance with the spatiotemporal features of motor behavioral organization established during development and maturation. As a consequence, they alter the closed-loop mechanisms of sensory feedback control, disturb cognitive, perceptual, and motor behavior, and compromise interactive performance [4] [9]. From a behavioral cybernetic perspective, these performance effects arise because the control and guidance of behavior is neurogeometric and neurotemporal - i.e., dependent on relative space and time displacements between movements and their sensory feedback [4] [6] [8] [9]. Interactive performance is based on the execution of movements to control behavioral interaction with the system through control of sensory feedback from both system design factors and the movements themselves. If the relative space and time displacements between a movement pattern and its sensory feedback are nonperturbed, the movement typically is executed "naturally, "with a proficiency that has emerged during the course of development, maturation, and past experience. However, if compliance between sensory feedback and sensory feedback control is displaced in some manner spatially or temporally, accurate and consistent performance will be achieved only with some degree of new practice and learning, which will vary in degree with the extent of the displacement. Moreover, if the displacement varies beyond a critical range of movement control capabilities, decrements in sensory feedback control arise, interactive performance suffers, and practice and learning are ineffective in restoring consistent and accurate performance. A limited body of evidence indicates that onboard driving performance is sensitive to both temporal and spatial displacements in sensory feedback. Performance effects of temporal delays between initiation of a behavioral act, and sensory feedback generated by that act provided to the operator, have long fascinated students of human behavior. Findings from many experimental studies conducted over the past 50 years indicate that feedback delay is almost unsurpassed in its ability to create pervasive and immediate disturbances in behavior [5]. From a behavioral cybernetic perspective, delay effects occur because effective guidance of behavior is critically dependent on close temporal alignment between movements and sensory feedback generated by those movements. 461</page><page sequence="6">Figure 3. Methods and findings for study of effects of angularly displaced visual feedback on onboard driving performance A number of factors can be identified that will contribute to feedback delays in steering response of a vehicle, including: (1) steering reaction time of the operator; (2) steering column coupling mechanics; (3) vehicle momentum; (4) time constant of powered steering; and (5) slipperiness of road surface. Delay magnitudes attributable to these factors will vary as a function of vehicle speed, mass, and mechanical design. Degradation of onboard driving performance under feedback delay has been documented in a number of studies. The importance of yaw response time of the vehicle for lateral control was noted earlier. Hoffmann [18] cites findings showing that driver ratings of vehicular performance are strongly influenced by both yaw response time and steering gain, and that steering performance is best with a feedback delay in yaw response time of 0.2 sec or less. In a driving simulator study, Frank and colleagues [39] introduced delays in both motion and visual feedback from the simulator to the operator. For dependent measures related to driving performance, major findings of this study are that: (1) visual feedback delay is more detrimental than movement delay; (2) relative to no delay conditions, performance degrades linearly with either visual or movement feedback delay out to 340 msec; (3) combining visual with movement feedback delay has a synergistic (nonadditive) effect on performance degradation; and (4) with asynchronous delay, better driving performance results if visual system feedback leads motion system feedback from the simulator. Turning to spatial displacement, a compelling demonstration of the degradative effects of this type of perturbation in visual feedback on onboard driving performance is provided by the study of Kao and Smith [[4] [40]. Methods and findings for this study are illustrated in Figure 3. As shown in Figure ЗА, three mounting positions were established for a television camera on the roof of an experimental station wagon, one in the center, one on the left edge, and one on the right edge of the front of the roof. These camera positions provided three modes of angularly displaced visual feedback of the roadway to a closed circuit television monitor situated in the cab in front of the driver. Subjects, all experienced drivers, were instructed to guide the vehicle by viewing the monitor, with the camera mounted in one of the three positions. Direct view of the roadway was blocked by blacking out the windshield on the driver's side. The task involved guiding the vehicle at low speed over a 55-foot S-shaped roadway, marked with pylons every 5 feet (Figure 3B). Touching a pylon was scored as an error. Results (Figure 3C) show that performance with the left- and center-mounted cameras did not differ significantly, whereas the right-mounted camera position produced significantly more driving errors. The finding indicates that although drivers can tolerate limited angular displacement of visual feedback, driving performance deteriorates when the displacement exceeds a critical angle. The results recapitulate the earlier finding of Gould and Smith [41] that visual-manual tracking performance starts to degrade when angular displacement of televised visual feedback exceeds a breakdown angle of about 40-50 deg. Our interpretation of these research findings is that driving performance, like other modes of behavior [8], is spatially as well as temporally organized. That is, intimate human-machine coupling in the driving task (Figure 1) involves close spatial compliance between movements of the operator and those of the vehicle. Evidence noted above that guidance of lateral motion relies greatly on control of angular displacement between vehicle heading and road markings (Figure 1), and that guidance of longitudinal motion relies greatly on control of relative angular velocities between following and lead vehicles, supports this interpretation. A major theme of this report (next section) is that spatial compliance is severely compromised during mobile eqyipment teleoperation, which in turn contributes to substantial performance degradation relative to onboard conditions. 462</page><page sequence="7">PROJECTIVE CONTROL OF BEHAVIOR IN DRIVING PERFORMANCE - (You DRIVE a car at 40 m.p.h.,but at 80 m.p.h.you're AIMING it'- seen on bumper sticker). A recurring theme in analyses of driving performance is that projective or feedforward control of behavior is integral to the task. For effective guidance of a moving vehicle, the operator must be provided with visual feedback from roadway features well ahead of the vehicle's current position. Postural, transport, and manipulative movements required for steering behavior are then projected in a predictive way to control the vehicle in relation to those features in an anticipatory or feedforward fashion. In the driving literature, there is no common agreement regarding terminology to distinguish guidance of the vehicle under feedforward versus feedback control conditions. Terms employed to describe these two conditions encompass driving or operator preview versus tracking control [23], pursuit versus compensatory control [42] [43], look-ahead versus follow-the-leader control [44], or steering versus vigilant tracking control [4]. In this report, the terms feedforward, projective, or predictive control, as opposed to feedback control, are employed. It can be argued that projective control of behavior represents one of the most critical concerns of human factors and human performance science. Predictive control of movement is synonymous with control of behavior. The foot and leg in preparing to land in a stride are controlled on predictive basis - leg extensor muscles contract to stabilize the knee to withstand the shock of the landing before it occurs. The hand in active grasping is adjusted in a predictive way during the travel movement to be prepared for the specific grasp to come. The eye in reading is projected on a predictive basis to perform saccades of specific length. Most tool-using and machine behavior involves projective performance. In interpersonal social behavior, the actions of one person project the responses of others, whose actual responses may or may not conform to the predictive actions of the first. Predictive behavior is most familiar in the context of directional control of mobile vehicles, in which a general course or path is followed. But such behavior is far more pervasive. Most forms of locomotion in walking, running, hopping, skipping, dancing, and so forth involve projective performance. Projective guidance of movement is inherent to all of the most significant forms of human activity, including such specialized activities as graphic behavior, artistic performance, writing, musical performance, machine performance, tool-using behavior, and athletic skills. General types of human activities such as work, recreation, play, social interactions, theatrical performance, household skills, and medical skills involve varied forms of behavioral guidance based predominantly on projective control. Planning and projecting our social, organizational, institutional, political, economic, national, and international futures is based on feedforward control of behavior. We assume that the main imperative facing human individuals in planning and design of their tools, machines, organizations and institutions, architecture, language, communications, work, and so forth is the demand for accurate, predictive guidance of behavior. Indeed, a case can be made for the view that human evolution has been guided, in a feedback fashion, by the search for more and more accurate methods of quantifying and organizing time in order to plan, project, and predict human behavior and the course of human society. Appreciation of the human factors significance of the feedforward control of behavior had its main origins in the study of target tracking during World War II. Experimental analysis of component movements required to control the direct pursuit, aided, or velocity tracking mechanisms employed in combat radar, gun, and aircraft training and equipment systems indicated that the servomechanism, stimulus-response, and sampled-data theories of tracking then in vogue could not explain the demands on tracking behavioral control imposed by these systems [48]. In demonstrating that direct pursuit tracking is significantly and consistently superior at all stages of learning to aided and velocity tracking, this research contributed to the recognition that most forms of aircraft, gunnery, and naval tracking involve a predictive rate control aspect that distinguishes such guidance from feedback control tracking. That is, to track a target effectively an operator not only has to position the cursor accurately, but also must establish a rate of movement of the cursor that will predict accurately the future position of the target in space. Direct pursuit tracking systems are superior to aided or velocity systems because, with the latter, assumptions have to be made about the nature and extent of projective control requirements in the software/hardware design of the rate control mechanism. These observations have direct relevance to understanding mobile equipment guidance behavior, in which the operator must project the position of the vehicle in time and space relative to roadway features and obstacles. Neuromotor mechanisms that possibly contribute to feedforward control of behavior have been recognized for some time. An early finding in primates is that voluntary contraction of hand muscles in response to a visual stimulus is anticipated, by about 90- 100 msec, by activation of neurons in the motor cortex controlling that contraction [45]. There is experimental evidence in humans for feedforward signalling of force during voluntary movement [46]. More recently it also has been shown in primates that voluntary eye movement to a new target is anticipated, by about 70 msec, by remapping of the activity of neurons in the visual cortex responsive to the retinal receptive field for that target [47]. These observations encourage the following speculative summary of the neurobehavioral substrates of operator performance during projective guidance of a mobile vehicle. Eye movement studies cited earlier [33] indicate that during open driving foveal vision fixates on a variety of different features, such as the center line, lane center, and right edge of the roadway, other vehicles, and road signs. Detection by peripheral vision of a feature requiring steering control action evokes eye movement to fixate foveal vision on that feature, about 70 msec after remapping of the activity of visual cortical neurons responsive to the retinal receptive field for the new feature. Steering action to control this 463</page><page sequence="8">visual feedback in turn is evoked (neural mechanism uncertain) by contraction of hand-arm muscles, some 100 msec after motor cortical neurons controlling these muscles become active. There also may be feedforward control of muscle force required to turn the steering wheel. The timing between visual feedback from the new feature and steering action to control this feedback is context-dependent upon the nature of and distance to the feature, road and vehicle alignments, road conditions, and vehicle speed, weight, and handling characteristics [18]. Evidence supporting this neurobehavioral analysis of feedfoward control behavior is provided by studies of the effects of feedback delay on projective performance. For large vehicles such as multi-ton trucks, large planes, or tankers, inertial properties of the system may engender considerable time delays between when a control movement is initiated to guide the vehicle, and its operational response. These machine delays actually are experienced and must be controlled in terms of relative space displacements between behavioral control actions and the operational actions of the machine [5] [8]. With teleoperated systems, delay in sensory feedback from system response can be inherent to transmission lag and/or computer processing design factors [35]. The experiment of Coleman, Ruff and Smith [49] with a feedforward control tracking task illustrates how feedback delay disrupts the integration of hand-arm and eye movements required for projective steering behavior. The object of the study was to determine time differences between eye motion and hand-produced target motion when feedback delays were introduced between hand and target motions. Projective control required in performance of the task is similar to that required for steering a mobile vehicle with feedback delay between steering movements and movements of the vehicle in relation to the road. Real time computer methods were used to introduce feedback delays between hand motions and sine wave variations of an oscilloscope target produced by the hand motions. A photomultiplier transducer was employed to record eye movements. The task of subjects was to move a strain gauge hand-motion wand back and forth so as to produce the steering action of the target on the oscilloscope. A total of 3952 eye movement measures were collected in each trial, representing time differences between directions of eye motion and directions of target motion. With rare exceptions these were measures of time lags between eye motion and target motion. The computer system was programmed to produce feedback delays of 0, 100, and 200 milliseconds between hand motion and target motion. Data were obtained from five university student subjects who performed in a balanced experimental design at the three feedback delays. The results of this experiment may be understood in terms of the normal action of the eye in steering. The eye does not follow movement of the hand or target in steering, but anticipates and predicts hand action. At no delay, it was observed that eye motion preceded target motion by about 120 msec. At 100 msec delay, this prediction time decreased by about 20 msec. However, a steering feedback delay of 200 msec reduced the eye prediction time to about 40 msec, to a level at which the eye no longer functioned to provide a projected reference of the course to be followed. The experiment also measured time differences between eye and target motions in manual tracking of environmentally generated targets. The targets in this case were computer generated replications of the patterns of hand-directed target movements in the steering trials. The finding was that with no delay between manual control and target action in this stimulus tracking task, the eye anticipated the course of target motion by about 200 msec. Findings from this experiment support two conclusions. First, timing of predictive movements of the eyes in projecting the course of steering action is different from that for stimulus tracking. Predictive eye movements occurred about 80 msec later for steering compared with stimulus tracking. The second conclusion pertains to effects of delay on feedforward control of steering performance. A delay of 100 msec between hand motion and motion of the steering target produced only minor changes in timing of the predictive action of the eyes in most subjects. A delay of 200 msec, however, all but wiped out the ability of the eyes to guide projective action of the hands in steering, since this delay produced predictive eye movement times of only 40 msec - far less than the response time of the hands in interacting with visual guidance. The main effect of hand -target steering feedback delay found in the experiment consisted of restricting severely the normal capability of the eye to project the course of self- generated steering movements. This occurred because the predictive role of visual perception in steering was significantly reduced below the temporal interval of visual- manual response time. In an actual vehicle steering situation, the delay effect would manifest itself as a desynchronization of eye and hand-arm movements in steering with visual feedback from the road display. In this discoordination, the eye would persist in following the road display out of synchrony with hand-arm steering movements and resulting movements of the vehicle, thus effectively uncoupling projective control of vehicle movements in relation to the course of the road. SERVO-CONTROL MODELS OF ONBOARD VEHICULAR OPERATION - This subsection provides a brief review of servo (negative feedback) control system models that have been developed to describe onboard operation of motor vehicles. The rationale for reviewing this material is that: (1) in some (but not all) respects, predictions of the models are aligned with empirical data regarding human driving performance; and (2) findings from our behavioral control systems research on perturbed visual feedback (below) may be interpreted in light of predictions of the models. Published descriptions of comprehensive servo models of onboard vehicle operation, with transfer functions specified, date back almost three decades [16] [23], and have since received extensive attention as applied to both lateral [42] [43] and longitudinal [44] control of driving. The impetus for deriving driving performance servo models was earlier development of control models of aircraft piloting 464</page><page sequence="9">Motor Feed Forward Condili ^ RaacbonTana "** ^ Central Nervous ^ ^ OfSenaory Da My "** ^ 9yetem ^ ^ ****** • Gem - Y,, • ЯмТго&gt;^ • Phnon DoytHcement « 0^ SyMen Sydrn Motor Feedback i ' r ' n™, l*ww Vehicle tn Гля|. Control beul ^ Errar, - . ' ' l*ww n™, Vehicle tn Гля|. Control System - ^ • У sex- . -^st^ ^ ► ii • # G-I-Ype a Ikes Tana- • Rise Tana - Tq. "" a Ptiaaa "" Оиикшатаи» = 0 • Phnaa m Вкфкшатша « 0^ ^Senaory Feadbocīi^^^^44^ / ModaMy, Delay. ' ( Spattai Daplacamant. ) Ч^^^Иуаюа! ОивМЬаа^^^/ Figure 4. Servo control model of driver/vehicle system, with dual mode feedback and feedforward control. performance [16]. Predictions from control models of driving performance have been shown to be generally aligned with frequency response data derived in experimental driving studies related to general steering control [23] [43] [44], response to crosswind gust disturbances [24] [25], and passing maneuvers [24]. The experimental findings are derived from both driving simulator and over-the-road methods. Different modelling approaches to human driving performance are reviewed by Sheridan [3] and Hoffmann [18]. Basic elements of a servo model combining dual mode feedback and feedforward control of driving performance [43] are illustrated in Figure 4. The diagram represents a control systems version of the behavioral cybernetic representation of driving performance in Figure 2. Two operational control blocks pertaining to driver performance (c), namely motor feedback (compensatory) and feedforward (pursuit) control, and one pertaining to vehicle performance or output (m), are shown in Figure 4. The model assumes that: (1) the frequency response for each of the operational control blocks depends upon their gain (Y), rise time (TR), and phase displacement (ф) levels computed relative to frequency characteristics of system input (i); (2) sensory feedback from vehicle performance or output is employed in a closed-loop servo fashion to control system input; (3) compensatory control relies upon detection of error between output feedback and input; (4) feedforward control relies upon visual feedback from the road ahead coupled with cognitive skill of the driver [43]; and (5) motor control functions of the driver are mediated by the central nervous system, including reaction time delays. Mathematical treatment [18] [42] [43] of the model shown in Figure 4 supports the following predictions regarding driver steering behavior. Specifically, any or a combination of the following changes in driver feedback and/or feedforward control capabilities will degrade steering performance: о A drop in gain of the behavioral control system, which reduces output and increases error of the system relative to input, о An increase in behavioral rise time, which reduces gain of the behavioral control system, о An increase in behavioral overshoot, which reduces gain of the behavioral control system, о Delay in visual feedback of steering performance, which reduces output and increases error of the behavioral control system relative to input. Our research indicates that all of these effects occur under perturbed visual feedback conditions (below). The model in Figure 4 does not explicitly predict décrémentai steering effects of a number of perturbed visual feedback factors whose operational effects on either onboard or teleoperation driving performance are well documented (next section). These include spatially displaced visual feedback (Figure 3), limited field of view, and/or lack of three dimensional perspective. The overall content and criterion validity of the servo model of steering performance, at its current stage of development, therefore is limited. It accounts for a number of the dynamic frequency response properties of the driver-vehicle system under nonperturbed visual feedback conditions, and predicts décrémentai effects of feedback delay on these properties, but does not address other perturbed visual feedback factors known to affect performance. BEHAVIORAL CYBERNETICS OF MOBILE EQUIPMENT TELEOPERATION This section takes up the question of how and why performance varies during teleoperation as opposed to onboard control of mobile equipment. 465</page><page sequence="10">¡ OPERATOR i" TELEOPERATED VEHICLE ! i i i 1 I 1 I 1 1 I 1 1 Motor Activity Motor Contrai of Sensory ¡ němotě Vehicular ¡ • Upper Limb Feedback Ron. Reieote j Andtoņc ^ ^ , i СипйЫ Work Station i т«ь- e Remote Cameras Remote i , • Postaral ► . Joy*)* Ancton iüSE . Virtde Speed Vahtaļar ! I • . Kqiboefd Aeictfons | . yeNdeTląeckey | ! * ^ .HndUpDtapw ļ . ' ļ J e Work Station Functions j « other7 J ¡ - т - : --'i -r - -, i ļ ! I REMOTE CONTROL WORKSTATION H9tF0flMANCE~ļ ļ ļ ¡ i. ^ ,i I REMOTE , CONTROL ? WORKSTATION : ļ i i. ļ Li Nervoue Světem Свпвту Г- db иск TelecommuntceMon То Rom Remote Conbol i Remote Control J • Receptor Activation- ¡ Work Stetion ¡ J Work Stetem ! ! ♦ S°nrtW" Perception I . Vtaua! DtaptaHtonta ^T*Ktr^iCaiūn.ļ. • VtaualS**. ! ¡ ♦ Perception ¡ -Remote Camera Views eopeniiond Feedback) i • AucfkvyStouds ¡ ! • Coalition -Virtual bistruments ¡ ¡ ! ' ! ! ! ' • о*«? 1 ! ' i • Visual-Local i i ' 1 i ! e Aucftory-Remote &amp; ¡ ¡ J i Local i i i ' в Оропшолв Рввфяск) • Otier Work Station ! i ¡ i i в Оропшолв Рввфяск) ii i i i -Tackle i i i ¡ - Kinesthetic ¡ i -Work Environment i i i L REMOTE COĶTTOĻ yKMKSTAVOH J Figure 5. Behavioral cybernetic model of teleoperation control of mobile equipment. Figure 5 is a behavioral cybernetic model of teleoperation performance of a mobile vehicle. Compared with onboard control (Figure 2), the performance environment for teleoperation is fundamentally altered, and the control demands more complex. The essence of the difference may be summarized by referring to the exoskeleton model of operator- vehicle interaction (Figure 1). This model no longer applies, because teleoperation abolishes the intimate spatiotemporal compliance between operator and vehicle movements that characterizes onboard performance. In other words, telepresence [36] with a teleskeleton is substantially impoverished relative to onboard presence with an exoskeleton. As shown in Figure 5, control of a remote vehicle by a teleoperator is mediated through a master remote control computer work station. Direct reactive, instrumental, and operational sources of sensory feedback are generated by operator interaction with the work station controls and displays, rather than by direct interaction with vehicle and in- cab performance conditions (Figure 2). Through display of video images from remote cameras mounted on the vehicle, the work station provides indirect, computer-mediated operational sensory feedback information from activity of the remote vehicle. It is possible, although less common, for tactile, force, and possibly auditory operational sensory feedback from the remote vehicle also to be provided. Thus, during teleoperation the operator must simultaneously control sensory feedback from three major modes of interaction, namely : (1) direct interaction with the remote control work station; (2) computer-mediated interaction with the remote vehicle; and (3) telerobot- mediated interaction with the task environment. Relative to onboard control, sensory feedback from modes 2 and 3 is substantially impoverished. Because the master computer rather than the operator mediates control of vehicle functions, reactive and instrumental sensory feedback from operator interaction with these functions is lacking. The primary and generally the only category of sensory feedback is dynamic operational feedback from the remote vehicle as it traverses its environment. Moreover, this feedback usually comprises a more limited range of sensory modalities, in that tactile, vestibular, and vibration feedback from the vehicle generally are lacking, and force and auditory feedback often are lacking. All of these differences from onboard performance lead to more complex and challenging demands on behavioral control during mobile vehicle teleoperation. What are the most important sources of performance variability in the latter case? Previous reviews have 466</page><page sequence="11">addressed this question with reference to teleoperation generally and telemanipulation in particular [35-38]. Based on extensive evidence from laboratory research on visual- manual tracking tasks [4-6] [8] [9], coupled with a smaller set of findings from telemanipulation tasks, the conclusion reached is that perturbations in sensory feedback, particularly spatial and temporal displacements, contribute more to décrémentai performance during teleoperation than any other design or behavioral factor that can be identified. The remainder of this section reviews evidence suggesting that the same conclusion applies to teleoperation of mobile equipment. The analysis focuses on design features specific to the mobile equipment teleoperation interface (Figure 5) that may be expected to engender performance problems, based on findings regarding performance requirements for onboard vehicle control (previous section). We focus on possible performance effects during mobile equipment teleoperation of three different types of perturbed sensory feedback conditions: perturbed visual feedback, feedback delay, and lack of force feedback. PERTURBED VISUAL FEEDBACK - Six different perturbed visual feedback conditions that may be expected to degrade performance with teleoperated vehicles are addressed below. Size Distortion of Image - There has been little research on performance effects of size distortion as a perturbed visual feedback factor, particularly during teleoperation. One study of hands-on performance during televised viewing with normal and size distorted visual feedback found, for tapping, panel control, and handwriting tasks, that no consistent differences in performance occurred under normal, miniaturized, and magnified visual feedback [8]. However, the same research examined the ability of graphic artists to draw objects to true size in televised, size- distorted fields. Inaccurate performance and no learning effects over three trials were observed with both miniaturized and magnified viewing, relative to direct viewing. A revealing comment made by one professional artist was that drawing with a miniaturized image made his arm "feel a good deal larger than it is." These observations suggest that the effects of size distortion on performance with televised viewing may be task dependent, and that for some tasks either image miniaturization or magnification can result in reduced performance accuracy. Based on observations with a large, teleoperated mobile excavator, Cook (Personal Communication) reports that relative to remote work with a standard display, remote work with an enlarged image appears to be associated with feelings of greater operator relaxation and comfort. This suggests that an enlarged image may reduce workload during mobile equipment teleoperation. It was noted earlier that lateral guidance during onboard steering of a mobile vehicle depends primarily on control of yaw or heading angle, yaw rate, and lateral displacement or error (Figure 1) relative to road markings [17][18]. Projection of the visual field ahead of a moving vehicle from a vehicle-mounted camera onto a standard sized display will reduce the magnitude of all three of these variables as perceived by the operator. It is likely therefore that size miniaturization will degrade teleoperation performance with mobile vehicles because visual feedback from key dynamic vehicle displacement factors can no longer be employed as effectively to guide steering. Further research is necessary to test this prediction. Three Dimensional (3D) Viewing - An extensive literature on binocular performance suggests that, relative to monocular viewing, binocular viewing results in improved performance as measured by: (1) threshold sensitivity, acuity, form recognition, and reaction time of the visual system [50]; and (2) improved judgment of 3D spatial relationships [51]. However, performance advantages of binocular viewing are not ubiquitous. Depth perspective may confer little or no advantage during visual tracking of rapidly moving targets [51]. Moreover, because humans are perfectly capable of resolving 3D spatial relationships with monocular viewing, performance differences between binocular and monocular viewing may be subtle or equivocal, depending upon the task [50]. Cook [52] has documented clear benefits of 3D versus two dimensional (2D) viewing for teleoperation performance with a large, remotely controlled mobile vehicle. In a pilot study of teleoperation by two subjects with a mobile teleoperated Field Material Handling Robot (FMR), he reports that, on average, performance times with stereo vision are about 48% faster than those with monocular vision, and times with high illumination are about 20% faster than those with low illumination. These results suggest that for this particular system, 3D perspective contributes more prominently than image quality to interactive performance variability. A subsequent study with a Caterpillar 235D excavator configured for remote control showed that 3D viewing significantly improves the ability of a skilled operator to judge vertical distance between the excavator end effector and a target [53]. Drascic [54] also reports improved materials handling performance with 3D relative to 2D viewing for a teleoperated mobile robot used to inspect and handle suspected explosive devices. The emphasis in all of these studies is on how 3D viewing during teleoperation benefits end effector manipulation or positioning rather than vehicle guidance tasks. Relative to teleoperation performance during driving therefore, a number of unanswered questions remain: (1) the contribution of 3D visual feedback to overall performance variance, relative to other visual feedback factors; (2) the degree to which 3D viewing benefits performance for different driving tasks and demands; (3) which 3D viewing technology is preferable; and (4) the acceptability of 3D viewing technology for long-term use under operational conditions. Benefits of 3D viewing that are demonstrated for teleoperation driving performance probably can be attributed primarily to enhanced projective control capabilities. As noted earlier, feedforward control of driving relies upon referencing steering movements to the predicted course of the vehicle provided by visual feedback from roadway features ahead of the vehicle's current position. Compared with a standard 2D display, a 3D display should improve the 467</page><page sequence="12">operator's ability and accuracy in perceiving and judging relative positions of the vehicle and oncoming road features, which in turn should improve feedforward steering control. Field-of-View- Recent findings of Haduch and Mitchell [55] indicate that field-of-view (FOV) conditions can significantly influence teleoperation driving performance under conditions where projective, or feedforward, control is required for accurate guidance of the vehicle. In a field study of a teleoperated high mobility multipurpose wheeled vehicle (HMMWV), target sighting distances (based on eye tracking data) were greater, and heading of the vehicle relative to oncoming obstacles was more precisely controlled, with onboard performance relative to teleoperation with a narrow FOV. During teleoperation with a narrow (55 deg) versus wide (165 deg) FOV, the latter condition reduced estimated workload by 21%, and also was associated with improved driving performance (shorter completion times, fewer errors, less steering and throttle activity). These findings support the conclusion advanced by the authors that a wider FOV improves feedforward driving control, particularly on curved roadways. Collectively, the stereo viewing and FOV results suggest that the system interface should incorporate both 3D viewing and a wide FOV to ensure effective projective control of driving during mobile equipment teleoperation. Spatial Displacement - The significance of spatial displacement of visual feedback (such as inversion, reversal, and/or angular displacement) as a major influence on performance variability during both hands-on and telemanipulation performance has been reviewed elsewhere [8] [35-37]. During remote driving performance, the most likely mode of spatial displacement is angular displacement of visual feedback, which could occur when either the orientation or the position of the remote camera is angularly displaced relative to the heading of the vehicle. Findings documenting a décrémentai effect of angularly displaced visual feedback on onboard driving performance have been described earlier (Figure 3). Past research has shown that performance decrements in visual-manual tasks emerge at angular displacements in visual feedback of 45 to 50 degrees (defined as the breakdown range) in both the horizontal plane [56] and vertical plane [57], with peak performance decrements observed at displacement angles of 120-130 deg for each plane. Our research (next section) recapitulates these findings. Interestingly, results of Coleman, Ruff, and Smith [49] indicate that decrements in onboard driving performance occur at a displacement angle of less than 45 degrees (Figure 3). This suggests that driving performance may be more sensitive to effects of angularly displaced visual feedback than is performance with other types of visual- manual tracking tasks. It is likely that angular displacement of visual feedback from a remote vehicle disrupts all of the major control behaviors that the teleoperator relies upon for effective steering. Lateral control is disrupted because alignment of roadway markings is displaced relative to the heading angle of the vehicle. Projective control is disrupted because the spatial coordinates of oncoming roadway features are displaced relative to the current position of the vehicle. The degree to which spatially displaced visual feedback may degrade teleoperation driving performance is context dependent upon system, interface, and task design features. It also remains to be determined how much spatial displacement factors contribute to total performance variance observed for remote driving, relative to other factors. Décrémentai effects of angular displacement on teleoperation also may occur when movements of the master controller are displaced relative to those of the slave being controlled. Our research (next section) and that of Ellis and colleagues [57] shows that when movements of a displayed tracking cursor are angularly displaced relative to those of a joystick controller in pursuit tracking tasks, the results are virtually identical to those observed with angular displacement of a displayed camera image: a breakdown angle of about 50 deg, and peak performance decrements at displacements angles of 120- 130 deg, in both the horizontal and vertical planes. With teleoperated mobile vehicles, this type of spatial displacement most likely will degrade performance primarily as a consequence of its effect on steering gain. For onboard driving with a steering wheel, Hoffmann [18] reports results indicating that although steering accuracy is better with a low steering gain ratio (5:1), the preferred gain ratio is 18:1. Joystick control of a teleoperated vehicle changes both the gain and the spatial relationships between movements of the controller and those of the vehicle. The degree to which these changes contribute to teleoperation performance variance during remote driving remains to be determined. Image Quality - Image quality encompasses such factors as illumination, glare, and/or contrast conditions in the visual field, plus image fidelity provided by the CRT displays. Recent evidence indicates that image quality can affect teleoperation performance with mobile equipment. As noted earlier, Cook [52] demonstrated with the FMR system that performance times improve 20% with high relative to low illumination of a remote task field. Perhaps a more recalcitrant threat to image quality during teleoperation, however, is degradation of image quality caused by low bandwidth video signal telecommunication. This issue is of particular significance for military systems in which video data must be communicated over low bandwidth secure radio channels. Haduch [58] discusses the possibility of degraded teleoperation performance due to poor image quality caused by low bandwidth telecommunication. Kay and Thorpe [59] describe an intelligent interface system for facilitating semi-autonomous supervisory control of a teleoperated HMMWV under low bandwidth and long delay operating conditions. As with spatial displacement, it is likely that poor image quality of visual feedback from a remote vehicle disrupts all of the major control behaviors that the teleoperator relies upon for effective steering. Both lateral and projective control may be disrupted because of the reduced ability of the operator to judge heading and position of the vehicle relative to roadway features. It remains to be determined how much image quality factors contribute to total performance variance observed for remote driving. 468</page><page sequence="13">Delayed Feedback - A number of authors [3] [35] [60] [61] have reviewed research demonstrating the degradative effects of delayed feedback on teleoperation performance. Compared with hands-on performance, a distinctive feature of teleoperation is that delays may occur in both visual and force feedback. The first systematic analysis of feedback delay effects on teleoperation was conducted in the Sheridan laboratory at MIT by Ferrell [62] [63]. One key finding of the first of these studies was that teleoperators could effectively compensate for delays in visual feedback by adopting a "move-and-wait" performance strategy. Conversely, the second study showed that performance under delayed force feedback was inherently unstable. Generally, the magnitude of performance decrements observed for teleoperation under feedback delay is comparable to or higher than that observed for hands-on tasks [35]. The move-and-wait observations of Ferrell led Sheridan [3] to develop the supervisory control paradigm for dealing with feedback delay effects on teleoperation performance with a remote vehicle. In this approach, the teleoperator relies on visual feedback from a remote camera, with the vehicle stationary, to provide the master control computer with a projected trajectory of the vehicle to a new position. Guidance of the vehicle along the trajectory is carried out under computer control, with no direct feedback to the operator. Once the new position has been reached, vehicle movement is terminated and the process is repeated. Kay and Thorpe [59] describe implementation of a supervisory control system for teleoperation of a remote HMMWV. The essential preconditions for operational application of this method are that the trajectory can be projected, and that there are no major unanticipated obstructions once the vehicle is underway. As with performance of visual-manual tracking and driving tasks under feedback delay [39] [49], it is likely that delay disrupts teleoperation driving performance primarily by compromising projective control (previous section). Further research is needed to test this hypothesis, and to assess the degree to which delay contributes to performance variance during teleoperation of remote vehicles, relative to other factors. LACKOF FORCE FEEDBACK- Hoffmann [ 1 8] notes that studies of onboard driving performance have shown that a light steering force makes it difficult to position the steering wheel precisely. Therefore, with those teleoperated vehicle systems for which no force feedback is provided from the steering wheel, it may be expected that steering control will be compromised to some (unknown) extent. LACK OF OTHER SENSORY FEEDBACK MODALITIES - Essentially nothing is known about the implications for teleoperation driving performance with no provision of auditory, vibratory, tactile, and/or vestibular modalities of sensory feedback (Figure 5). BEHAVIORAL CONTROL UNDER PERTURBED VISUAL FEEDBACK This section describes methods and results for a series of experimental studies we have completed examining modifications in the control properties of behavior under perturbed visual feedback conditions. As noted previously, driving performance has received extensive research attention from a control systems perspective, with variables such as rise time, gain, phase displacement, and frequency response of both the operator and the vehicle being incorporated into control models of the human-vehicle system (Figure 4). This section presents a series of results showing how selected behavioral control variables are affected by temporal or spatial displacements in visual feedback. In presenting these findings, we emphasize that the methodology involves laboratory tracking studies using a joystick and computer workstation, not onboard or simulated driving. For this reason, the face and criterion validity of the research, as it may relate to vehicle driving performance, remains an open question. However, given that perturbed visual feedback factors are implicated as major contributors to variability in teleoperation performance with mobile vehicles (previous section), the information below may provide some insight into behavioral mechanisms underlying performance problems with remote driving. Further research, using actual teleoperated vehicle systems, will be necessary to assess the applicability of the observations to remote driving performance. As reported previously [35], all experiments described below involve tracking tasks installed on an Apple Macintosh Ilfx computer with a 19-inch SuperMac monitor". All data acquisition, experimental testing, and data processing are implemented using National Instruments LabVIEW (versions 2.2 and 3.1), an experimental control software system. The tracking device is a Gravis Mousestick II joystick. Many of the subjects used were the same from study to study. Although tracking task requirements and experimental designs were different for each study, it is possible that overlap in the subject pool may have biased the results in some manner. The subsections below describe methods and findings for four experiments in which dependent measures of behavioral control were determined under perturbed visual feedback conditions. Three of the experiments deal with effects of delayed visual feedback, the fourth with effects of angular displacement. In each experiment, subjects tracked movements of a displayed target by using the joystick to control movements of a displayed tracking cursor. Visual feedback was perturbed by introducing temporal or spatial displacements between movements of the joystick and those of the cursor. LabVIEW was used to control all phases and conditions of each experiment. Results are presented in Figures 6-9. Data in these figures are plotted as mean values (averaged over all replicate trials and sessions), with error bars of ±1 standard deviation (SD). Results are statistically analyzed using analysis of variance (ANOVA) for main effects. Publications providing more extensive details and discussion of this research are in preparation. Behavioral gain (Figures 6B,9B) is calculated as the ratio of joy stick and target movement amplitudes, a measure "Mention of any company or product name does not imply Bureau endorsement. 469</page><page sequence="14">550 500 - 450 - Т 400 - ~ ^ 350 - _ 1 ° -_ £ 300 - i 250 " СС _ 200 - _ Т/1 150 - - /I loo - TXÎ 50 ï^J_ 0 L - I 1 1 1 1 1 1 1- 0 .2 .4 .7 1 1.5 2 2.5 3 Delay Interval (sec) Figure 6A. Behavioral control under visual feedback delay - RMS error as a function of delay level. 1.4 л 1.3 - С т ф -р § 1.2 - 0 E Ф 11 - с * -г т Т ^ «о 1.0 т -г о - О 1 0.9 g -L _1_ * 08 м - s 08 м - -1- -1- О в ат - m Ь - i 1 1 1 i i i 0 Л Л .7 1 1Л 2 2.5 3 Delay Interval (sec) Figure 6B. Behavioral control under visual feedback delay: gain as a function of delay level. of spatial alignment of these two signals. Phase difference (Figures 6C,9C) is a measure of the temporal alignment between joystick and target movements. A gain near l.Oand a phase difference near 0 implies high fidelity tracking performance. A gain greater than 1.0 means that joystick movements are amplified relative to target movements; a gain less than 1.0 means the inverse. A phase difference greater than 0 means that joystick movements are leading target movements; a phase difference less than 0 means the inverse. EXPERIMENT 1 - BEHAVIORAL CONTROL UNDER DELAYED VISUAL FEEDBACK: EFFECT OF DELAY INTERVAL- In this experiment, tracking error, and gain and phase differences in tracking relative to target movements, were determined in a one-dimensional pursuit tracking task. Subjects were asked to track a sinusoidally varying target, with fixed feedback delays of between 0 and 3.0 sec imposed between joystick movements and visual feedback from corresponding movements of the displayed tracking cursor. F.vngrimental Design and Conditions - Nine subjects (mean age 34.4 years, age range 25-53 years, 8 males, 1 female) and nine levels of visual feedback delay (0, 0.2,0.4, 0.7, 1.0, 1.5, 2.0, 2.5, and 3.0 sec) were employed. A trial with one delay level imposed lasted 63 sec. Each subject completed two replications of each trial at each delay interval on each of five successive week days. Subjects were tested at about the same time of day on each testing day. The order of presentation of delay levels during an experimental session was randomized. The task involved pursuit tracking of a target generated as a solid line sweeping right to left on the monitor. Three sinusoidal functions of different amplitudes and frequencies were added to generate a sinusoidally varying target function with a frequency of 0.3 Hz and randomly varying amplitude. Velocity of target sweep was contr led such that a given target locus traversed the monitor display in 0.56 sec. During a trial, subjects were asked to move the joystick towards or away from them to align the vertical position of the tracking cursor as closely as possible with the shifting position of the target line. Successive cursor and target positions were sampled at a frequency of 23.1Hz. To account for the initial time required for subjects to align the cursor with the target, the first 50 data points sampled for each trial were deleted. Thus, 60.8 sec or 1404 sampled points per trial were analyzed. Dependent variables for this study are root-mean- square (RMS) error, gain, and phase difference. RMS error computation is based on the difference in vertical positions between cursor and target for successive sampled data points. Gain and phase difference were computed for cursor (joystick) relative to target movements. To determine gains and phase differences, a Fast Fourier Transform (FFT) first was calculated for successive blocks of 1024 sampled data points of cursor positions, resulting in a total of 381 overlapping FFTs (1404-1024+1) per trial for the cursor signal. The FIT yields a power spectrum of the prevalence of different frequencies in the sampled signal, with a peak in the power spectrum typically occurring at one frequency most prevalent in the signal, termed the fundamental frequency (FF). An FFT power spectrum also was computed for the target signal, which had a fixed fundamental frequency (FFt) of 0.3 Hz. The mean amplitude of the cursor power spectrum at FF, was calculated by averaging values derived from the 435 overlapping FFTs. Gain of the cursor relative to the target signal (GM) was calculated by dividing the mean amplitude of the cursor signal at FF, by that of the target signal at FF,. Phase difference for the cursor relative to the target signal (PDc.t) was calculated by subtracting the phase associated with FF, in the target signal from that associated with FF, in the cursor signal [64] [65]. Results - Figure 6A shows mean RMS error as a function of visual feedback delay interval. Mean error increased over eightfold with an increase in delay from 0 and 3.0sec. There appears to be no threshold below which delay intervals greater than 0 do not evoke increased error, and error has not leveled off at 3.0sec delay. The main effect of delay is highly significant (Fg64=211.5,p&lt; .0001). Figure 6B shows mean gain as a function of visual 470</page><page sequence="15">1.4 ^ I 1.2 - в « -г с &gt; £ с &gt; i if • £ 0.2 - 5 Í о.в - // Is 5 Í о.в - // 1 W 1 «et I I I I I I I I О Л .4 .7 1 IS 2 2.5 3 Delay Interval (see) Figure 6C. Behavioral control under visual feedback delay: phase difference as a function of delay level. feedback delay interval. Gain is slightly less than 1.0 at delays from 0 to 0.4 sec, somewhat lower at delays from 0.7 to 1.5 sec, and almost equal to 1.0 at delays from 2.0 to 3.0 sec. The main effect of delay on gain is significant (Fe64=4.977,p&lt;.0001). Figure 6C shows mean phase difference (in radians) as a function of visual feedback delay interval. Mean phase difference is slightly greater than 0 at 0 delay, increases to over fourfold higher at 1.5 sec delay, and then declines somewhat from 1.5 to 3.0 sec delay. The main effect of delay on phase difference is significant (Fg64=75.52, p&lt;.0001). A common feature of the data in Figures 6A through 6C is that performance variability (shown by magnitudes of the SD values) increases dramatically as delay increases. EXPERIMENT 2 - BEHAVIORAL CONTROL UNDER DELAYED VISUAL FEEDBACK: EFFECTS OF TARGET SPEED - This experiment employed a one- dimensional pursuit tracking task identical to that used in Experiment 1. In this study however, both speed and feedback delay of the displayed target signal were varied. Experimental Pesien and Conditions - The workstation, tracking task, and experimental design were identical to Experiment 1 , except that four visual feedback delay levels (0, 0.2,0.5, and 1.0 sec) and four target speeds (.05, .10, .15, and .20 Hz) were employed. Ten subjects (mean age 35.8 years, age range 26 to 54 years, 7 males, 3 females) participated. Results - Figure 7 summarizes the combined effects of delay and target speed on tracking error observed in this study. Mean RMS error increased with delay at each target speed. At the two lowest delay levels, error changed little across the four target speed conditions. At the two highest delay levels however, error increased with increasing target speed. The speed by delay interaction is significant (F, „ = 34. 19, p&lt;. 0001). EXPERIMENT 3 - BEHAVIORAL CONTROL UNDER DELAYED VISUAL FEEDBACK: TRANSIENT RESPONSE EFFECTS - This study employed a step change (rather than continuous) pursuit tracking task in order to ITS 1 sec delay 19 - is - I ш * « - ' ísscdslw^----" i я " ao ■ .2 iftcdrtay 25 1 и- t О I I шб mo ais «un Speed (Hz) Figure 7. Behavioral control under visual feedback delay: combined effects of delay and target speed on RMS error. evaluate the effects of delayed visual feedback on transient movement response characteristics of subjects. Experimental Design and Conditions - Eight subjects (mean age 35.6 years, age range 28-54 years, 6 males, 2 females) participated. The workstation, interface, and LabVIEW control of experimental conditions were as described for Experiment 1 . At the onset of each trial, a target (box) and tracking cursor (circle) were displayed to the subject, aligned on the vertical axis in the center of the display (horizontal positions were held constant). Subjects were instructed to move the joystick towards or away from them as quickly as possible in order to move the cursor vertically down or up and center it in the target box. After a predetermined time interval, the vertical position of the target was suddenly changed up or down in a step fashion, and subjects again tried to reposition the cursor on the target as rapidly as possible. One trial comprised four replications of each of three target step change movement distances (1.11, 1.67, and 2.22 inches) at a given visual feedback delay interval. Five feedback delay levels - 0, 0.22, 0.42, 0.64, or 0.83 sec delay between joystick and cursor movements - were evaluated. Subjects performed two replications of five trials per day over five successive workdays. The order of presentation of within-trial target movement distances, and between-trial delay levels, was ordered randomly. Figure 8A shows an idealized profile of a transient joystick response to a target step change, with vertical position of the joystick from starting (bottom solid line) to ending (top solid line) position on the Y axis plotted against time on the X axis. Designated in the figure are dependent variables for the study: dead time (td) in sec, rise time (tr) in sec, maximum overshoot (M0), expressed as a percentage of input magnitude, and settling time (ts) in sec. These variables were computed for each joystick movement made by a subject to realign the cursor with the target after a vertical step change in target position. Results - Only rise time and maximum overshoot results are presented here. Figure 8B illustrates mean rise time values plotted as a function of feedback delay, averaged 471</page><page sequence="16">mk For r&gt;/s response stays within this strip m0 : ' 09 / '^/Tž///7777&gt; o.i J 1 ! 00 ^ &lt; - fs &gt; Figure 8A. Idealized time profile of transient response to target step change, with dependent variables indicated. over all target movement distances. Rise time increased about 0.2 sec with an increase in delay from 0 to 0.8 sec. The main effect of delay on rise time is significant (F756 = 15.582, p&lt;. 003). Figure 8C illustrates mean maximal overshoot values plotted as a function of feedback delay, averaged over all target movement distances. Maximal overshoot percentage increases about twofold with an increase in delay from 0 to 0.8 sec. The main effect of delay on maximal overshoot is significant (F756=14.36,p&lt; .0001). As with the delay results in Experiment 1 (Figures 6A- 6C), delay also elevates transient response performance variability, as shown by the increase in SD magnitudes with delay in Figures 8B and SC. EXPERIMENT 4 - BEHAVIORAL CONTROL UNDER ANGULARLY DISPLACED VISUAL FEEDBACK: EFFECT OF DISPLACEMENT ANGLE - The purpose of this experiment was to assess the effects of angular displacements in visual feedback on tracking error and gain and phase differences in tracking relative to target movements, using a two-dimensional pursuit tracking task. Subjects were asked to track a target varying in two axes, with angular displacements from 0 to 180 deg imposed between joystick movements and visual feedback from corresponding movements of the displayed tracking cursor. Experimental Design and Conditions - Eight subjects (mean age 39.4 years, age range 32-53 years, 6 males, 2 female) and ten levels of angularly displaced visual feedback (0, 30, 45, 60, 75, 90, 105, 120, 150, and 180 deg) were employed. The workstation, interface, and LabVIEW control of experimental conditions were as described for Experiment 1. A trial with one displacement level imposed lasted 68 sec. Each subject completed two replications of each trial at each angular displacement level on each of five successive week days. Subjects were tested at about the same time of day on each testing day. The order of presentation of displacement levels during an experimental session was randomized. 1.1 i - OJ - i Iм- T &lt;&gt; 1 2 0.4 - 02 - J- o ■ I I I 1 O ¿ .4 J J Delay magnfeude (aec) Figure 8B. Behavioral control under visual feedback delay: effects of delay on transient response rise time. The task involved pursuit tracking of a target spot traversing a randomly varying path in two dimensions. Three X-axis and three Y-axis sinusoidal functions of different amplitudes and frequencies were added to generate the two-axis target path, with a speed of 0.3 Hz and randomly varying trajectory. During a trial, subjects were asked to move the joystick to align the position of the tracking cursor as closely as possible with that of the target spot. Successive cursor and target positions were sampled at a frequency of 25.1Hz. To account for the initial time required for subjects to align the cursor with the target, the first 50 data points sampled for each trial were deleted. Thus, 66 sec or 1654 sampled points per trial were analyzed. Spatial displacement in visual feedback was introduced by displacing the angle of tracking cursor movement relative to that of joy stick movement. Thus, at a displacement angle of 180 deg, left horizontal movement of the joystick would cause right horizontal movement of the tracking cursor. At a displacement angle of 90 deg, left horizontal movement of the joystick would cause upwards vertical movement of the tracking cursor. 40 30 - a T &lt;r О fc » - T T a о ^ 0 ■5 io - о - 1 ■5 io - о - .. i 1 1 о . - -ļ_- - am I 1 1 1 1 I О Л .4 Я Я Delay magnRude (aec) Figure 8C. Behavioral control under visual feedback delay: effects of delay on transient response maximal overshoot. 472</page><page sequence="17">ш т СО -г Т ^ т -г I1»- с 0 CL (;. Он». т / s u - ,, 1 1 1 1 •а х 1 т ii lliliililłlil g IS ao 45 ID 75 10 HB Ш 135 18D IB m Angular Pteptacomcrt (degrees) (сигюг feWira to joy tódO Figure 9A. Behavioral control under angularly displaced visual feedback: X-axis component RMS error as a function of displacement angle. Dependent variables for this study are RMS error, gain, and phase difference. Gain and phase difference values were computed for cursor (joystick) relative to target movements, as described for Experiment 1 . The joystick/tracking cursor position signal yielded a total of 631 overlapping FFTs (1654- 1024 + 1) per trial. For each dependent variable, X-axis component, Y-axis component, and X-Y composite values for joystick movement were calculated. However, results below deal only with X-axis component findings. Results - Figure 9A shows mean X-axis component RMS error as a function of degree of angular displacement. Error starts to increase at a displacement angle of about 45 deg (first shown by Gould and Smith [41]), peaks at a displacement angle of about 120 deg, and moderates at displacement angles beyond 120 deg. Ellis and colleagues report a similar pattern [57]. Figure 9B shows mean X-axis component gain as a function of degree of angular displacement. At displacement angles up to 75 deg and above 120 deg, gain is almost constant at levels close to 1.0. Gain is reduced at 05 m и о £ I 04 - píl -г ôr-а ЙГ'Т « - Т Т Л -г т т ôr-а « - Т т т Т ^ Ł i Ел! oí - Ск" - ^ - о - о о it! |о£ ВО у Л ^ 1 , ВО у ^ |о£ I !*•&gt; - 1 (О* 1111 »III 1 I I I I I I О IS О 4 О 7S ID MS UD 190 ISO МБ МО МБ Angular Biopto« noni (degrees) (curoor rahtfto to joy todt) Figure 9C. Behavioral control under angularly displaced visual feedback: X-axis component phase difference as a function of displacement angle. 12 с T -a ° ^ T -r ° * ^ Iм " t T T t T T -r t |s ' T T T I Vя ' ° - T ^ - ° 1 1« 1 ^ £ I 1 X iu £ I 1 ! I I a S'« - X OS ' 1 I I I I I о is a « o 7S awiai8ia«iB Angular Dinptoremort (degrees) (cursor ratovi to joy tock) Figure 9B. Behavioral control under angularly displaced visual feedback: X-axis component gain as a function of displacement angle. displacement angles where error is highest (Figure 9A). The main effect of angular displacement on gain is significant (F7i63=2.241,p = .0179). Figure 9C shows mean X-axis component phase difference as a function of degree of angular displacement. Phase difference is slightly higher than 0 and changes little across the range of displacement angles evaluated. The main effect of angular displacement on phase difference is not significant (F763=. 438, p = . 9149). For all three of these variables, performance variability (shown by magnitudes of the SD values) is highest at angular displacement levels associated with the highest performance error (Figure 9A). DISCUSSION Comparing and contrasting our analyses of what is known about onboard performance (second section) versus teleoperation performance (third section) with mobile equipment suggests that when it comes to the latter, our empirical understanding is painfully limited. Our premise in this report is that interface design factors generally, and perturbed sensory feedback factors in particular, make a prominent contribution to variability in driving performance. Evidence was cited in the second section providing support for this conclusion for onboard driving. Previous research [35-38] strongly suggests that this conclusion also applies to teleoperated mobile vehicles. Unlike the case for performance with hands-on behavioral tasks however [13][14][35][36]Jhe validity of the premise for teleoperated driving performance must be considered speculative at this time. Indeed, there is limited evidence to suggest that the relative contribution of design versus behavioral factors to variability in remote driving performance may differ from that observed for hands-on tracking tasks. For example, contrary to results from research with spatial and temporal displacement perturbations [14] [35] [36], Cook found in a study of telemanipulation with the FMR that between-subject differences in performance are somewhat greater than those 473</page><page sequence="18">related to viewing (3D versus 2D) and illumination (high versus low) visual feedback conditions. Nevertheless, it seems safe to conclude from research on onboard driving performance that remote driving performance can be critically influenced by perturbations in visual feedback inherent to the teleoperation interface. Our analysis identifies a series of perturbed visual feedback factors - reduced image size, poor image quality, lack of 3D perspective, limited field-of-view, spatial displacement, and/or feedback delay - that may seriously compromise remote driving performance by degrading both lateral and projective control during teleoperation. These effects may be further exacerbated by lack of force feedback and other sensory feedback modalities. Findings from studies of decrements in behavioral control under perturbed visual feedback conditions (third section) may provide insight into behavioral mechanisms underlying performance problems with remote driving. Increased performance error engendered by feedback delay (Figure 6A) appears to be associated more with changes in phase difference (Figure 6C), and increases in behavioral rise time and overshoot (Figures 8B,8C), rather than gain (Figure 6B). According to steering control models (Figure 4) [43], these changes in behavioral control parameters can be predicted to result in degraded driving performance. Target speed also appears to exacerbate the degradative effects of delay on performance (Figure 7), with nonlinear increases in error observed at longer delay intervals with high relative to low target speeds. The finding suggests that driving performance with a remote vehicle at high versus low speeds with long delays could be similarly affected. Results for the angular displacement study (Figure 9) are not as easily interpreted. Changes in gain (Figure 9B) and phase difference (Figure 9C) that occur with different displacement angles do not appear to be enough to account for the increased performance error observed at large displacement angles (Figure 9A). Perhaps changes in transient response properties of behavior under angular displacement conditions contribute to the error, as was observed for feedback delay (Figure 8B,8C). As noted earlier, empirical observations of driving performance decrements caused by angular displacement (Figure 3) are not predicted by steering control models. Further research is needed to characterize the relative contribution of both design and behavioral factors to total variability observed during teleoperation performance with mobile equipment. Specific remote driving issues that need to be addressed include: (1) effects of interface design factors on driving control behavior; (2) performance effects of combined perturbations in two or more sources and/or modalities of sensory feedback; (3) learning with perturbations in one or more modalities of sensory feedback; and (4) mechanisms underlying spatial displacement effects. REFERENCES 1. Book, W.J. (1985). Teleoperator arm design. In S.Y. Nof (Ed.), Handbook of Industrial Robotics (Chap. 9, pp. 138-157). New York: Wiley. 2. Vertut, J., and Coiffet, P. (1985). Teleoperation and Robotics. Evolution and Development. London: Kogan Page. 3. Sheridan, T.B. (1992). Telerobotics. Automation, and Human Supervisory Control. Cambridge, MA: The MIT Press. 4. Smith, T.J. , and Smith, K.U. (1987). Feedback-control mechanisms of human behavior. In G. Salvendy (Ed.), Handbook of Human Factors (pp. 251-293). New York: Wiley. 5. Smith, K.U. (1962). Delayed Sensory Feedback and Behavior. Philadelphia: Saunders. 6. Smith, K.U. (1972). Cybernetic psychology. In R.N. Singer (Ed.), The Psychomotor Domain (pp. 285-348). New York: Lea and Febiger, New York. 7. Smith, K.U., and Smith, M.F. (1966). Cybernetic Principles of Learning and Educational Design. New York: Holt, Rinehart and Winston. 8. Smith, K.U. , and Smith, W.M. (1962). Perception and Motion: An Analysis of Space-Structured Behavior. Philadelphia: Saunders. 9. Smith, T.J., and Smith, K.U. (1988). The cybernetic basis of human behavior and performance. Continuing the Conversation. A Newsletter of Ideas in Cybernetics. Winter 1988(15). 1-28. 10. Smith, T.J. , and Smith, K.U. (1987). Motor feedback control of human cognition - implications for the cognitive interface. In G. Salvendy, S.L. Sauter and J.J. Hurrell (Eds.), Social. Ergonomie and Stress Aspects of Work with Computers (pp. 239-254). Amsterdam: Elsevier. 11. Smith, T.J., and Smith, K.U. (1988). The social cybernetics of human interaction with automated systems. In W. Karwowski, H.R. Parsaei, and M.R. Wilhelm (Eds.), Ergonomics of Hybrid Automated Systems I (pp. 691-711). Amsterdam: Elsevier 12. Adolph, E. F. (1982). Physiological integrations in action. The Physiologist. 25(2) Supplement, 1-67. 13. Smith, T.J. (1993). The scientific basis of human factors - a behavioral cybernetic perspective. In Proceedings of the Human Factors and Ergonomics Society 37th Annual Meeting (pp. 534-538). Santa Monica, CA: Human Factors and Ergonomics Society. 14. Smith, T.J. , Henning, R.A., and Smith, K.U. (1993). Sources of performance variability. In W. Karwowski and G. Salvendy (Eds.), Human Factors in Advanced Manufacturing (pp. 336-425). New York: Wiley. In press. 15. Smith, K.U. , and Smith, T.J. (1988). Analysis of the human factors in automation. In K.M. Blache (Ed.), Success Factors for Implementing Change. A Manufacturing Viewpoint (pp. 259-338). Dearborn, MI: Society of Manufacturing Engineers. 16. McRuer, D.,and Weir, D.H. (1969). Theory of manual vehicular control. Ergonomics. 12(4), 599-633. 17. McLean, J.R.,and Hoffmann, E.R. (1971). Analysis of drivers' control movements. Human Factors. 13(5). 407- 418. 18. Hoffmann, E.R. (1975). Human control of road vehicles. Vehicle Svstem Dynamics. 5(1-2), 105-126. 474</page><page sequence="19">19. Mosher, R.S. (1964). Industrial manipulators. Scientific American. 211(4). 88-98. 20. Mosher, R.S. , and Murphy, W. (1965). Human control factors in walking machines. In Proceedings of the American Society of Mechanical Engineers Human Factors Conference. Chicago: ASME. 21. Smith, K.U. (1965). Human Factors Analysis of the Mechanism of Walking With Special Reference to Design of a Pedioulator Vehicle. Madison, WI: University of Wisconsin Behavioral Cybernetics Laboratory. 22. Smith, K.U. (1965). Sensorv-Feedback Analysis of Manlike Machine Systems: A New Behavioral Theory for Human Engineering. Madison, WI: University of Wisconsin Behavioral Cybernetics Laboratory. 23. Wierwille, W.W., Gagne, G. A., and Knight, J.R. (1967). An experimental study of human operator models and closed-loop analysis methods for high-speed automobile driving. IEEE Transactions on Human Factors in Electronics. HFE-8 (3), 187-201. 24. Weir, D.H., and Wójcik, C.K. (1971). Simulator studies of the driver's dynamic response in steering control tasks. Highway Research Record. 364. 1-15. 25. Weir, D.H., and McRuer, D.T. (1973). Measurement and interpretation of driver/vehicle system dynamic response. Human Factors. 15(4), 367-378. 26. Drury, C.G., and Dawson, P. (1974). Human factors limitations in fork-lift truck performance. Ergonomics. 17(4), 447-456. 27. Biggs, N.L. (1966). Directional guidance of motor vehicles - a preliminary survey and analysis. Ergonomics. 9(3), 193-202. 28. Smith, T.J. (1994). Core principles of human factors science. In Proceedings of the Human Factors and Ergonomics Society 38th Annual Meeting (pp. 536-540). Santa Monica, CA: Human Factors and Ergonomics Society. 29. Flach, J. M. (1995). Beyond error: the language of coordination and stability. In J. Rasmussen and B. Brehmer (Eds.), The Evolution and Breakdown of Adaptive Systems. New York: Wiley. In Press. 30. Ryan, A.H., and Warner, M. (1936). The effect of automobile driving on the reactions of the driver. American Journal of Psychology. 48, 403-421 . 31. Duchon, J.C., and Smith, T.J. (1993). Extended workdays and safety. International Journal of Industrial Ergonomics. 1.1, 37-49 32. Summala, H. (1981). Driver/vehicle steering response latencies. Human Factors. 23(6), 683-692. 33. Mourant, R.R., and Rockwell, Т.Н. (1970). Mapping eye-movement patterns to the visual scene in driving: an exploratory study. Human Factors. 12(1). 81-87. 34. Godthelp, H., and Käppier, W-D. (1988). Effects of vehicle handling characteristics on driving strategy. Human Factors. 30(2), 219-229. 35. Smith, T.J.,Koehler, E., Keran, C.,and Mathison, P. (1994). The Behavioral Cybernetics of Telescience - An Analysis of Performance Impairment During Remote Work. SAE Technical Paper 941438. Warrendale, PA: SAE International. 36. Smith, T.J. , and Smith, K.U. (1990). The human factors of workstation telepresence. In S. Griffin (Ed.), Third Annual Workshop on Space Operations Automation and Robotics (SOAR '891 (NASA Conference Publication 3059, pp. 235-250). Houston, TX: NASA. 37. Smith, T.J. .Stuart, M.A., Smith, R.L.,and Smith, K.U. (1990). Interactive performance variability in telerobot operation: nature and causes. In W. Karwowski and M. Rahimi (Eds.), Ergonomics of Advanced Manufacturing and Hybrid Automated Systems II (pp. 857-870). Amsterdam: Elsevier. 38. Smith, T.J. .Smith, R.L., Stuart, M. A., Smith, S.T.,and Smith, K.U. (1989). Interactive performance in space - the role of perturbed sensory feedback. In M. Smith and G. Salvendy (Eds.), Work with Computers: Organizational. Management. Stress and Health Aspects (pp. 484-495). Amsterdam: Elsevier. 39. Frank, L.H., Casali, J.G.,and Wierwille, W.W. (1988). Effects of visual display and motion system delays on operator performance and uneasiness in a driving simulator. Human Factors. 30(2), 201-217. 40. Kao, H., and Smith, K.U. (1969). Cybernetic television methods applied to feedback analysis of automobile safety. Nature. 222. 299-300. 41. Gould, J.D., and Smith, K.U. (1963). Angular displacement of visual feedback in motion and learning. Perceptual and Motor Skills. 17. 699-7 10. 42. Weir, D.H., and McRuer, D.T. (1970). Dynamics of driver vehicle steering control. Automatica. 6, 87-98. 43. McRuer, D.T., Allen, R.W., Weir, D.H., and Klein, R.H. (1977). New results in driver steering control models. Human Factors. 19(4). 381-397. 44. Bekey, G.A., Burnham, G.O., and Seo, J. (1977). Control theoretic models of human drivers in car following. Human Factors. 19(4), 399-413. 45. Evarts, E.V. (1966). Pyramidal tract activity associated with a conditioned hand movement in the monkey. Journal of Neurophysiology. 29. 1011-1027. 46. Roland, P.E. (1978). Sensory feedback to the cerebral cortex during voluntary movement in man. The Behavioral and Brain Sciences. 1, 129-171. 47. Duhamel, J.-R., Colby, C.L., and Goldberg, M.E. (1992). The updating of the representation of visual space in parietal cortex by intended eye movements. Science. 255.90-92. 48. Lincoln, R.S., and Smith, K.U. (1952). systematic analysis of factors determining accuracy in visual tracking. Science. 116. 183-187. 49. Coleman, P., Ruff, C.,and Smith, K.U. (1970). Effects of feedback delay on eye-hand synchronization in steering behavior. Journal of Applied Psychology. 54. 271-277. 50. Arditi, A. (1986). Binocular vision. In K.R. Boff, L. Kaufman, and J. P. Thomas (Eds.), Handbook of Perception and Human Performance. Volume I. Sensory Processes and Perception (Chapter 23, pp. 23-1 to 23-41). New York: Wiley. 51. Yeh, Y-Y., and Silverstein, L.D. (1992). Spatial judgments with monoscopic and stereoscopic 475</page><page sequence="20">presentation of perspective displays. Human Factors. 34(5), 583-600. 52. Cook, T.M. (1993). Teleoperation of heavy equipment: individual and environmental correlates of operator performance. In M. Smith and G. Salvendy (Eds.), Human-Computer Interaction: Applications and Case Studies (pp. 278-282). Amsterdam: Elsevier. 53. Cook. T.M.(1995). Teleoperation of Heavy Equipment: Derivation of Stereovision Requirements: A Case Study. SAE Technical Report 951481. Warrendale, PA: SAE International. 54. Drascic, D. (1991). Skill acquisition and task performance in teleoperation using monoscopic and stereoscopic video remote viewing. In Proceedings of the Human Factors Society 35th Annual Meeting (pp. 1367-1371). Santa Monica, CA: Human Factors and Ergonomics Society. 55. Haduch, T.W.,and Mitchell, B.T. (1995). A Human Factors Approach To Unmanned Ground Vehicle Operator Control Unit Interface Research. SAE Technical Report 951482. Warrendale, PA: SAE International. 56. Gould, J.D., and Smith, K.U. (1963). Angular displacement of visual feedback in motion and learning. Perceptual and Motor Skills. 17, 699-710. 57. Ellis, S.R., Tyler, M.,Kim, W.S.,and Stark, L. (1991). Three-Dimensional Tracking With Misalignment Between Display and Control Axes. SAE Technical Paper 911390. Warrendale, PA: SAE International. 58. Haduch, T.W. (1993). Operator interaction with unmanned ground vehicles (UGV) with limited data transmission. In M.J. Smith and G. Salvendy (Eds.), Human-Computer Interaction: Applications and Case Studies (pp. 289-294). Amsterdam: Elsevier. 59. Kay, J., and Thorpe, C. (1995). Operator Interface Design Issues in a Low-Bandwidth and High-Latencv Vehicle Teleoperation System. SAE Technical Report 951485. Warrendale, PA: SAE International. 60. Sheridan, T.B.(1989).Telerobotics. Automatica. 25(4), 487-507. 61. Held, R., and Durlach, N., 1989, Telepresence, time delay, and adaptation. In S.R. Ellis and M.K. Kaiser (Eds.), Spatial Displays and Spatial Instruments (pp. 28-1 - 28-16). Moffett Field, CA: NASA Ames Research Center. 62. Ferrell, W.R. (1965). Remote manipulation with transmission delay. IEEE Transactions on Human Factors in Electronics. HFE-6(1). 24-32. 63. Ferrell, W.R. (1966). Delayed force feedback. Human Factors. October. 449-455. 64. DiStefano, J.J. ,111, Stubberud, A. г., and Williams, I.J. (1967). Schaum's Outline of Theory and Problems of Feedback and Control Systems. New York: McGraw- Hill. 65. Hostetter, G.H., Savant, C.J., Jr., and Stefani, R.T. (1982). Design of Feedback Control Systems. New York: Holt, Rinehart and Winston. 476</page></plain_text>
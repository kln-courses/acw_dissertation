<plain_text><page sequence="1">The Questions of Animal Cognition Readings in Animal Cognition Edited by Marc Bekoff and Dale Jamieson. Cambridge, MA: MIT Press, 1996. 392 pp. Paper, $30.00. The goal of the book, according to the preface, is to introduce readers to the rapidly growing field of animal (nonhuman) cognition. In fact, there are at least two fields of animal cognition. The one represented in this book is concerned primarily with cognitive ethology, which is the investigation of the behavioral evolution of cognitive capacities (see Dale Jamieson &amp; Marc Bekoff, Chapter 5). There is another field of animal cognition that is more concerned with the mechanisms by which these cognitive capacities are realized (e.g., Roitblat, 1987), but for the most part the mechanistic issues are not the concern of the authors represented in the present text. The current line of investigation can be said to have started with Griffin's (1976) proposal (see DaleJamieson &amp; Marc Bekoff, Chapter 5) that it would be fruitful for ethology to abandon its focus on its own nativist brand of be- haviorism and to entertain the hypothesis that animals have awareness and minds. The chapters in this book report on the progress that has been made along the path marked by Griffin and consider the merits of that path. For many years the dominant view in psychology and biology was that it was almost an oxymoron to claim that animals had minds. To entertain the possibil- ity was tantamount to vitalistic anthropomorphism. Against this background, Griffin's proposals received little support from behavioral biologists. Animals may indeed have minds, but to consider such mentalistic concepts to be causally rel- evant was to commit a category error. Mentalistic terms, such as mind, had no place in biology's ontological scheme (see John Andrew Fisher, Chapter 1). 641 BOOK REVIEWS</page><page sequence="2">AMERICAN JOURNAL OF PSYCHOLOGY, WINTER 1997 Several factors conspired to strain this ontological complacence. One of these was the continued development of cognitive psychology, both of humans and of animals. The use of cognitive terms to describe psychological aspects of ani- mal behavior was initially seen as either unwarranted anthropomorphism or mere imitation, misapplying categories of variables that were fashionable for the description of human behavior to that of animals, but eventually these objec- tions began to disappear as an independent computational cognitivism became more common among psychologists interested in identifying the mechanisms of behavior. This cognitivism was neither anthropomorphic nor imitative. The second factor that conspired to make cognitive explanations more plau- sible was the development of cognitive neuroscience (see Roger Crisp, Chap- ter 20). Much was becoming known about the neural substrate of cognitive capacities and functions. It became more acceptable to discuss at least some aspects of cognition in terms of its biological substrate. It also became more plausible that common neural structures could mediate similar function in animals and humans. The development of artificial neural networks also con- tributed to the plausibility of a biological cognitivism by demonstrating how simple neural elements could be used to solve such problems as pattern classifi- cation that had resisted solution by more traditional means (e.g., Rumelhart &amp; McClelland, 1986). These developments made clear that it was possible to talk about cognitive processes and events without committing the anthropomorphic fallacy. They provided support for the plausibility of Griffin's program and for the develop- ment of an experimental approach to understanding the cognitive mechanisms of animals. Methods and techniques were available to begin the investigation of such phenomena as memory, decision making, and perception, but these developments did not lead immediately to methods for studying the kinds of questions that Griffin and the authors represented here found most pertinent, such as whether animals are conscious. Psychologists could describe the infor- mation the animals had and how they used it, but they could not describe how that information was experienced. Some biologists, such as Carolyn Ristau, collected data that would contrib- ute to Griffin's approach, but her major success was in showing that plovers performing distraction displays were not responding simplistically to intruders approaching their nest sites but rather were responding contingently (see Carolyn Ristau, Chapter 6). The behavior of nesting parent plovers depends on characteristics of the intruder and its behavior. Furthermore, the behavior can be modified as a result of experience. These data are consistent with the hypothesis that the plovers monitor the behavior of intruders. Their behavior performed the function of leading the intruder away from the nest. However, the data are less than compelling in demonstrating that the plovers used a representation of the intruder's intentions in selecting their own behavior, or even that the plovers intended to lead the intruders away. They are consistent, as Ristau notes, with the hypothesis of first-order intentionality (that is, the bird wanted to lead the intruder away from the nest), but they are also compatible with other interpretations. Suggestions of first-order intentionality (the animal has beliefs) have definite 642</page><page sequence="3">heuristic value, but the difficulty has been to translate that heuristic into em- pirically rigorous and compelling evidence. This failure to realize its promise has been a continuing problem with Griffin's program. It is notoriously difficult to evaluate the contents of other minds. It seems gratuitous to simply dismiss the possibility that members of other species might possess anything that could sensibly be called a mind. On the other hand, with the exception of my own mind, the only way that I can detect its presence in others is through inference from behavior. John Dupre (Chapter 21) echoes this point. We can never verify the pres- ence of such mental activity in anyone else (human or animal). Therefore, there is no ultimate justification (that is, there can be no proof) for believing that other individuals have minds. We observe in our own case special mental states, which are correlated with certain behavioral dispositions. We then infer (falli- bly) the same mental states in other people who exhibit similar behavior. As any courtroom or theater shows, this method of "ejective" inference (Romanes, 1883/1977) is notoriously difficult to use with humans, let alone with other animals. It is important to be clear on exactly what is being claimed in this "other minds" argument. All science rests on inferences that have at best only limited justification (see Lakatos &amp; Musgrave, 1970). The issue is not merely a ques- tion of scientific validity; rather it is a phenomenological one. When a cat comes running to its bowl at the sound of a can opener, it is difficult to doubt that, for the cat, the sound of the opener is a signal for the impending delivery of food to its bowl. The cat has this information; the information is part of the cat's cognitive content. When we say that the cat has certain information we need not be claiming anything more than that the cat's behavior is contingent on the signal. We need not make any special claims about the format or code of the cat's representation. What we cannot know is what the cat experiences when it hears the can opener. What is the experience like? What mental states exist in the cat? I am trying here to express a difficult distinction. I used the terms cognitive content to characterize the information available to the cat (what it knows or should know) and mental content to describe its mental states. I intend these terms as temporaryjargon to facilitate this discussion. I am using cognitive content to refer to the knowledge that the animal has and mental content to refer to its conscious attitude toward that knowledge (in the jargon of technical philosophy, exam- ples of this latter kind of representation are called qualia). The cat could know, for example, that the can opener signals food and can respond to it, even with- out having any awareness or experience of responding to the can. As another example of this distinction, I might believe that George Clooney acted the part of the butler in Batman. That belief might very well be mistaken (that is, its cognitive content might be inconsistent with other facts), but I cannot be mis- taken about having that belief. It would not make any sense, for example, to say that I thought I believed that George Clooney played the butler, but I was wrong. I did not have that belief. Similarly, pain is mediated by activity in certain nerve fibers. The same neu- rophysiological fibers occur in many different species of animals. We can equate 643 BOOK REVIEWS</page><page sequence="4">AMERICANJOURNAL OF PSYCHOLOGY, WINTER 1997 the activity of these fibers with the cognitive content of pain and use knowledge of this activity to predict the animal's behavior. However, we cannot know any- thing significant about the animal's experience of the pain, how it feels to the animal, its mental content. We can no more know what it is like to be a cat than we can know what it is like to be George Clooney. We can guess, we can sup- pose, but there is no criterion against which to judge the validity of our infer- ence. Any science that takes on the task of identifying with any substantial confi- dence the mental content of others is doomed to failure. Such a task is logically, not empirically, impossible. However, I would argue that this is not a significant issue, nor is it the means by which we predict the behavior of others. Cognitive content is sufficient for predicting behavior; mental content is not necessary, and it is fortunate that such content can be investigated empirically. For example, we can know something about the cat's beliefs, even if we might hesitate to call them beliefs. For example, the cat might believe something like, "When I hear the can opener I run to the kitchen." This is admittedly not a very interesting belief, and it might even be something of a stretch to call it a belief at all. Alternatively, the cat might believe something like, "The sound of a can opener signals something tasty in the kitchen. I am hungry and want something tasty. I will run to the tasty thing and eat it." This latter version is more like the typical descriptions characteristic of belief-desire psychology (believe that an outcome is available and desire that outcome, so perform the action that brings about the outcome). Of course, I am claiming not that the cat has any verbal capacity that would allow it to produce sentences of this sort, merely that these sentences reflect at least vaguely the cat's beliefs. Experimen- tal psychology has developed methods for investigating cognitive contents such as the cat's belief about the can opener and the food (Dickinson, Nicholas, &amp; Adams, 1983). These methods yield data that are more consistent with the sec- ond interpretation than with the first. The attribution of beliefs such as these to cats or other animals is not an- thropomorphism. The nature of the argument is not that the cat has human- type beliefs, but that it has cat-type beliefs (see John Andrew Fisher, Chapter 1; also see Sandra D. Mitchell, Chapter 9, for a related issue concerning units of behavior). We are limited to describing those beliefs in humanlike terms, but that is not necessarily a reflection of the inadequacy of the approach, just of our vocabulary. The confusion between cognitivism and anthropomorphism is considered by John Andrew Fisher (Chapter 1). The confusion is largely a product of our Cartesian cultural history and widespread assumptions that animals are stimulus-response machines, whereas thinking requires language. John Andrew Fisher put it this way: Most philosophers have tended to think that there is a sharp division between hu- mans and other animals-either humans have minds and animals do not, or hu- mans are rational and animals are not, or humans use language and animals do not-such that it is a mistake in principle to apply various [mental] predicates to animals. (p. 8) This demarcation between humans and nonhumans eliminates the possibility of studying mental events in animals by fiat. There can be no more justifica- 644</page><page sequence="5">tion for this position than for the position that only one person in the world (in my case, me) has a mental life. The issue, then, is not whether there are mental events in animals, but what kinds of mental events there are. Hugh Wilder (Chapter 3), for example, uses Clever Hans as a metaphor for under- standing the nature of animal mental events. Clever Hans was a horse exhibit- ed in the early 20th century. This horse had the apparent ability to solve math- ematical problems and to answer other questions by tapping his foot. It was later discovered that Hans's surprising performance depended on subtle cues being passed from the questioner to the horse, usually without the knowledge of the questioner. The issue that Clever Hans raises is how we interpret the animal's cognitive content on the basis of the behavior we observe. Many investigators of Hans's performance were convinced that his training had resulted in raising the in- telligence of a horse to that of a human. As it turns out, there are two types of cognitive content that could be attributed to Hans. One involves the conclu- sion that Hans's cognitive content included knowledge of spelling, arithmetic, and so on. The other is that Hans's cognitive content included the recognition of subtle cues, which he then used to begin and stop tapping his foot. Both alternatives assume that Hans had some kind of cognitive content, but they differ on what that content entailed. Hugh Wilder argues for an application of Morgan's canon of parsimony to our interpretation, reserving our attribution of high mental faculties for those times when lower ones will not suffice, but there are two problems with this. First, we need a theory of what constitutes higher and lower mental faculties (including a theory of faculties). Second, it confuses the capability of cogni- tive content with the nature of that content. Even if the organism has the ca- pability to entertain certain kinds of beliefs or have certain kinds of knowledge, it does not necessarily have those beliefs at any point in time. This case is very apparent in second language acquisition by humans. It is possible to learn a few phrases in a second language to a high level of fluency. A native speaker, hearing that utterance, might attribute a linguistic capability to the speaker that is erroneous. Whether animals are capable of having cognitive content is a cosmological question; what that content is, is an empirical question (see Colin Allen &amp; Marc Hauser, Chapter 4). In the case of trying to apply parsimony to interpretation of animal behavior, issues are further complicated by the pro- found ignorance of the investigator. In fact, so little is known about the details of cognitive processing in animals that it is all too easy to conclude that a giv- en animal lacks a capability. Absence of evidence is different from evidence of absence. The book also includes an excellent group of essays concerned with the adaptive value of cognitive processes and the role of evolution in shaping those processes. For example, the discussion of the adaptive value of play (Alexander Rosenberg, Chapter 14, and Colin Allen &amp; Marc Bekoff, Chapter 15) illustrates well the controversies and evolutionary issues that surround our notions of play in animals. How does an animal distinguish a play bite, for example, from an aggressive bite? Play would seem to require an awareness of intentional state 645 BOOK REVIEWS</page><page sequence="6">AMERICANJOURNAL OF PSYCHOLOGY, WINTER 1997 of the individual with whom one is playing. The chapters on communication (Michael Philips &amp; Steven N. Austad, Chapter 17, and W.John Smith, Chapter 16) are closer to traditional ethological analyses of these topics but cover them quite well. The animal language studies (Sue Savage-Rumbaugh &amp; Karen E. Brakke, Chapter 18, and Louis M. Herman &amp; Palmer Morrell-Samuels, Chap- ter 19) are good descriptions of their respective work, but the book would have benefited from some counterperspective, for example, from Derek Bickerton or other animal language critics. This book does an excellent job of presenting cognitive ethology in a way that makes clear its underlying assumptions and the issues that surround those assumptions. I have focused in this review on the issues of cognitive status in animals. The editors have put together an excellent collection of articles that present the cognitive ethological approach to these issues of mentalism. This book is essential reading for anyone interested in cognitive ethology or for anyone who is dismissive of the field. It shows that the field cannot be easily dismissed, but is not without controversy. Herbert L. Roitblat Department of Psychology University of Hawaii 2430 Campus Road Honolulu, HI 96822 E-mail: roitblat@hawaii.edu References Dickinson, A., Nicholas, D.J., &amp; Adams, C. D. (1983). The effect of instrumental train- ing contingency on susceptibility to reinforcer devaluation. Quarterly Journal of Ex- perimental Psychology, 35B, 35-51. Griffin, D. (1976). The question of animal awareness. New York: Rockefeller University Press. Lakatos, I., &amp; Musgrave, A. (1970). Criticism and the growth of knowledge. Cambridge, En- gland: Cambridge University Press. Roitblat, H. L. (1987). Introduction to comparative cognition. New York: W. H. Freeman. Romanes, G.J. (1883/1977). Animal intelligence. Washington, DC: University Publications of America. Rumelhart, D., &amp; McClelland,J. (1986). Parallel distributed processing. Cambridge, MA: MIT Press.</page></plain_text>
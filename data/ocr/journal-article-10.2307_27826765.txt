<plain_text><page sequence="1">AMPLIFICATION ASPECTS OF BIOLOGICAL RESPONSE AND MENTAL ACTIVITY By JOHN R. PLATT University of Chicago T3 ECENTLY three physical and mathematical disciplines have aided our understanding of biological behavior and mental ac tivity. These are feed-back theory, information theory, and theory of games. I wish to point out here the value of a fourth, complementary, approach which might be called amplifier theory. It is based on the paral lels between biological responses in all living systems and electronic amplification processes. I. GENERAL PROPERTIES OF AMPLIFIERS Physical Relationships The general principles of amplification are shown in the operation of many familiar devices. A radio or television set amplifies radio waves and transforms them into sound or visual patterns. A photoelectric cell or photomultiplier tube amplifies faint light signals and opens a door or rings an alarm bell. In each case there is an input signal of a certain kind to which the amplifier responds. For the radio and the photocell, and for the eye, the least detectable signal might be a single photon or quantum of radiant energy, but usually it will include several photons, enough to produce a response above the background noise level. The sense of smell requires chemical amplifiers whose input signal consists of a few molecules of certain particular chemicals that come in and react and initiate a chemical and electrical neural pulse. The amplifier uses the energy of the selected input signal to trigger a much larger release of output energy. These two energies may have any ratio, provided the output is strong enough to be relatively immune to statistical fluctuation. For a photomultiplier tube the energy amplifi cation factor within the tube may be measured in millions, and the current released may then move a relay to control thousands or millions of times more energy still. In the biological amplifiers of the retina, the energy of the elementary light signal may be multiplied thousands of times in producing a single neural spike; and such a spike may operate a kind of biological relay and be multiplied thousands of times more in the energy of a gross motor response. Figure 1 is a schematic diagram of a photomultiplier amplifier showing the necessary component parts and their relationships. It might serve as a prototype of all sensory amplifiers. A motor amplifier such as a me chanical relay or relay-motor combination is not different in principle 180</page><page sequence="2">BIOLOGICAL RESPONSE AND MENTAL ACTIVITY 181 and contains components with similar functions related in a similar way. Certain features are common to all amplifiers. 1. The input transducer alone determines the kind of signal detected. Man-made amplifiers, with electronic amplification, and sensory nerve endings, with chemical and electrical amplification, must transduce their input signals into electrical or chemical terms before the signals can be amplified. In a photomultiplier the input transducer is the photo cathode which converts photons of incident light into emitted electrons. In a radio it is the antenna. In the eye it must be a retinal pigment molecule capable of photochemical change. What each amplifier responds to depends entirely on the nature of its transducer. GLASS ENVELOPE INTERNAL STRUCTURES Fig. 1. Schematic diagram of a photomultiplier amplifier. 2. The increase of energy is supplied by the amplifier. The power supply must provide an energy several orders of magnitude larger than the signal energy. 3. The amplifier usually needs to be physically much larger than the least input transducer or input particle. Otherwise the power concentra tion after amplification may cause overheating. It takes a macroscopic amplifier to detect a microscopic particle. 4. The output transducer alone determines the kind of output. At the output another transducer converts the electrical signal into whatever form is wanted, such as the movement of a motor or a muscle. The energy of the power supply is released to the external world in the way determined by the transducer. It may vary in amount but not in kind. Within the amplifier, only a single variable is amplified, such as electric current; the output is therefore also restricted to one-dimensional varia tion, whether continuous like a current or discontinuous like a pulse. 5. An amplifier has a characteristic time constant, t0. Within this time?the decay time of a continuous amplifier or the dead time of a pulse amplifier?two successive inputs cannot be discriminated. This characteristic time might be called the interval of the amplifier. It may</page><page sequence="3">182 AMERICAN SCIENTIST be the time for the input transducer to recover its initial state or for the power supply to restore its lost energy. An amplifier is macroscopic in time as well as space. The response frequency for continuous amplifiers is naturally limited on the low-frequency side also. The amplifier partly or wholly ignores sufficiently slow input variations. Anthropomorphically, it adapts or accommodates to a slow change of environment; it forgets. 6. An amplifier must be a rigid or semi-rigid structure. From the time of one act of amplification to the next, there must be a stable or a recurrent spatial relation between input transducer, power supply, amplifying structures, and output transducer, if there is to be a formal similarity between the acts. Amplifiers must behave reproducibly? that is, "causally," so that a similar input cause produces a similar out put effect again and again?if they are to have any operational value. To meet this requirement, once more an amplifier must be at least macromolecular in size, so it can have a fixed topological relationship between its components that it keeps or returns to after each operation. Several of these features, in particular numbers 1, 4, 5, and 6, are found also in some selective unidirectional devices that do not actually amplify energy or power, for example, non-amplifying grid-controlled electronic tubes (as in a cathode-follower or mixer circuit) and perhaps the synapse-neuron junctions of a nervous network. They may be re garded as degenerate amplifiers; and the term amplifiers as used here after will be understood to include them. Output Limitations These physical features of generalized amplifiers imply some broader conclusions. 1. Amplification requires selection. Even with the same kind of input transducer, a separation of two amplifiers in space implies a separation and selection in inputs. This is what makes directional vision possible. The input transducer is functionally selective as well as spatially selective. An indiscriminate amplifier that responded equally to every kind of input, that is, to every fluctuation in its environment, would be useless physically and biologically. It would not be an amplifier at all, but only a site of continuous power dissipation. 2. The dimensionality of the output is always less than the dimensionality of the potential input field. For each sensory amplifier, the field of all possible inputs is, of course, inferred and not observed. But it is at least as manifold as the realm of known physical variables?which we know from observing other amplifiers having other input transducers and having apparently independent response patterns. This potential in formation is thrown away by each particular amplifier. It cannot enter into information theory, which only deals with sensory amplifier output</page><page sequence="4">BIOLOGICAL RESPONSE AND MENTAL ACTIVITY 183 information?for this is the code translating the raw stimulus field into the language of the information network. My radio set is useful because it gives such a highly limited response to its environment. It ignores wind velocity and bacterial population. Even among radio waves, it ignores in its own dimension, alas, those signals too weak or too rapid for a faithful response. But in other di mensions, happily, it omits the whole multiply-infinite electromagnetic spectrum of communications it is not tuned to. 3. Information is always lost in an amplifier. Here I speak of the potential information leaving the input transducer. The amplifier adds noise and distortion and transformations, such as changing the signal from radio to audio frequency or cropping it to produce a pulse. In its own dimension, the output does not represent all the input information. 4. All that an observer on the output side knows about the input is the one output variable. This is all a single amplifier can tell us about what it "saw." All that we can respond to is the output, for our response is but a further amplification. Amplification and Measurement With these limitations in mind, consider then the fundamental im portance of amplification: Measurement is amplification (Feynman tu). This is obvious in the case of the measurements of modern physics on fundamental particles or fields. The electronic amplifiers fill the laboratories. The droplet and bubble amplifiers of cloud chambers and bubble chambers and the photographic grain amplifiers of the nuclear emulsion or the spectrum plate give the tracks and lines the physicist measures. Feynman has suggested that the loss of information in these primitive amplifiers is the origin of the uncertainty principle in physics. But macroscopic measurement is also amplification. Locating a star or weighing a truck involves the selective input transducer and amplifi cation of the telescope or photocell or weighing machine coupled to the human eye. The purposeful human amplifier is a necessary part of the measure ment process. When the ruler lies on the table, the table is not being measured. When the dog or the indifferent maid looks at the ruler on the table, it is not being measured. It is only measured when an interested eye notes the spatial contiguity of photon patterns and amplifies the signal into an immediate or stored specific biological response. Measure ment is amplification for a biological purpose. It is a link in the com plicated human response-amplification chain. And the Feynman theorem can be enlarged to touch other fields. In biology response is amplification. In the theory of knowledge, knowledge is amplification.</page><page sequence="5">184 AMERICAN SCIENTIST These assertions provide new approaches for viewing the nature of biological and nervous response and the organization and scope of the brain. II. PULSE AMPLIFIERS AND THE POLAR OPTION The Output Pulse as a Polar Option Sensory nerve endings belong to the class of pulse-producing ampli fiers, and many non-neural biological amplifiers can also be put in this class. It is suggestive to think of a pulse output as being a polar option. I use the anthropomorphic word "option" because of the apparent resemblance to our neural processes. In any one of its intervals, the amplifier "chooses" (or the input field "determines") whether it is to pulse or not to pulse. These are not equivalent alternatives. Information theory may treat them so, and clever circuit design may let them trigger equivalent processes in some later stage; but for the amplifier the difference is like that between waiting and acting, not like that between one action and another. Not-to-pulse leaves it in the same state and does not com promise further choices; to-pulse incapacitates it for any further choice for the rest of the interval. The option is "polar" with highly dissimilar alternatives. They differ so fantastically in degree, because of the ampli fication factor, that it is, paradoxically, a greater difference than a mere difference in kind. In this way the output signal can be lifted high enough to be above confusion with extraneous noise pulses in subse quent stages; and pulse-frequency systems, such as nerves use, can be made particularly noise-free?an important element in the consistency of learned or instinctive biological responses. Note how closely a pulsed amplifier output resembles the "part functions" in Ashby's theory of learning, [2] which are zero most of the time and non-zero only in certain intervals. Primitive Vital Acts as Polar Options The amplification character of biological response would be an ex tensive subject. I wish to single out here the familiar "all-or-none" aspect, that is to say, the polar-option aspect, of the most elementary biological outputs; and to describe some of their features in the present language. In the most primitive self-reproducing knot of amino acids, we may imagine the commonest vital act to be an act of growth. Food or growth molecules drift through the solution and touch the knot. This contact is different from the random contacts with the water or non-growth molecules. This specific low-energy mechanical contact triggers a release of further potential energy, stored somehow from the sun's radiation,</page><page sequence="6">BIOLOGICAL RESPONSE AND MENTAL ACTIVITY 185 so that a new chemical bond is formed. The knot has grown one step or has gone one step farther toward producing a daughter. The output variable of this most primitive biological amplicafition is two-valued and polar: to grow or not to grow. One alternative is vital, the other is only patient. A little farther up the scale of life the types of amplification become more numerous, but the usual vital output function must still be a polar option. Only when we reach interacting amplifiers and neural networks will we find the nature of the choice modified. At the primitive level, the options from one trigger input are: to eat or to ignore. From another input: to run or to stay. From another: to divide or to wait. Each is an amplification of a signal. Each has one vital or mortal alternative, and one patient alternative. The survival value of polar options may consist in this, that if they are repeated sufficiently often, the vital alternative eventually becomes inevitable. The probabilities of the patient alternative multiply and finally approach zero, but the probability steadily increases that some thing will happen, and when it does it is complete and not partial or ambiguous. So in "Russian roulette," which is a repeated polar option, the mortal alternative of getting shot finally becomes inevitable. By using amplifiers with polar options, life becomes armed with in evitability and can surmount the damage from thermal fluctuations and irradiation and attack by lesser organisms. Individual death is also a polar option and therefore inevitable. For life in general, however, death appears as the patient or do-nothing alternative of a larger polar option, whose other and inevitable arm is evolution. III. AMPLIFICATION AND THE NERVOUS SYSTEM Properties of Neural Nets In higher organisms, each sense bud amplifies its selected input to an output level above statistical fluctuation. Along each nerve the only further amplification is the continuous electrochemical amplification necessary to keep the signals from dying out, like the booster or repeater units in communication lines. But at the end of the nerve, the output goes to a synapse which transfers it to another nerve. With respect to its incoming synapses, this second nerve acts like a sense bud and like an amplifier in many respects, although the amplification factor may be small or unity. It selects the inputs from one set of nerves and mixes and filters them to give outputs to another nerve or set of nerves. Let us consider the loss of information and the nature of possible choices in a network of neurons connected by synapses. The net, like a simple amplifier, is organized to produce response, to take action, to make a decision.</page><page sequence="7">186 AMERICAN SCIENTIST A decision is the selection of one response or one response-pattern? one next movement or group of movements?from all the possible al ternative responses, with suppression of conflicting alternatives. If we think of each response-pattern as a polar option, perhaps the output of a particular neuron, then the vital alternative has been chosen for one option, the patient alternative for the rest. (Or the response might be broken into parts which may each be treated in this way.) The polar option has been generalized to a polar decision. This picture of the operation of the network suggests several theorems. 1. The dimensionality of the sensory input signals is smaller than that of the stimulus field. The sensory amplifiers, no matter how numerous, are still spatially and functionally selective. 2. Satisfaction of two equivalent but conflicting polar option inputs is impossible. With two or more amplifiers of the same type, there is more information than with one, but also more possibility of conflict in their indications. If one signal says "go" or "pulse," the other "stop" or "non-pulse," there is grave danger to the animal from indecision. Either one signal must always agree with the other, or it must be regularly suppressed, being in either case useless; or else some chemical or elec trical mixture of the signals, as in a neuron receiving inputs from several synapses, must lead to a polar decision to resolve the conflict. (Such a neuron has some of the properties of the "singular" transmitters dis cussed by Rapoport. [3]) 3. Information is lost in a polar decision. A decision that resolves a conflict suppresses information; if it did not, there would never have been a conflict. This is true even when the conflict is between non equivalent inputs. An electrical sum or difference of two pulse-frequency messages contains less information than the two messages separately. If we have m sensory inputs, then in each interval of time there are 2m possible different combinations of signals, about IO10' for the rods and cones of the human eye. Essentially no combination can ever be re peated in the mere 1012 intervals of a single lifetime. So if we made a different response to every combination, learning would be impossible. We can well afford to, in fact we must, throw away all but a micro microscopic number of the most significant and vital features of this flux. We must select these features by a series of polar decisions. 4. The dimensionality of response is smaller than that of the stimulus field. Information is lost at the input and at every synaptic decision stage. A vast number of alternative stimulus fields will lead to the same final response-pattern. An example may suggest how the reduction comes about. If there are m independent response polar options in a given in terval, they carry m bits of information; but if they are alternative, a polar decision can specify which one is chosen with only log2 m bits of in formation, a much smaller quantity.</page><page sequence="8">BIOLOGICAL RESPONSE AND MENTAL ACTIVITY 187 Numerical Relationships in an Efficient Decision Network Some theoretical models of neural nets and of automata or decision making networks have been extensively discussed by Von Neumann, McCulloch and Pitts, and others. Nevertheless it is worth digressing here for a brief look at another similar model of an efficient decision making network, possibly resembling the brain in some respects. This will show the possible usefulness of the present view that synapse neuron junctions act like mixer-type amplifiers; for it leads to quantita tive suggestions about brain structure and operation, about the time rate of loss of information by these amplifiers in making decisions, and therefore about the time rate of successive decisions. The remarks can readily be extended to treat the efficiency and time constants of other decision-making networks such as a business organization or an army. 1. A decision network in which an average element {neuron) combines inputs from about r elements of the preceding stage will have = logf m stages between the m sensory inputs and any final simple polar decision. The number of active neurons leading to the decision decreases by a factor r in each stage. With 108 or more rods and cones, if the average effective r is 2, as in a tennis tournament, a human visual response would require about 28 stages. It is easily shown that the minimum total number of neurons is obtained when r equals e or 2.718, but that this total number changes little for values of r between 2 and 4. Whether or not our knowledge of brain histology can be reconciled with such low values of r, it seems introspectively that many of the combinations that reduce information to final decisions are pairwise comparisons between only two input stim uli. In the visual network, for example, this is suggested by our attention to contrasts and to colors, which are pigment-differentials, and by the mechanism of nystagmus which seems expressly designed to locate con trast boundaries in the field. Our sensitivity to rates of change suggests pairwise comparison of an input with itself at two different times, pos sibly by means of a time-delay. It may be that what we mean by a circle or a flower or Mrs. Jones is a set of constant differences of dif ferences somewhere in the network; just as in numerical analysis a fifth degree curve, no matter how displaced or distorted by lesser variations, still has constant fifth differences. Some decision stages may combine more than two inputs at a time, but probably not many. Ashby points out that the most efficient way to solve a large problem is to break it up into a large number of small prob lems and solve them one at a time. Perhaps if the value of were an order of magnitude different from the value given here, so that we normally made, say, hundreds of stages of pair-wise comparisons, the limitation of the celebrated game to only</page><page sequence="9">188 AMERICAN SCIENTIST "Twenty Questions" would become impossible because of the fantastic subdivision of the universe of attention. 2. The mean repetition rate of the average sense bad should be about one per two intervals, or J/#0. The maximum information is obtained if each alternative, to pulse or not to pulse in one interval, is equally probable. Adaptation and fatigue may be devices for adjusting the sensitivity so as to divide the alternatives about equally in each environment, and maximize the information. This hypothesis assumes that each alternative has equal value. If one is much more vital than the other, it can justify its cost, like an alarm bell, even if it is rarely needed. One of the advantages of an in formation-handling network may be that it does not have to waste space with special, and normally unused, sense buds for every possible alarm. It can use all its buds all the time for various purposes, and set off the alarm reaction only when their combined information spells alarm. 3. The interval of the synapses should be matched to that of the sensory input amplifiers, t0. Faster synapses would gain nothing; slower ones would lose information unnecessarily. For the human visual system, t0 is usually given values in the neighborhood of 1 millisecond. 4. The network time per stage is about equal to t0. In an efficient network, this time will presumably be as short as possible, but one may suspect that the act of combination of inputs by a synapse, especially if they are imperfectly synchronized, takes one full interval and must be completed at each stage before the output is passed on to the next. If this were so, the shortest neurons would just be able to contain one spike at a time. There would be an approximately fixed frequency for successive synap tic acts, of the order of 1000 cycles per second in the brain, like the fixed frequency of addition operations in an electronic computer. 5. The transit time, T, across the network is about nto. It would take of the order of 50 milliseconds for a nerve impulse of normal speed to tra verse the length of the human brain. If this would represent a transit through all the stages of the network, would be of the order of 50 stages, in reassuring agreement with the value from (1) above. The restrictions of (4) and (5) could be avoided if all time delays were carefully matched and if there were no internal feedback; but each of these suppositions seems biologically improbable. 6. The maximum speed of making conscious decisions or independent perceptions is one per transit, or 1/T. This is the flicker frequency, the bass threshold, the word-scanning frequency in an easy book; of the order of 20 per second, in reassuring agreement with the conclusions of (1) and (5) and evidently a general fundamental constant for human beings. It is of the order of twice the frequency of the alpha rhythm when the impulse traverses the brain back and forth and it reverberates like an empty room. Conceivably if conscious formulated thought could</page><page sequence="10">BIOLOGICAL RESPONSE AND MENTAL ACTIVITY 189 be separated into elements, we should find the element frequency would be again about 20 per second. 7. The maximum muscle response frequency matches the maximum perception frequency, or 1/T. Otherwise either some perceptions or de cisions would be wasted or some movements would be unguided. This is the phonetic frequency, the letter-frequency of a fast typist, and the tremor frequency, when the muscle moves as fast as its chemistry and inertia will permit. Actually the phonetic frequency is probably set by the hearer rather than by the speaker. The latter may need to make only two or three new decisions per sentence, letting habit carry the rest, and occupying his mind with many other things while talking. I have heard some after dinner speeches where there was no evidence of any further operation of the speaker's mental decision-net after he rose from his dessert and clutched his lapel. Hypotheses (6) and (7), if true, demonstrate clearly the loss of in formation in a response. My response of "running away" would be the same, except perhaps for its verbal component, whether my stimulus is a lion, a charging buffalo, or a forest fire. This decision may take only one transit. After I have started running, I can make decisions about other things. Even for the verbal component, although at every transit I may be aware introspectively of the whole lion, position and markings and smell, all I can get out about him in one transit is a single phoneme, wrhich would have been the same for an infinity of other situations. It is true that if the lion obligingly lies down and stays in one position, and I catch my breath, I may send a succession of many phonemes which will begin to trace out some of my introspective field to my audience. But in every transit time, the vast extent of my full renewed intro spective field during that transit is still incommunicable, as I find im mediately when the lion jumps up and makes motions in every transit which the millions of bits of information in a motion picture film can scarcely record. Compared to the full input field, communication carries so little in formation in its one phoneme per transit that the only way it can be of much value to us is by manipulating symbols of abstractions at a rela tively high stage in the decision network, where the vital usefulness of the polar decisions to which they correspond makes up for their low in formation rate. So if I shout the warning "Lion!," the dozen or so bits of information extracted from my phonemes and my tone can send the neighbors running without waiting to enjoy the lion's full million-fold sensory field. Synaptically Excited Neurons as Input-Mixer Tubes In the parallel between synaptically-excited nerves and non-amplify</page><page sequence="11">190 AMERICAN SCIENTIST ing electronic mixer tubes, some other features besides the loss-of-in formation aspect may also deserve exploration. Sum and difference comparisons of input frequencies are easily generated in a mixer tube and perhaps in such nerves. (The frequency language is equivalent to the pulse-per-interval language which has been more useful up to this point.) With high sensitivity, a neuron might fire as often as it receives impulses from either synaptic input; so that it would sum the input frequencies, up to its maximum fre quency. With low sensitivity, it might take the difference frequency be tween a pair of inputs, firing only as often as they both coincide in the same interval. With a quasi-logarithmic intensity-frequency relation in the sense buds, a difference-frequency corresponds to a ratio of in tensities. This suggests that many perceptions are linear in the difference frequencies, with a constant liminal difference which ought to be about one pulse per transit, or 1/T. These assumptions would account qualita tively for many of the liminal contrast data, for color vision, and for perceptual independence of absolute stimulus intensity. Moreover, we can see how such a synaptic addition or subtraction could easily become a learned response. Addition is one rotation of two inputs in input space; subtraction to give differences of input frequencies, another. On the Ashby model of learning, a failure from one response causes the system to try another response at random. If failure is represented by pain, we can imagine, for example, that pain nerves release a chemical in the brain or in the synaptically-excited nerves that acts to produce a permanently lowered sensitivity in nerves that have recently been active; perhaps by reacting with decomposition products from the excitation, so as to prevent full recovery. The lowered sensitivity will convert some input additions into sub tractions. The total effect is a random rotation in m-space, leading to a different response, in the Ashby fashion. If this new response also fails, the further pain will lower the sensitivities of more neurons and rotate their polar decisions, until finally a non-painful or successful assembly of polar decisions is reached. A sufficiently intense pain could even operate further on neurons that have already been rotated from addition to subtraction, by destroying their sensitivity altogether. (The local similarity to traumatic amnesia might not be accidental.) These consequences of the parallel with mixer tubes suggest numerous experiments, especially on the biochemistry and action of synapse neuron junctions under pain, and on visual learning in congenitally blind subjects who recover sight. They also raise many questions, such as the role of substitutes for pain, like anticipated pain or dissatisfac tion, and the possible biochemistry and histology by which satisfaction might reinforce a response.</page><page sequence="12">BIOLOGICAL RESPONSE AND MENTAL ACTIVITY 191 IV. PSYCHOLOGICAL ASPECTS OF DECISION NETWORKS The notion of a network collating and losing information as it makes a decision gives another language for describing some psychological phenomena. Thus the field of behavior becomes largely the field of de cisions. Likewise the materials of introspection are the inputs from in ternal stages rather than from the sensory amplifiers. A few points are especially noteworthy. The Polar Decision and the Gestalt A vast number of different combinations of stimuli lead to the same polar decision. Something in us says, "Harry!," regardless of distance and angle and light. The latter information has been thrown away so far as recognition is concerned. Identification is the type problem in gestalt theory, as well as a serious practical problem in military com munications; and it is perhaps the most characteristic polar decision. It may be made at an early stage in the visual network. Our certainty about it in the case of a friend suggests that it is a final decision at that stage and that trivially conflicting information, such as a new blemish or shoulder padding, is thrown away along with the environmental trivia. It takes much longer?perhaps more stages and more gathering of additional information and recycling?to say "No, I don't know him." From an abstract point of view, one might define a gestalt as the class of all combinations of stimuli that produce the same polar response. A given gestalt problem might then be translated into the behavioral problem of determining, from the first response in infancy onwards, how the class of stimuli producing a given response is successively limited or enlarged. Information, Feedback, and Decisions The statement, Amplifier pulses are polar options, is changed in a network into the statement, Amplifier pulses are collated into polar decisions. Or more bluntly, The function of information is to make de cisions. This must be true not only of the brain, but of the information net works that lead to executive decisions in a business organization or an army. Starting with the initial data of the market survey or the patrol reports, we can see the information dwindle as the vital parts are suc cessively summarized in the stages up the hierarchy. This is necessary, for the general can make no more decisions per transit time than any private in any one of the squads. When the last polar decision is made, we can see the response proliferated again in the motor network into so many thousands of sales operations or so many rounds of artillery.</page><page sequence="13">192 AMERICAN SCIENTIST Cybernetics has emphasized the importance of the feedback loop in purposeful behavior. The loop comprises the feedback or error stimulus supplying information to a network that produces a correction or feed back response. The present remarks suggest the further importance of amplifiers, with all their limitations, at several places in this loop. There must be selective sensory amplifiers to gather the information, synaptic stages to collate it and reduce it to a decision, and motor ampli fiers to translate the decision into a response. To say only that the function of information in an organism is to produce positive feedback, would be to miss both the million-fold loss of-information aspect and the million-fold gain-of-energy aspect. The more highly organized life is, the more precarious; so that a subtle change of environment, the scent of prey, or the shadow of a falling tree or the new tracks in the aerial photograph, may have great vital conse quence. At such times, more than a little feedback is necessary for sur vival: the detectors must be manifold, the interpretation shrewd, and the response simple, sudden, and great. The information must lead to a polar decision and the decision to an amplification before the feed back can be right or adequate. Equivocal Decisions and Anxiety It is striking to compare the normal speed and satisfaction of a polar decision like identification, with the slowness and difficulty of equivocal decisions like which dress to buy. The customer recycles the information through her network trying to generate a preference. Higher forms of life, stretching inadequate information to foresee remoter consequences, may face equivocal decisions more often than lower. We frequently try to twist our equivocal decisions into polar ones, as when we choose a car principally by the color. In other cases, we may keep needling ourselves on to a choice by saying, It is better to do some thing than to do nothing; or, Doing nothing is a decision, too. The present point of view suggests that anxiety occurs when a polar decision cannot be produced from vital information. The anxiety may appear unreasonable to other men. Or it may be a learned lesson that saves the anxious man from an easy decision and a worse fate. Until it is resolved, an equivocal decision uses up network time that could be used for other decisions, and perhaps distorts what other decisions are made. No doubt the deliberation over an equivocal decision has survival value. It may be related to the state of "attention" after an alarm, with all responses cancelled that would conflict with either of the equivocal pair, and with the sensory detectors directed toward collecting informa tion at the maximum rate on the one subject, Friend or Foe? It is per haps when such a state is prolonged by inadequate information, so</page><page sequence="14">BIOLOGICAL RESPONSE AND MENTAL ACTIVITY 193 that it interferes with necessary decisions such as eating and sleeping, that it ceases to be "attention" and becomes "anxiety." V. AMPLIFICATION AND KNOWLEDGE The Knowable Universe We see that no man can ever even in principle achieve Laplace's pro gram, to "know the positions and velocities of all the particles in the universe," which classically was supposed to permit prediction of the future motion of every part. There would have to be more amplifiers than particles, with the amplifiers outside the universe. The number of independently knowable particles must always be orders of magnitude less than the number of particles in the amplifiers. Laplace's determinism, which was 19th-century determinism, was only tenable for the kinds of experiments he specialized in, with a few "particles" and many amplifiers?a few planets and the human eye. But the motions of the millions of molecules in even a microscopic gas bubble are unknowable even in principle, and therefore to us inconse quential, because the amplifiers are impossible to build. The least amplifier is bigger than the particle or, more precisely, bigger and with more parts than the least input transducer. How much bigger still must be the man who makes it! Here is a regress of another few orders of magnitude. To build the smallest physically operable macroscopic secondary amplifier takes primary amplifiers?eyes and brain, or the automatic machinery they can construct?whose parts must be still more numerous and occupy a still larger volume of space or time. For it takes many sense buds and many decisions and many motor operations in the primary amplifier system to extract from the universe and to shape a single component of the secondary amplifier and to assemble it into its proper place among the other components. (Can we regress one more step? The eyes and brain had to be made in turn by the zero-order amplifier, evolution, using and wasting still more parts and taking an even greater stretch of time. This leads to the amusing thought that there may be an order-of-magnitude connection between the age of the universe and the number of fundamental parti cles a scientist can detect in any one interval.) Bigger than the least amplifier also must be the information-handling network that collates the output of many amplifiers and makes polar decisions. It must have more parts or must take a longer time to do its work than the amplifiers, or both. The frequency with which scientific inputs to human beings can be acted upon, must always be low, perhaps only a few per hour, since scientific decisions must be squeezed in among more humanly intimate decisions and since perhaps only one decision of any kind can be made</page><page sequence="15">194 AMERICAN SCIENTIST per transit time. What we can learn from historical records is similarly limited. Our information-handling network is available only part time for such work. It follows that electronic calculating machines will have to be given instructions for an increasingly humanized evaluation and rejection of their own results, to keep us from being drowned by the flood of decisions as the machines handle more and more information. We may accept results selected in this way by machines, but we will not "understand" them in the old sense if we do not know for ourselves what has been rejected and why. The low scientific-decision-making frequency per human being, and our reluctance to relinquish evaluation may set the ultimate gainful limit to the capacity of electronic com puters, and so to the amount of primary amplifier data we can absorb per scientist. The output does not represent knowledge if it is printed on paper faster than we can read if off or understand it. The Polar Option and Two-Valued Logic Two-valued logic is the logic of the polar option, of the pulse ampli fier, of the "part-function." No pulse is a not-pulse. No not-pulse is a pulse. No output signal is both a pulse and a not-pulse. The biological amplifiers that failed to exclude the excluded middle were probably eliminated early through their ambiguity. It is true that we are not aware of our first-stage sensory options, but we are aware of the polar option for each response-pattern, and keenly aware of the two polar options when we are faced with equivocal decisions. It seems almost necessary that a network selected by evolu tion to operate with polar options should feel compelled to base its "laws of thought" on two-valued logic. It is "self-evident," "innate"? born in us?to give an evolutionary twist to Plato and Kant; not some thing learned, except as survival is learning. An N-valued logic is the logic of a polar decision, such as identifica tion. Bill and Mary and Tom were there. Who else? Nobody else I knew. It could be written as the product of overlapping polar options with suppression of conflicts, since each patient alternative has room for any number of vital alternatives of other kinds. It is much simpler to make an N-valued logic in this way than by a product of two-valued equivalent options, with their manifold product terms. This may be related to Ashby's conclusion that the speed of analysis of a complex situation by an organism is much higher if the inputs are part-functions. Decision-Making and the Laws of Thought The "laws of thought" that we reach by introspection should cor respond to the brain network operations that we infer by observation. If two-valued logic corresponds to a polar option, perhaps the basic syllogism is a description of amplifier operation. The classic work of</page><page sequence="16">BIOLOGICAL RESPONSE AND MENTAL ACTIVITY 195 McCulloch and Pitts and Rashevsky showed that the whole apparatus of symbolic logic and of Aristotelian reasoning can be manipulated or represented by suitably chosen neural nets. The point here is that such nets are not merely possible, they are probably necessary in biological systems that have evolved to operate with polar options using ampli fier principles, and that many of our laws of thought may have a similar evolutionary necessity. One might think of a biological "syllogism" in which the amplifier is the major premise; the input is the minor premise; and the output is the conclusion. The surviving one-celled animal has an amplifier that makes the physiological premise, "Fresh water is to be avoided." The input makes the physical premise, "This is fresh water." The output draws the amplified conclusion, "Avoid it!," and the animal does. Of this species, all the individuals that had no such amplifier, or a faulty one, died early. This individual syllogism might be thought of as a sharpened example of an evolutionary "association of ideas," what might almost be called an evolutionary syllogism involving evolutionary amplifiers. Bees must get nectar to survive. Only flowers have nectar. Therefore bees must visit flowers. Any bees (or flowers) so poorly constituted genetically that they can not make this conclusion?this association of ideas?would be at a dis advantage, so that the species that survive are those capable of com pleting the association and the "syllogism." The importance of what Russell calls "animal inference" [4] was continuous throughout evolution. Survival selects the reproducible, that is, the causal, aspects of the world to use as amplifier inputs. Associative inference is not peculiar to the development of individual learning in the higher brain. If we step outside ourselves and view the causality that our species attributes to the world in its thought, we will find that it is self-consistent but biologically circular reasoning in a life form that has evolved in the world only by maintaining a formal sta bility and a causal stability in its amplifiers. The network, like the amplifier, is a unidirectional logic machine. Between the multidimensional stimulus and the single polar decision lies an elaborate vital syllogism. Every pair of neurons converging to a third is an associative process, is a pair of premises leading to a con clusion, is a set of particular cases from which a generalization is ab stracted by induction. Every pair of diverging branches from a neuron is a set of particulars derived from the general. More generally, many or all of the "postulates of scientific inference" that underlie human reasoning but are not themselves provable must be similarly related to the evolved structure of the brain, that is, to the</page><page sequence="17">196 AMERICAN SCIENTIST loss of information in a decision-making network. Our need for self consistency in making theories may be related to the necessary blocking of conflicting responses in the brain, which may in turn have been pro duced by the pain and malfunction of the organism when it tried to pull itself apart to satisfy conflicting responses. Our need for simplicity of explanation may be the pressure to make decisions more efficiently by making them at an earlier stage in the network. We have an unprovable belief in the continuity and short-time independence of the "things" we see. But the analysis of our sensory inputs into the perception of independent and continuous and recog nizable objects may be the fifth or the tenth differentiation ("differences of differences") in the network, of such high survival value?because it represents one of the useful regularities of the world?that it takes place below our level of adult awareness or normal debate. Our perception of analogies may be the fifteenth differentiation, and so on. Successive "levels of abstraction" may be successive stages in the decision net. Forster's well-known electrical stimulation experiment showed they were associated with different spatial areas of the brain. In network language, the classical "properties" of objects may be signals abstracted at various decision stages. The quality of "blueness," like the property of being "Harry," is not affected by the light or the material or the angle because of clever differentiation in the network. Plato's dictum, "Experience is a rough approximation to universals," would, of course, be turned around today to read, "Universals are a rough approximation to experience"; but in either form it could be translated here as, "Information is always lost in a polar decision." All three statements describe a network property of great survival value. Unidirectionality in Amplifier Systems Many unidirectional systems, asymmetric in time, are amplifier systems. The common amplifier aspect thus links up some areas normally separated in our thinking. For example, the direction of stimulus-response is the direction of the primitive biological amplifiers, the direction of reproduction and survival, the direction of evolution. It is the direction of cause and effect. "The fire was so hot it made me draw back." And when we stimulate the world (by our response) we wait for it to respond (and stimulate us)?for this is our evolved method of getting what we need? and we call it anthropomorphically cause-and-effect, as though the world were another person, which it often is. Cause and effect are as asym metric in time as our sense amplifiers which cannot emit their input and our motor amplifiers which cannot respond to their output. It is non-amplification processes, such as the collision of billiard balls</page><page sequence="18">BIOLOGICAL RESPONSE AND MENTAL ACTIVITY 197 in 19th-century physics, that are reversible in amplifier-time and permit the interchange of cause and effect. The direction of stimulus-response is the direction of increasing loss of information in our amplifiers and of uncertainty in prediction. The past is equally uncertain except for what we have amplified and stored. We speak of the universe as governed by an uncertainty principle; it is our amplifiers that have lost some conceivable degrees of cer tainty. We speak of disorder or entropy as increasing; but the order may have been thrown away in the information rejected by our ampli fiers. Order is only order when it is humanly measurable, and ordered by human standards. The most divine and intricate order, in dimensions yet unguessed, if it is strained through the sieve of our amplifiers and cramped to the mold of our polar decisions, may be only disorder and entropy to us. We speak of consciousness as being irreversible, as having a directed time axis; it is our amplifiers. The direction of stimulus and response is the direction of pulses across our neural net, the direction of flow of information, the direction of premise and conclusion, the direction of decision. And perhaps that is what we mean by the direction of time. VI. ACKNOWLEDGMENTS Section I was suggested by a lecture in Ann Arbor in 1951 on the uncertainty principle by Professor Richard P. Feynman, now of the California Institute of Technology. I am indebted to Professors Anatol Rapoport and James G. Miller, now of the University of Michigan, for helpful criticisms, and to Professor Miller for the important observa tion that synaptically-excited nerves must also behave like amplifiers. REFERENCES 1. Richard P. Feynman, Unpublished lectures. 2. W. H. Ashby. Design for a Brain. Chapman and Hall, London, 1952. 3. A. Rapoport, Bull. Math. Biophysics, 17, 15 (1955). 4. Bertrand Russell. Human Knowledge, Its Scope and Limits (Especially Part Six). Simon and Schuster, New York, 1948.</page></plain_text>
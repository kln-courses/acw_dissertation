<plain_text><page sequence="1">Brit. J. Phil. Sci. 43 (1992) 537-553 Printed in Great Britain Mental Content' COLIN ALLEN ABSTRACT Daniel Dennett and Stephen Stich have independently, but similarly, argued that the contents of mental states cannot be specified precisely enough for the purposes of scientific prediction and explanation. Dennett takes this to support his view that the proper role for mentalistic terms in science is heuristic. Stich takes it to support his view that cognitive science should be done without reference to mental content at all. I defend a realist understanding of mental content against these attacks by Dennett and Stich. I argue that they both mistake the difficulty of making content ascriptions precise for the impossibility of doing so. 1 Introduction 2 Dennett's Argument 3 Stich's Argument 4 Conclusions I INTRODUCTION Several recent authors have argued for a limited role, or no role at all, for mentalistic, or intentional, terms in cognitive science. At least two of these authors (Dennett [1969], Stich [1983]) have focused attention on the notion of the content of a mental state. Both have argued that there are particular difficulties for specifying the content of mental states, and both claim that these difficulties support their (different) stances on the role of mentalistic terms in cognitive science. My objective in this paper is to defend a realist understanding of the notion of mental content against the attacks of Dennett and Stich. By a 'realist understanding', I mean the view that mental states and their contents are ontologically respectable for scientific explanations of behaviour. I am particularly interested in the arguments regarding the difficulty of specifying the contents of non-human animal2 mental states, although there will be 1 I would like to thank Keith Donnellan, Alan Nelson, and an anonymous reviewer for their helpful comments. 2 I shall use 'animal' instead of the clumsier 'non-human animal' in what follows.</page><page sequence="2">538 Colin Allen some discussion of allegedly difficult human cases, particularly with reference to Stich's arguments. The conclusions I draw regarding mental content are not limited to animal cases alone. 2 DENNETT'S ARGUMENT Dennett [1969] defends a view of the role of intentional terms in science that he calls 'centralism'. Of centralism, he says: the centralist makes his initial characterization of [behavioural events] Inten- tional, describing the events to be related in law-like ways using either ordinary, or semi-ordinary, or even entirely artificial Intentional expressions. He then hopes that an adequate physical basis can be found among the internal states and events of the organism so that 'reductions' of Intentional sentences of the theory to extensional sentences of the theory is (sic) possible. (pp. 41-42) According to this view, intentional terms serve a heuristic purpose, indicating places in scientific accounts of phenomena where extensional explanations of those phenomena are lacking. In serving this heuristic role, intentional terms provide an 'interim way of speaking' in lieu of a physical (i.e. neurophysiological) explanation of behaviour (Dennett [1983], p. 343).3 Dennett's position is a form of eliminativism, and this is confirmed by the account he gives of the early history of the use of intentional terms in human attempts to describe the world [1969], p. 89). For example, he points out that where humans once used to speak of rivers wanting to reach the sea, we have abandoned the intentional idiom in favour of explanations using physical concepts only. The view is called 'centralism' because unlike behaviourism it makes use of attributions of internal states to organisms. Dennett's centralism relegates intentional descriptions to the role of place holders, heuristically useful insofar as they indicate where science needs to do better. He is apparently driven to this view by arguments purporting to show that intentional descriptions cannot provide causal explanations of behaviour. I will dispute these arguments in this section of the paper. I have reconstructed two arguments which, I believe, represent Dennett's principal objections to treating seriously explanations that make use of intentional terms. As we will see below, Dennett does not present these two arguments separately. For reasons of exposition, however, it will be useful Dennett has considerably clarified (and modified) his views on the importance of intentional terms in science over the years. I am not, however, interested in tracing the development of his views. In this paper, I focus on the clear eliminativist tendency in his view, no matter that this view is now tempered with an increased assessment of the heuristic importance of intentional terms for the practice of science.</page><page sequence="3">Mental Content 539 to consider them separately as far as possible. The arguments may be outlined as follows: A (1) 'Sciences' of intentionality are committed to 'the Intentionalist's irreducibility hypothesis', 'that Intentional phenomena are absol- utely irreducible to physical phenomena' ([1969], p. 30). (2) The irreducibility hypothesis entails that intentional explanations cannot be Humean causal explanations. (3) Scientific explanations require Humean causal explanations. So (4) 'Sciences' of intentionality cannot provide scientific explanations. B (1) If intentional state attributions are to feature in scientific explana- tions, they must be genuinely predictive. (2) To be genuinely predictive, intentional attributions require a degree of precision that cannot be provided. So (3) Intentional attributions are not genuinely predictive and cannot feature in scientific explanations. I shall concentrate on argument A before turning to argument B. In particular, I hope to clarify the irreducibility hypothesis, and to argue against acceptance of the second premiss, A(2). First, the irreducibility hypothesis. As stated in A(1), the hypothesis claims that intentional phenomena are absolutely irreducible to physical phenom- ena. This formulation is curious since one does not normally think of phenomena reducing to one another. The formulation suggests that there are indeed two phenomena, rather than a single one with different descrip- tions. Dennett himself immediately clarifies what he means by the irreduci- bility hypothesis, saying, Put in terms of sentences, the claim is that Intentional sentences cannot be reduced to or paraphrased into extensional sentences about the physical world. The claim goes beyond the obvious fact that Intentional sentences are intensional, and hence cannot be, as they stand, extensional-to the more remarkable claim that no sentence or sentences can be found which adequately reproduce the information of an Intentional sentence and still confirm to extensional logic. (p. 30) This is still rather vague, since it is not obvious just what is required for one sentence to paraphrase another, or for one sentence to reproduce adequately the information of another. For present purposes though, I propose to understand the irreducibility hypothesis as the view Fodor [1974] defends, that the (intentional) kind terms appropriate for stating generalizations (laws) in psychology are not coextensive with the (extensional) kind terms appro- priate for stating generalizations (laws) in neuroscience.4 4 The view requires that, for instance, the term 'pain' does not make the same contribution to truth conditions as 'C-fibres firing' in sentences in which they appear, even if human pain</page><page sequence="4">540 Colin Allen Since I am prepared to accept a version of the irreducibility hypothesis, I am not concerned to dispute premiss A(1).5 Neither will I dispute A(3). Rather, it is A(2) to which I turn. This premiss is supported by Dennett's assertion that intentional explanations of behaviour are not contingent because there is a conceptual link between desiring P and taking actions to achieve P. Taken alone, this assertion is not enough to justify the claim that intentional explanations are not causal explanations. Davidson [1963] has argued that desires can be Humean causes of actions despite a conceptual link between desire and action. Davidson interprets Hume's analysis to 'mean that "A caused B" entails that there exists a causal law instantiated by some true descriptions of A and B' (p. 17). He argues that intentional explanations are consistent with this because there are descriptions of the intentional phenomena that meet the Humean requirement. Dennett is aware of Davidson's argument and hence aware that lack of contingency does not by itself rule out causal explanation. As an example he considers the relationship between conception and pregnancy. Despite the conceptual link between the two, conception is a Humean cause of of pregnancy since there is a way of describing conception that is logically independent of a description of pregnancy. But, Dennett argues, this is not the case with intentional explanations. This is because, he claims, 'It follows directly from the Intentionalist's irreducibility hypothesis that no independent characterization [i.e. description] of an Intentionally characterised antecedent is ever possible' (p. 35).6 Contrary to Dennett, I maintain that the irreducibility hypothesis does not entail that independent descriptions of particular instances of cause and effect are unavailable. The claim that intentional descriptions are not in themselves predictive is compatible with Davidson's argument that intentional expla- nations are causal explanations. Intentional descriptions are predictive only actually turns out to be C-fibre firing. The truth conditions for 'x is in pain' and 'x has C-fibres firing' will be different so long as pain in other organisms is not C-fibres firing. The version of the irreducibility hypothesis adopted here is stated in terms of 'kinds' to rule out generalizations stated in terms of disjunctions of extensional predicates. Conceivably (barely) one might identify all the neurological (or other physical) correlates of pain in every organism and then restate a true psychological law involving pain by substituting the disjunction of these extensional descriptions of states for the term 'pain'. I am inclined to agree with Fodor's [1974] view that the resulting generalization, while true, is not a law. 5 Whether the version I adopt is committed to 'absolute irreducibility' as per A(1), I am not sure, since I do allow that there may be token-token identifications. While a stronger version of irreducibility might make A(2) more plausible, it would weaken the scope of the conclusion, A(4), to a point where it could not support Dennett's eliminativism against my view. 6 Centralism avoids the alleged problem arising from the irreducibility hypothesis because it relies upon the possibility of replacing intentional descriptions of certain causes and effects with extensional descriptions. (The phenomena are only intentionally described, not intrin- sically intentional.)</page><page sequence="5">Mental Content 541 by virtue of their association with predictive extensional descriptions, but they are also causal by virtue of this same association. As Dennett stated the irreducibility hypothesis, it is a thesis about the possibility of paraphrasing intentional sentences into extensional ones. I proposed to understand the hypothesis as the claim that intentional kind terms do not have counterpart extensional kind terms-the truth conditions for the intentional and exten- sional terms will be different. Understanding irreducibility in this way does not rule out a science of intentionality. Supposing that certain physical states can be given intentional descriptions, it might still be the case that no extensional description was available with the same truth conditions. That is, it might be possible to accept an identification between states described intentionally and extensionally while still accepting the irreducibility hypoth- esis. How might this be? Functionalism provides one possible answer. Because, according to the functionalist, there are an indefinite number of physical systems which could realise a given intentional system, there could be no extensional description with just the same truth conditions as the intentional description of a particular system. Every intentional state of the system would nonetheless be identified with a physical state of the system. And since the physical apparatus implements its intentional properties by means of causal interactions between its physical parts, intentional explana- tions of the behaviour of the system could be turned into causal explanations in a Davidsonian manner. Functionalism is not necessarily the only theory capable of supporting the irreducibility hypothesis. For instance, any theory which takes mental states to supervene on physical states and allows that different physical states may support the same mental state would do. Thus Davidson's [1970] theory of mind, which he labels 'anomalous monism', allows that mental states are causes without being committed to a complete reduction of mental sentences to physical ones. The view of intentional terms I am proposing is that they provide a vocabulary for the unification of explanation of events with different underlying physical properties. For instance, intentional descriptions are capable of providing a language for the formulation of general hypotheses that will apply across a large number of different organisms (and, perhaps, other devices). Different organisms may have different behavioural outputs and the particular output produced by a particular organism with a given cognitive state will be contingent on the resources available to that organism. The level at which the connection between intentional descriptions and behaviour appear to be analytic, is a level which ignores the contingent conditions that determine exact behaviour in any particular case. For instance, the connection between being hungry and seeking food may well be analytic. But if a bird takes flight in order to catch insects there is no analytic connection between the hunger and the beating of the wings that is its effect. A different organism may also engage in food-seeking</page><page sequence="6">542 Colin Allen behaviour, but this may occur not by flying but by some other form of locomotion. These considerations suggest another way in which the sentences of intentionalist theories of behaviour may not be reducible to sentences of extensionalist theories. Even if it were true that descriptions of intentional states could be replaced by extensional descriptions, it might not be true that behavioural hypotheses could be specified extensionally. Such hypotheses establish causal links between intentional states and behaviour. In order for such hypotheses to be phrased extensionally, both intentional states and behaviour would have to be reducible. But the level at which such hypotheses may be stated, e.g. the animal looked for food because it was hungry, describe behaviour in such a way that it may not be specifiable extensionally. The physical movements associated with food-seeking behaviour will be suffi- ciently different between different organisms that there will be no single extensional characterization available. This level of abstraction of animal behaviour is in keeping with general biological practice in evolutionary explanation (Asquith [1984], p. 142). Dennett's arguments fail to convince us that there is not some version of the irreducibility hypothesis that is consistent with the view that intentional explanations are causal explanations. Premiss A(2) need not be accepted. Unlike phenomenologists, I am convinced that identification of (token) intentional states with (token) physical states is necessary for scientific understanding of minds, since these identifications appear necessary if we are to adopt Davidson's strategy for providing causal explanations. Dennett ([1969], p. 189) refers to the need for a 'rapprochement' between the language of mind and the language of science. On his own eliminativist view, the requirements of such a rapprochement are quite weak-merely that intentional descriptions serve to pick out, albeit only roughly, phenomena which are properly explained using extensional language. If, after the rapprochement, we say that pain is C-fibre firing, then perhaps all that this indicates is that C-fibre firing now explains (most of, or at least some of) the phenomena previously explained by pain. Dennett, however, see difficulties for his opponents, who need more precise identifications. It is the second argument, outlined above, which presses these difficulties. As with the first argument, my criticism will focus on the second premiss, in this case B(2). B(2) claims that to be predictive, ascriptions of intentional states require a degree of precision that cannot provided. This premiss might be criticized either by denying that precision is required for predictiveness, or by denying that sufficient precision is unobtainable. I shall use the first of these strategies against the first difficulty Dennett raises for the theorist who would identify intentional states with physical states, and I shall use the second strategy against Dennett's second point. The first problem Dennett raises is that of how to properly individuate the</page><page sequence="7">Mental Content 543 neural structures which are appropriate bearers of content. He thinks that it is 'all but impossible' (p. 82) to do this because of the intimate connection between mental states, sensory input and behaviour-the latter pair being tied to neuronal stimulations outside the brain-which means the appro- priate structures for the ascription of content, being spread all round the body, could not be easily located. This objection seems weak. Difficulty in locating the physical components of a particular state does not give any theoretical reason for questioning a realist stance toward it. For instance, the components of the circulatory system are widely distributed around the body and have a very complicated microstructure. Furthermore, these components can play anatomical and physiological roles in other systems. For these reasons, it would be very hard to identify precisely the com- ponents of the circulatory system. However, this in no way shows that the circulatory system is not a real entity suitable for biological study. In other words, precise physical delineation of the kind Dennett demands is not necessary. The second difficulty for rapprochement is with the use of language to express the content of neural events. Dennett's view is that ascription of content to these states is an interpretational move rather like producing a semantics for a mathematical axiom system-'a move which does not affect its functions or implications but may improve intuitive understanding of the system' (p. 79). Rapprochement would require that 'Assigning content to an event must be relating the event to a particular verbal expression' (p. 82). It is in this context that Dennett raises difficulties for the ascription of content to animal beliefs. Dennett asks us to imagine some centralist scientists of the future who have knowledge of the neural states and events of the brain of a dog, Fido. Fido is observed, and when presented with a piece of steak located in the middle of a frozen pond he does not go out across the ice to retrieve the steak. The centralist, who has access to Fido's brain states through some measuring devices, can detect neural states which normally occur when Fido sees a steak and so has every reason to believe that Fido has detected its presence. In addition, Dennett's story goes, the scientists detect that Fido's normal retrieval behaviour is being inhibited by 'signals with a source traceable to a previous experience when he fell through thin ice' (p. 84). Dennett says: the centralist has information regarding neural functioning that puts him in a strong position to say that Fido's behaviour is determined in this case by the stored information that it is dangerous to walk on thin ice... On the basis of his past knowledge of the functional interrelations in Fido's nervous system, the centralist assigns certain contents to certain events and structures. Roughly, one afferent signal means 'get the steak', its continuation means 'get the steak', some structure or state stores 'thin ice is dangerous' and produces,</page><page sequence="8">544 Colin Allen when operated on by a signal meaning 'this is thin ice', another signal meaning 'stop; do not walk on the ice' (p. 84). Given this story, Dennett asks us to consider the accuracy of these content ascriptions. As an example, he points out that it seems unlikely that we should use the word 'steak' because it is far too specific. Fido would probably react no differently if the object was a pork chop rather than a piece of steak. Even 'meat' would be too specific because 'the dog does not recognize the object as a butchered animal part, which is what the word meat connotes' (p. 84). Alternatively, 'food' would not be specific enough because the dog would have shown less interest in dog biscuits. Dennett claims that 'What the dog recognizes this object as is something for which there is no English word' (p. 85). Dennett's strategy, in this argument, is to consider a few particular sentences to see whether they express the content of the animal's state. After several sentences have been tried and rejected, it is then claimed that no sentence will suffice. But, in the absence of some principle to explain why no sentence will do, the possibility remains that there is some suitably complicated sentence which we lack enough ingenuity (or are too lazy) to discover. Dennett considers this possibility. He writes: It might seem that we could get at the precise content of the signal by starting with an overly general term, such as 'food', and adding qualifications to it until it matches the dog's differentiations, but this would still impact sophisti- cations to the description that do not belong to the dog. Does the dog have the concept of nourishment that is involved in the concept of food? What could the dog do that would indicate this? Wanting to get and eat x is to be distinguished from recognizing x as food. (p. 85) There are apparently two points to be distinguished in this passage. First, there is the claim that even after adding qualifications the resulting description would be too sophisticated. Still this does not seem to give us an argument to justify the claim that no appropriately qualified sentence would do. Dennett asks whether the dog has the concept of nourishment involved in the concept of food-implying that since the dog does not, it would be incorrect to use the word 'food' at all. But precisely the point of adding qualifications would seem to be the removal of connotations which the word 'food' might normally bear. We can well imagine a person who distinguishes food in the sense of being able to choose the things that are desirable to eat, without that person knowing anything about nourishment-e.g. without understanding why it is that they have to eat food. Having made these qualifications, it might be thought that it is correct to say they believe of a piece of fruit that it is food. If we think of the list of concepts, such as nourishment or edibility, that are related to the concept of food, then it might be possible to specify the deletion or addition of links to specific concepts</page><page sequence="9">Mental Content 545 from this list and thereby end up with a concept which does match the dog's. While Dennett is undoubtedly right that 'the differentiations of a dog's brain' do not 'match the differentiations of ordinary English' (p. 85) it does not follow that the differentiations of dictionary English cannot be manipulated so as to delineate the differences of the dog's brain. Thus far, it does not seem that Dennett has given us a principled reason for thinking that these manipulations are not possible. The second point arising from the preceding passage concerns the relation between behavioural evidence and the ascription of content. It is not entirely clear what role this point is playing in Dennett's strategy. If his point is just that we may have difficulty making the observations which would enable us to determine the content of a particular state, this seems true, but it does not seem to show that there is no correct ascription which can be made. If Dennett is saying that in fact there will be no behaviour in any circumstances from the dog which would lead us to say that the dog has the concept of nourishment, then maybe we should infer that the dog does not have this concept. From that we could infer that the dog does not exactly have our concept of food (if our concept of food involves the concept of nourishment). But, even these circumstances do not rule out the possibility that we could specify the dog's concept by claiming it to be like our concept of food but without any connotations about food having nutritional value. Indeed, there must have been a time when humans had a concept of things that were good to eat without having any concept of nutrition. There may even still be humans in this position. So, the argument may apply equally (well or poorly) to humans and animals. There is still no reason to think that we cannot carry out the suggestion made just above-that of manipulating English so as to explain what the dog's concepts are. The exact details of such an approach are likely to be very messy. As a start we could say that the dog has a concept that is similar to our concept of food insofar as items which form part of the animal's normal diet fall under the concept. As further explanation, we add that when a dog recognizes an item as falling under this concept it has no beliefs at all about the nutritional value of the item. It will clearly be seen that after a few rounds of such qualifications we could end up with a very unwieldy description of the dog's concept. At this point it would not be unreasonable to give the concept an invented name to be used as a shorthand for the long description. By doing this we would have started to create an artificial language to describe the contents of the animal's mental states. But Dennett specifically objects to this procedure. He continues the last quoted passage saying: These hair splitting objections might lead the zealously rigorous centralist to formulate artificial languages for expressing the content of the events and states he isolates, but to go to such efforts in the name of centralism, is to lose sight of the essential point and burden of centralism. (p. 85)</page><page sequence="10">546 Colin Allen The first point to notice here is that Dennett is no longer saying that the contents could not be specified in this way. Instead his point is that a specification of this kind would not have any value. Before considering why Dennett thinks that this is so, let us reconsider the status of the conclusion that it is impossible to use English to express the content of animal beliefs. The first stage of the argument tried to establish that since English words would always involve concepts which the dog does not have, it would not be possible to find a simple English expression for the content of the dog's beliefs. The second stage suggests that an attempt to sufficiently qualify English so that un unwanted connotations remain is likely to lead to the introduction of an artificial language. As I envisage things, the use of an artificial language is not crucial for the centralist. It is introduced as a shorthand for the longer-winded descriptions in English. Consequently, those descriptions could always be used to replaced the terms of the artificial language. Since Dennett is no longer arguing against the possibility of using artificial language to express the content of neural events and states (he is only arguing against its usefulness) then his arguments against artificial languages, even if successful, will not show that it is impossible in principle to specify precisely the content of an animal's belief. At most they will show that such a precise specification is not useful. But is Dennett justified in concluding that precise specification of content is useless? He states: Precision would be a desideratum if it allowed safe inferences to be drawn from particular ascriptions of content to subsequent ascriptions of content and eventual behaviour, but in fact no such inferences at all can be drawn from a particular ascription. (p. 85) Here, Dennett's claim is that since intentional explanations are not really able to predict anything, precision in them is of no value. This adverts to argument A, above. On Dennett's view, 'predictions' in intentional language presuppose that the predicted mental states have already been linked to their neural and behavioural manifestations. His objection to independent sciences of intentionality was that such links are ruled out by the irreducibility hypothesis. This, together with the conceptual dependence of intentional descriptions on behaviour, means that the intentional 'predictions' cannot predict anything on their own. It is for this reason that Dennett regards the formulation of artificial languages to describe the dog's belief as losing sight of the essential point of centralism. Since centralism regards ascription of content as not predictive, precision is unnecessary. From the point of view of the centralist, the heuristic role of intentional descriptions can be played without precise ascription of content. However, in the first part of this section, I criticized argument A and described how the irreducibility hypothesis is compatible with causal</page><page sequence="11">Mental Content 547 explanation. Without argument A to bolster this part of argument B, and in the absence of a principled reason for the impossibility of precise enough specification of the contents of mental states we are not committed to the view that the notion of content cannot be used to play a more important role in science than Dennett would have us believe. 3 STICH'S ARGUMENT Stich [1983] argues that the mentalistic, intentional terms of folk psychology need to be replaced by a new set of theoretical constructs. Stich's strategy is divided into two parts. In the first part, he attempts to characterize precisely the concepts of belief and desire as they appear in folk psychology. Stich considers the ascription of content to mental states as central to folk psychology. The second part is dedicated to showing that content ascription cannot form an adequate basis for the practice of cognitive science. As part of the second part of this strategy, Stich considers the ascription of intentional states to animals. He argues that folk psychology is inadequate with respect to animals. This inadequacy can be traced, according to Stich, to what he terms 'ideological differences' between ourselves and animals, and to the fact that animals are not part of a linguistic community. To support the first of the points Stich employs an argument that is very similar to that given by Dennett. However, the arguments for both of Stich's points are related, and I shall consider both. Stich's discussion of the problems for folk psychology presented by ideological differences focuses not on animals but on what he calls 'exotic folk'. One of his examples concerns the Nuer people who believe during certain religious ceremonies that a sacrificial cucumber is an ox. Stich says that on first acquaintance with this piece of information a natural (and not unsophisticated) reaction is to decide that Nuer people, as a group, exhibit a pre-rational mentality (p. 99). However, he claims, commonsense notions of psychology also provide people with a second reaction to these kinds of cases. Given a thorough account of the Nuer rituals and beliefs, he says one can come to see them, 'including the one about the cucumber and the ox, as a sensible systematic attempt to deal with the natural and social environment the Nuer confront' (p. 99). Stich believes that it is necessary to explain why it is that we react in these two different ways and he takes these different reactions as evidence that the folk notion of belief which produces them is unclear and inconsistent (p. 104). He says: 'Having projected ourselves into an exotic belief network we are inclined to say both that the subject believes that a cucumber is an ox and that English content sentences are not up to characterizing his beliefs at all' (p. 102). Stich claims that two intuitions such as these are 'simply incompatible' and they cannot be resolved 'by appeal to different contexts of judgement' (p. 101). Since both</page><page sequence="12">548 Colin Allen intuitions are the product of our folk psychological notions, he infers that there is a problem with those notions. Immediately after discussing the Nuer, Stich turns his attention to animals. He introduces a dog, named Fido, and describes Fido chasing a squirrel which passes out of view down an alley. Fido follows down the alley and reaches an oak tree where he stands, looking up into the tree and barking. Stich says: To explain Fido's behavior it would be perfectly natural to say he believes that the squirrel is up in the oak tree. But suppose now that some skeptic challenges our claim by focusing attention on the differences separating Fido's belief from ours. 'Does Fido really believe it is a squirrel up in the oak tree? Are there not indefinitely many logically possible creatures which are not squirrels but which Fido would treat indistinguishably from the way he treats real squirrels? Indeed does he believe, or even care, that the thing up the tree is an animal? Would it not be quite the same to Fido if he had been chasing some bit of squirrel-shaped and squirrel-smelling machinery, like the mechanical rabbits used at dog-racing tracks? The concept of animal is tied to the distinction between living and nonliving, as well as to the distinction between animals and plants. But Fido has little grasp of these distinctions. How can you say that he believes it is a squirrel if he doesn't know that squirrels are animals?' Confronted with the challenge, which focuses attention on the ideological gap that separates us from Fido, intuition begins to waiver (sic). It no longer sounds quite right to say that Fido believes there is a squirrel up in the oak tree. (pp. 104-105) The similarity of this with Dennett's story about his Fido and the steak on the ice is obvious. In both cases we are told that English words are inappropriate for giving the content of the animal's belief because the English concepts to not match the dog's concepts. In the case of the Neur people, Stich claimed that our initial reaction was to think that they exhibited a pre-rational mentality. In other examples of ideological dissimilarity between persons, he suggests that an initial reaction is to think of the other person or persons as mad. With the Nuer, the intuition arises because we think to ourselves that no fully rational human being could believe that a cucumber is an ox. But with Fido it is not possible to generate a corresponding intuition-there is no sense in which we feel that Fido is less than rational. In the case of animals, it does not seem that the folk psychological notion of belief gives rise to a conflict of intuitions, since the first kind of intuition simply does not arise. The second intuition from folk psychology is that the suggested English content sentences do not adequately capture the dog's belief states. Even if this is true, it does not imply, as we saw earlier, that there are no English sentences that will do. Stich reports that, in order to deal with the second intuition, the inclination of anthropologists faced with radically different belief systems, such as those of the Nuer, is to utilize native terminology. He says:</page><page sequence="13">Mental Content 549 This will work, of course, only when supplemented by an elaborate gloss explaining how these beliefs, characterized by native content sentences, relate to one another ... there is no shorter way to characterize their cognitive world. The descriptive apparatus of folk psychology is not designed to deal with the beliefs of exotic folk. (p. 102) This procedure of anthropologists described by Stich is similar in some respect to the procedure given for the contents of animal beliefs I advocated in the previous section. In both cases one introduces the content of the beliefs with many qualifications about the relationships between the concepts of the subjects. The difference in the case of the Nuer is that they have their own language which helps provide some shorthand terms for our long-winded, English language descriptions of their concepts. It is not the descriptive apparatus of folk psychology, as Stich puts it, which is unable to deal with the Nuer. Rather, it is the lack of singular terms in English to express Nuer concepts that is the problem. We might put the point by saying the descriptive apparatus of English is not designed to deal with the beliefs of the Nuers. Indeed, it is curious that Stich thinks that the kind of descriptions of exotic belief systems provided by anthropologists represents a failure of content-based cognitive science. He says the native 'can still have belief-like states and desire-like states, even though we have no content sentences to characterize them' (p. 103). But the realist is committed only to the view that cognitive science is to include generalizations based on the content of mental states. He is not committed to saying that English must be capable of neatly expressing the contents of everyone's mental states. If a Nuer belief has content X, where X is not expressible in English, it is still perfectly possible that the belief would interact with other mental states, or the environment, in virtue of its content. A long-winded description in English of X may tell us the content of the belief without giving us an English sentence with the same content, and this may be the best that we can do. But it would still be true that the belief has a content and that this is an important fact as far as cognitive science is concerned. Furthermore, as far as predicting behaviour is concerned it is also possible that the long-winded description in English would be enough to generate the relevant predictions. If, in fact, we could come up with descriptions of the foreign concepts by qualifying the concepts of English, it seems very likely that such descriptions would give us behavioural predictions. Rather than signalling the failure of content based cognitive science, this kind of attempt by anthropologists to describe native beliefs would seem to represent precisely the kind of refinement in specification of content necessary for a sophisticated cognitive science. In Fido's case there are elements of two problems. First, the concepts available to the dog differ from those available to ourselves. Thus it is difficult to use our concepts to describe the dog's (as it is difficult to use our concepts</page><page sequence="14">550 Colin Allen to describe those of the Nuer). However, we have seen that it is not necessarily impossible. Secondly, there may, in the case of animals, be some truth to the charge that the descriptive apparatus provided by folk psychology is inadequate to describe the mental states of the dog. This is because folk psychology has largely been concerned with human mental states, generally taken to include beliefs, desires, etc. These states have a certain relationship to one another, and it may well be the case that the mental states of dogs relate to each other differently. While this might suggest a different taxonomy of mental states, it does not rule against the use of content bearing mental states to describe animals. In the passage (from pp. 104-105) quoted above, Stich's skeptic says that because there are an indefinite number of logically possible objects Fido would treat indistinguishably from a squirrel, it is not correct to say that Fido's belief is a belief about a squirrel. This point is rather similar to the one made by Dennett, when he claims that his Fido's indifference between steak and some other piece of meat raises a question about the content of the dog's belief. If Stich (and mutatis mutandis Dennett) is basing his case on the fact that there may be objects Fido would treat indistinguishably from squirrels in all circumstances, the conclusion is unwarranted. It is also true of humans that there are an indefinite number of logically possible objects which are indistinguishable from squirrels. Yet we do not ordinarily think that this possibility causes any problems for the specification of the contents of human beliefs about squirrels, so why should it present a problem for Fido's belief? Of course, if people constantly failed to distinguish between two kinds of object we would certainly doubt whether they had the concepts under which the things were different. But, under the sceptic's challenge, interpreted in this way, we are supposed to be worried about the mere logical possibility of some object that would be treated indistinguishably from an actual thing. Perhaps, though, Stich (and Dennett) have less arcane possibilities in mind. Stich asks whether it would make any difference to Fido if he were chasing a mechanical squirrel. He suggests that Fido might be fooled by such a device, just as racing greyhounds are fooled by mechanical rabbits. (Actually, greyhounds need not be fooled at all-they can be trained using only mechanical rabbits.) But, in this case, it is simply not true that the mechanical substitute is completely indistinguishable to the dog-I would wager that Stich's Fido would behave somewhat differently if he managed to sink his teeth into the mechanical substitute than if he was able to get his teeth into the real thing. (And Dennett's Fido might well show a preference for pork chops over steak.) But if Stich means only that Fido would treat these things indistinguishably in certain circumstances (e.g. chasing, but not sinking teeth into) once again it does not seem that there is any special question, arising from the fact that Fido is not human, to be raised about the content of Fido's</page><page sequence="15">Mental Content 551 beliefs. As before, there is a symmetry between Fido and humans. In certain circumstances people will treat iron pyrites (fool's gold) indistinguishably from gold. Yet we do not have any conflicting intuitions about the content of their beliefs in such circumstances. Gold miners who thought they had struck it rich when really all they had found was a vein of iron pyrites nonetheless believed that they had gold in their possession. If Stich means only that Fido will treat two or more things the same in some circumstances, this does not seem relevant to the content of his beliefs, provided that he does distinguish between those things in some other situations. In some circumstances we may treat things which fall under different concepts identically. Nonetheless, in those circumstances our beliefs will be different according to which concept the things fall under. When baking a particular pie it may not matter to me whether I have lemons or limes. It does not follow that there is any question about whether or not I believe I am grating a lime, when I am in fact doing so. Considerations about indistinguishability do not, therefore, help to provide a principled reason for why English sentences cannot be used to given the content of animal beliefs. It is the absence of a langugage in animals that provides Stich with the second source of doubt about the ascriptions of content to animal beliefs. He says: Fido does not express his belief verbally and is not a member of a linguistic community. So the fact that he does not distinguish squirrels from other (actual or possible) squirrel-like things generates puzzles about how his belief is to be characterized... shall we say that he believes [the thing he is chasing] is a squirrel? Or should we say that he believes it is a furrel, where 'furrel' is a new term denoting the heterogeneous collection of animals and artifacts that Fido treats indistinguishably from ordinary squirrels? (p. 105)? Stich claims that folk psychology is unable to answer this question. His diagnosis is that there are conversational contexts where it would be true and appropriate to say of Fido that he believes he is chasing a squirrel, and other contexts where the very same sentence would be false. This is possible, Stich claims, because 'belief ascriptions are similarity claims, and similarity claims are context dependent' (p. 106). Stich's view is that ascription of content to beliefs of a subject gives us information about how the subject is likely to behave. This information is derived from our knowledge of how we would behave if we held the same belief. In some contexts it is all right to say that the dog believes that it is chasing a squirrel because in that context the dog will behave similarly to a normal English speaker who is chasing a squirrel. In other contexts, the dog would not behave similarly at all, so it would be false to say that the dog believes it is chasing a squirrel. Stich admits that in cases where precision is a desideratum the tendency is to deny that English sentences accurately capture the content of the animal</page><page sequence="16">552 Colin Allen beliefs. If (contrary to Stich) it were the case that a cognitive science relied on the notion of content, it would seem that accuracy would require the use of terms such as 'furrel' rather than squirrel when describing animal beliefs. But the term 'furrel' cannot be a term in the dog's language since the dog does not have a language. Instead it is just an artificial term describing the concept applied by the dog. I argued above, that such artificial terms are harmless conveniences. Stich thinks them harmless in certain contexts, but that cognitive science will have no use for such inventions. Admitting difficulty in ascribing content to mental states need not provide a reason for abandoning the attempt. As was discussed with reference to the Nuer people, we may be able to rely on the fact that an organism has mental states even when we cannot come up with a precise specification of the content of those states. For instance, we may know that Fido has, instead of our concept of ice, a concept of a hard, shiny, cold, brittle substance (or something like that). We might use this to help explain why he is just as unwilling to set out across some marble floors as across a frozen pond. Once again, the attempt to specify content, whether with artificially introduced terms or with lengthy English expressions seems to represent the kind of development to be expected and hoped for in a more sophisticated cognitive science. 4 CONCLUSIONS I have argued that the notion of content is sufficiently robust to be used in scientific explanations of behaviour. Along the way, I have argued that there are no insuperable difficulties in specifying the mental contents of animals as well as humans. This does not, of course, exhaust the challenges that have been raised against the use of intentional terms in the behavioural sciences. However, in the limited space available here I hope to have convinced the reader that there is hope for taking attributions of mental states and content seriously. Department of Philosophy Texas A&amp;M University College Station Texas 77843-4237 U.S.A. REFERENCES ASQUITH, P. J. [1984]: 'The inevitability and utility of anthropomorphism in description of primate behaviour', in R. Harr6 and V. Reynolds (eds.), The Meaning of Primate Signals, pp. 138-74. Cambridge: Cambridge University Press.</page><page sequence="17">Mental Content 553 DAVIDSON, D. [1963]: 'Actions, Reasons and Causes', Journal of Philosophy, LX, pp. 685-700. DAVIDSON, D. [1970]: 'Mental Events', in L. Foster and J. W. Swanson (eds.), Experience and Theory. Amherst: University of Massachusetts Press. DENNETT, D. C. [1969]: Content and Conciousness. Paperback edition 1986. London: Routledge and Kegan Paul. DENNETT, D. C. [1983]: 'Intentional systems in cognitive ethology: the "Panglossian Paradigm" defended', Behavioral and Brain Sciences, 6, pp. 343-90. FODOR, J. A. [1974]: 'Special Sciences', Synthese, 28, pp. 77-115. Reprinted in J. A. Fodor, Representations. 1981. Cambridge, Massachusetts: M.I.T. Press. STICH, STEPHEN [1983]: From Folk Psychology to Cognitive Science: the case against belief. Cambridge, Massachusetts: M.I.T. Press.</page></plain_text>
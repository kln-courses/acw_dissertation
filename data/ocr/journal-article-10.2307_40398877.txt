<plain_text><page sequence="1">Recommendation Agents for Electronic Commerce: Effects of Explanation Facilities on Trusting Beliefs WEIQUAN WANG AND IZAK BENB AS AT Weiquan Wang is an Assistant Professor in the Department of Information Systems at City University of Hong Kong. He received his Ph.D. in Management Information Systems from the University of British Columbia. His research interests include online recommendation agents, trust in technological artifacts, user acceptance of information technology, and human-computer interaction. Izak Benbasat is a CANADA Research Chair in Information Technology Manage- ment at the Sauder School of Business, University of British Columbia, Canada, and a Fellow of the Royal Society of Canada. He received his Ph.D. in Management Information Systems from the University of Minnesota. Dr. Benbasat is the past edi- tor-in-chief of Information Systems Research and is currently a Senior Editor of the Journal of the Association for Information Systems. He is a Fellow of the Association for Information Systems. His current research interests include designing and evaluat- ing human-computer interfaces for e-business. Abstract: We empirically test the effects of explanation facilities on consumers' initial trusting beliefs concerning online recommendation agents (RAs). RAs provide online shopping advice based on user-specified needs and preferences. The characteristics of RAs that may hamper consumers' trust building in the RAs are identified, and the provision of explanation facilities is proposed as a knowledge-based approach to enhance consumers' trusting beliefs by dealing with these obstacles. This study examines the effects of three types of explanations about an RA and its use - how, why, and trade-off explanations - on consumers' trusting beliefs in an RA's compe- tence, benevolence, and integrity. An RA was built as the experimental platform and a laboratory experiment was conducted. The results confirm the important role of explanation facilities in enhancing consumers' initial trusting beliefs and indicate that consumers' use of different types of explanations enhances different trusting beliefs: the use of how explanations increases their competence and benevolence beliefs, the use of why explanations increases their benevolence beliefs, and the use of trade-off explanations increases their integrity beliefs. Key words and phases: decision support, decisional guidance, electronic commerce, explanations, recommendation agents, trust. Journal of Management Information Systems / Spring 2007, Vol. 23, No. 4, pp. 217-246. Â© 2007 M.E. Sharpe, Inc. 0742-1222 / 2007 $9.50 + 0.00. DOI 10.2753/MIS0742-1222230410</page><page sequence="2">2 1 8 WANG AND BENBAS AT Explanation facilities have been one of the key components of intelligent and knowledge-based systems (KBSs) since their inception [28]. This study empirically investigates how and to what extent consumers' use of explanation facilities provided by online recommendation agents (RAs) increases their trusting beliefs concerning the RAs. RAs are Internet-based software that carry out a set of operations on behalf of users and provide shopping advice based on users' needs, preferences, profiles, and previous shopping activities [3]. RAs have been proposed as support tools for consumers in the various steps of their decision-making processes in e-commerce environments [29, 57, 67]. They help buyers reduce information and choice overload, improve decision qual- ity, and increase product choice confidence [32, 36, 49, 56]. Online stores offer more product choices due to their virtually infinite "shelf space" [32]; in addition, multiple product choices are offered by a multitude of online stores that are easily accessible on the Internet. However, the provision of extensive choices, though initially appealing, may lead to consumers being more frustrated with the decision-making process, more dissatisfied with their choices, and less likely to purchase products [39]. By screening out unsuitable products, RAs reduce consumers' choice loads and lead to higher deci- sion quality and satisfaction. Moreover, RAs provide customers with shopping advice that is particularly helpful for complex products [57, 72], such as digital cameras and computers. Without proper support, consumers may be limited in their ability to evalu- ate products, because they cannot consult with salespeople as in traditional shopping environments [44]. The challenge of choosing a complex product on the Web can be alleviated by an interface that informs and directs customer choices [29]. RA technologies are being utilized by a variety of firms, including Yahoo ! , Amazon, com, and Sony.com, to provide shopping advice for consumers. The Economist (June 4, 2005, p. 11) reports that eBay recently paid $620 million for Shopping.com, an online comparison shopping site that provides recommendation services, further indi- cating the importance of RA technologies to e-commerce leaders. However, a survey conducted by Burke [11] shows that a significant percentage (21 percent) of online shoppers have negative reactions to such recommendation services. Consequently, there is the need to investigate the designs that lead to more effective RA technolo- gies for e-commerce. Many RAs still lack adequate explanation facilities. For example, the RAs pro- vided by DiscoverYourRide.com do not provide explanations regarding why certain questions were asked or how conclusions were reached. Without such explanations, consumers may experience difficulties in evaluating the RAs and their recommenda- tions. Explanations are important components of intelligent systems, including RAs, because by making the performance of systems transparent to users, they can improve users' trust in the systems, facilitate the transfer of knowledge to users, and lead to more effective use of the systems and better product choices [28, 33]. Explanation facilities were rated by users as the fourth most important among 87 KBS capabili- ties [78]. Although recent research on KBS shows that explanations continue to be fundamentally important [27], so far no guidelines exist for the particular types of explanations that should be provided by RAs.</page><page sequence="3">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 219 Furthermore, few prior studies have focused on the way to enhance consumers' trust in technological artifacts (such as RAs). Trust is well-recognized as a key success fac- tor for e-commerce [25, 40, 63] and one of the most significant barriers to realizing its potential [70, 82]. Consumers' trust in an RA influences their evaluations toward the RA and their intentions to use it [2, 83]. The present study identifies the charac- teristics of RAs that may hamper consumers' trust. Explanation facilities are utilized as a knowledge-based trust-building mechanism to alleviate these obstacles. Trust develops when users gain knowledge about an RA [13, 25, 53]. However, empirical evidence on the effects of explanation facilities on trust is lacking [52]. In this light, the key research question to be explored in this study is how and to what extent differ- ent types of explanations influence consumers' trust in the RAs. Consumers delegate a range of tasks to an RA that acts on their behalf. If they want to follow the advice from the RA, they need to trust it [83]. This study focuses on initial trust in RAs and especially on trusting beliefs that are formed after customers have a first experience with an RA. Initial trust is influential in consumers' intentions to use an RA again [83] and in their intentions to transact with the Web site [24, 64]. While we recognize the importance of the evolving nature of trust, our focus is on initial trust mainly because consumers' perceptions of uncertainty and risk about using an RA are especially salient when they are not familiar with the RA during the initial contact (e.g., [64]). Therefore, sufficient initial trust in the RA is needed to overcome these perceptions. This study has important implications for both research and practice. For academics, this is the first study that empirically investigates the effects of explanation facilities on consumers' trusting beliefs concerning RAs. The provision of explanation facilities by an RA is examined as a knowledge-based trust-building mechanism that directly mitigates the underlying informational unbalance due to the agency relationships be- tween the RA and its users. For practitioners, by identifying the effective explanation types for RAs, we provide designers with the knowledge needed to develop RAs that will be more trusted and hence will have a higher chance of user adoption. Recommendation Agents for E-Commerce This study focuses on product-brokering RAs that provide users with advice about what to buy. Although there are different methods of generating recommendations, the present study investigates RAs utilizing the content-filtering method that uses RA-user dialogues to elicit user needs and preferences [72]. In these dialogues, con- sumers answer questions asked by an RA (see Figure 1), and the RA provides product recommendations based on consumers' answers (see Figure 2). Such RAs hold great potential for e-commerce because they can provide not only the most-needed advice for a variety of complex products but also more accurate advice than other types of RAs, such as collaborative-filtering-based RAs [72]. Many commercial systems - for example, those offered by WiseUncle and ActiveDecisions - use the content-filtering method. Details about other types of RAs are found in Ansari et al. [3] and Maes et al. [57].</page><page sequence="4">220 WANG AND BENBASAT Figure 1. RA-User Dialogue from the Experimental RA Figure 2. Recommendations from the Experimental RA</page><page sequence="5">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 22 1 Two characteristics of the RAs investigated in this study have been identified as obstacles to trust building in RAs. First, there is an agency relationship between an RA and its users. Users (principals) delegate the task of finding suitable products to the RA (agent), who acts as a virtual shopping advisor [7]. Although the principal-agent perspective was originally formulated in the context of agency theory in employment relationships (e.g., [77]), it has been widely extended to many types of relationships and exchanges including buyer-seller exchange relationships and online marketplaces and transactions [5, 14, 76]. The ubiquity of agency relationship has been recognized in the literature [69, 77]. Given that a user delegates some responsibility to the RA, who acts on the user's behalf, we extend the agency relationship to the RA-user relationship. The agency relationship is characterized by information asymmetry and goal incon- gruence [8, 22, 43, 76]. l Information asymmetry means that an RA possesses more information than the principal with respect to the target behavior (e.g., how the RA generates recommendations). When such information is not provided, the principal cannot completely verify the skills and abilities of the RA [22, 34]. Goal incongruence means that the objectives of the RA provider (i.e., the e- vendor) may differ from those of the RA users. An RA could be designed in such a way that it is intended to focus on a higher profit for the e- vendor only, who provides and owns the RA, and it may not act in the best interests of users [8, 43]. Accordingly, users may be aware of an RAs opportunistic behavior and realize that they may be taken advantage of because of the goal incongruence. Due to the information asymmetry and goal incongruence issues, users may have concerns about the RAs having the ability to recommend a product that fits their preferences and worries about the RAs acting in a manner that is inconsistent with users' interests, resulting in agency problems [8]. Second, when using RAs, consumers have a high degree of discretion in specify- ing their inputs, which are composed of their needs, product uses, and preferences. However, lacking adequate knowledge about products, consumers may employ their choice discretion improperly when expressing their needs and preferences, leading to misspecification in the RA-user dialogues [47]. For example, for most products, prod- uct attributes are correlated. A lower price often means fewer advanced features for a product, and therefore consumers may have to make trade-offs regarding their choices. Without sufficient product knowledge, users may overestimate their real needs and end up with a very powerful product but at a very high price. Consequently, the high amount of discretion available to users may lead to negative user perceptions of RAs. These two characteristics hamper consumer trust building in RAs. The central premise of this study is that appropriate explanations need to be provided to deal with these issues so that trust in RAs will be enhanced. Literature Review and Hypothesis Development Trust in RAs Before introducing the explanation facilities to be investigated and predicting their impact on consumer trust in RAs, this section first defines trust in RAs. Academics</page><page sequence="6">222 WANG AND BENBASAT and practitioners have long recognized trust as an important antecedent of buying intentions in e-commerce [25, 40, 68]. Recent literature in information systems (IS) has discussed four general approaches to defining trust [25, 63]: (1) a belief or a collection of beliefs [9], (2) emotional feelings [45], (3) an intention [61], and (4) a combination of these elements [62, 63]. Several comprehensive reviews of the trust literature have already been published (e.g., [25, 61, 63]). We focus on trusting beliefs in this study (i.e., the first approach) because trusting beliefs have been identified as important mediators that influence trusting intentions [51, 62, 63]. Based on Komiak and Benbasat [46] and McKnight et al. [63], trust- ing beliefs concerning an RA include one's perceptions about the RA's competence, benevolence, and integrity. According to McKnight et al. [63], competence belief is a consumer's perception that an RA has the ability, skills, and expertise to perform effectively in specific domains; benevolence belief is a consumer's perception that an RA cares about the consumer and acts in the consumer's interest; and integrity belief is the perception that an RA adheres to a set of principles (e.g., honesty and keeping promises) that are generally accepted by consumers. Our conceptualization of trusting beliefs concerning RAs extends interpersonal trust to trust in technological artifacts. Trust is a social construction that originates from interpersonal relationships [79]. According to the theory of social responses to computers [71], people treat computers as social actors and apply social rules to them. Evidence from more than 30 empirical studies conducted by Reeves and Nass shows that even technologically sophisticated people treat technological artifacts as if they were human beings, rather than simple tools [71]. People easily assign personalities (e.g., dominance, friendliness and helpfulness) to computers. Although human properties do not intrinsically exist in technological artifacts, the important fact is that they are perceived to be so by users when they interact with computers [21, 71, 83]. It is important to study users' perceptions of a technology because they have a determinant influence on users' attitude, intentions, and, ultimately, behavior with respect to the technology [1]. Prior studies have also extended trust to abstract and technical systems and intel- ligent computer agents (e.g., [47, 65]). In particular, trust literature shows that the components of trusting beliefs are not significantly different, whether toward other humans or toward technological artifacts. [41]. In order to understand the similarities and differences among human-human trust, trust in human-machine relationships, and trust in general, Jian et al. [41] conducted a word elicitation and comparison study. The results indicate that particular components of trusting beliefs are similar across different contexts. Even for trust in machines, participants use words such as "integ- rity," "honesty," and "cruel." Regardless of the focus being on human-human trust or human-machine trust, the final scale developed by Jian et al. [41] includes items that represent "human attributes" such as "the system has integrity" and "I am suspicious of the system's intent, action, or output." The ascription of human-like attributes and characteristics to technological artifacts has been widely referred to as anthropomorphism in the computing domain, and this metaphor has become firmly embedded in our society [42, 60]. Marakas et al. have</page><page sequence="7">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 223 suggested that "computers are commonly associated with cognitive processes that often seem, at least superficially, analogous to those which go on in people" [60, p. 722]. Anthropomorphic behavior toward a technology has become the standard by which people formulate their communications with the technology [60]. In summary, there are several theories and ample empirical evidence supporting the fact that people respond socially to technological artifacts and do perceive that technological artifacts have human-like properties. A user is able to form trusting beliefs concerning whether or not an RA has the expertise to provide recommenda- tions (i.e., is competent), or whether or not it is designed to "push" the products of a certain manufacturer (i.e., has integrity). Hence, the key focus in this study in on users' perceptions of trusting beliefs concerning RAs. Explanation Facilities and Trusting Beliefs Concerning RAs This study examines a knowledge-based trust-building mechanism. Knowledge-based trust occurs when one has enough information about an RA to understand it and to use it properly [53]. Particularly, we investigate the impact of explanation facilities on consumers' initial trusting beliefs concerning RAs. During initial trusting belief formation, due to the lack of prior interactions with an RA, consumers look for any cues or information about the RA to evaluate it [24]. Therefore, explanation facili- ties have the potential to play a key role in alleviating the obstacles to trust in RAs identified in the second section (i.e., agency relationship and high choice discretion), thereby facilitating consumers' trusting belief formation. To alleviate the problems related to agency relationships, the agency theory solutions are (1) signaling, which is typically operationalized as investments in nonsalvageable assets and design that are clearly visible and signal high quality (e.g., a well-designed interface of the RA and the online store), and (2) incentives (e.g., consumers will pay a price premium for the recommendation services) [8, 22]. However, as Singh and Sirdeshmukh pointed out, these solutions, while useful, are not sufficient because neither of them "directly helps to reduce the information asymmetry experienced by the principal" [76, p. 153]. A well-designed interface signals high quality but does not explain the quality of services per se (e.g., information on how recommendations are generated). A price premium (incentive) implemented as a service fee (e.g., consum- ers need to pay for the recommendation services) may reduce the possibility of an agent's opportunistic behavior because consumers may withdraw the price premium if they suspect such behavior. However, the incentive does not deal with the concern of goal incongruence per se between the agents and principals. Therefore, this study tests a more direct way of signaling-provision of explanations. In general, previous research has focused on two areas of study, referred to as KBS explanations and decision support systems (DSS) decisional guidance. KBS explana- tions deliver knowledge about a KBS's actions to make it more transparent to its us- ers - what the system does, how it works, and why its actions are appropriate [19, 28]. On the other hand, studies of decisional guidance [6, 54, 58, 75, 85] have focused on presenting knowledge that can guide decision makers using a DSS (e.g., about how to</page><page sequence="8">224 WANG AND BENBASAT proceed or what input values to use). Based on the literature on KBS explanations and DSS decisional guidance, three types of explanations (i.e., how and why explanations from KBS explanations, and trade-off explanations from DSS decisional guidance) will be evaluated as part of RAs. Impact of How and Why Explanations Various KBS explanations and different ways to classify them are summarized in the literature [19, 28]. One approach to classify explanations is based on the nature of explanation queries (e.g., what, why, how, when, and where) [84]. In particular, the how (referred to in some studies as "lines of reasoning") and why explanations are of interest in this study because they directly deal with the two main concerns identified with the agency relationships (i.e., information asymmetry and goal incongruence) and thereby facilitate trust building in RAs. How explanations reveal the line of reasoning used by an RA based on consumer needs and product attribute preferences, and they outline the logical processes involved in reaching final recommendations. Why explanations justify the importance and pur- pose of an RA's questions to consumers, in addition to providing justifications for the recommendations provided after the consultation is complete. To elaborate on these explanations, Table 1 provides some examples that come from the digital camera RA used in the experiment conducted for this study. The how and why explanations, first introduced in MYCIN [10], remain the founda- tions of most explanation facilities for current KBS applications [19]. Because users are ultimately responsible for, and are affected by, their own choices, they will tend to reject advice from a KBS whose reasoning they do not understand [35]. Most studies have suggested that explanation facilities can make the advice from a KBS more ac- ceptable to users and more effective in influencing their beliefs [86]. A full coverage of the findings of KBS explanation studies is available in Gregor and Benbasat [28]. In the present study, how explanations are provided in an RA to address the infor- mation asymmetry between the RA and its users (see Table 1). When it is properly designed, an RA is able to generate product recommendations satisfying users' needs, and it should not miss good product alternatives. However, if an RA does not explain how it generates its recommendations, it will create a "knowledge gap" between the RA and its users in that users lack the information regarding the reasoning process of the RA. As a result, users will not be able to verify the RA's expertise and ability [22, 34] . Hampton-Sosa and Kouf aris [3 1 ] assert that using certain technologies may have a negative impact on customer trust, especially when customers may not understand the technologies due to the knowledge asymmetries. How explanations alleviate the information asymmetry barrier to trust building by bridging the "knowledge gap." They inform the principal (users) about the "procedures" that an RA applies to gener- ate recommendations. How explanations are viewed as links between what buyers know - that is, their needs, intended uses, preferences, and so forth - and what they need to know - that is, the product attributes that satisfy their needs, uses, and preferences [72]. How</page><page sequence="9">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 225 Table 1. Examples of How, Why, and Trade-Off Explanations Question in the How far away are the subjects that will be focused on most RA-user dialogue often by the digital camera? 1 . I do not need my camera to focus on anything other than subjects in the immediate vicinity. 2. 1 want a camera that will focus on subjects at a moderate distance. 3. I want a camera that will focus on subjects from far away. 4. I do not have an opinion on this. How explanation Your distance from the subjects you want to focus on will determine the suitable zoom level of a digital camera. If you want a camera that will focus on subjects farther away, the camera with a stronger optical zoom level will have higher priority in my recommendations. Specifically, the four options will determine the following zoom levels: 1 . 2X optical zoom and below. 2. Between 2X and 5X optical zoom. 3. 4X optical zoom and above. 4. No minimum requirement in zoom capability. Why explanation The purpose of asking this question is to know what kinds of photos you will often take. It is quite useful to take photos at different distances. For example, for portraits of family and friends, subjects are close to a camera, but for many scenery or artistic photos, subjects may be far from your camera. Trade-off explanation Most digital cameras can take pictures beyond the immediate vicinity. However, cameras capable of taking pictures from very far away will be more expensive. As well, your choices will be more limited (only about 20 percent). Hence, be careful not to overestimate your needs. explanations reveal the underlying reasoning processes that govern an RA's decision making and thus demonstrate the skills, competencies, and expertise that enable the RA to generate recommendations. In discussing human trust in an automated system, Lee and Moray [50] suggest that a system's technical competence is perceived by human operators through their understanding of the underlying processes governing the system's behavior. Muir and Moray [65] have suggested that trust in a machine is based primarily on user perceptions of the expertise of the machine. The skills and expertise that an entity (functioning as a trustee) demonstrates increase its competence in the eyes of its users (the trustors) and hence increase the likelihood that users will trust the entity [37]. Therefore, Hypothesis 1: Consumers will have higher competence beliefs in the RAs with how explanations than in those without how explanations. The provision of why explanations is also justified by the existence of agency relationship between an RA and its users. Users may perceive the existence of goal incongruence due to the agency relationship [8, 43]. Users may be concerned that the</page><page sequence="10">226 WANG AND BENBASAT RA is designed to "work" for the provider (e- vendor or manufacturer), and they may question whether or not the RA puts their interests first. Therefore, not explicitly ex- plaining the good intentions behind the provision of recommendation services would create an "intention gap." Given that an RA is designed to find products that satisfy users' needs and preferences, it is to the RA provider's advantage to embed explana- tions in RAs to reveal such desirable capabilities, signaling to users that the RA is of a type that users are seeking [7]. Why explanations in this study are used to demonstrate that an RA is designed with the endeavor and purpose of satisfying users' needs, interests, and preferences; they convey goodwill toward users. Consequently, why explanations bridge the potential "intention gap" perceived by users, and alleviate their concerns about goal incongruence. Given the virtual nature of an Internet-based RA, fewer cues are available for consumers to evaluate the RA and form perceptions, compared with salespersons in physical stores whose motivations may be discerned from their appearance, attitude, tone, and so on. Instead, w/zy explanations can be used effectively to convey an overall message that an RA provides recommendation services to satisfy users' needs and interests. Studies on interpersonal communication show that revealing information on motives and intentions is important and effective in conveying an impression of benevolence toward others [16, 23]. This theory can be extended to computer systems as well. Castelfranchi and Tan [13] contend that users search for the motives and goals of an RA when forming their trusting beliefs concerning RAs. Trust emerges when a party identifies and understands another party's goals and intentions better [20]. Research on trust in automated systems suggests that a system's ability to communicate mo- tivational information enhances users' benevolence perception of the system [e.g., 65]. Therefore, Hypothesis 2: Consumers will have higher benevolence beliefs in the RAs with why explanations than in those without why explanations. Impact of rrade-Qff Explanations It is contended that the how and why explanations enhance consumers' competence and benevolence beliefs by alleviating the trust obstacles related to the agency relation- ship. To deal with the third obstacle related to users' potential misspecification in the RA-user dialogues, decisional guidance is utilized. As noted in the second section, without sufficient product knowledge and expertise, consumers may be unable to make trade-offs among product attribute preferences, leading to preference misspecification issues (e.g., overestimate their needs or express their preferences improperly) [47]. As a result, the RA may provide very limited product choices for consumers (e.g., only high-end products) and consumers may perceive the RA to be biased. This may influence consumers' integrity belief in the RA. Accordingly, by supplying consumers with relevant knowledge, decisional guidance aims at overcoming this obstacle and enhances consumers' integrity beliefs. Silver has defined decisional guidance in the context of DSS as knowledge pro- vided in a system to "enlighten or sway its users as they structure and execute their</page><page sequence="11">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 227 decision-making processes - that is, as they choose among and use the system's functional capabilities" [75, p. 107]. Guidance is not necessarily intended to steer decision makers in a given direction. In some situations, it can be suggestive, making judgmental recommendations to users, while in others, it may simply be informative, providing users with unbiased, pertinent information [75]. In order to deal with the aforementioned trust obstacle, the particular form oÃ­ guidance examined in this study is the trade-off explanation. It is defined as informative guidance aimed at helping users make trade-offs among product attribute preferences by revealing potential constraints applied to different levels of attribute preferences. Table 1 presents an example of a trade-off explanation provided by the experimental RA. 7raÂ¿fe-0jÃ­f explanations provide objective knowledge regarding the potential constraints brought about by different choices for the questions in the RA-user dialogue. They help consumers make evaluative judgments and provide inputs to the RA. Unbiased product information is among the information that online shoppers want most [66]. Marketing research has shown that many people have negative perceptions about salespeople because they are under pressure to achieve their sales quotas and they may provide biased suggestions and guidance [48]. Objectivity (or lack thereof) is among the main concerns that consumers have when using RAs and virtual shopping assistants [47]. Consumers need objective product information to make their judgments and choices in the RA-user dialogues. For example, based on their needs, users can choose an option for each question to indicate their product attribute preferences in an RA-user dialogue, but they also need to know the costs (e.g., price increase or product choice range limitation) of obtaining the product feature that satisfies their needs. In this study, Ã­raÂ¿/Ã©?-tfj(f explanations help users express their needs properly by making proper trade-offs among product attribute preferences and overcome the misspecifica- tion of preferences in the RA-user dialogues, given the high input choice discretion. Using trade-off explanations, users will be informed about both the usefulness of dif- ferent product features and the potential costs of having such features. Such balanced information conveys an image of objectivity and fosters consumers' integrity perceptions toward RAs. A trustee is deemed to exhibit high integrity when a trustor believes the trustee has a strong sense of justice, honesty, and objectivity [61]. Therefore: Hypothesis 3: Consumers will have higher integrity beliefs in the RAs with trade- off explanations than in those without trade-off explanations. Table 2 summarizes the relationships between obstacles to trusting beliefs, the three types of explanations that can help deal with the obstacles, and the hypothesized im- pact of three types of explanations on trusting beliefs. Prior studies on communication and advertising show that different types of messages facilitate trust building along different belief dimensions [23, 26, 55]. Accordingly, we hypothesized the primary effect of each type of explanation on a certain trusting belief. To illustrate an example of the how explanations, the primary effect of how ex- planations is posited to be on the competence belief because the how explanations directly demonstrate the "expertise" in generating recommendations. Nevertheless, an explanation may exert some effects on trusting beliefs other than the one we hy- pothesized. Providing how explanations to share information with users regarding</page><page sequence="12">228 WANG AND BENB ASAT Table 2. Trust Obstacles, Explanation Types, and Trusting Beliefs Trusting belief Trust obstacle Explanation type affected Agency relationship Information asymmetry How explanations Competence (H1) (^ knowledge gap ) Goal Â¡ncongruence Why explanations Benevolence (H2) (-&gt; intention gap ) RA-user dialogue High user choice discretion Trade-off explanations Integrity (H3) (-&gt; misspecification) its reasoning may indicate being open and not hiding information from users, which may enhance the integrity belief. Nevertheless, the most influential way to signal the integrity property is to employ trade-off explanations to expose both the pros and cons of consumers' choices, indicating being honest. How explanations do not directly help users deal with misspecification issues because they do not inform about the constraints of different options (e.g., high price and limited number of product choices induced by a very high resolution). Furthermore, even with how explanations, it might still be difficult for consumers to believe that the RA would follow the decision rules. This can be likened to a smart salesperson who, by showing his or her expertise, may not necessarily demonstrate he or she holds high integrity. In sum, because there is no direct theoretical or empirical evidence to indicate the extent to which how explana- tions will influence benevolence or integrity beliefs, the impact of how explanations on benevolence and integrity beliefs may not be substantial. This also applies in the cases of why and trade-off explanations. Therefore, we have only hypothesized the primary effect of a type of explanation on a certain trusting belief. Control Variables Prior research into explanations and trust suggests a number of additional factors that should be controlled due to their potential influence on trust. Among them are con- sumers' trust propensity, level of product expertise, and preferences for effort saving versus decision quality. Trust propensity is a personality trait that will affect the likelihood that an entity will exhibit trust [5 1, 61]. As consumers develop trust for trustees, they look for cues and information about the trustees. The trust propensity of individual consumers magni- fies, or reduces, the effectiveness of the cues and information provided by trustees [51]. Me Knight et al. [63] have likewise suggested that consumers' disposition to trust should influence their trusting beliefs. Hence, trust propensity is included in this study as a control variable in analyzing the impact of explanations on trusting beliefs. Many studies (e.g., [4, 86]) have shown that domain expertise influences the use and effects of explanations. Customers' product expertise provides a foundation for</page><page sequence="13">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 229 their understanding of the explanations, and therefore, will influence the effects of these explanations. Consumers' preferences for effort saving versus decision quality are also included as a control variable because they affect consumers' intentions to use and adopt a computerized decision aid [81]. Use and assimilation of the explanations will require cognitive effort, and hence their preference for effort saving versus decision quality should affect their use and understanding of explanations, and consequently the ef- fects of explanation use. Research Method To examine the effects of the three types of explanations on trusting beliefs, a 2 x 2x2 factorial experimental design was employed. The manipulated factors are how (with, without), why (with, without), and trade-off (with, without) explanations. All three factors were manipulated between participants. For the experiment, an RA that makes recommendations for digital cameras based on the preferences and needs specified by consumers was developed based on a con- tent-filtering method. Our experimental RA was designed to simulate two well-known operational RAs. One is from www.MyProductAdvisor.com and the other is from www.dealtime.com. They are the leading RA providers and are widely used by many Web sites, such as RadioShack.ca and Sony.com. In order to elicit users' preferences and needs, an RA-user dialogue was used to simulate dialogues presented in other studies [72] and in commercial applications. Digital cameras were chosen for two reasons. First, the content-filtering-based RA technology works best for relatively complex products [72], and indeed several commercial RAs have already been de- veloped for use in the marketing and sale of digital cameras. Digital cameras have a variety of attributes (e.g., zoom and resolution) that require a certain level of expertise from consumers. Second, an informal survey that we conducted indicated that many undergraduate students do not have digital cameras, although they are interested in them. This ensures a high motivation level for the participants in the experiment. A user-invoked method was used for explanation provision [28]. In order to reduce users' effort in getting the explanations, pop-up windows were used. When a user pointed the mouse to an explanation icon, an explanation window would appear automatically, and then disappear when the mouse was moved away. A pilot test indicated that most users liked the use of "pop-up" mechanisms to provide explanations. Figures 1 and 2 provide screen shots of the RA-user dialogues and the final recommendations.2 Pilot Test on Explanation Validation In an effort to assess the face validity and definitional accuracy of the explanations that were incorporated into the RA prototype, a pilot test was conducted to validate the explanations. Definitional accuracy refers to how faithfully an explanation repre- sents an operationalization of the definition of its class (e.g., how, why, and trade-off explanations in this study) [18].</page><page sequence="14">230 WANG AND BENB ASAT In the pilot test, eight graduate students who are experienced digital camera users were asked to classify the explanations to be examined in this study into one of the three categories (how, why, and trade-off explanations) or none of them. About 92 percent of the how explanations, 80 percent of the why explanations, and 90 percent of the Ã­raÂ¿fe-6&gt;jff explanations were correctly classified. The explanations thus appeared to be consistent with their definitions. The suggestions from the pilot test regarding clarity in wording were incorporated into the explanations used for the main experiment. Participants, Incentives, and Experimental Tasks and Procedures A total of 120 students at a large North American university were recruited for the experiment. Based on Cohen [15], the choice of the sample size is to ensure sufficient statistical power (about 80 percent) at the significance level of 0.05 when medium effect size (f= 0.25) was assumed for the main effects of the explanations based on previous empirical studies [18]. To avoid potential biases in their evaluations, only individuals who did not already own or had not bought digital cameras beforehand were invited to participate in the study.3 This filtering is justified because most consumers may need extra shopping advice when they first buy a product such as a digital camera, and do not have sufficient expertise and experience. The experiment proceeded as follows. A research assistant first trained participants how to use and navigate the assigned Web interface using a tutorial RA that had the same features as the experimental RA. Then, each participant was asked to finish two tasks: first, choosing a digital camera for a good friend, and then selecting another camera for a close family member. The order of the two tasks was counterbalanced. After each task, the participants were directed to an online form to write down their choice and its justifications. There was no time limit for the tasks. Two tasks were used instead of one in order to ensure that participants had sufficient interactions to evaluate the RA.4 Finally, after the two tasks, participants were asked to complete a questionnaire that included the measures of dependent variables. Each participant was guaranteed a monetary compensation for his or her participa- tion ($15). As in many other experimental studies (e.g., [59]), asking participants to provide justifications for their choices and providing extra performance-based incen- tives are very helpful in motivating participants to view the experiment as a serious online shopping session and increasing their involvement. As such, the top 25 percent of participants were offered an extra amount ($25), and the participant with the best performance was offered $200. The participants were advised before the experiment of all monetary offerings. They were also told before the experiment that they would be asked to provide justifications for their choices, and their performance would be judged based on these justifications. The main criterion for the judgment was based on the extent to which their justifications were appropriate and convincing to support their choice of digital camera. The use of such incentives may change the goal of the tasks from problem solving to both problem solving and learning, which may induce some differences in consumers' use of explanations, and subsequently their evaluations and perceptions of the RA</page><page sequence="15">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 23 1 [28]. Hence, this could be a limitation of this study. Nevertheless, "in situations where there is no clear standard of performance, incentives often cause subjects to move away from favorable 'self-presentation' behavior toward more realistic choices" [12, p. 36]. Because the criteria for task performance were quite subjective in this study, the use of performance-based incentives should be appropriate and desirable. Measures This study used validated scales for all constructs. The measures for the three trusting beliefs in RAs that were developed and validated by Komiak [45] have been adapted for the current study. The validity and reliability of the trust measures has also been confirmed by Wang and Benbasat [83]. Although Komiak's [45] trust measure was par- ticularly developed for RAs, the measure is similar to the Web trust measure developed by McKnight et al. [63]. Measures for the control variables have been adapted from Davis [17], Komiak [45], and Lee and Turban [51]. All measurement items are listed in the Appendix. Because the constructs were measured by multiple items, summated scales based on the average score of the multi-items were used in the analysis [30]. Responses were recorded on a nine-point Likert scale, with the endpoints labeled as "extremely disagree" and "extremely agree." Data Analysis and Findings The descriptive statistics are provided in Table 3. The measures for the three trusting beliefs and three control variables have good reliabilities (Cronbach's alphas &gt; 0.70, as indicated in Table 3) and satisfactory discriminant and convergent validity. We used partial least squares (PLS), as implemented in PLS Graph version 3.0, to assess the psychometric properties of the trust measures [75]. 5 We examined the item loadings, composite reliability of constructs, and average variance extracted (AVE). All of the measures display strongly positive loadings that are significant at the 0.001 level, indicating high individual item reliability. No item loads higher on another construct than it does on the construct it is designed to measure and the square root of each construct's AVE is greater than the correlations between the construct and others. Therefore, the trust measures have good discriminant and convergent validity. A manipulation check was conducted first to examine the extent of participants' use of the explanations. Then, a 2 x 2 x 2 factorial analysis of covariance (ANCO VA) was conducted to test the effects of explanations on trusting beliefs after accounting for the effects of covariates [30]. Manipulation Check Participants' navigation screens were recorded unobtrusively as videos by screen capture software (Camtasia Recorder, version 3.0) during the experiments. The first author and a research assistant reviewed these videos to count independently par- ticipants' use of explanations.6 Table 4 reports the distribution of explanation usage</page><page sequence="16">232 C/3 'S &lt; t&gt; Â«S O u en e2 GO d S 'S) c ^ ^t &gt;&gt; Tt ^ 9 -Â° ?Â° 1 C/3 03 &lt;U ?3?| 3 t fa S co ^ ^ in c'| q T- &gt;&gt; o o o o I cr c *S '5 * * * .g S S S Â§ Ã¨ i Ã¶ 6 Ã¶ o Ã¶ Ã¶ .S I S g ms mo N o iÃ¶ .SÃ Ã¶ Ã¶ Ã¶ d d r fe -- ; cd Â«A | I 8 8 KÂ¡ 8 3 8 -rf 2 S .2 1 8 ^ | S?S888Ã1 ^ in(D(OlÃ­)NC0gÂ¿ y i .S *n M V c ^ Â£ Â§â  -3 -Â«a i 8 Â£ i i 9 SPf I lÂ¡lfll?i â¢g ucÃ»S^SÃ»-I^ Ã­&gt; T^cvicÃ´^ioco^Ã¯</page><page sequence="17">233 C/3 Â§ o3 I x I p 5 Â§ ! i Is Ã- s s S "8 3 o Z Sa ex "S II 0 Jh i&gt; di II ÃI l! e ^ ** s c: Â§ ^ viÃ¼Ã¼Ã¼o vi vi vi -t x | &gt;â  ^ ** n viÃ¼Ã¼Ã¼o x &gt;â  â S ** Â°C n O viÃ¼Ã¼Ã¼o O Q.Q.8.S Wg x &gt;â  â¢g MO IIÂ°-VVVA oÂ¿| â¢g ? 11 Ro28SÃ¤ oÃ¬ If ft â g I i i 2 2 Â¡2 Â«3 H -2 2 Xi.Ã®i, o^MonnoSÂ« I s iH Â§â¢! et 1 &amp; ^ o i Â« i^S-o ooo 2 "S * So iiÂ°-vvva * Â¿ li RoSSSR SI* Ã¶| .s I Â§ a- a. a g g&gt; Ã¼ 8.1-1 'figs ^ o S &lt; 0 Â« -S Â« Â« Ã Ãµ Â« ^ Â«Â§ J8 C^ i- CM CDo^Ã Â«SS fc S Ã¼ Â«o Ã 5 Â«SS 3 S- S fc S s 5 Ã¼ t Â«o a Ã S 5 c ^u - si1! S C &gt;&lt; * -Ã ed S s C I &gt;&lt; ia * ni -Ã ed 1 S ii^vvvA Â§ Â«S 6 Â§1 Ro28S8. -g-sS Ã j3 Sog " &amp; i Â«s i Ã¬</page><page sequence="18">234 WANG AND BENBASAT rate7 in the "with" particular explanation groups. On average, 42 percent of the how explanations, 34 percent of the why explanations, and 47 percent of the trade-off explanations were viewed by participants. These usage numbers refer to the average percentage of explanations that were viewed by participants in the different treatment groups. For each type of explanation, all participants who were given explanations viewed at least some of them. Overall, the average usage rates are quite high compared with other empirical studies (e.g., [18]).8 Hence, the three types of explanations in the experimental system were deemed well designed and extensively used. ANCOVA Results Of the 120 participants, 62 were female and 58 were male, and 109 were undergraduate and 1 1 were graduate students. Most participants were in their early twenties. Ninety- seven percent of the participants had more than two years of Internet use experience. No significant differences were found among participants, who were randomly assigned to different treatment groups, with respect to their gender, age, Internet experience, online shopping experience, comfort levels with using computers and shopping online, and levels of the three control variables. ANCOVA was conducted to examine the effects of the three types of explanations on the three trusting beliefs. Multivariate analysis of covariance (MANCO VA) was not conducted mainly because the focus of this study is not on the general impact of all explanations on all trusting beliefs but, rather, as hypothesized, on the impact of a particular type of explanation on a particular type of trusting belief That is, each type of explanation was predicted to influence only one of the trusting beliefs. As suggested by Huberty and Morris [38], the choice of MANCOVA versus multiple ANCOVAs depends on whether the effects of a particular treatment "pertain to a collection of outcome variables or to a single outcome variable" [38, p. 302] and multiple ANCO- VAs are appropriate to "study the effects of some treatment variable or variables on conceptually independent outcome variables" [38, pp. 303-304]. MANCOVA is used basically to identify an overall effect of a particular treatment on a set of outcome variables [30, 38, 74], thus it was not employed. Before applying the ANCOVA analysis, outliers and violations of statistical as- sumptions of ANCOVA were investigated [30, 80]. Variables with standardized scores in excess of 3.29 were classified as potential outliers [80, p. 67]. Only one case, of which the standardized score of integrity was 3.62, was found to be a potential outlier. However, no data or sampling errors were found and the influence of the case was negligible.9 As such, the case was considered as a legitimate part of the data. Further inspection of Mahalanobis distance [30] showed no multivariate outliers. Therefore, all cases were retained in the final analysis. Data were also checked for violation of statistical assumptions. Data normality was assessed visually as well as by skewness and kurtosis statistics and all three dependent variables had normal distributions. Levene statistics indicate no significant differences in different experimental groups, hence the assumption of equal error variance of different groups is also satisfied. Among the three control variables, only trust propensity affected the dependent vari-</page><page sequence="19">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 235 able scores significantly at the 0.05 level. Hence, in the later analysis, trust propensity was included as a covariate. Group means of trust beliefs are reported in Table 5 and ANCO VA results are shown in Tables 6-8. All three hypotheses are supported, but we also found an unpredicted effect of how explanations on the benevolence belief. The use of how explanations has significant and positive effects on users' competence belief (F(l,lll) = 6.85, p &lt; 0.05) and be- nevolence belief (F(l,lll) = 4.38, p &lt; 0.05), but not on integrity belief (F(l,lll) = 1.90, p &gt; 0.1), at the 0.05 level. The effect sizes10 if) of the use of how explanations on competence and benevolence are 0.25 and 0.19, which are considered as medium and small-to-medium, respectively. The use of why explanations significantly and positively affects users' trusting beliefs regarding the RAs' benevolence (F(l,lll) = 4.93, p &lt; 0.05) but not the competence belief (F( 1 , 1 1 0) = 0.0 1 , p &gt; 0. 1 ) or the integrity belief (F( 1 , 1 1 1 ) = 2.03, p &gt; 0. 1 ). The use of why explanations exerts an about medium effect (f= 0.21) on the benevolence belief. The use of trade-off explanations signifi- cantly and positively affects users' trusting beliefs regarding RAs' integrity (F( 1 , 1 1 1 ) = 5.70, p &lt; 0.05) but has no significant effects on competence (F(l,l 11) = 0.26, p &gt; 0.1) or benevolence (F(l,lll) = 0.53, p &gt; 0.1) beliefs. The use of trade-off explana- tions exerts an about medium effect (/= 0.23) on the integrity belief. Regarding the control variable, trust propensity influences only the competence belief positively and significantly at the 0.05 level. There are no statistically significant two- or three-way interactions among how, why, and trade-off explanations. Because the amounts of explanation usage were not the same among all participants, we conducted a supplementary analysis and retested the hypotheses by excluding the participants with very low usage of explanations from the sample. ANCOVA was re-performed three times with the omission of those participants who used only one or two, or fewer, and three or fewer explanations, respectively, for any one explana- tion type (how, why, and trade-off explanations). In all these conditions, none of the conclusions changed, that is, no effects gained or lost statistical significance at the 5 percent level, and the changes in the F- and p-values were slight. Therefore, the results regarding the effects of explanations are not influenced by the presence of low usages of explanations. Discussion and Implications Discussion of Findings This experimental study provides strong evidence that the use of explanation facilities enhances consumers' initial trusting beliefs concerning RAs. From prior research, we know that higher initial consumer trust in RAs leads to a higher chance of R A adoption [83]. More importantly, this study reveals that different explanation types influence different trusting beliefs: consumers' beliefs in the competence of RAs can be increased by their use of how explanations, whereas their benevolence and integrity beliefs in the RAs can be increased by the use of why and trade-off explanations, respectively. The three types of explanations exert medium-sized effects on the trusting beliefs</page><page sequence="20">236 co .2 1 a 1 tu â¢e 8. X tÃ¬ CO .2 .S 13 PQ to I "S eÂ« | Ã  1 s cd CO c cd I Â»ri e2 â¢o g c3-2 co N T-oo i-m 'S cd ^^ ^P i-m ^^ I&gt; ^^^^^^ 1 SÃ 5Ã SS 5 IO CD IT) CO If) CD a o J2'i3 T-co coco T- hÂ». â¢O g ^^ ^T ^^ o co -S 'S (D Â® Â§ Â°^^i ^^i PÂ°N 2 in cb in cd cd cd 8 55 3 I &lt;5 Â¡ as ss n jg in ih tri in in in â¢^ CD CD CD CD CD CD 'Ã co 1 I 8 S S ? â¢a S S Â§ Â§ |S SS Ã¤s Ã Q. O Q. O Ã¯fc O x o Â§ Â«e</page><page sequence="21">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 237 Table 6. Results of ANCOVA (Dependent Variable: Competence Belief) Degrees of Sum of Mean Source freedom squares square F p-value How explanations 1 12.64 12.64 6.85 0.010 Why explanations 1 0.02 0.02 0.01 0.908 Trade-off explanations 1 0.47 0.47 0.26 0.611 Trust propensity (covariate) 1 15.24 15.24 8.53 0.004 How* why 1 3.37 3.37 1.89 0.172 How* trade-off 1 0.17 0.17 0.09 0.759 Why* trade-off 1 0.19 0.19 0.10 0.747 How* why* trade-off 1 0.32 0.32 0.18 0.675 Error TM 198.32 1/79 Table 7. Results of ANCOVA (Dependent Variable: Benevolence Belief) Degrees of Sum of Mean Source freedom squares square F p-value How explanations 1 6.83 6.83 4.38 0.039 Why explanations 1 7.69 7.69 4.93 0.028 Trade-off explanations 1 0.82 0.82 0.53 0.469 Trust propensity (covariate) 1 4.71 4.71 3.03 0.085 How* why 1 1.17 1.17 0.75 0.388 How* trade-off 1 0.34 0.34 0.22 0.641 Why* trade-off 1 0.06 0.06 0.04 0.847 How* why* trade-off 1 0.04 0.04 0.02 0.879 Error TM 172.96 1^55 Table 8. Results of ANCOVA (Dependent Variable: Integrity Belief) Degrees of Sum of Mean Source freedom squares square F p-value How explanations 1 2.65 2.65 1.90 0.171 Why explanations 1 2.83 2.83 2.03 0.158 Trade-off explanations 1 7.96 7.96 5.70 0.019 Trust propensity (covariate) 1 1.64 1.64 1.18 0.280 How* why 1 2.47 2.47 1.77 0.186 How* trade-off 1 0.061 0.061 0.04 0.835 Why* trade-off 1 0.34 0.34 0.25 0.620 How* why* trade-off 1 0.76 0.76 0.55 0.461 Error TM 155.02 1^</page><page sequence="22">238 WANG AND BENB ASAT as we predicted. But among them, the how explanations are relatively more influential than the other two explanations because how explanations increase both competence and benevolence beliefs. Two possible explanations could account for this unpredicted effect of how explanations on the benevolence beliefs. The first is that the questions in the RA-user dialogue are needs based. Instead of asking users to specify the product attribute levels directly (e.g., the zoom level of a digital camera), RAs inquire about users' preferences for using the product and their needs (e.g., "How far away are the subjects that will be focused on most often by the digital camera?"). These questions may convey cues to users that their needs are considered, and such goodwill may en- hance their benevolence beliefs in RAs [16]. Moreover, when users see the underlying reasoning in the how explanations, they may be more confident that their needs were considered, as reflected in the nature of the needs-based questions, and as a result, their benevolence beliefs may be further enhanced. A second possible explanation is that sharing an RA's underlying reasoning processes with its users may lower the potential of goal incongruence and the likelihood that the RA acts in an opportunistic manner [64]. Further, when an RA is more forthcoming in revealing its reasoning, users may perceive that the RA will generate recommen- dations in a predictable manner, thus their evaluations will be reinforced. Because goal incongruence and opportunism are opposite to benevolence, this will increase the benevolence belief. Limitations and Future Research Before discussing the implications of this study, we first consider its limitations. First, the application of this study's findings to other types of RAs requires caution. The present study focuses on one type of RA - namely, a content-filtering-based product- brokering RA. Explanations that are embedded in other types of RAs might differ and thus lead to different outcomes. For example, collaborative-filtering-based RAs utilize customer characteristics, based mainly on customer profiles or identified from current and past purchases, to classify customers into groups [3, 57]. Recommendations are then generated based on the products most frequently chosen by others in the same group. For this type of RA, users do not explicitly inform RAs about their needs and preferences, thus they have little choice discretion in expressing their requirements. Accordingly, guidance in the form of trade-off explanations for user input will no longer be needed. Nevertheless, the RA may provide multiple recommendations, and trade-off explanations for choosing different recommendations (e.g., pros and cons) might be desirable. Furthermore, other forms oÃ­ guidance may be needed for different types of RAs. Given the different contents of explanations provided by RAs using different algorithms, additional research is needed to explore the specific forms of explanations and guidance for different types of RAs and examine their impact. Second, a variety of other explanations provided in traditional KBSs may have the potential to further increase trust. The selection of explanations explored in this study was based primarily on the two characteristics of RAs that introduce some obstacles to trust building. However, other important explanations, such as terminological ("what")</page><page sequence="23">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 239 explanations and justifications for reasoning processes [28], have not been addressed in this study due to cognitive effort considerations. By this we mean that users may be overloaded if too many explanations are provided [28]. This study controlled for subjects' preferences for effort saving versus decision quality, which had no effects on trusting beliefs. It is possible that the cognitive cost of using the explanations pro- vided in this study is low, thus including additional explanations might be feasible. Therefore, other types of explanations that may further enhance consumers' trust in RAs deserve attention in future research. Third, since the experimental participants are university students, readers should exercise caution in generalizing the results of this study to other demographic groups. In addition, only one type of product was used. Further research with different par- ticipant samples and different types of products is suggested. A few other avenues are also identified for future research. First, the effects of explanation facilities are not restricted only to trust [28]. For example, they may also influence the transfer of the domain knowledge about choosing a product from the RA to users, and improve users' satisfaction with the RA. Future research is needed to examine all potential effects of explanation facilities and how these effects may finally influence users' intentions to adopt an RA and to transact with the RA provider. A related issue is that, although the three types of explanations might directly enhance trusting beliefs, they might also affect the substantive recommendations provided by an RA, which might, in turn, affect trusting beliefs. For example, the use of trade-off explanations can help users better understand the constraints of dif- ferent attribute levels and assess their attribute preferences accordingly. As a result, the recommendations provided by an RA will be more suitable to users. Users may assess their trusting beliefs concerning RAs based on both their understanding of RAs and the recommendation quality. However, our experimental data could not reveal to what extent the impact of explanation facilities on trusting beliefs is mediated by the quality of recommendations. This is a limitation of the present study and an area that deserves future research. Second, the specific implementation of explanations may influence the effects of explanation facilities. We have carefully developed and validated the explanations that were tested in the experiment and the validation results were satisfactory (see the results in the Pilot Test on Explanation Validation section). Nevertheless, the ex- planations could be worded in different ways and the quality of explanations may be further improved. Future research is needed to investigate to what extent the effects of explanation facilities are attributable to the explanations in general and to what extent to the specific implementation of the explanations. Implications for Research and Practice Notwithstanding these limitations, this study makes significant contributions to research and practice. The main contribution to IS research is a fine-grained under- standing of the impact of explanation facilities on consumers' trust building in RAs. In essence, the provision of explanation facilities is a knowledge-based trust-build-</page><page sequence="24">240 WANG AND BENB ASAT ing mechanism [53]. Other studies have examined some knowledge-based trust antecedents such as familiarity in the context of trust in e- vendors [24, 25]. To our knowledge, this is the first empirical study that examines explanation facilities as a knowledge-based trust-building mechanism. Previous studies have produced only generalized suggestions that explanations are influential for user acceptance of KBSs and for improving user trust in the advice provided. The present study integrates two streams of explanation research, KBS explanations and DSS guidance studies, and it is the first empirical study that reveals their complementary impact of explanation facilities on trust building: different types of explanations will increase consumer trust via different trust components. The competence belief is increased by the use of how explanations, the benevolence belief is increased by the use of how and why explanations, and the integrity belief is increased by the use of trade-off explanations. The effects of explanations depend largely on the contents and types of explanations that are provided (i.e., different forms of knowledge). In addition, working from the explanation literature, this study investigates a new way to deal with the issues related to agency relationships in an e-commerce context. All previous solutions from agency theory have been indirect and failed to "mitigate the underlying informational unbalance that caused the agency problem in the first place" [76, p. 153]. The provision of explanation facilities explored in this study is a direct and effective way of dealing with agency problems as well as high choice discretion issues as discussed in the second section [76]. We found empirical evidence to sup- port the explanation solution to deal with agency problems, which is complementary to other solutions based on the agency theory (e.g., [22]). The primary contribution for practice is an effective approach to store knowledge in RAs to improve consumers' trusting beliefs about RAs and consequently RA adoption [83]. Our results show that the three types of explanations investigated in the present study deliver different types of knowledge to users and have a complementary impact on the formation of trusting beliefs. Furthermore, the how explanations are relatively more beneficial because they exert effects on two trusting beliefs while each of the other two explanations exerts effects on only one trusting belief. Therefore, to enhance users' trust in RAs, the provision of how explanations is a minimum requirement. In Internet environments, consumers may want to learn from every transaction in order to be more knowledgeable and self-reliant [73]. Explanations in RAs can achieve two goals. First, the explanations facilitate the flow of knowledge from RAs to their users. This knowledge improves users' understanding of and trust in the RAs; furthermore, it improves users' knowledge of the particular domains of the RAs' expertise, such as digital cameras. Second, the explanations also improve the way that consumers convey their needs and preferences to the RAs; as a consequence, the recommendations and advice that consumers receive from the RAs may fit their particular needs and goals much better. These two goals demonstrate that codifying and storing knowledge in RAs and sharing it with customers are very useful when providing shopping advice to consumers. With adequate and appropriate knowledge embedded within them, RAs can be a cost-effective way for companies to provide electronic customer service to facilitate online consumer decision making.</page><page sequence="25">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 24 1 Acknowledgements: The authors are grateful to the editor, Shirley Gregor, Dongmin Kim, Sherrie Komiak, Young-Eun Lee, Ji-Ye Mao, D. Harrison McKnight, Mark S. Silver, Noam Tractinsky, Charles Weinberg, Robert W. Zmud, and the anonymous reviewers for valuable comments on earlier versions of this paper. They also thank Kevin Chen, who helped build the experimental Web site and agent. Steve Doak and John Curtin's editorial help improved the presentation and readability of this paper. The work described in this paper was partially supported by grants from the Social Sciences and Humanities Research Council of Canada (SSHRC), the Natural Sciences and Engineering Research Council of Canada (NSERC), City University of Hong Kong (Project No. 7200059), and the Research Grants Council of Hong Kong S.A.R. (Project No. CityU 1498/06H). Notes 1. Another issue characterizing an agency relationship is differential risk preferences: "the principal and agent may have different attitudes toward risky behavior" [8, p. 141]. This issue is not dealt with using explanations, and thus will not be addressed in this paper. 2. Figure 1 shows a sample of questions in the RA-user dialogue. In total, four pages of questions were delivered in the dialogue and each page included three to four questions. Fig- ures 1 and 2 show the case with explanations provided. Figure 1 presents a why explanation invoked and Figure 2 does not present any explanations invoked although the explanations were provided by the RA in the figures. In a "without," a certain type of explanation condition, the corresponding explanation icon was not provided, thus participants were unable to invoke that type of explanation. 3. The pilot test revealed that participants who already owned or had bought digital cameras before based their evaluations primarily on whether or not the RA recommended the model that they owned. Hence, their evaluations might be biased. 4. During the interviews with participants in the pilot test, some of them commented that they were not very confident in evaluating the RA after completing only one task and wanted to have more interactions with the RA to evaluate it. After two tasks, they had no difficulties in completing the questionnaire. 5. Detailed measurement validation can be found in Wang and Benbasat [83], which provides nomological validity for the measures for trust in RAs and examines an integrated trust-technology acceptance model for user acceptance of RAs. Different from Wang and Benbasat [83], this study focuses on an important antecedent of trust in RAs - that is, explanations. 6. Because Java scripts were used to provide explanations, the client computer and server could not record participants' use of explanations automatically. The count of explanation use was accomplished objectively. The agreement is close to perfect (98 percent). We used the average scores of the two judges in the calculations of the explanation use rate. 7. After the experiment, we counted how many explanations were viewed by each participant based on the videos. For example, if a participant viewed 13 why explanations out of 19, then the usage rate for the why explanations was 13/19 = 68.4 percent. For how and Ã­raÃ­/e-tf/f explanations, the same calculation method was used. The numbers reported in the paper are the averages of usage percentages for all participants in the "with" particular explanation conditions. 8. In Dhaliwal's study, the average usage rates for how and why explanations were 20.3 percent and 17.9 percent, respectively, while trade-off explanations were not examined. 9. The removal of the case did not produce any differences in the ANCO VA analysis results. 10. Cohen's [15] effect size if) for the ANCOVA was used. Statistics of 0.10, 0.25, and 0.40 are considered small, medium, and large effects, respectively. 11. We use the term virtual advisor to refer to the recommendation agent because in our pilot test, participants suggested that using virtual advisor is easier to understand than recom- mendation agent. References 1. Ajzen, I., and Fishbein, M. Understanding Attitudes and Predicting Social Behavior. Upper Saddle River, NJ: Prentice Hall, 1980.</page><page sequence="26">242 WANG AND BENBASAT 2. Andersen, V.; Hansen, C.B.; and Andersen, H.H.K. Evaluation of agents and study of end-user needs and behaviour for e-commerce. COGITO Focus Group Experiment Report CHMI-01-01, Riso National Laboratory, Roskilde, Denmark, 2001. 3. Ansari, A.; Essegaier, S.; and Kohli, R. Internet recommendation systems. Journal of Marketing Research, 37, 3 (2000), 363-375. 4. Arnold, V.; Clark, N.; Collier, P.A.; Leech, S.A.; and Sutton, S.G. The differential use and effect of knowledge-based system explanations in novice and expert judgment decisions. MIS Quarterly, 30, 1 (2006), 79-97. 5. Ba, S., and Pavlou, P.A. Evidence of the effect of trust building technology in electronic markets: Price premium and buyer behavior. MIS Quarterly, 26, 3 (2002), 243-268. 6. Barkhi, R. The effects of decision guidance and problem modeling on group decision making. Journal of Management Information Systems, 18, 3 (Winter 2001-2), 259-283. 7. Bergen, M., and Dutta, S. Agency relationships in marketing: A review of the implications and applications of agency and related theories. Journal of Marketing, 56, 3 (1992), 1-24. 8. Bhattacherjee, A. Managerial influences on intraorganizational information technology use: A principal-agent model. Decision Sciences, 29, 1 (1998), 139-162. 9. Bhattacherjee, A. Individual trust in online firms: Scale development and initial test. Journal of Management Information Systems, 19, 1 (Summer 2002), 211-241. 10. Buchanan, B.G., and Shortliffe, E.H. Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. Reading, MA: Addison- Wesley, 1984. 1 1 . Burke, R.R. Technology and the customer interface: What consumers want in the physical and virtual store. Journal of the Academy of Marketing Science, 30, 4 (2002), 411-432. 12. Camerer, CF., and Hogarth, R.M. The effects of financial incentives in experiments: A review and capital-labor-production framework. Journal of Risk and Uncertainty, 19, 1-3 (1999), 7-42. 13. Castelfranchi, C, and Tan, Y.-H. The role of trust and deception in virtual societies. International Journal of Electronic Commerce, 6, 3 (Spring 2002), 55-70. 14. Clemons, E., and Hitt, L. Poaching and the misappropriation of information: Transac- tion risks of information exchange. Journal of Management Information Systems, 21, 2 (Fall 2004), 87-107. 15. Cohen, J. Statistical Power Analysis for the Behavioral Sciences, 2d ed. Mahwah, NJ: Lawrence Erlbaum, 1988. 16. Cook, J., and Wall, T. New work attitude measures of trust, organizational commitment, and personal need nonfulfillment. Journal of Occupational Psychology, 53, 1 (1980), 39-52. 17. Davis, F.D. Perceived usefulness, perceived ease of use and user acceptance of informa- tion technology. MIS Quarterly, 13, 3 (1989), 319-340. 18. Dhaliwal, J.S. An experimental investigation of the use of explanations provided by knowledge-based systems. Ph.D. Dissertation, Division of MIS, University of British Colum- bia, Vancouver, 1993. 19. Dhaliwal, J.S., and Benbasat, I. The use and effects of knowledge-based system explana- tions: Theoretical foundations and a framework for empirical evaluation. Information Systems Research, 7, 3 (1996), 342-362. 20. Doney, P.M., and Cannon, J.P. An examination of the nature of trust in buyer-seller relationships. Journal of Marketing, 61, 1 (1997), 35-51. 21. Dryer, D.C. Getting personal with computers: How to design personalities for agents. Applied Artificial Intelligence, 13, 4 (1999), 273-295. 22. Eisenhardt, K.M. Agency theory: An assessment and review. Academy of Management Review, 14, 1 (1989), 57-74. 23. Gabarro, J. Socialization at the top - How CEOs and subordinates evolve interpersonal contracts. Organizational Dynamics, 7, 3 (1979), 2-23. 24. Gefen, D.; Karahanna, E.; and StrÃ¤ub, D.W. Inexperience and experience with online stores: The importance of TAM and trust. IEEE Transactions on Engineering Management, 50, 3(2003), 307-321. 25. Gefen, D.; Karahanna, E.; and StrÃ¤ub, D.W. Trust and TAM in online shopping: An integrated model. MIS Quarterly, 27, 1 (2003), 51-90. 26. Giffin, K. The contribution of studies of source credibility to a theory of interpersonal trust in the communication department. Psychological Bulletin, 68, 2 (1967), 104-120.</page><page sequence="27">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 243 27. Gregor, S. Explanations from knowledge-based systems and cooperative problem solving: An empirical study. International Journal of Human-Computer Studies, 54, 1 (2001), 81-105. 28. Gregor, S., and Benbasat, I. Explanations from intelligent systems: Theoretical founda- tions and implications for practice. MIS Quarterly, 23, 4 (1999), 497-530. 29. Grenci, R.T., and Todd, P.A. Solutions-driven marketing. Communications of the ACM, 45, 3 (2002), 65-71. 30. Hair, J.F.; Anderson, R.E.; Tatham, R.L.; and Black, W.C. Multivariate Data Analysis, 5th ed. Englewood Cliffs, NJ: Prentice Hall, 1998. 31 . Hampton-Sosa, W., and Koufaris, M. The effect of Web site perceptions on initial trust in the owner company. International journal of Electronic Commerce, 10, 1 (Fall 2005), 55-81. 32. HÃ¤ubl, G., and Trifts, V. Consumer decision making in online shopping environments: The effects of interactive decision aids. Marketing Science, 19, 1 (2000), 4-21. 33. Hayes-Roth, F., and Jacobstein, N. The state of knowledge-based systems. Communica- tions of the ACM, 37, 4 (1994), 27-39. 34. Hollander, S.C., and Rassuli, K.M. Shopping with other people's money: The market- ing management implications of surrogate-mediated consumer decision making. Journal of Marketing, 63, 2 (1999), 102-118. 35. Hollnagel, E. Commentary: Issues in knowledge-based decision support. International Journal of Man-Machine Studies, 27, 5-6 (1987), 743-751. 36. Hostler, R.E.; Yoon, V.Y.; and GuimarÃ£es, T. Assessing the impact of Internet agent on end users' performance. Decision Support Systems, 41, 1 (2005), 313-323. 37. Hovland, C.I.; Janis, I.L.; and Kelley, H.H. Communication and Persuasion. New Haven: Yale University Press, 1953. 38. Huberty, C.J., and Morris, J.D. Multivariate analysis versus multiple univariate analyses. Psychological Bulletin, 105, 2 (1989), 302-308. 39. Iyengar, S.S., and Lepper, M.R. When choice is demotivating: Can one desire too much of a good thing? Journal of Personality and Social Psychology, 79, 6 (2000), 995-1006. 40. Jarvenpaa, S.L.; Tractinsky, N.; and Vitale, M. Consumer trust in an Internet store. Infor- mation Technology and Management, 7, 1-2 (2000), 45-71. 41. Jian, J.Y.; Bisantz, A.M.; and Drury, C.G. Foundations for an empirically determined scale of trust in automated systems. International Journal of Cognitive Ergonomics, 4, 1 (2000), 53-71. 42. Johnson, G.J. Of metaphor and the difficulty of computer discourse. Communications of the ACM, 37, 12 (1994), 97-102. 43. Keil, M.; Mann, J.; and Rai, A. Why software projects escalate: An empirical analysis and test of four theoretical models. MIS Quarterly, 24, 4 (2000), 631-664. 44. Kim, J., and Yoo, B. Toward the optimal link structure of the cyber shopping mall. Inter- national Journal of Human-Computer Studies, 52, 3 (2000), 531-551. 45. Komiak, S.Y.X. The impact of internalization and familiarity on trust and adoption of recommendation agents. Ph.D. Dissertation, Division of MIS, University of British Columbia, Vancouver, 2003. 46. Komiak, S.Y.X., and Benbasat, I. The effects of personalization and familiarity on trust and adoption of recommendation agents. MIS Quarterly, 30,4 (2006), 941-960. 47. Komiak, S.Y.X. ; Wang, W.; and Benbasat, I. Trust building in virtual salespersons versus in human salespersons: Similarities and differences. e-Service Journal, 3, 3 (2005), 49-63. 48. Kopp, R.J. Ethical issues in personal selling and sales force management. In N.C. Smith and J.A. Quelch (ed.), Ethics in Marketing. Homewood, IL: Richard D. Irwin, 1993, pp. 539-556. 49. Lee, B.-K., and Lee, W.-N. The effect of information overload on consumer choice quality in an on-line environment. Psychology &amp; Marketing, 21, 3 (2004), 159-183. 50. Lee, J., and Moray, N. Trust, control strategies, and allocation of functions in human-ma- chine systems. Ergonomics, 35, 10 (1992), 1243-1270. 5 1 . Lee, M.K.O., and Turban, E. A trust model for consumer Internet shopping. International Journal of Electronic Commerce, 6, 1 (Fall 2001), 75-91. 52. Lerch, F.J.; Prietula, M.J.; and Kulik, C.T. The Turing effect: The nature of trust in expert system advice. In P.J. Feltman, K.M. Ford, and R.R. Hoffman (eds.), Expertise in Context: Human and Machine. Cambridge, MA: MIT Press, 1997, pp. 417-448.</page><page sequence="28">244 WANG AND BENBASAT 53. Lewicki, R.J., and Bunker, B.B. Trust in relationships: A model of trust development and decline. In B.B. Bunker and J.Z. Rubin (ed.), Conflict, Cooperation, and Justice. San Francisco: Jossey-Bass, 1995, pp. 133-173. 54. Limayem, M., and DeSanctis, G. Providing decisional guidance for multi-criteria decision making in groups. Information Systems Research, 11,4 (2000), 386-401. 55. Maclnnis, D.J., and Jaworski, B.J. Information processing from advertisements: Toward an integrative framework. Journal of Marketing, 53, 4 (1989), 1-23. 56. Maes, P. Agents that reduce work and information overload. Communications of the ACM, 37, 7(1994), 31-40. 57. Maes, P.; Guttman, R.H.; and Moukas, A.G. Agents that buy and sell. Communications of the ACM, 42, 3 (1999), 81-91. 58. Mahoney, L.S.; Roush, P.B.; and Bandy, D. An investigation of the effects of decisional guidance and cognitive ability on decision-making involving uncertainty data. Information and Organization, 13, 2 (2003), 85-110. 59. Mao, J., and Benbasat, I. The use of explanations in knowledge-based systems: Cognitive perspectives and a process-tracing analysis. Journal of Management Information Systems, 17, 2 (Fall 2000), 153-179. 60. Marakas, G.M.; Johnson, R.D.; and Palmer, J. A theoretical model of differential social attributions toward computing technology: When the metaphor becomes the model. International Journal of Human-Computer Studies, 52, 4 (2000), 719-750. 61. Mayer, R.C.; Davis, J.H.; and Schoorman, F.D. An integrative model of organizational trust. Academy of Management Review, 20, 3 (1995), 709-734. 62. McKnight, D.H., and Chervany, N.L. What trust means in e-commerce customer relation- ships: An interdisciplinary conceptual typology. International Journal of Electronic Commerce, 6, 2 (Winter 2001-2), 35-59. 63. McKnight, D.H.; Choudhury, V.; and Kacmar, C. Developing and validating trust mea- sures for e-commerce: An integrative typology. Information Systems Research, 13, 3 (2002), 334-359. 64. McKnight, D.H.; Choudhury, V.; and Kacmar, C. The impact of initial consumer trust on intentions to transact with a Web site: A trust building model. Journal of Strategic Information Systems, 11, 3-4 (2002), 297-323. 65. Muir, B.M., and Moray, N. Trust in automation: Part II - Experimental studies of trust and human intervention in a process control simulation. Ergonomics, 39, 3 (1996), 429^60. 66. Nielsen, J.; Molich, R.; Snyder, C; and Farrell, S. E-Commerce User Experience. Fremont, CA: Nielsen Norman Group, 1999. 67. 0'Keefe, R.M., and McEachern, T. Web-based customer decision support systems. Com- munications of the ACM, 41, 3 (1998), 71-78. 68. Pavlou, P.A., and Gefen, D. Building effective online marketplaces with institution-based trust. Information Systems Research, 15, 1 (2004), 37-59. 69. Pavlou, P.A.; Liang, H.; and Xue, Y. Understanding and mitigating uncertainty in online exchange relationships: A principal-agent perspective. MIS Quarterly (forthcoming). 70. Ratnasingam, P. The importance of trust in electronic commerce. Internet Research, 8, 4 (1998), 313-321. 7 1 . Reeves, B., and Nass, C. The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places. New York: Cambridge Universitv Press, 1996. 72. Russo, J.E. Aiding purchase decisions on the Internet. Paper presented at the Winter 2002 SSGRR International Conference on Advances in Infrastructure for Electronic Business, Educa- tion, Science, and Medicine on the Internet, L'Aquila, Italy, July 29-August 4, 2002. 73. Saint-Onge, H. How knowledge management adds critical value to distribution channel management. Journal of Knowledge Management Practice, 1 (January 1998) (available at www.tlainc. com/article 1 .htm. 74. Share, D.L. Interpreting the output of multivariate analyses: A discussion of current ap- proaches. British Journal of Psychology, 75, 3 (1984), 349-362. 75. Silver, M.S. Decisional guidance for computer-based support. MIS Quarterly, 15, 1 (1991), 105-122. 76. Singh, J., and Sirdeshmukh, D. Agency and trust mechanisms in consumer satisfaction and loyalty judgments. Journal of the Academy of Marketing Science, 28, 1 (2000), 150-167.</page><page sequence="29">RECOMMENDATION AGENTS FOR ELECTRONIC COMMERCE 245 77. Spence, M. Job market signaling. Quarterly Journal of Economics, 87, 3 (1973), 355-374. 78. Stylianou, A.C.; Madey, G.R.; and Smith, R.D. Selection criteria for expert systems shells: A socio-technical framework. Communications of the ACM, 35, 10 (1992), 30-48. 79. Sztompka, P. Trust: A Sociological Theory. Cambridge, UK: Cambridge University Press, 1999. 80. Tabachnick, B.G., and Fidell, L. Using Multivariate Statistics, 4th ed. Boston: Allyn &amp; Bacon, 2001. 81. Todd, P., and Benbasat, I. Evaluating the impact of DSS, cognitive effort, and incentives on strategy selection. Information Systems Research, 10, 4 (1999), 356-374. 82. Urban, G.L.; Sultan, F.; and Quails, W.J. Placing trust at the center of your Internet strat- egy. Sloan Management Review, 42, 1 (2000), 39-48. 83. Wang, W., and Benbasat, I. Trust in and adoption of online recommendation agents. Journal of the Association for Information Systems, 6, 3 (2005), 72-101. 84. Wick, M.R., and Slagle, J.R. An explanation facility for today's expert systems. IEEE Expert, 4, 1 (1989), 26-36. 85. Wilson, E.V., and Zigurs, I. Decisional guidance and end-user display choices. Account- ing, Management and Information Technology, 9, 1 (1999), 49-75. 86. Ye, L.R., and Johnson, P.E. The impacts of explanation facilities on user acceptance of expert systems advice. MIS Quarterly, 19, 2 (1995), 157-172. Appendix. Measurement Items Trust-Competence 1. This virtual advisor11 is like a real expert in assessing digital cameras. 2. This virtual advisor has the expertise to understand my needs and preferences about digital cameras. 3. This virtual advisor has the ability to understand my needs and preferences about digital cameras. 4. This virtual advisor has good knowledge about digital cameras. 5. This virtual advisor considers my needs and all important attributes of digital cameras. Trust-Benevolence 1. This virtual advisor puts my interest first. 2. This virtual advisor keeps my interests in its mind. 3. This virtual advisor wants to understand my needs and preferences. Trust-Integrity 1. This virtual advisor provides unbiased product recommendations. 2. This virtual advisor is honest. 3. I consider this virtual advisor to be of integrity.</page><page sequence="30">246 WANG AND BENB ASAT Trust Propensity 1 . It is easy for me to trust a person/thing. 2. My tendency to trust a person/thing is high. 3. I tend to trust a person/thing, even though I have little knowledge of it. 4. Trusting someone or something is difficult for me. Preference for Effort Saving Versus Decision Quality 1. I am willing to examine the product attributes very carefully in order to make sure that the product fits my preferences perfectly. 2. I prefer to shop hard in order to get exactly what I want. Product Expertise 1. I am an expert in digital cameras. Product Expertise: Essay/Self-Report Questions 1. When, if ever, is resolution important for digital cameras? 2. When, if ever, is zoom important for digital cameras?</page></plain_text>
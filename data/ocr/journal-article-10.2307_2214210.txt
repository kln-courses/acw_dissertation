<plain_text><page sequence="1">Philosophical Perspectives, 9, AI, Connectionism, and Philosophical Psychology, 1995 CONSCIOUSNESS AS INTERNAL MONITORING, I The Third Philosophical Perspectives Lecture William G. Lycan University of North Carolina, Chapel Hill Locke put forward the theory of consciousness as "internal Sense" or "reflection"; Kant made it "[i]nner sense, by means of which the mind intuits itself or its inner state."' On that theory, consciousness is a perception-like second-order representing of our own psychological states and events. The term 'consciousness' of course has many distinct uses.2 My concern here is with that use according to which much of one's mental or psychological activity is unconscious or subconscious even when one is wide awake and well aware of other goings-on both external and internal. I shall argue that what distinguishes conscious mental activity from un- and subconscious mental activity is indeed second-order representing. Locke's idea has been urged in our own time by philosophers such as D.M. Armstrong and by psychologists such as Bernard Baars; I have previously defended it too.3 But some interesting criticisms have been raised against the view by a number of theorists. My most urgent task in this paper is to overcome an objection due to Georges Rey.4 1. Armstrong states the Inner Sense doctrine as follows. Introspective consciousness...is a perception-like awareness of current states and activities in our own mind. The current activities will include sense-perception: which latter is the awareness of current states and activities of our environment and our body.' As I would put it, consciousness is the functioning of internal attention mechanisms directed upon lower-order psychological states and events. I would also add (or make more explicit) a soupcon of teleology: Attention mechanisms are devices which have thejob of relaying and/or coordinating information about ongoing psychological events and processes.6 Armstrong offers a plausible Just-So Story to explain the prevalence of introspective consciousness:</page><page sequence="2">2 / William G. Lycan [T]he biological function of introspective consciousness...is to sophisticate our mental processes in the interests of more sophisticated action. Inner perception makes the sophistication of our mental processes possible in the following way. If we have a faculty that can make us aware of current mental states and activities, then it will be much easier to achieve integration of the states and activities, to get them working together in the complex and sophisticated ways necessary to achieve complex and sophisticated ends. ...[C]o-ordination [of many parallel processes] can only be achieved if the portion of the computing space made available for administering the overall plan is continuously made "aware" of the current mental state of play with respect to the lower-level operations that are running in parallel, Only with this feedback is control possible... . It is no accident that fully alert introspective consciousness characteristically arises in problem situations, situations that standard routines cannot carry one through.7 A slightly deflated version of this idea will figure in my own defense of the Inner Sense theory. The Lockean thesis is a component of a wider project of mine: that of establishing the hegemony of representation. I am concerned to maintain a weak version of Brentano's doctrine that the mental and the intentional are one and the same. Weak, because I am not sure that intentionality suffices for representation; but my claim is strong enough: that the mind has no special properties that are not exhausted by its representational properties. It would follow that once representation is (eventually) understood, then not only consciousness in our present sense but subjectivity, qualia, "what it's like," and every other aspect of the mental will be explicable in terms of representation, without the positing of any other ingredient not already well understood from the naturalistic point of 8 view.' I should repeat and emphasize that my concern in this paper is solely with the notion of conscious awareness, with the distinction between conscious mental states and un-, sub- or otherwise non-conscious mental states. In particular, I am not here addressing issues of qualia or phenomenal character, which I have resolved almost entirely satisfactorily elsewhere.9 There may be Inner Sense theorists who believe that their views solve problems of qualia; I make no such claim, for I think qualia problems and the nature of conscious awareness are mutually independent and indeed have little to do with each other.'0 2. The Inner Sense view of consciousness has a number of advantages, the first of which is that it does distinguish awareness from mere psychology, and conscious states/events (in the sense indicated above) from mere mentation. We may plausibly suppose that many lower animals have psychologies and mentation, or at least internal representation, without awareness. Second, the view affords some grades of un- or subconsciousness; e.g., a state/event may be unconscious just because it is unattended, but a Freudian wish to kill one's father may have been rendered unattendable by some masterful Censor. -And further distinctions are available, both for animals and for human beings.</page><page sequence="3">Consciousness as Internal Monitoring, I / 3 Third, the Inner Sense account affords the best solution I know to the problem of subjectivity and "knowing what it's like," raised by B.A. Farrell, Thomas Nagel and Frank Jackson; Georges Rey and I hit upon that solution independently a few years ago." It involves the behavior of indexical terms in the proprietary vocabulary mobilized by the relevant attention mechanisms. But there is no time to rehearse it here. Fourth, the Inner Sense view sorts out a longstanding issue about sensations and feeling: Consider pain. A minor pain may go unfelt, or so we sometimes say.'2 Even quite a bad pain may not be felt if attention is distracted by sufficiently pressing concerns. Yet such assertions as my last two can sound anomalous; as David Lewis once said, meaning to tautologize, "pain is a feeling." When one person's commonplace sounds to another contradictory on its face, we should suspect equivocation, and the Inner Sense model delivers: Sometimes the word 'pain' is used to mean just the first-order representation of damage or disorder, a representation which can go unnoticed. But sometimes "pain" means a conscious feeling or mode of awareness, and on that usage the phrase "unfelt pain" is simply self-contradictory; it comprehends both the first- order representation and the second-order scanning together. Thus the equivocation, which gave rise to the issue; the issue is dissolved. 3. In correspondence, Fred Dretske has asked a good pair of questions about the Inner Sense view: '3 Why is consciousness (or just representation) of certain physical states enough to make those states themselves "conscious"? And more specifically, what is it that is so special about physical states of that certain sort, that consciousness of them makes them-but not just any old physical state-conscious? After all, we are conscious of (what are in fact) physical states of our stomachs; for that matter, through ordinary perception we are conscious of physical states of our skins, such as their being freckled, but no one would distinguish between "conscious" stomachs and "unconscious" stomachs, or between "conscious" and "unconscious" frecklednesses. Indeed, why does the concept work that way (assuming it does work that way)? It may have something historically to do with the fact that until the 20th century the mental/psychological was simply identified with the conscious, and so only recently have we had to adopt a taxonomic distinction between states we are aware of holding and states we are not. (I am assuming that there is such a distinction in reality, and I believe-what is not uncontroversial-that the distinction in theory applies to any ordinary mental state, not counting states described as "being consciously aware of [such-and-such].") What is it that is so special about physical states of that certain sort, that consciousness ofthem makes them "conscious"? That they are themselves mental. Stomachs and freckled patches of skin are not mental. It seems psychological states are called "conscious" states when we are conscious of them, but nonpsychological things are not. Given the reality of the distinction between states we are aware of being in and states we are not aware of being in, the only remaining question is that of</page><page sequence="4">4 / William G. Lycan why the word "conscious" is thus dragged in as an adjective to mark it. My bet is that there is a grammatical answer. Maybe it is a transferred epithet: We begin with the adverbial form, as in "consciously thought" or "consciously felt," and when we make the verb into a noun the adverb automatically becomes an adjective-as in the move from "meditatively sipped" to "took a meditative sip." That is fairly plausible; at any rate it is the best I can do for now. In any case, it is important to see that the question pertains to the notion of conscious awareness itself; it is not a problem for or objection to the Inner Sense theory of awareness in particular. 4. An initial flaw in the version stated so far is that it makes a Cartesian assumption recently highlighted by Dan Dennett: 14 that there is some determinate stage of information-processing that constitutes the locus of conscious mental states/events. More specifically, "Cartesian materialism" is the (usually tacit) assumption that there is a physically realized spatial or temporal turnstile in the brain, a stage where "it all comes together" and the product of pre-processing is exhibited "to consciousness." Dennett attacks that assumption. However natural it may be, it is gratuitous and empirically implausible: First, it is a priori unlikely that Mother Nature has furnished the human brain with any central viewing-room or single monitor to do the viewing; nor is there any positive neurophysiological sign of such an organ. Second, Dennett argues at length that the famous "temporal anomalies" of consciousness discovered by psychophysical research, such as color phi, the cutaneous rabbit and Libet's "backward referral" of sensory experiences,15 are anomalous only so long as Cartesian materialism is being assumed; jettison the assumption, and the phenomena are readily explained. Dennett's analyses of the experimental data are not completely uncontroversial,'6 but I find them convincing on the whole, and it is hard to think how anyone might defend Cartesian materialism on purely neurophysiological grounds. The point is not just that there is no immaterial audience in the brain, nor just that there is no undischargeable homunculus, but that there is no such locus at all, however physically characterized-no single Boss Unit or even CPU within the brain, to serve as chief executive of my utterings and other actions. The central nervous system is as central as it gets. There is, if you like, a "stream of consciousness": "We are more-or-less serial virtual machines implemen- ted-inefficiently-on the parallel hardware that evolution has provided for us," "Joycean" machines that formulate synthesized reports of our own passing states,'7 though the reports are never entirely accurate. The Inner Sense theory has it that conscious awareness is the successful operation of an internal scanner or monitor that outputs second-order represen- tations of first-order psychological states.'8 But an "internal scanner" sounds very much as though it presupposes an internal audience seated in a Cartesian Theater, even if it and the Theater are made of physical stuff. Is the Inner Sense view not then committed to Cartesian materialism? It is not hard to come up with a pretty damning collection of direct</page><page sequence="5">Consciousness as Internal Monitoring, I / 5 quotations. Armstrong spoke (above) of "the portion of the computing space made available for administering the overall plan." And (just to save you looking) I myself wrote of an internal scanner's "delivering information about...[a first-order] psychological state to one's executive control unit."'9 For shame. There may be an "executive control unit" in some functional sense, but very probably not in the sense of being: that agency, arrival at which makes information conscious. But it should be clear that the Inner Sense view is not per se committed to Cartesian materialism. For even if an internal scanner resembles an internal audience in some ways, the "audience" need not be seated in a Cartesian Theater: There need be no single, executive scanner, and no one scanner or monitor need view the entire array of first-order mental states accessible to consciousness. Accordingly, there need be neither a "turnstile of consciousness" nor one central inner stage on which the contents of consciousness are displayed in one fixed temporal order. An internal monitor is an attention mechanism, that presumably can be directed upon representational subsystems and stages of same; no doubt internal monitors work selectively and piecemeal, and their operations depend on control windows and other elements of conative context. On this point, the Inner Sense theory has already parted with Cartesian materialism. A qualification: We should not throw out the integration-and-control baby with the Cartesian bathwater. The operation of an internal monitor does not eo ipso constitute consciousness. For we can imagine a creature that has a panoply of first-order states and a rich array of monitors scanning those states, but in such a way that the monitors' output contributes nothing at all to the creature's surrounding psychology, maintenance, or welfare; the outputs might just go unheard, or they might be received only by devices that do nothing but turn patches of the creature's skin different colors. For consciousness-constituting, we must require that monitor output contribute-specifically to the integration of information in a way conducive to making the system's behavior appropriate to its input and circumstances. Though the latter formulation is terribly vague, it will do for present purposes; the requirement rules out the ineffectual monitors without falling back into the idea of a Cartesian Theater or single CPU. (This is a good juncture at which to underscore and deepen the teleological cast I am imparting to the Inner Sense theory. I said that for an internal monitor to count in the analysis of consciousness, in the present sense of 'conscious', the monitor must have monitoring as its function, or one of its functions. But that is not all. To count in the analysis of my consciousness, the monitor must do its monitoring for me. A monitor might have been implanted in me somewhere that sends its outputs straight to Reuters and to CNN, so that the whole world may learn of my first-order psychological states as soon as humanly possible. Such a device would be teleologically a monitor, but the wire services' monitor rather than mine. More importantly, a monitor functioning within one of my subor- dinate homunculi might be doing its distinctive job for that homunculus rather than for me; e.g., it might be serving the homunculus' event memory rather than</page><page sequence="6">6 / William G. Lycan my own proprietary event memory.20 This distinction blocks what would otherwise be obvious counterexamples to the Inner Sense view as stated so far.) Rejection of Cartesian materialism is not only compatible with the Lockean view. In an important way, it supports the Inner Sense theory: It predicts introspective fallibility of two characteristic sorts. First, as Dennett emphasizes, the result of an introspective probe is a judgment made by the subject, which judgment does not (or not eo ipso) simply report a "presentation" to an inner audience. And the "temporal anomalies" alone should have made us question the reliability of introspective reports. Introspection gets small temporal details wrong. That tends to confirm rather than to impugn the Inner Sense view of consciousness. If conscious awareness is indeed a matter of introspective attention and if introspection is the operation of a monitor or self-scanner, then such anomalies were to be expected-for monitors and scanners are characteristi- cally fallible on details, and Dennett shows admirably how such devices might corporately mix up temporal sequence in particular. Second, if there is no single Cartesian Theater, then there should be no single optimal time of probing a first-order process. More strongly, Dennett argues that probing "changes the task," i.e., interferes with the very process it purports to be monitoring. That too is good news for the Inner Sense theory. For if introspection is the operation of a monitor or self-scanner, then revisionary effects of the present sort are again just what we should have expected; monitoring instruments (such as ammeters) typically do affect the values of the magnitudes they measure.21 Thus the Inner Sense theory of consciousness survives the collapse of Cartesian materialism, and is even strengthened by it. 5. On at last to Rey's objection. It is that if all it takes to make a first-order state a conscious state is that the state be monitored by a scanner that makes integrative use of the information thus gleaned, then consciousness is a lot more prevalent than we think. Any notebook computer, for example, has devices that keep track of its "psychological" states. (If it be protested that no computer has genuinely psychological states-e.g., because it has neither authentic intentional states nor sensory states-that is inessential to the point. Once we had done whatever needs to be done in order to fashion a being that does have first-order intentional and sensory states, the addition of an internal monitor or two would be virtually an afterthought, a trifling wrinkle, surely not the sort of thing that could turn a simply nonconscious being into a conscious being.) For that matter, individual subsystems of our own human psychologies doubtless involve their own internal monitors, and it is implausible to grant that those subsystems are themselves conscious. Several replies may be made to this. First, for consciousness we should require that our monitor emit a genuine representation, not just physical "information" in the Bell-Telephone sense or a simple nomological "indication" in the Wisconsin sense. But that is of little help, since surely our subsystems do contain monitors that output genuine representations.</page><page sequence="7">Consciousness as Internal Monitoring, I / 7 Second, it should trouble no one that s/he has proper parts that are conscious. The proper part of you that consists of you minus your left arm is conscious, as is the part consisting of you minus your skin and most of your musculature. Other (individually) expendable chunks include: your entire gastrointestinal tract, your auditory system, much of your cortex, and possibly much of a hemisphere. Each of your respective complementary proper parts is conscious, even as we speak. But (it may be said) the second reply is of little more help than the first. For each of the large proper parts I have mentioned would qualify, mentally speaking, as being you, if taken on its own. Its consciousness is your consciousness; at least, there is nothing present to its consciousness that is not also present to yours. But the sort of case that worries Rey is one in which self- monitoring is performed by a silent, subterranean subsystem, perhaps one of "all those unconscious neurotic systems postulated in so many of us by Freud, ... [or] all those surprisingly intelligent, but still unconscious, subsystems for perception and language postulated in us by contemporary cognitive psychology" (p. 11). What troubles Rey is that he or you or I should contain subsystems that are conscious on their own though we know nothing of them, and whose conscious contents are not at all like ours. It does sound eerie. But I am not so sure that the individuation of consciousnesses is so straightforward a business. For one thing, that the contents of one consciousness coextend with those of mine hardly entails that the first consciousness is (=) mine; they still may be two. For another, the commissurot- omy literature has raised well-known thorny questions about the counting of consciousnesses in the first place,22 and it is abetted in that by thought- experiments such as Dan Dennett's in his classic "Where Am I?" and a more recent one by Stephen White.23 My own preference is to doubt there to be any fact of the matter, as to how many consciousnesses live in a single human body (or as to how many bodies can be animated by the same consciousness). A third reply to the argument: In his own essay on Rey's objection,24 Stephen White enforces a distinction that Rey himself acknowledged but slighted: the difference between consciousness and self-consciousness. Rey had argued that if we already had a nonconscious perception-belief-desire machine, the addition of a "self' concept would be trifling (just as would be that of a simple internal monitor); one need only give the machine a first-person representation whose referent was the machine itself, i.e., add the functional analogue of the pronoun 'I' to the machines language-of-thought. But White argues on the basis of an ingenious group-organism example that the matter is hardly so simple, and that the difference between consciousness and self-consciousness is far larger and more important than Rey allowed. Surprisingly, having a functional inner 'I' does not suffice for being able to think of oneself as oneself; nor does mere consciousness as opposed to self-consciousness confer personhood or any moral status. And it turns out on White's analysis that although subsystems of ours might count as conscious, they would not be self-conscious in the way we are.</page><page sequence="8">8 / William G. Lycan That difference helps to explain and assuage our reluctance to admit them to our own country club.25 I find White's defense of these claims quite convincing.26 But I do not invest much in these second and third meditations as replies to Rey's objection. I have presented them mainly for the purpose of softening you up. 6. So I turn to my fourth and (chez me) most important reply. It is: emphatically to deny (what John Searle has recently asserted with unsurprising boldness27) that consciousness is an on-off affair, that a creature is either simply Conscious or simply not conscious. (If Searle did not exist I would have to invent him, for he actually puts it that way: "Consciousness is an on/off switch; a system is either conscious or not" (p. 83).) I maintain that consciousness comes in degrees, which one might describe as degrees of richness or fullness.28 We human beings are very richly conscious, but there might be more complex and/or more sophisticated organisms that are more fully conscious than we. "Higher animals" are perhaps less fully so; "lower" animals still less, and so forth. In saying this (you will have noticed), I am shifting my sense of 'conscious' slightly. For there is not obviously any great spectrum of degrees of: whether something has an internal monitor scanning some of its psychological states. (Actually there probably is a significant spectrum, based on the extent to which monitor output contributes to integration of information and to control; as was conceded at the time, I did leave the formulation vague. But I will not rest anything on this.) The paronymy works as follows. A thing is conscious, at all, if it is conscious to any degree at all, i.e., if it has at least one internal monitor operating and contributing etc. etc.; we might call this "bare" or "mere" consciousness. The thing may be more richly or more fully conscious if it has more monitors, monitors more, integrates more, integrates better, integrates more efficiently for control purposes, and/or whatever. Actually I have not yet achieved paronymy, for I have located the degrees in the modifers ('richly' and 'fully') rather than in the basic term 'conscious' itself, which so far retains its original sense. But I do still mean to shift its meaning, for I want to allow at least a very vague sense in which some "barely" conscious devices are not really conscious; I take that one to be the ordinary sense of the word. But I would insist that that sense still affords a largeish spectrum of degrees. (Granted, this needs defense, and I shall provide some shortly.) My principal answer to Rey is, then, to deny his intuition: So long as it contributes in the way aforementioned, one little monitor does make for a little bit of consciousness. More monitors and better integration and control make for fuller and fuller consciousness.29 Rey conjectures (p. 24), as a diagnosis of his own chauvinist intuitions about machines, that if consciousness is anything, it is like an "inner light" that is on in us but could be off in or missing from other creatures that were otherwise first-order-psychologically and functionally very like us; that is why he finds it so obvious that machines are not conscious even when they have been</page><page sequence="9">Consciousness as Internal Monitoring, I / 9 hypothetically given a perception-belief-desire system like ours. (Naturally given his conditional assumption, he asks why we should believe that we are not just very complicated perception-belief-desire machines, and offers the eliminative suggestion that we are therefore not conscious either; consciousness is not anything.30) But I see no reason to grant the conditional conjecture. I have no problem saying that a device whose internal monitor is contributing integration- and-control-wise is conscious of the states reported by the monitor. There is a rhetorical difference between saying that a device is conscious of such-and-such and saying that it, itself, is...conscious! But, I contend, that is only a rhetorical difference, barring my slight paronym above. What is special about us is not our being conscious per se, but that we monitor so much at any given time and achieve so high a degree of integration and control. Thus two remarks made by psychologists and quoted by Rey as "astonishing" him by their naYvete do not astonish me in the slightest: Perceptions, memories, anticipatory organization, a combination of these factors into learning-all imply rudimentary consciousness. (Peter H. Knapp)3' Depending on what Knapp meant by "anticipatory organization," this is not far wrong. If anticipatory organization implies internal monitoring that contributes, or if the "combination of...[the] factors into learning" involves such monitoring, or both, I endorse the statement. Consciousness is a process in which information about multiple individual modalities of sensation and perception are combined into a unified, multi- dimensional representation of the state of the system and its environment and is integrated with information about memories and the needs of the organism, generating emotional reactions and programs of behavior to adjust the organism to its environment. (E. Roy John)32 No quarrel there either, assuming again that the "combining" is done in part by contributory monitoring. The main obstacle to agreement with my matter-of-degree thesis is that we ourselves know only one sort of consciousness from the inside, and that one is particularly rich and full. We have elaborate and remarkably non-gappy visual models of our environment; we have our other four main sense modalities, which supplement the blooming, bursting phenomenological garden already furnished by vision; we have proprioception of various sorts that orient us within our surroundings; and (most importantly) we have almost complete freedom of attention within our private worlds, i.e., we can at will attend to virtually any representational aspect of any of our sensations that we choose. (All this creates the Cartesian illusion of a complete private world of sensation and thought, a seamless movie theater. There is no such completeness even phenomenologically, what with failings like the blind spot and the rapid decay of peripheral vision,</page><page sequence="10">10 / William G. Lycan but the illusion is dramatic.) Now, since this is the only sort of consciousness we have ever known from the inside, and since the only way to imagine a consciousness is to imagine it from the inside, we cannot imagine a conscious- ness very different at all from our own, much less a greatly impoverished one. What we succeed in imagining, if we try to get inside the mind of a spider or a notebook computer, is either an implausible cartoon (with anthropomorphic talk balloons) or something that hardly seems to us to deserve the title, "conscious- ness." It is a predicament: we are not well placed to receive the idea that there can be very low degrees of consciousness.33 7. But now, finally, for a bit of argument. (1) consider the total mental states of people who are very ill, or badly injured, or suffering the effects of this or that nefarious drug. Some such people are at some times called "semicon- scious." Any number of altered states are possible, many of them severely diminished mental conditions. For some of these, surely, there will be no clear Searlean "Yes" or "no" to the question, "Is the patient conscious?," but only a "To a degree" or "Sort of." (2) We could imagine thousands of hypothetical artifacts, falling along a multidimensional spectrum having at its low end ordinary hardware-store items like record-changers and air conditioners and at its high end biologic human duplicates (indistinguishable from real living human beings save by their histories).34 Along the way(s) will be robots of many different sorts, having wildly different combinations of abilities and stupidities, oddly skewed and weighted psychologies of all kinds. Which are "conscious"? How could one possibly draw a single line separating the whole seething profusion of creatures into just two groups? (3) For that matter, the real world provides a similar argument (for those who favor the real world over science fiction); consider the phylogenetic scale. Nature actually contains a fairly smooth continuum of organisms, ranked roughly by complexity and degree of internal monitoring, integration and efficient control. Where on this continuum would God tell us that Consciousness begins? (Appropriately enough, Searle himself declares deep ignorance regarding consciousness and the phylogenetic scale.35) (4) If (3) does not move you (or even if (3) does), consider human infants as they develop from embryo to fetus to neonate to baby to child. When in that sequence does Consciousness begin? I do not say that any of these arguments is overwhelming. But taken together-and together with recognition of the imaginative predicament I mentioned prior to offering them-I believe they create a presumption. At the very least, they open the door to my matter-of-degree view and make it a contender. Therefore, one cannot simply assume that consciousness (if any) is an on-off switch. And Rey's argument does assume that. Thus I do not think Rey has refuted the Inner Sense view.36 Notes 1. Locke, As Essay concerning Human Understanding, ed. A.C. Fraser (New York:</page><page sequence="11">Consciousness as Internal Monitoring, I / 11 Dover Publications, 1959), Book II, Ch. I, sec. 3, p. 123; Kant, Critique of Pure Reason, tr. Norman Kemp Smith (New York: St. Martin's Press, 1965), A23/B37, p. 67. 2. See my "What is 'The' Problem of Consciousness?," MS. 3. D.M. Armstrong, A Materialist Theory of the Mind (London: Routledge and Kegan Paul, 1968), and "What Is Consciousness?," in The Nature of Mind and Other Essays (Ithaca, NY: Cornell University Press, 1980). Baars, "Conscious Contents Provide the Nervous System with Coherent, Global Information," in R. Davidson, G.E. Schwartz and D. Shapiro (eds.), Consciousness and Self-Regulation, Vol. 3 (New York: Plenum Press, 1983), pp.41-79; A Cognitive Theory of Consciousness. Lycan, Consciousness (Cambridge, MA: Bradford Books / MIT Press, 1987), Ch. 6. 4. "A Reason for Doubting the Existence of Consciousness," in Davidson, Schwartz and Shapiro, op. cit., pp. 1-39. In a sequel to the present paper, I shall also address criticisms made by Christopher Hill, David Rosenthal, Fred Dretske, and others. 5. "What is Consciousness?," loc. cit., p. 61. 6. There is an potential ambiguity in Armstrong's term, "introspective consciousness": Assuming there are attention mechanisms of the sort I have in mind, they may function automatically, on their own, or they may be deliberately mobilized by their owners. Perhaps only in the latter case should we speak of introspecting. On this usage, "introspective" consciousness may or may not be a result of introspecting. Armstrong himself makes a similar distinction between "reflex" introspective awareness and "introspection proper," adding the suggestion that "the latter will normally involve not only introspective awareness of mental states but also introspective awareness of that introspective awareness" ("What is Consciousness?," loc. cit., p. 63). 7. "What is Consciousness?," loc. cit., pp. 65-66. Robert Van Gulick has also written illuminatingly on the uses of consciousness, though he does not focus so specifically on introspection; see particularly "What Difference Does Consciousness Make?,". Philosophical Topics 17 (1989): 211-30. 8. I began this project with respect to subjectivity and qualia respectively in Chs. 7 and 8 of Consciousness, loc. cit. Parts of it have also been pursued by Gilbert Harman ("The Intrinsic Quality of Experience," in J.E. Tomberlin (ed.), Philosophical Perspectives, 4, Action Theory and Philosophy of Mind, 1990 (Atascadero, CA: Ridgeview Publishing, 1990)), Michael Tye ("Qualia, Content, and the Inverted Spectrum," Nou2s, forthcoming (1994)), and Sydney Shoemaker ("Phenomenal Character," Nou2s, forthcoming (1994)). 9. In Consciousness, loc. cit.; see also my "Functionalism and Recent Spectrum Inversions," unpublished MS, and "True Colors," in preparation. 10. When I made this point emphatically after a presentation of this material at the NEH Summer Institute on "The Nature of Meaning" (Rutgers University, July, 1993), Bill Ramsey responded much as follows: "I see; once you've got the explanandum whittled all the way down, as specific and narrow as you want it, the big news you're bringing us is that what internal monitoring really is, at bottom, is...internal monitoring!" That characterization is not far wrong. Though the Inner Sense doctrine is not tautologous and faces some objections, I think it is very plausible, once it has been relieved of the extraneous theoretical burden of resolving issues that</page><page sequence="12">12 / William G. Lycan are not directly related to the "conscious"/"nonconscious" distinction per se. Incidentally, I do not offhand know of any Inner Sense proponent who does claim that the theory resolves qualia problems. Yet there is a tendency among its critics to criticize it from that quarter; I conjecture that such critics are themselves confusing issues of awareness with issues of qualitative character. 11. Rey, "Sensations in a Language of Thought," in E. Villanueva (ed.), Consciousness (Philosophical Issues, 1, 1991) (Atascadero, CA: Ridgeview Publishing, 1991), and "Sensational Sentences," in M Davies and G. Humphreys (eds.), Consciousness (Oxford: Basil Blackwell, 1992); Lycan, "What is the 'Subjectivity' of the Mental?," in J.E. Tomberlin, op. cit. 12. From a current trash novel: "Each step was painful, but the pain was not felt. He moved at a controlled jog down the escalators and out of the building." (John Grisham, The Firm (New York: Island Books, Dell Publishing, 1991), p. 443. David Rosenthal offers a nice defense of unfelt pain, in "The Independence of Consciousnessand Sensory Quality," in Villanueva, op. cit. See also David Palmer's "Unfelt Pains," American Philosophical Quarterly 12 (1975): 289-98. 13. In "Conscious Experience" (Mind 102 (1993): 263-83), he has also made a couple of substantive objections to Inner Sense theory. I shall address those in the sequel to this paper. 14. Consciousness Explained (Boston, MA: Little, Brown &amp; Co., 1991); D.C. Dennett and M. Kinsboume, "Time and the Observer: The Where and When of Consciousness in the Brain," Behavioral and Brain Sciences 15 (1992): 183-201. 15. P. Kolers and M. von Grunau, "Shape and Color in Apparent Motion," Vision Research 16 (1976): 329-35; F.A. Geldard and C.E. Sherrick, "The Cutaneous 'Rabbit': A Perceptual Illusion," Science 178 (1972): 178-79; B. Libet, "Cortical Activation in Conscious and Unconscious Experience," Perspectives in Biology and Medicine 9: 77-86. 16. E.g., B.J. Baars and M. Fehling, "Consciousness is Associated with Central As Well As Distributed Processes," Behavioral and Brain Sciences 15 (1992): 203-04, and B. Libet, "Models of Conscious Timing and the Experimental Evidence," ibid.: 213- 15. Dennett and Kinsboume reply to their critics in "Authors' Response," ibid.: 234- 43. 17. Consciousness Explained, loc. cit., pp. 218, 225. 18. For convenience, I shall continue to speak of the states that get monitored as "first- order" states, but this is inaccurate, for introspective states can themselves be scanned. This will be important later on. 19. Consciousness, loc. cit., p. 72. 20. On such distinctions, and for more illuminating examples, see Chs. 3 and 4 of Consciousness, loc. cit. 21. One might be tempted to infer (something highly congenial to Dennett himself) that introspection is woefully fallible, unreliable to the point of uselessness. But that inference would be unjustified. Though the "temporal anomalies" alone should have made us question the reliability of introspective reports, notice that the scope of unreliability exhibited by the anomalies is very small, tied to temporal differences within the tiny intervals involved, a small fraction of a second in each case. 22. For a survey and discussion, see C. Marks, Commissurotomy, Consciousness and the Unity of Mind (Montgomery, VT: Bradford Books, 1979). 23. Dennett, "Where Am I?," inBrainstorms(Montgomery, VT: Bradford Books, 1978),</page><page sequence="13">Consciousness as Internal Monitoring, I / 13 reprinted in D.R. Hofstadter and D.C. Dennett (eds.), The Mind's I: Fantasies and Reflections of Self and Soul (New York: Basic Books, 1981); see also D.H. Sanford, "Where Was I?," in Hofstadter and Dennett, op. cit. White, "What Is It Like to Be a Homunculus?" Pacific Philosophical Quarterly 68 (1987): 148-74. 24. "What Is It Like to Be a Homunculus?," loc. cit. 25. Moreover, as he observes (p. 168), we have no access to unproblematic examples of consciousness in the absence of self-consciousness, and that fact contributes to an important predicament that I shall expound below. 26. In like wise, he maintains, no notebook computer is self-conscious even if some are conscious in a less demanding functional sense. (I believe White would accept my claim that mere consciousness is more prevalent than philosophers think; seep. 169.) But I do not see that his analysis of self-consciousness generates that result, since his main concern was to argue only that self-consciousness is restricted to the highest level of organization in a group organism, which result does not help deny self-consciousness to whole computers. (White has explained in conversation that his analysis alone was not intended to do that; he has other means.) 27. The Rediscovery of the Mind (Cambridge, MA: MIT Press, 1992). 28. I have defended this thesis before, in "Abortion and the Civil Rights of Machines," in N. Potter and M. Timmons (eds.), Morality and Universality (Dordrecht: D. Reidel, 1985), pp. 144-145. It should be noted that Searle himself goes on (ibid.) to qualify his "on/off' claim: "But once conscious, the system is a rheostat: there are different degrees of consciousness"; he speaks of levels of intensity and vividness. Thus, it seems, our real disagreement is over, not degrees per se, but the question of whether a creature or device could have a much lower degree of consciousness than is ordinarily enjoyed by human beings and still qualify as being conscious at all. 29. I should emphasize again that a monitor makes for consciousness when what it monitors is itself a psychological state or event. My suggestion that notebook computers are after all conscious is conditional upon the highly controversial assumption that such computers have psychological states such as beliefs and desires in the first place. 30. By way of further diagnosis (p. 25), Rey offers the additional conjecture that our moral concern for our living, breathing conspecifics drives us to posit some solid metaphysical difference between ourselves and mere artifacts, as a ground of that concern. He opines that we need no such ground in order to care more for human beings than for functionally similar machines, but he does not say what he thinks would ground that difference in care. 31. "The Mysterious 'Split': A Clinical Inquiry into Problems of Consciousness and Brain," in G. Globus, G. Maxwell and I Savodnik (eds.), Consciousness and the Brain (New York: Plenum Press, 1976), pp. 37-69. 32. "A Model of Consciousness," in G.E. Schwartz and D. Shapiro (eds.), Consciousness and Self-Regulation, Vol. 1 (New York: Plenum Press, 1976), p. 1-50. 33. Samuel Butler said, "Even the potato, rotting in its dank cellar, has a certain low cunning." But I grant the potato has no internal monitors. 34. This is the one argument I gave in "Abortion and the Civil Rights of Machines," loc. cit. 35. "I have no idea whether fleas, grasshoppers, crabs, or snails are conscious" (p. 74). He suggests that neurophysiologists might find out, by a method of apparent-</page><page sequence="14">14 / William G. Lycan consciousness-debunking, viz., looking for evidence of "mechanical-like tropism to account for apparently goal-directed behavior in organisms that lacked conscious- ness" (p. 75); he pooh-poohs "mechanical-like" functional processing as being in no way mental or psychological. On this, see D.C. Dennett's review of The Rediscovery of the Mind, Journal of Philosophy 90 (1993): 193-205. 36. This essay was presented as the Third Philosophical Perspectives Lecture at California State University, Northridge, in the fall of 1994. I am grateful to James Tomberlin and his colleagues for that invigorating occasion. I am grateful to Joe Levine, Ned Block and Georges Rey for extensive comments and discussion.</page></plain_text>
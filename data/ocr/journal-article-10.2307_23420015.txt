<plain_text><page sequence="1">European Journal of Psychology of Education 1995, Vol. X, n°3. 289-301 © 1995. l.S.P.A. How Do Children Represent Intelligent Technology? Mike van Duuren Michael Scaife Sussex University, United Kingdom Given the increasingly important role of "clever" technology within primary school setting this study investigated aspects of young chil dren 's representation of intelligent (computational) devices. 230 chil dren aged 7 to 11 years were asked to write a story about either a computer, a robot or a control object, a mountain bike. A comparison group of adults was also tested. Stories were analysed in terms of a number of general features including: descriptions of target objects, the use, if at all, of the term "program and the setting and function of target objects. Further more, semantic information as to the ontological status of these objects was derivedfrom an analysis of pronoun and verb-phrase use. There was strong evidence that, across the age range, the computer and the robot were represented as more complex objects and were more likely to be attributed with animate characteristics than the bike. Developmentally, children shifted from describing perceptually salient features of the computer/robot to more abstract features, especially programmab ility. Introduction The increasing use of "intelligent" technology raises important questions about the ways that people understand it. Computers and robots, in particular, are intriguingly positioned between the animate and the inanimate. Examples of this are the apparently "cognitive" quali ties of a computer or the "motor behaviour" of a robot. Such devices can be mysterious for adults who typically employ a wide range of anthropomorphic imagery and metaphors to describe them e.g. cartoons caricaturing so-called intelligent bombs by showing them as "ma king up their minds" to fly back to where they were launched. There has even been considera ble controversy within cognitive science as to how far non-biological systems can be said to show "real" intelligence (e.g., Boden, 1980; Churchland &amp; Churchland, 1990; Searle, 1990). We would like to gratefully acknowledge the support of ESRC research grant No. C08250010 to MS which formed the basis of the project and an ESRC linked studentship to MVD which suported the empirical work.</page><page sequence="2">290 M. VAN DUUREN &amp; M. SCAIFE But what is most salient about such technology for young children? Is the metaphorically rich language surrounding these devices accessible to them? Do they lack the appropriate con ceptual support which underlies these metaphorically rich connections? How far are their representations informed by the similarities of such devices to people or animals? Are, for example, robots with their greater perceptual and motor resemblance more likely to be described as "intelligent" than computers which can be considered as cognitively similar? Keil (1989) proposes that, developmental^, concepts of complex artefacts such as com puters can best be regarded as being represented towards the middle of a continuum with nominal kinds, e.g circles, at one extreme and natural kinds, e.g., lemons and minerals, at the other extreme. Furthermore, he claims that children's developing understanding, to a greater or lesser extent, of all concepts along this continuum can be typified by a shift from initial sur face characterisations to an understanding based on definitions. Understanding based on characteristics, e.g., the description of a computer as an object "with lots of pictures on it", is typically subjective, whereas a understanding based on definitions, e.g., the description of a computer as a programmable object, has a more universally applicable character. Unders tanding by definitions, as used in the above sense, can be regarded as having access to some thing like a theory, in the way that a concept of an uncle, as the brother of one's father, implies a theory of kinship. According to Keil (1989) younger children distinguish themselves from older ones by having a much cruder grasp of the theoretical principles that are fundamental for organising classes of objects within seperate domains. Futhermore, young children are thought to have considerable difficulty in explaining the properties and the relations of objects belon ging to one domain in relation to those belonging to another. Regarding "intelligent" objects such as the ones under consideration here we propose that a concept of programmability is likely to be a key concept in such a domain-specific organisation. Previous research does not allow us to address these kind of issues. The great majority of studies on children and computers has been concerned with different issues, for example those that purport to isolate the social/cognitive effects in the form of children's violent behaviour, as a result of their involvement with violent computer games (e.g., Chambers &amp; Ascoine, 1987; Schutte, 1988). Such studies do not provide us with a direct picture of how children re present intelligent devices. We simply do not have an adequate idea of the kinds of theory and concepts that children bring to the setting (educational or otherwise) in which they interact with a computational device. One relevant study, however, suggests a developmental ly com plex picture. Turkle (1984) claims that the spontaneous commentary of young children using clever devices, e.g., an electronic version of noughts and crosses, is characterised by frequent comparisons between aspects of human mental functioning and that of clever objects, e.g., on the ability to cheat. The collection of such data is undoubtedly important. Educational priorities are now focused on the preparation of children for life in a society in which computational devices are commonplace. Such devices also play an increasingly important role within the school itself (e.g., Senior, 1989). These considerations alone should lead us to investigate how children construe this technology. It is common practise in e.g., biology to teach children about differ ent ways of categorising (e.g., distinctions between organic and inorganic objects). In the same way it is important when we teach children about information technology to teach them about the ontological status of "intelligent" objects rather than to let them manage with opaque or magical references to this technology. There are also good theoretical reasons for doing this. The nature of children's mental models (e.g., Du Boulay, O'Shea, &amp; Monk, 1981; Kurland, &amp; Pea, 1985; Scaife &amp; Taylor, 1991) plays a vitally important part in children's suc cessful use of computers and other intelligent devices. This paper reports a study that investigates aspects of children's understanding of the nature of computational devices. Here we employ the methodology of story analysis, a well -established means of exploring children's representations. This allows us three advantages. Firstly, story writing is seen as an important medium through which children can build sys tematic representations of experience (e.g., Applebee, 1978; Cowie, 1983; Stein, 1988; Wilkinson, Barnsley, Hanna, &amp; Swan, 1980). Within the developmental context it has been</page><page sequence="3">EARLY REPRESENTATIONS OF INTELLIGENT TECHNOLOGY 291 claimed that stories are not simply examples of escapism which are eventually replaced by more realistic concepts of the world but, rather, function as important means for creating sys tematic representations of experience, providing interpretations of the past as well as a means for anticipating the future (Cowie, 1983). A further advantage of using story writing in this way is that it allows children to formulate their representations in a relatively unconstrained way. This is especially important since we simply do not know the extent to which objects like computers and robots constitute a class in their own right for children. Finally by using this format of investigation we can undertake a number of analyses of the kind of language, including semantic information from the particular use of pronouns and verb phrases, that children employ to describe these objects. The methodology applied here is consistent with other "ecologically-oriented" approaches to investigating the use of clever technology. Examples of these are Suchman's analysis of naturally occurring protocols of dyads of people interacting with an "intelligent" photocopier (Suchman, 1987) and Turkle's use of unstructured interviews and naturalistic observations of children playing with intelligent toys (Turkle, 1984; see also Martin, 1988; Sheingold, Hawkins, &amp; Char, 1984). Such means of inquiry allow for investigations of the child's repre sentations with minimal task constraints. This approach is appropriate since children's beliefs will come from a variety of culturally-diverse sources, both within and outside the school set ting including hands-on-experience, parental and peer discourse and media representation. Indeed recent work on perceived distinctions in 5- to 10-year-olds between scientific cate gories as fundamentally different as "plant" and "animal" shows a strong effect of cultural influences (Hatano, Siegler, Richards, Ingaki, Stavy, &amp; Wax, 1993). Given the immensely va ried nature of descriptions of computers, robots and other intelligent machines in contempo rary media we are likely to need correspondingly sensitive and diverse modes of investigation. In this study participants, aged 7 to 11, were asked to write a story about a robot and a computer. A mountain bike was used as a control object, because of its generally desired sta tus and relative cultural novelty, and a comparison group of adults was also tested. A pilot study showed 7 to be the youngest age at which stories longer than a few of sentences could be obtained. Aims of the study A number of questions are of specific interest here. Firstly, what kind of terminology do children of different ages use to describe objects such as computers and robots? Is there any indication that there is a lot more to learn, about what can make complex artefacts such as these constitute a class of things, compared to, for example, more simple artefacts? Secondly, how often and in what way does the important concept of programmability feature, if at all, in the stories of young children? Finally, to what extent do young children attempt to locate "intelligent" objects such as a computer within the animate domain? More specifically we looked at those instances in which the computer or the robot featured as sentence subject (Keenan, 1976) and classified these along an animate-inanimate dimension (Oatley &amp; Yuill, 1985). Further language analyses included an investigation into the kinds of pronouns and naming conventions that were used to describe the target objects. Method Subjects Children were drawn from two local primary schools. Adult participants were registered at the Open University Summer School at Sussex University to do a Social Science degree. Age groups were as follows: seventy 7-year-olds (31 boys/39 girls, mean age 7.2); sixty-four</page><page sequence="4">292 M. VAN DUUREN &amp; M. SCAIFE 8-year-olds (34 boys/30 girls, mean age 8.2); ninety-six 11-year-olds (46 boys/50 girls, mean age 11.0); thirty-eight adults (20 men/18 women, mean age 40.0). Relevant Experience of the subjects All teachers of classes participating in the study were given a questionnaire from which it transpired that, independent of age, roughly 4-6 hours a term was made available on the school computer for each child. From a questionnaire distributed among the children's parents it turned out that in addition to the school computer roughly 85% of children had some hands on experience of a computer at home or elsewhere. By far the most popular computer-based activity, either at school or at home, involved software created for leisure and or educational purposes such as adventure games and games designed to foster numeracy skills (for more details see van Duuren, 1994). Only a few (10%) of the older children appeared to have had some experience of programming (e.g., Logo, Basic). All adults taking part in the study com pleted a questionnaire in which roughly 90% claimed to have had some experience with com puters including such activities as programming, information retrieval, data manipulation and spreadsheet use. Procedure For each age group children from three different classes participated in the study. Each class was instructed by the teacher, in the context of a normal school exercise, to write about a different target object, for example all children from one class wrote a story about a robot. In addition teachers had been explicitly briefed not to set any further parameters in relation to this task. Children were encouraged to write "any story you like about X (were X was either a computer, robot, or mountain bike), and you can give your story any title you want". Story writers were told they could work on their story until it was finished to their satisfaction. Only two children needed an extra schoolday to complete their story. For adults, different groups of students were approached at the end of a seminar and asked, as part of a research project on story writing, to write a story about either a robot or a computer or mountain bike. Students were asked to return their stories as soon as they had fi nished writing them but to return the stories within a day. Numbers of stories are shown in Table 1, the variation in sample sizes between conditions being simply a reflection of class sizes. Table 1 Number of stories and mean length (mean number of words and SD) Age Target Object Computer Robot Bike 7-Year olds 23 25 22 52(22) 64(50) 97(53) 8-Year olds 25 22 17 137(83) 208(72) 118(67) 11-Year olds 35 29 22 345(123) 410(97) 215(83) Adults 12 12 14 463(248) 310(245) 414(177)</page><page sequence="5">EARLY REPRESENTATIONS OF INTELLIGENT TECHNOLOGY 293 Results Descriptions of target objects Many authors, commenting on children of primary school age, have reported that story length greatly increases with age (e.g., Wilkinson et al., 1980). This was also the case in the present study as Table 1 shows but story length did not vary systematically with target object (One-way Anova, F(2,254)=2.22,ns). In order to firstly present a more general overview a descriptive analysis was undertaken were an inventory was made for each story of terms that "related" to the target object. Terms qualified as related if they could be counted as technical or general attributes to the object, e.g., "micro chip" for a computer. Each item was noted only once, independent of the number of times it featured in a particular story. For the bike there was not much difference between the various age groups. "Gears" was the most frequently mentioned term and a number of items including "brakes", "punctures" and brand-names were used across all ages. For the computer and robot the picture was considerably less homogeneous (see Table 2). The 7- and 8-year-olds mentioned perceptually salient items such as "buttons" or "disks" (computer) and "feet" or "bolts" (robot) to a far greater degree than the older age groups. By contrast the 11 -year-olds, like adults, mentioned a much greater range of different items and their vocabulary was both more specialised, including such items as "micro chips", "viruses" and "network", and correspondingly less focused on perceptual features. In addition adults referred to these objects in many alternative ways using for example the phrase "mechanical thug" to describe their robot. Programmability of target object An appropriate understanding of intelligent devices is of course importantly predicated on having a concept of "programmability". For this reason we were particularly interested in stories where the terms "program" or "programming" were used at least once (see Table 2). It transpired that relatively few school children used these terms in their stories compared to adults (%2(l,n=26)=&amp;.l3, /K.Ol). However there was a significant increase in usage through out school aged children (^2(2,n=17)=15.6, /K.001). This terminology first appeared in the robot stories of 8-year-olds and computer-stories of 11-year-olds. With respect to the compu ter stories two-thirds of the 11-year olds used "program" as a noun, e.g., "There was a pro gram he liked playing". However the remainder demonstrated a broader understanding that programs are written to solve a particular set of problems (e.g., "I started to write a program in to the computer but it would never do what I wanted it to do"). Regarding the robot stories, the 8- and 11-year olds who used these terms implied some external, often unspecified, mediation to the robot in order for it to accomplish a specified feat, e.g., "The boy made a robot to lawn -mower [sic] but the program went wild and he had to pay for the damage". The earlier use in the robot stories of this terminology may suggest that children start to use these words to refer to some observable behavioural outcome, as in the quote, which is being accomplished by the (robot's) program, rather than the more abstract results of an execution of a desk top computer program. By contrast all adults who featured these terms demonstrated knowledge of program ming as the creation of a set of instructions. Indeed adults often illustrated their wider grasp by, for example, noting the constraints implicit in the formal nature of programs, e.g., "He [the robot] felt like crying but he was programmed to be brave". Function and setting of target object Given this broad picture we then looked at two kinds of judgement. The first was con cerned with the accuracy with which children viewed the normal functioning of target objects.</page><page sequence="6">294 M. VAN DUUREN &amp; M. SCAIFE How similar, if at all, were the beliefs children seem to have internalised from those of adult story writers? The second was evidence for possible attributions of animacy. How far did the children seem to endow the computer/robot with characteristics of living things? In all cases the data were coded by a single individual and 25% of the data were independently coded by two other raters. Cohen's (1968) Kappa statistic for agreement is given below for each judge ment type. Table 2 The six most frequently mentioned object-related items (%&gt; of all stories) Target Object Age Computer Robot 7-year olds 17.4 Computerised object 4.0 Oil 13.0 Buttons 4.0 Feet 13.0 Disks 4.0 Head 4.3 Oil 4.3 Computer game Diff. items found 5 3 8-year olds 36.0 Computerised object 18.2 Bolts &amp; nuts 16.0 Computer game 18.2 Batteries 12.0 Screen 9.1 Program(ming) 8.0 Wires 9.1 Buttons &amp; switches 8.0 Electricity 9.1 Head 4.0 Disk 4.5 Wires Diff. items found 10 14 11-year olds 31.1 Microchips 24.1 Circuits &amp; chips 22.2 Brand-name 20.7 Program(ming) 20.0 Program(ming) 17.2 Electricity &amp; batteries 20.0 Screen 13.8 Metal 17.8 Viruses 13.8 Buttons &amp; switches 13.3 Computer game 13.8 Computer 13.3 Network Diff. items found 27 24 Adults 41.6 Program(ming) 58.3 Alternative description 33.3 Loggin-in 50.0 Computer 33.3 Alternative description 33.3 Program(ming) 25.0 Network 33.3 Switches 16.7 Computer language 25.0 Circuits 16.7 Virus 25.0 Remote control Diff. items found 34 21 For each story a judgement was made about (I) how the writer described the principal function of the target object and (II) whether the writer described it in a conventional or realis tic setting or not. Inter-rater reliability for these judgements produced Kappa values of 0.79 (function) and 0.83 (setting). The mountain bike was represented (see Table 3) throughout the age range as an object of transport or leisure (/jf2(3,n=75)=l.l 1,/w). The computer was viewed by adults as an adminis trative/business tool and by school-based participants as a leisure/play-related object</page><page sequence="7">EARLY REPRESENTATIONS OF INTELLIGENT TECHNOLOGY 295 (/£2(2,h=52)=17.63,/?&lt;.001). For the robots there was a significant difference between adults, who regarded the robot as part of a production process, and children who viewed the robot as a domestic utility/leisure-play object (;£?(1,h=39)=15.28,/?&lt;.001). Table 3 The four most frequently mentionedfunctions of the target objects (% of all stories) Target Object Age Computer Robot Bike 7-year olds 63.2 Unclear 44.0 Domestic utility 45.5 Leisure/Play 21.1 Leisure/Play 32.0 Unclear 36.4 Unclear 10.5 Education/Sc ience 8.0 Leisure/Play 18.2 Transport 5.3 Admin./Business 8.0 Friendship/Dom. utility 8-year olds 43.8 Unclear 45.5 Unclear 52.9 Unclear 37.5 Leisure/Play 18.2 Leisure/Play 35.5 Leisure/Play 6.3 Education/Science 18.2 Domestic utility 11.8 Various 6.3 Admin./Business 9.1 Production work 11-year olds 50.0 Leisure/Play 24.1 Various 40.9 Unclear 16.7 Unclear 24.1 Unclear 31.8 Leisure/Play 14.3 Education/Science 17.2 Domestic utility 27.3 Various 11.9 Admin./Business 10.3 Education/Science Adults 58.8 Admin./Business 50.0 Production work 50.0 Leisure 16.7 Various 25.0 Domestic utility 21.4 Transport 16.7 Unclear 16.7 Unclear 14.3 Status 8.3 Leisure/Play 8.3 Various 14.3 Various Across the age range mountain bikes were depicted (see Table 4) in realistic locations (garage, rough terrain). By contrast participants differed across the age range as to their choice of settings for robots and computers. Both with respect to the computer (£2(1,m=105)=15.05, pc.001) and the robot (£2(l,w=88)=l 1.08, /K.001) significantly fewer 7- and 8-year-olds choose a conventional setting compared to the two older age groups. Younger children described settings such as streets, in the sea, church, forest, out in space (computer), as well as street, forest, hedge, river (robot). The older groups appropriately located robots and compu ters at home, work or school. Attributions of animacy: naming and pronoun use One indication of possible attribution of animacy was whether objects had been given names normally associated with such beings, (e.g., "Harry" rather than "XV8"). A decision was made for each story as to whether the target object had been given an animate name or not (either no name or an impersonal one). Inter-rater reliability for these judgements produced a Kappa of 0.98. Over the entire age range only three participants gave an animate name to the bike. The robot was the target object most likely to be given an animate name, occurring equally in about a third of stories at all ages (£2(3,w=88)=5.60,ns). Surprisingly the computer was named in this way by 26% of 7-year-olds but by no 8- or 11-year-olds. Another indication of the different status of the intelligent devices from that of the bike comes from an examination of personal pronoun usage in the stories. A score was computed for the number of stories in which the target object was referred to at least once by the perso</page><page sequence="8">296 M. VAN DUUREN &amp; M. SCAIFE nal pronouns "I", "you", "we" or "s/he" as opposed to the exclusive use of "it" or the (indefi nite article. These data are shown in Table 5. Across the age-range significantly fewer story writers referred to the bike by a personal pronoun compared to the robot and computer (2'2(l,/7=268)=38.09, p&lt;.001). In contrast throughout the age-range story writers were more likely to refer to the robot using personal pronouns rather than (in)definite articles. There were no age differences in this respect (^2(3,«=88)=4.56,/k). Table 4 Type of setting in which the target object is placed in the story (% of all stories) Target Object Age Setting Computer Robot Bike 7-year olds Unusual 15.8 16.0 45 Usual 42.1 60.0 72.7 Unclear 42.1 24.0 22.7 Total 100 100 100 8-year olds Unusual 18.8 45.5 — Usual 68.8 36.3 70.6 Unclear 12.5 18.2 29.4 Total 100 100 100 11-year olds Unusual 4.8 17.2 9.1 Usual 90.5 79.3 86.4 Unclear 4.8 3.4 4.5 Total 100 100 100 Adults Unusual — _ _ Usual 83.3 91.7 92.8 Unclear 16.7 8.3 7.1 Total 100 100 100 Table 5 Percentage of stories in which a personal pronoun was usedfor the target object Age Target Object Computer Robot Bicke 7-Year olds 61% 64% 0% 8-Year olds 20% 77% 6% 11-Year olds 20% 62% 14% Adults 58% 92% 21% Attributions of animacy: verb phrase use A final examination of language use looked for evidence of animate attributions by examination of verb phrases. A number of authors have commented on the important psycho logical role that verbs play in terms of mediating experience (e.g., Givon, 1979; Keenan,</page><page sequence="9">EARLY REPRESENTATIONS OF INTELLIGENT TECHNOLOGY 297 1976; Li, 1976). Keenan emphasises the importance of the relationship between a sentence subject and the (main) sentence verb, the latter predicting semantic category information, such as animacy, of the referent of the subject (Keenan, 1976). All story sentences in which the tar get object featured as a sentence subject were selected and pooled. Analysis was done using an adapted version of the verb-classification scheme used by Oatley and Yuill (1985) to cate gorise different levels of attribution of participants asked to describe a set of moving geometri cal shapes. Verb phrases would be classified in one of four categories. These were: Personal -intentional - intentional action by animate character implied (e.g., "S opened the door"); Interpersonal-intentional - interpersonal volition implied (e.g., "S was hitting him"); Mental states - where cognitive/emotional aspects of mental life are implied ("S thinks that"); and finally Impersonal - no animate agency necessarily implied (e.g., "S is out of warranty"). Inter-rater reliability for these judgements produced a Kappa of .89. Table 6 shows the results of this analysis. Children and adults consistently used the bike least as sentence subject and, across the age range, typically represented it as a non-agent (impersonal category). This was significantly different from their constructions for the com puter (2"2(l,n=462)=43.07, p&lt;.001) or the robot (^2(1,«=565)=43.48, p&lt;.001) for which there was much more attribution of agency. Table 6 Percentage of verb phrases showing evidence of animacy for the target object Target Object Computer Robot Bicke Types animacy 7-y 8-y 11-y Ad. 7-y 8-y 11-y Ad. 7-y 8-y 11-y Ad. («=61 )(n=5 8)(«=98)(«=92) («=78)(«=69)(n= 174)(«=91) (n=17)(«=14)(n=58)(«=64) Personal-Intent. 31 22 30 19 41 16 32 30 6 7 16 22 Interpers.-Intent. 5 7 6 12 10 12 10 4 0 0 7 2 Mental States 15 7 21 51 13 20 9 40 6 0 5 11 Impersonal 49 64 43 19 36 52 49 26 88 92 72 66 Total 100 100 100 100 100 100 100 100 100 100 100 100 Although there was some increase across the age-range in attempts to personify (i.e., verb phrases classified as personal-intentional, interpersonal-intentional or mental states) the age -groups for the bike did not differ significantly in this respect (%2(3,n=l 53)=6.60,ns). There was an overall age difference in terms of usage of impersonal verb-phrases versus the other categories of verb-phrases indicating a degree of personification. Generally the older participants (i.e., participants aged 8, 11 or adults) tended to use verb phrases indicative of personification both for the computer (yy2(3,n=309)=33.62, /K.001) as well as for the robot (j2(3,w=412)=16.59, /K.OOl). However, over the whole age range participants did not differ in allocating both the robot and the computer more verb-phrases signifying personification than verb-phrases indicating non-personification (%2( I ,«=721 )=0.1 (),ns). Discussion This study set out to investigate children's representations of computational devices. We looked specifically the extent to which young children were willing to anthropomorphise com puters and robots, and the degree to which their stories reflected some understanding of these</page><page sequence="10">298 M. VAN DUUREN &amp; M. SCAIFE devices as complex artefacts. The data show evidence of animate attributions across the age range and interesting developmental differences in the nature of the representations. The age general animate attributions may be contrasted with the established finding that children as young as four and five distinguish strongly between (natural) living and non-living beings (e.g., Laurendeau &amp; Pinard, 1962; Richards &amp; Siegler, 1986). As such they have implications for education that we summarise below. Firstly, however, the use of stories as basic data to infer representations here needs to be scrutinised. One objection is that while no constraints were put on what the participants could write, it could be argued that younger children in particular may have understood the instruc tions to "write a story about X" as one in which X needed to be "animated" in some way. If this was the case it is not clear why they only did so for computers and robots but not bikes. A further objection concerns the developmental acquisition of story genres, with changing con ventions for portraying story characters. This is certainly noticeable in the adult stories, and a small subset of those of the 11-year-olds, where use of intentional verb phrases and personal pronouns for the bike shows a marked increase over the younger children. These stories seemed to be written in what might be called a "Thomas Tank Engine" genre - after a well known children's story series - where inanimate objects are personalised to make the story supposedly more interesting for a young audience (c.f. Billingham &amp; Fu, 1980; Tulviste, 1982). Again, however, while these may well contribute to differences between ages they do not fully explain the differences between the target objects at particular ages. Thus we need to be cautious in basing claims on any single analysis and to consider the group of findings as a whole. This general picture is, in fact, surprisingly clear. The use of descriptive terms showed that there was little developmental change in reported complexity of the control object, the bike. By contrast references to computers and robots became more abstract with details of structure and function increasingly prevalent. This is demonstrated in the use of "program" and "programming", words whose frequency of use and depth of understanding increased as children got older. The children demonstrated other differences to adults. They typically depicted the computer as a leisure-related object. This finding is supported by Harvey and Wilson (1985) who found that a group of children aged 10-12, clearly associated microcom puters with 'fun' when they were asked to write an essay about them. The robot on the other hand was represented as a domestic help. Adults depicted the com puter as an administrative tool and the robot as a production worker. In reality the vast majori ty of robots operate in manufacturing industries and the domestic robot is still some way from becoming available as a domestic utility. This "error" was especially noticeable in the case of the robot stories of the 7-year-olds in which the robot is frequently portrayed as cleaning the dishes and making the beds. This is consistent with the story literature which reports a prepon derance of domestic scripts in the stories of young children (e.g., Wilkinson et al., 1980). A number of measures showed that there was a notable difference between the attribu tions of animacy to the computational devices and the control object. Thus it is the former that are given animate names, referred to by personal pronouns and portrayed as capable of (inter personal volitional action or having a mental life. This attribution is especially significant for the computer since, unlike the robot, it shares no obvious perceptual or motor similarities to living beings. These results support the hypothesis that young children do seem to treat artifi cially intelligent objects in different ways to more traditional objects - eventhough they may not have an adequate grasp of the programmable nature of these devices. The finding that young children often lack the concept programmability is consistent with other studies utili sing other means of investigation (Scaife &amp; van Duuren, in press). Homeostatic clusters (Keil, 1989) consisting of inter-correlated concepts, are the means by which a person can differen tiate one class of objects, e.g., artificially intelligent devices, from another. Clusters can serve to causally explain the kind of phenomena selected by the cluster. Having an adequate concept of programmability would undoubtedly enrich its associated homeostatic cluster. Precisely how young children represent "intelligent devices", and whether they truly re present a "category" in their own right one cannot conclude from the present study. Indeed , as</page><page sequence="11">EARLY REPRESENTATIONS OF INTELLIGENT TECHNOLOGY 299 far as adults are concerned it may be the case that even adults who have considerable experi ence with a specific intelligent machine may some of the time regard it as a mere tool whilst at other times as an agent capable of interacting (Suchman, 1987). Furthermore, where children in the present study did not differ importantly in terms of temporal experience with computers, further work would need to look at a group less homogenous in this respect. However the results of the present study do suggest some important educational consequences. One is that there may be ample scope to involve children in quite sophisticated oriented discussions in order to advance their knowledge and theories about natural and artificial intelligence. Here one might think of using, for example, the school computer or programmable robot as stimu lus objects in their own right. Lipman an educationalist and erstwhile professor of Philosophy, appears to have had considerable success with a discussion programme designed for use in a supportive and structure-rich environment in which children as young as 5 can explore new concepts for themselves (Lipman, 1991, 1988). In the present context such discussions could, for example, focus on a variety of questions such as "Are robots (with their perceptual and behavioural characteristics) more like humans or computers?" or "Does programming compu ters make them similar to human beings?" Given the importance of analogy and mental mo dels in learning (e.g., Johnson Laird, 1988) this would be clearly beneficial both in terms of improving the child's potential to use such objects and, perhaps, in terms of an increased understanding of the animate/inanimate domains. References Applebee, A. N. (1978). The Child's Concept of Story: Ages Two to Seventeen. Chicago: University of Chicago Press. Billingham, R. E., &amp; Fu, V. R. (1980). Animistic thinking between parents and children. Journal of Psychology, 105, 35-39. Boden, M. A. (1980). Artificial Intelligence and intellectual imperialism. In A. J. Chapman &amp; D. M. Jones (Eds.), Models of Man (pp. 129-143). Leicester: British Psychology Society. Chambers, J. H., &amp; Ascoine, F. R. (1987). The effects of prosocial and aggressive videogames on children's donating and helping. Journal of Genetic Psychology, 148,499-505. Churchland, P. M., &amp; Churchland, P. S. (1990). Could a machine think? Scientific American, January 1990. Cohen, J. (1968). Weighted kappa: Nominal scale agreement with provision for scaled disagreement or partial credit. Psychological Bulletin, 70, 213-220. Cowie, H. (1983). An approach to the evaluation of children's writing. Early Child Development and Care, 12, 319 -331. Du Boulay, B., O'Shea, T., &amp; Monk, J. (1981). The black box inside the glass box: Presenting computing concepts to novices. International Journal of Man-Machine Studies, 14, 237-249. Givon, T. (1979). On Understanding Grammar: Perspectives in Neurolinguistics and Psycholinguistics. London: Academic Press. Harvey, T. J., &amp; Wilson (1985). Gender differences in attitudes towards microcomputers shown by primary and se condary school pupils. British Journal of Educational Technology, 16, 183-187. Hatano, G., Siegler, R. S., Richards, D. D., Ingaki, K., Stavy, R., &amp; Wax, N. (1993). The Development of biological knowledge: A multinational study. Cognitive Development, 8, 47-62. Johnson-Laird, P. N. (1980). Mental models in cognitive science. Cognitive Science, &lt;71-115. Keenan, E. L. (1976). Towards a universal definition of subject. In C. N. Li (Ed.), Subject and opic. New York: Academic Press.</page><page sequence="12">300 M. VAN DUUREN &amp; M. SCAIFE Keil, F. C. (1989). Concepts, Kinds and Cognitive Development. Cambridge, MA: MIT Press. Kurland, D. M., &amp; Pea, R. D. (1985). Children's mental models of recursive Logo programs. Journal of Educational Computing Research, 1, 235-243. Laurendeau, M., &amp; Pinard, A. (1962). Causal Thinking in the Child. New York: International Universities Press. Li, C. (1976). Subject and Topic: A new Typology of Language. In C. N. Li (Ed.), Subject and Topic (pp. 457-491). New York: Academic Press. Lipman, M. (1988). Philosophy goes to school. Philadelphia, Penn: Temple University Press. Lipman, M. (1991). Thinking in Education. New York: Cambridge Unversity Press. Martin, D. C. (1988). Ethnographic methods for studying microcomputer implementation in schools. Working paper, Department of Electrical Engineering and Computer Science, George Washington University. Oatley, K., &amp; Yuill, N. (1985). Perception of personal and interpersonal action in a cartoon film. British Journal of Social Psychology, 24, 115-124. Richards, D. D., &amp; Siegler, R. S. (1986). Children's understandings of the attributes of life. Journal of Experimental Child Psychology, 42, 1-22. Scaife, M., &amp; Taylor, J. (1991). Graduated learning environments for developing computational concepts. Journal of Artificial Intelligence in Education, 2 (2), 31-42. Scaife, M., &amp; van Duuren, M. A. (in press). Do computers have brains? What children believe about intelligent arte facts. British Journal of Developmental Psychology. Schutte, N. S., Malouff, J. M., Post-Gordon, J. C., &amp; Rodasta, A. L. (1988). Effects of playing videogames on children's aggressive and other behaviors. Journal of Applied Social Psychology, 18, 454-460. Searle, J. (1990). Is the brain's mind a computer program? Scientific American, January 1990. Senior, S. (1989). Using IT across the National Curriculum. Tunstall: Owlet. Sheingold, K., Hawkins, J., &amp; Char, C. (1984). "I'm the thinkist, you're the typist": The interaction of technology and the social life of the classroom. Journal of Social Issues, 40 (3), 49-61. Stein, N. L. (1988). The development of children's story telling skill. In M. B. Franklin &amp; S. S. Barten (Eds.), Child lan guage: A book of Readings. New York: Oxford University Press. Suchman, L. (1987). Plans and Situated Actions: The Problem of Human Machine Communication, Cambridge: Cambridge University Press. Tulviste, P. (1982). Is there a form of verbal thought specific to childhood? Soviet Psychology, II, 3-17. Turkle, S. (1984). The Second Self: Computers and the Human Spirit. New York: Simon and Schuster. van Duuren, M. A. (1994). The attribution of brain-like properties. How do children regard "intelligent" objects? Unpublished manuscript. van Duuren, M. A. (1994). The use of intelligent technology at home and at school: What do parents think? British Journal of Educational Technology, 25, 3, 231-233. Wilkinson, A., Barnsley, G., Hanna, P., &amp; Swan, M. (1980). Assessing Language Development. Oxford: Oxford University Press. Key words: Animacy, Children's ideas about computational devices, Linguistic measures, Primary school level, Programmability.</page><page sequence="13">EARLY REPRESENTATIONS OF INTELLIGENT TECHNOLOGY 301 Received: May 1994 Revision received: November 1994 Michael Alexander van Duuren. School of Cognitive and Computing Sciences, Sussex University, United Kingdom. Current theme of research: The implications of media mis-representation for children's understanding of intelligent artefacts. Computer game addiction. Economic socialisation. Most relevant publications in the field of Psychology of Education: van Duuren, M. A. (in press). The use of intelligent technology at home and at school: What do parents think? British Journal of Educational Technology, 25, 3, 231-233. van Duuren, M. A., &amp; Scaife, M. A robot's brain controls itself, because a brain hasn't got a brain, because a brain is a brain itself, so it just controls itself - Young children's attributions of brain related behaviour to intelligent arte facts. Unpublished manuscript. van Duuren, M. A. Parental attitudes to young children's use of clever technology. Educational Studies. Unpublished manuscript. Scaife, M., &amp; van Duuren, M. A. (in press). Do computers have brains? British Journal of Developmental Psychology. Michael Scaife. School of Cognitive and Computing Sciences, Sussex University, United Kingdom. Current theme of research: Children's representation of intelligent devices. Children's understanding of evolution/biology. Human-computer inter action. Most relevant publications in the field of Psychology of Education: Scaife, M. J., &amp; Van Duuren, M. A. (in press). Do computers have brains? British Journal of Developmental Psychology. Scaife, M. ( 1987). The need for developmental theories in cognitive science: children and computing systems. In J. Rutkowska &amp; C. Crook (Eds.), Computers, Cognition and Development (pp. 281-293). Chichester: Wiley. Scaife, M., &amp; Bond, R. (in press). Developmental changes in Childrens Use of Computer Input Devices, Early. Child Development and Care. Scaife, M., &amp; Taylor, J. (1991). Graduated Learning Environments for Developing Computational Concepts in 7-11 -year-old Children. Journal of Artificial Intelligence in Education, 2, 31-42.</page></plain_text>
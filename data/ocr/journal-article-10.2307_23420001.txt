<plain_text><page sequence="1">European Journal of Psychology of Education 1996, Vol. XI, n"4, 365-376 ) 1996.1.S.P.A. "Because a robot's brain hasn't got a brain, it just controls itself'- Children's attributions of brain related behaviour to intelligent artefacts Mike van Duuren Michael Scaife University of Sussex, F aimer, Brighton, United Kingdom Educational settings have seen an increased presence of intelligent artefacts. Objects such as computers and robots take up new positions along the animate-inanimate continuum due to their substantive "cog nitive" and "sensori-motor" repertoires including for example an abil ity to engage with a diversity of problem-solving tasks and having a memory. In the present study we report children's understanding of a variety of stimulus objects with different anthropomorphic features, including a person, robot, computer and doll. Attributional judgements were elicited from 60 children aged 5-11 and a comparison group of adults. Children were asked for judgements (and justifications) whether the above objects were capable of realising a large number of items drawn from 6 major behavioural categories (e.g., involuntary activity). The data, show that the different objects did not generally elicit sub stantially different justification patterns. The exception to this is a clear developmental pattern in terms of an increased understanding of the nature of clever artefacts. Results are discussed in terms of different forms of causal reasoning and the specific nature of the act of pro gramming in terms of a growing understanding of the behaviour of intelligent artefacts. Introduction The post-Piagetian era has seen a renewed interest in the developing abilities of young children to represent the distinction between animate and inanimate objects. Indeed, as Legerstee ( 1992) suggests, an adequately developed conceptual system in which both objects and people are represented, will need to take account of the similarities, as well as the differ ences between animate and inanimate matter. For example, although both are subject to the same sets of physical laws, and can be perceived in terms of physical dimensions, only ani mate things, especially people, are typically thought of as being capable of communication, intentional expression, or having feeling states. Generally speaking then, where the behaviour An ESRC linked studentship to MVD, and ESRC Research Grant No. C08250010 are gratefully acknowledged.</page><page sequence="2">366 M. VAN DUUREN &amp; M. SCAIFE of inanimate objects is stable and predictable that of animate entities is complex and rich. Given the importance of this ontological distinction, it is not surprising that much experimen tal effort has been devoted in outlining its developmental pathway. For Piaget (e.g., 1926, 1954) the young child does not distinguish these two categories reliably since it regards all behaviour, including that of inanimate objects, as an expression of (human) intentional causality rather than the result of objective, mechanical causality. In con trast, more recently, a growing body of experimental findings suggests that even very young children can successfully discriminate animals and people from physical objects. Here chil dren are shown to use a number of criteria effectively, including: autonomous movement, (e.g., Gelman 1979; Massey &amp; Gelman, 1988); expression of intentionality (Frye, Rawling, Moore, &amp; Meyers, 1983; Gelman &amp; Spelke, 1981); growth (e.g., Inagaki, 1993; Backscheider, Shatz, &amp; Gelman, 1993); social responsiveness (e.g., Legerstee, 1992). Studies such as these typically employ stimulus materials which are unequivocally animate or inanimate. Of course not all objects can be dispatched so readily into either animate or inanimate categories. Obvious examples here are artefacts with cognitive repertoires (computers) or those with cognitive as well as (sensori-) motor-repertoires (robots). The indeterminate status of such objects is reflected within the cognitive science community in the continuing debate surrounding complex artefacts (e.g., Boden, 1977; Searle 1990; Turkle, in press). Naive epis temologies, mediated by everyday language, also are replete with references to cognitive char acteristics of such artefacts, for example, when we talk of memory - or processing capacity, or of "reading" or "writing" to a disk, or in terms of their specific problem-solving capacities. Recently it has been suggested that artefacts with varying anthropomorphic characteris tics, such as the above, are better thought of as being placed along an animate-inanimate con tinuum (e.g., Keil 1991; Van Duuren &amp; Scaife, 1995). Here questions arise such as "where would young children place these objects along such a continuum?" and "do young children have something of a Theory of Mind regarding artificially intelligent objects which could underpin the status they accord these objects?" (e.g., Astington &amp; Gopnick, 1988; Resnick &amp; Martin, 1991; Wimmer&amp; Perner, 1983). How then can a growing understanding of intelligent artefacts best be understood? Currently models of conceptual development are favoured which attempt to chart growth in relatively independent knowledge domains. Though a number of such domains have been cited, the majority of work has been concerned with the domains of na√Øve - physics, biology and psychology (e.g., Carey 1985; Hatano &amp; Inagaki, 1994; Wellman &amp; Gelman, 1992). Carey (1985), with reference to biology, claims that although young children are not in principle constrained in understanding phenomena based on underlying mechanistic causality, nonetheless they tend to favour a different kind of rationale. More specifically, children aged 5 are most likely to employ psychological (or intentional) explanations for biological phenome na, featuring the (human) organism as the central locus of control, responsible for making bio logical processes happen (e.g., "we get rid of body waste because we go to the toilet"). Such reasoning is gradually succeeded by reasoning based on physiological causal mechanisms, which herald the understanding of biology as a separate domain of knowledge at around 11 years of age. Inagaki and Hatano (1993) claim that while Carey's (1985) developmental picture is basi cally correct it is not complete. Investigating young children's ability to make mind-body dis tinctions they found evidence for a third, intermediate, form of reasoning. In their study 6-year olds generally preferred vitalistic reasoning where "... young children try to understand the workings of internal body organs by regarding them as... human-like agents, and by assigning their activities global life sustaining characters" (Hatano &amp; Inagaki, 1994, p. 177). In line with these more recent findings Johnson and Wellman (1982) have shown that while older children clearly recognise a strong involvement of the brain with a variety of behavioural categories, children aged 4 to 5 almost exclusively associate brains with mental acts, but not with other behaviours such as motor activity, sensory acts or involuntary behav iour. Here younger children also assign local agency on the basis of what could be called a one-body-part-one-function criterion, where "eyes are for seeing" and "legs are for walking".</page><page sequence="3">CHILDREN'S ATTRIBUTIONS TO INTELLIGENT ARTEFACTS 367 Present study Scaife and Van Duuren (1995) investigated young children's willingness to attribute brains to a battery of test objects differing in anthropomorphic features including, a person, robot, computer and doll. Here it was demonstrated that while older children typically showed a willingness to attribute both intelligent artefacts with a brain only few of the 5-year olds did so. In the present study we examine the extent to which children aged 5 to 11, and a compari - son group of adults, are willing to attribute the above test objects with a number of behaviours, the execution of which would normally be believed to involve a brain and to what extent chil dren and adults are likely to employ similar types reasoning with all four test objects. Examples of behavioural items were drawn from six categories as used by Johnson and Wellman (1982). These included, mental acts, emotional states, school based tasks, motor behaviour, sensory acts, involuntary behaviour (see Table 1). In addition to asking simple yes/no questions e.g., "Can the computer think all by itself?" subjects were asked to justify their responses. Because of the large volume of question items participants were not asked to justify their answers to all items (see Table 1) and for the same reason fewer questions were asked of the test-object person. Method Participants The subjects were: 20 5-year-olds (range 5.4-5.11, mean age 5.5, SD 2.9 months); 20 7 year-olds (range 7.4-7.11, mean age 7.7, SD 2.7 months); 20 11-year-olds (range 11.4-11.11, mean age 11.9, SD 2.9 months); 20 adults (range 18-45, mean age 23, SD 13.9 months). Children came from a local primary school, adults were enrolled at the Open University Summer School taking a general Social Sciences degree. Relevant Experience All school-based subjects had the same hands-on time, roughly between 5-6 hours a term, at the school computer. In addition the vast majority of these subjects had some experience of a computer at home. Leisure and/or educational software such as adventure games and games designed to foster numerical skills was reported as most frequently used either at school or at home. Less than 10% of the older children appeared to have had some experience of program ming. The vast majority of adults (90%) claimed to have had experience with computers including programming, database manipulation and spreadsheet use. Materials Four test objects were used: (I) A robot, programmable by remote control, approximately 45cm in height made of grey plastic. This resembled a person in that it had a head, eyes, arms, hand-like grippers, and a body. It moved about on wheels normally not visible; (II) a micro computer of a type used in class; (III) an ordinary pink plastic doll; (IV) the experimenter, who served as an example of the category "person". Procedure Prior to the experiment children were familiarised with the test objects in a room separate from the classroom. Subjects were given a brief demonstration of the programmable nature of the robot. After stating "I'm going to tell the robot to turn in a circle and then go backwards</page><page sequence="4">368 M. VAN DUUREN &amp; M. SCAIFE across the room" a remote control was used to issue instructions for the robot to turn through a 360 degree circle followed by reversing in a straight line. Subjects were tested individually in the same room after the familiarisation procedure. Subjects were shown standard Polaroid colour photographs "to remind you of the objects you saw yesterday" and told they would be asked a number of questions about these objects. Older participants were told that some of the questions might sound a little obvious to them, but that young children needed to answer the same questions and might not find this to be the case. Subjects were first asked for yes/no judgements e.g., "Can the robot (test-object) think (brain-related item) all by itself?" If in addition subjects were asked to justify their response (see Table I ) this was done immediately afterwards. Questions were presented in a randomised order and interviews were audio-tape recorded. Table 1 Brain related items questioned on, by test-object and behavioural category. For item-object combinations marked (*) justifications were asked Behavioural category Target object Mental act Emotional School based task Simple motor Sensory Involuntary Robot dream* feel sad* read* walk* see* cough* Computer be clever* feel cold count talk hear sweat Doll think* remember feel sleepy spell grab smell having a fever Person dream* be clever* remember feel sad* grab* see Correspondence analysis A correspondence analysis of frequencies of the 12 descriptive categories was carried out with age as independent variable. Correspondence analysis, a technique widely used by French investigators, is based on chi-square tests and allows for the factoring of qualitative data, similar to factor analysis and a graphical representation of the solution (e.g., Greenacre, 1985; van IJzendoorn &amp; Kroonenberg, 1988; van IJzendoorn, Goldberg, Kroonenberg, &amp; Frenkel, 1992). Results Yes/no type judgements All participants were able to identify the test-objects correctly from the photographs. Table 2 shows subject's "yes/no" judgements as to whether the test-object questioned on is capable of realising a brain-related item by itself. Clearly there is considerable clarity across the age-range with respect to the objects at opposite ends of the anthropomorphic scale: the person and the doll, with remarkably few "animistic" attributions made by young children to the doll. Surprisingly, some doll-item com binations were judged positively by a small number of adults. However, from the justifications given for these items it was evident that the doll had been mistaken for a more sophisticated programmable-mechanical object.</page><page sequence="5">CHILDREN'S ATTRIBUTIONS TO INTELLIGENT ARTEFACTS 369 Table 2 r ercentage of brain related items (aggregate) attributed to different objects by age Target object Age group Person Robot Computer Doll 5-Year olds 100 30.1 4.1 1.6 7-Year olds 100 42.6 17.6 0.3 11-Year olds 99.2 46.5 27.3 0.8 Adults 100 40.9 28.8 2.3 Mean 99.8 40.0 19.5 1.3 A remarkably less homogenous picture is evident as regards the two complex artefacts, the robot and computer. Firstly, fewer than half of the subjects in any age cohort claimed either the robot or computer had the capacity to execute a brain-related item by itself. Of those who did 5-year olds (¬ø"-=6.24, df=l,/?&lt;.05), but not 7-year olds (j2=0.04, df=l, ns), attributed significantly fewer items to the robot than the older remainder of the subjects. As regards the computer 5-year olds {f2=5\.43, df=l,/?&lt;001) as well as the 7-year olds (jp=7.1, df= 1, p&lt;.01 ) attributed it with significantly fewer brain related items than the older remainder. 5-year olds also attributed fewer brain-related items to the computer than 7-year olds (j2=25.7, df=l, /j&lt;.001). Table 3 shows the extent to which items from the different categories were attributed to the robot and computer. Most notable is the small number of mental acts items accorded by the youngest children to the computer compared to the robot. This may suggest that for this age group mental acts are more readily associated with a robot's motor-behavioural repertoire than with a computer's cognitive repertoire. Across the age range the robot rather than the computer was deemed capable of realising items from the categories of simple motor acts, sensory activity, feeling states, and involuntary behaviour (see Table 3). A surprisingly large number of simple motor - and sensory activity items were attributed by adults to the comput er. From justifications given it transpired that these adults argued that the computer could be equipped with specific accessories (e.g., a camera) which in fact would turn it into a robot. Table 3 Percentage of brain related items attributed to Robot and Computer, by individual item cate gory and age group Age group Behavioural category Target object 5-Year olds 7-Year olds 11-Year olds Adults Mental acts Robot 21.3 33.8 40.0 21.3 Computer 6.3 38.8 51.3 23.8 School based tasks Robot 18.3 29.3 35.0 43.4 Computer 11.7 28.3 38.3 51.7 Simple motor acts Robot 45.0 60.0 68.3 61.7 Computer 0.0 3.3 6.7 16.7 Sensory activity Robot 28.3 31.0 20.0 31.7 Computer 1.7 5.0 5.0 28.3 Feeling states Robot 16.7 18.3 13.6 10.0 Computer 3.3 5.0 11.7 6.7 Involuntary acts Robot 10.0 5.0 11.7 8.3 Computer 0.0 1.7 5.1 6.7</page><page sequence="6">370 M. VAN DUUREN &amp; M. SCAIFE Justifications No systematic pattern was evident where type of judgement (i.e., "yes" or "no") could predict the type of justification given, hence all judgement responses were grouped together for subsequent analysis. Justifications elicited from questioning on all four test objects result ed in a classification scheme with 12 codable categories. These were as follows: Responses were classified as simple brain references if the test object was thought (in) capable of realis ing the item because it had a brain or a simply qualified brain (e.g., a real-, sort of-, or wire brain). Realness status captures explanations based on the subject's concern with whether the test object was real enough to realise the item. Material composition indicates reasons based on the material the test object was made of; human attribute - or artefactuai attribute reflect reasoning based on the presence (or absence) of a physical human attribute other than a brain or some additional artefact (e.g., "the robot could walk if it had the programs to walk"); per ceptual factors classify reasons based on the test object looking or sounding "right" for item realisation; three different forms of causal reasoning were coded: intentional causality refers to the test-object's intention to cause the target behaviour; vitalistic causality suggests that the target behaviour is caused by the agency of an individual organ or component; mechanistic causality refer to instances thought to cause the target behaviour including (I) general physio logical mechanisms, (II) brain as specific physiological mechanism, (III) human act of pro gramming; mentalist attribute captures any reference made to the role played in item realisa tion by mental aspects the test-object was (not) deemed to have (e.g., cognitions, emotions); finally conceptual classification refers to the object's (lack of) membership of a specified super ordinate class as a reason for item-realisation. Inter-rater reliability measures, indicating high inter-coder reliability, where calculated for each of the four age-groups separately as well as for the total sample, producing the fol lowing measures expressed as Cohen's (1968) Kappas: 0.87 (overall ages); 0.97 (5-year olds); 0.85 (7-year olds); 0.85 (11-year olds); 0.81 (adults). Of the four test subjects the average cumulative inertia of the first two dimensions, of a three dimensional solution, explained 94% of the solution allowing for the age - and category variables to be satisfactorily displayed in a two dimensional Correspondence Analysis solution (see Figures 1-4). Generally, for all four test objects the justification patterns of why a particular test object is (is not) able to realise a specified brain related behaviour (e.g., "can the robot walk all by itself?") are importantly similar. In all cases the horizontal dimension is equatable with "age" clearly separating the youngest children from adults with the two middle age groups clustered more closely together. Firstly, more specifically, regarding the justification patterns of robot and computer, (see Table 4 and Figures 1 and 2) the 5-year olds either claimed not to know or based their justifi - cation on whether the object was perceived as "real" (e.g., "the robot can't see all by itself cause it's not real"). By contrast adults' reasons included: explicit cognitive/mentalistic refer ences (e.g., "a computer can't dream because it has no imagination"); referring to the concep tual status of the object (e.g., "the robot can't cough by itself because it is a mechanical object"); and finally reasons based on mechanical causality including: (I) more general (e.g., "the computer can think all by itself because it can produce results that have not been fed into it"), (II) explicit reference to the brain's role ("the computer can't be clever cause it does not have a brain to help it think"), (III) the specific act of programming (e.g., "the robot can walk all by itself if it had been programmed"). Although few such explicit references to the brain's role were mentioned across the age range there were quite a few simple brain references (see Table 4) suggesting, in line with pre vious findings that a number of children, some as young as 5-years, did apparently regard the clever artefacts in some sense as "cognitive" (Scaife &amp; van Duuren, 1995). Justifications based on the object's lack of a human attribute (other than a brain) were popular throughout the age range but were more frequently given regarding the computer than the robot (see Table 4). This suggests a representation of a computer as a robot minus its sen sory or motor features (e.g., "the computer can't read because it has no eyes").</page><page sequence="7">CHILDREN'S ATTRIBUTIONS TO INTELLIGENT ARTEFACTS 371 Table 4 Reasons why a target object is (not) capable of realising a specific brain related activity (per centages) Target object Robot Computer Reason category 5y 7y lly adts 5y 7y lly adts a. Don't know 13.4 1.2 1.1 0.0 15.8 0.0 3.4 0.0 b. Simple brain reference 7.6 14.4 10.6 3.1 9.2 10.0 4.6 5.3 c. Realness status object 29.2 8.4 7.3 0.6 16.4 3.0 0.0 0.6 d. Material composition object 4.4 1.8 5.0 0.0 2.0 1.1 0.6 0.0 e. Human attribute 9.6 8.9 6.1 6.9 36.1 32.5 31.4 13.5 f. Perceptual factors 0.0 1.2 1.7 0.0 0.0 0.6 1.1 0.0 g. Artefactual attribute 6.4 4.7 6.7 3.2 2.0 4.7 6.8 15.8 h. Intentional causality 12.7 15.0 5.0 3.8 6.5 9.5 13.8 1.2 i. Vitalisitic causality 6.3 13.1 8.9 3.8 2.0 10.1 3.4 1.2 j. (I) Mechanistic causality: Brain 5.7 21.0 8.9 17.6 6.5 15.3 8.0 9.4 (11) Mechanistic causality: General 0.0 0.0 3.3 0.0 0.0 3.0 1.7 1.2 (III) Mechanistic causality: Programming 0.0 1.2 14.2 21.4 0.0 0.0 9.1 18.8 k. Mentalist attribute 1.3 7.2 13.5 22.9 1.3 7.1 10.9 18.8 1. Conceptual classification 3.2 3.0 7.8 17.6 2.0 3.0 7.4 14.1 Total % 100 100 100 100 100 100 100 100 Target object Person Doll Reason category 5y 7y lly adts 5y 7y lly adts a. Don't know 8.5 0.0 0.0 1.1 13.6 0.0 2.3 0.0 b. Simple brain reference 10.9 14.4 16.5 7.7 9.6 14.4 20.4 16.7 c. Realness status object 41.4 10.3 2.9 0.0 39.6 12.2 14.1 3.0 d. Material composition object 2.4 0.0 0.0 0.0 11.0 20.6 15.8 0.6 e. Human attribute 9,-8 8.2 6.8 6.6 3.2 4.4 5.1 10.7 f. Perceptual factors 1.2 2.1 1.0 0.0 0.6 0.6 2.3 0.0 g. Artefactual attribute 1.2 2.1 0.0 0.0 1.9 0.0 1.7 5.9 h. Intentional causality 9.8 25.8 20.3 2.2 8.4 16.7 5.6 1.8 i. Vitalisitic causality 9.8 14.4 2.9 0.0 7.1 13.3 6.2 0.6 j. (1) Mechanistic causality: General 2.4 3.1 3.9 37.4 0.6 5.5 6.2 2.4 (11) Mechanistic causality: Brain 0.0 2.1 9.7 5.4 0.0 2.2 4.0 1.8 (III) Mechanistic causality: Programming 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 k, Mentalist attribute 0.0 6.2 16.5 31.8 0.6 2.8 5.0 20.2 1. Conceptual classification 2.4 11.3 19.4 7.7 3.2 7.2 11.3 36.3 Total % 100 100 100 100 100 100 100 100</page><page sequence="8">372 M. VAN DUUREN &amp; M. SCAIFE a ¬´5 yrs 0 e '^adults k j d g V b i ‚ô¶ 11 yrs yrs f -¬°&gt;0 -1.5 -1.0 -.5 00 .5 1.0 1.5 10 Figure 1. Robot 5 yrs ‚ô¶ adults ‚Ä¢t j k d b e 7 h&lt; i ^1 yrs ^yrs f -10 -1.5 -1.0 -.5 0.0 .5 1.0 1.5 10 Figure 2. Computer d 3 5 urs e j^adults k b g i 7 yr f h s V yrs 1 i ‚ñ† ‚ñ† 1 1 ‚Ä¢ LO -1.5 -to -.5 ao S 1.0 1.5 zo Figure 3. Person a ^5 yrs C 9 adults ‚ô¶ 1 k 9 K hdf 4 1 ‚ô¶ 7 yrs b hi yrs i ‚ñ† 10 -1.5 -1.0 -.5 ao .5 1.0 1.5 ¬£0 Figure 4. Doll Key: Reason category a: Don't know g: Artefactual attribute b: Simple brain reference h: Intentional causality c: Realness status object i: Vitalisitic causality d: Material composition object j: Mechanistic causality e: Human attribute k: Mentalist attribute f: Perceptual factors 1: Conceptual classification Figures 1-4. Two dimensional Correspondance Analysis solution of age and reason category for different target objects Regarding the different types (psychological-intentional, vitalistic, and mechanistic) of causal reasoning used it can be seen from Tables 4 and Figures 1 and 2 that intentional causal ity is indeed more associated with the younger age groups the 5-and 7 year olds especially in the case of the robot (e.g., "the robot is not clever cause it can't move all by itself'). Vitalistic reasoning (e.g., "the robot can be sad cause it can pull its mouth down") would seem more closely associated with the middle aged groups than the age groups at both extremes, though it can not be said that it is more typical of the older children than the previous causal explana</page><page sequence="9">CHILDREN'S ATTRIBUTIONS TO INTELLIGENT ARTEFACTS 373 tion. Mechanical causality however is, as expected, more closely tied with the adult reasoning. An interesting shift occurs between the two middle aged groups: whilst 7-year olds and 11 year olds make roughly to the same degree reference to mechanical causality, the older chil - dren, similar to adults, prefer to talk about the act of programming ("the robot can see cause it is programmed not to walk into things") rather than general references to causal mechanisms ("the computer can't think all by itself cause it needs to be switched on"). This relatively late awareness of the purpose of programming was found previously (Scaife &amp; van Duuren, 1995; van Duuren &amp; Scaife, 1995). Secondly, concerning person and doll (see Tables 4 and Figures 3 and 4) intentional causality declines with age but interestingly this form of reasoning when applied to person remains more prominent with the oldest school aged children ("a person can be clever because he can do anything"). Again consistent with the findings of Inagaki and Hatano (1993) vitalis - tic causality peaks at 7-years for both doll and person. Although mechanistic causality as a form of reasoning appears to increase with age, the remarkable exception are the adult justifi cations directed at the doll, which appear to favour judgements based on conceptual status of the object ("the doll can't walk cause it is a toy") rather than reasoning based on mechanistic causality ("the doll can't grab something all by itself cause it does not have an independent mind"), the opposite is true for the test object person. This is not surprising since conceptual classification in the case of person would be apt to lead to a tautologous statement, for exam ple, "the person can (e.g., walk) because he is a person"! The doll was more likely to draw reasons for item realisation which referred to the mater ial it is made of, the fact that 5- and 7-year olds used this type of reasoning substantially less with regard to the intelligent artefacts may suggest that the latter were regarded as more com - plex. Similarly subjects, across the age range, used more reasons based on the absence of a brain with regards the doll than computer and robot, this may be another indication that the latter objects were seen as having a more problematic status. Discussion The present study examined young children's willingness to judge objects, occupying different places along an animate-inanimate continuum, in terms of their ability to realise items from different categories of brain-related behaviour. Compared to the person and doll the robot and computer were regarded more ambiguously, with subjects in the older age groups being markedly divided as to whether these objects could realise target items by them selves. In contrast, the two younger age-groups appeared more certain that these intelligent artefacts could not realise target items: for the robot the most salient age differences being between the 5-year olds and older subjects, and for the computer, between 5- and 7-year olds and the older remainder. The earlier preference to view the robot, rather than the computer, as capable of realising brain-related items is consistent with earlier findings (Scaife &amp; Van Duuren, 1995) and may indicate that a capacity for motor-behaviour is seen as more likely to be associated with brain functioning, at least compared to other behavioural categories. With respect to subjects' reasoning underlying these judgements, surprisingly little differ ence was found between objects importantly different in their anthropomorphic features. It would appear that conceptually the traditional artefact (doll) was not generally represented dif ferently from the complex ones (robot and computer) used in this study. There were two major exceptions to this. 11-year olds begin to show an understanding that complex artefacts such as computers and robots need, for their realisation of specific input-output relationships (e.g., inputting and getting the answer to an arithmetic problem on a computer), the intervention of human programming to establish some of the feats usually requiring a brain. Secondly, adults were much more likely to appeal, in the case of the doll, to its status as a kind of object in the world among other kinds of objects, whereas in the case of the computer and robot explana tions would centre around notions of causal mechanisms.</page><page sequence="10">374 M. VAN DUUREN &amp; M. SCAIFE All three forms of causal reasoning (person (object)-intentional, vitalistic, mechanical) previously reported in children's judgements of more traditionally inanimate or animate objects were also employed across all target-objects including the robot and computer. Although the above forms of reasoning were used across the whole age range, a developmen tal pattern reported earlier (e.g., Inagaki &amp; Hatano, 1993; Hatano&amp; Inagaki, 1994) was evi dent: the two youngest age groups were more likely to favour person (object)-intentional and vitalistic forms of causal reasoning; the two oldest age groups tended to use mechanical causality where (bodily) processes are mediated by specified input-output relationships. Most notably, in the cases of the robot and computer, programming intervention began to be used by the age of 11. These findings need to be considered in the light of evidence that young children first associate the brain with mental properties rather than any other behavioural forms (Johnson &amp; Wellman, 1982) and that prior to understanding biology as a series of physiological processes, children assign agency to individual parts on a one-(body) part-one-function fashion (e.g., Carey, 1985). Firstly, it would appear entirely consistent that in view of young children's lack of biological knowledge, where the brain's role in connection with all behaviour is under stood, they are most likely to associate the brain with cognitive behaviour. Without this knowledge other parts/organs must be seen as carrying the "responsibility" for their own func tioning. Secondly, in the course of children's everyday existence there are numerous media (mis)representations' which appear to reinforce the one-body-part-one-function notion. Examples here include stories like "Iron Man" a popular children's story by Ted Hughes, the poet laureate, in which after falling apart a robot begins to re-assemble itself when the leg starts to hop around and bumps into the eye, after which together they effectively look for the other body parts. Other examples include children's early learning books (e.g., Oakley, 1995), were anatomy is explained on a organ by organ basis, each organ explained in terms of con trolling its own function. A further word of caution is needed, it may of course be that young children have an implicit understanding without being able to explicitly verbalise this (e.g., Gelman 1979; Inagaki &amp; Hatano, 1993). Indeed the frequent references made by the youngest children to the alleged (or lack of) realness status of an object in realising the targeted behaviour may mask the child's actual understanding of underlying mechanisms. The understanding of artificially intelligent devices may not comprise of a separate domain of the child's understanding, it is however clearly central to a complete understanding of animate-inanimate distinctions and therefore also related to developing concepts of alive and of biology (Carey, 1985). More specifically, in the way in which an increased understand ing of the role of the brain in all behaviour is likely to establish a more independent domain of knowledge, so to does an understanding of for example the role of human programming lead the child to a different picture of the behaviour of intelligent artefacts. References Astington, J.W., &amp; Gopnick, A. (1988). Knowing you have changed your mind: Children's understanding of representa tional change. In J.W. Asington, P.L. Harris, &amp; D.R. Olson (Eds.), Developmental Theories of Mind (pp. 193 -207). Cambridge: CUP. Backscheider, A.G., Shatz, M., &amp; Gelman, S.A. (1993). Preschooler's ability to distinguish living kinds as a function of regrowth. Child Development, 64, 1242-1257. Boden, M.A. (1977). Artificial Intelligence and Natural Man. Hassocks: Harvester press. Carey, S. (1985). Conceptual Change in Childhood. Cambridge, MA: MIT Press. Cohen, J. (1968). Weighted kappa: Nominal scale agreement with provision for scaled disagreement or partial credit. Psychological Bulletin, 70, 213-220. Contento, I. (1981). Children's thinking about food and eating: A Piagetian based study. Journal of Nutrition Education, 13, 86-90.</page><page sequence="11">CHILDREN'S ATTRIBUTIONS TO INTELLIGENT ARTEFACTS 375 Frye, D., Rawling, P., Moore, C., &amp; Meyers, L. (1983). Object-person discrimination at three and 10 months. Developmental Psychology, 19, 303-309. Gellert, E. (1962). Children's conceptions of the content and functions of the human body. Genetic Psychology Monographs, 65,291 -411. Gelman, R. (1979). Preschool thought. American Psychologist, 34, 900-905. Gelman, R., &amp; Spelke, E.S. (1981). The development of thoughts about animate and inanimate objects: Implications for research on social cognition. In J.H. Flavell &amp; L. Ross (Eds.), Social Cognitive Development: Frontiers and Possible Futures (pp. 43-67). Cambridge: Cambridge University Press. Greenacre, M. (1985). Theory and applications of correspondence analysis. London: Academic Press. Hatano, G., &amp; Inagaki, K. (1994). Young children's naive theory of biology. Cognition, 50, 171-188. Inagaki, K. (1993). Young children's differentiation ofplants from non-living things in terms of growth. Paper presented at the 60th meeting of the Society for Research in Child Development, New Orleans. Inagaki, K., &amp; Hatano, G. (1993). Young children's understanding of the mind-body distinction. Child development, 64, 1534-1549. Johnson, C.N., &amp; Wellman, H.M. (1982). Children's developing conceptions of the mind and brain. Child Development, 53, 222-234. Keil, F. (1991). Concepts, kinds, and cognitive development. Cambridge, MA: MIT Press. Legerstee, M. (1992). A review of the animate-inanimate distinction in infancy: Implications for models of social and cognitive knowing. Early Development and Parenting, 2, 59-67. Massey, C., &amp; Gelman, R. (1988). Preschoolers' ability to decide whether a photographed familiar object can move itself. Developmental Psychology, 24, 307-317. Oakley, M. (1995). Sharks. Loughborough: Ladybird. Piaget J. (1926). The child's conception of the world. London: Routledge &amp; Keegan Paul. Piaget J. (1954). The Construction of reality in the child. New York: Basic Books. Resnick, M., &amp; Martin, F. (1991). Children and Artificial Life. In 1. Harel &amp; S. Papert (Eds.), Constructionism (pp. 41 -71). New Jersey: Ablex. Scaife, M., &amp; van Duuren, M.A. (1995). Do computers have brains? What children believe about intelligent artefacts. British Journal of Developmental Psychology, 13, 367-377. Searle, J. (1990). Is the brain's mind a computer? Scientific American, January, 1990. Turkle, S. (in press). Romantic reactions: Paradoxical responses to the computer presence. In M. Sosna &amp; J.J. Sheehan (Eds.), Boundaries of humanity: Humans, animals, machines (pp. 224-252). Berkeley, CA: University of California Press. van Duuren, M.A., &amp; Scaife, M. (1995). How do children represent intelligent technology? European Journal of Psychology of Education, 10, 289-301. van IJzendoorn, M.H., &amp; Kroonenberg, P.M. ( 198.8). Cross-cultural patterns of attachment: A meta-analysis of the strange situation. Child Development, 59,147-156. van IJzendoorn, M.H., Goldberg, S., Kroonenberg, P.M., &amp; Frenkel, O.J. (1992). The relative effects of maternal and child problems on the quality of attachment: A meta-analysis of attachment in clinical samples. Child Development, 63, 840-858. Wellman, H., &amp; Gelman, S.A. (1992). Children's understanding of the non-obvious. In R.J. Sternberg (Ed.), Advances in the Psychology of Intelligence (vol. 2, pp. 60-78). Hillsdale: Erlbaum. Wimmer, H., &amp; Perner, J. (1983). Beliefs about beliefs: Representations and constraining function of wrong beliefs in young children's understanding of deception. Cognition, 13, 103-128. Les situations √©ducatives utilisent de plus en plus d' "artefacts" intelligents. Les objets tels que les ordinateurs et les robots occupent une place particuli√®re sur le continuum anim√©-inanim√© du fait de leurs r√©pertoires "cognitif et "sensori-moteur". Ils sont par exemple dot√©s d'une m√©moire et capables de traiter une grande diversit√© de t√¢ches en r√©solution de probl√®mes. La recherche pr√©sent√©e concerne la com pr√©hension qu'ont les enfants d'une vari√©t√© d'objets-stimulus pr√©sentant diff√©rentes caract√©ristiques anthropomorphiques: une personne, un</page><page sequence="12">376 M. VAN DUUREN &amp; M. SCAIFE robot, un ordinateur et une poup√©e. On a sollicit√© les jugements attribu tifs de 60 enfants √¢g√©s de 5 √† 11 ans et compar√© ces jugements √† ceux d'un groupe d'adultes. On a demand√© aux enfants de juger (avec justifi cations) la capacit√© des objets ci-dessus √† avoir toute une s√©rie de com portements regroup√©s en six cat√©gories principales (par ex. agir involontairement). Les donn√©es montrent que, d'une fa√ßon g√©n√©rale, les diff√©rents objets ne sont pas √† l'origine de diff√©rences substantielles dans les patterns de justifications. On observe cependant une nette √©vo - lution li√©e √† l'√¢ge de la compr√©hension de la nature des "artefacts" intelligents. Les r√©sultats sont discut√©s en termes de diff√©rentes formes de raisonnement causal. La nature sp√©cifique des actes de programma tion est discut√©e en termes d'accroissement de la compr√©hension du comportement des artefacts intelligents. Key words: Animate-inanimate continuum, Causal reasoning, Input-output relationships, Intelligent artefacts, Naive epistemologies. Received: September 1995 Revision received: December 1995 Mike van Duuren. Psychology Group, School of Science, Technology and Design King Alfred's College, Winchester S022 4NR, Hants, United Kingdom. Current theme of research: Media (mis)representations of intelligent technologies and children's cognitions. Most relevant publications in the field of Educational Psychology: van Duuren, M.A. (1994). The use of intelligent technology at home and at school: What do parents think? British Journal of Educational Technology, 25, 231-233. van Duuren, M.A., &amp; Scaife, M. (1995). How do children represent intelligent technology? European Journal of Psychology of Education, 10, 289-301. Scaife, M., &amp; van Duuren, M.A. (1995). Do computers have brains? What children believe about intelligent artefacts. British Journal of Developmental Psychology, IS, 367-377. Mike Scaife. Psychology School of Cognitive and Computing Sciences, University of Sussex, Brighton, BN 1 9QH, United Kingdom. Current theme of research: Application of a theory of external representation for designing and evaluating interactive information and innovative technologies. Most relevant publications in the field of Educational Psychology: Scaife, M., &amp; Taylor, J. (1991). Graduated learning environments for developing computational concepts in 7-11 year old children. Journal of Artificial Intelligence in Education, 2, 1-42. Scaife, M., &amp; van Duuren, M.A. (1995). Do computers have brains? What children believe about intelligent artefacts. British Journal of developmental Psychology, 13, 367-377. Scaife, M., &amp; Rogers, Y. (1995). External Cognition: How do graphical representations work? International Journal of Human-Computer Interaction. (In press).</page></plain_text>
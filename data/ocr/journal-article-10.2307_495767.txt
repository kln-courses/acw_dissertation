<plain_text><page sequence="1">WILLIAM C. WIMSATT SOME PROBLEMS WITH THE CONCEPT OF 'FEEDBACK' The concept of 'feedback', originally a technical term of cybernetics, has been so widely applied that it has become part of our everyday vocabulary. Though both scientists and philosophers have considered in detail a number of conceptual issues suggested by the perspectives of cybernetics, this basic concept has not yet received the critical attention it deserves. Thus, while Taylor [1-31 Scheffler [4-5], and others have criticized Rosenblueth, Wiener, and Bigelow [6-8] for trying to define 'teleological' behavior in terms of negative feedback, their objections are directed primarily against the use of 'naive' or 'black box' behavioristic assump- tions and the choice of the term 'teleological' to describe the phenomena in question. The concept of feedback is largely accepted by both factions on more or less intuitive grounds. I will use results derived by Kleene [9] in another context to argue that it is not possible to define the concept of feedback solely in terms of the externally observable behavior of a pur- ported feedback system. This result necessitates a look in other directions for possible criteria. Nagel [10], Beckner [1 1-13] and others [4-5] have proposed analyses for 'self-regulating' and 'goal-directive' systems in terms of their internal organization. It seems to be widely supposed that these analyses capture the notion of negative feedback. But I will argue that these criteria fail to distinguish between negative feedback systems and any open system tending to steady-state equilibrium. I. FEEDBACK AND BEHAVIOR In attempting to make a place for purpose and teleological language in the scientific description of physical systems, Rosenblueth, Wiener, and Bigelow overtly espouse an almost paradigmatic description of naive behavioristic aims and approaches: ([6], pp. 19-20). Given any object, relatively abstracted from its surroundings for study, the behavioristic approach consists in the examination of the outputs of the object and of the relation Boston Studies in the Philosophy of Science, VIII. All rights reserved.</page><page sequence="2">242 WILLIAM C. WIMSATT of this output to the input. By output is meant any change produced in the surroundings by the object. By input, conversely, is meant any event external to the object that modifies the object in any manner. The above statement of what is meant by the behavioristic method of study omits the specific structure and intrinsic organization of the object. This omission is funda- mental, because on it is based the distinction between the behavioristic and the alternate functional method of study. In a functional analysis, as opposed to a behavioristic approach, the main goal is the intrinsic organization of the entity studied, its structure and its properties; the relations between the object and its surroundings are relatively incidental. ... By behavior is meant any change of an entity with respect to its surroundings... any modification of an object detectable externally may be denoted as behavior. This position is reaffirmed in their reply to Taylor (1) some seven years later: ([7), p. 323). ... if the term 'purpose' is to have any significance in science, it must be recognizable from the nature of the act, not from the study of or from any speculation on the structure and nature of the acting object. In spite of increasingly widespread dissatisfaction with naive behaviorism in general, and among philosophers, with the proposed analysis of teleolo- gical behavior, neither philosopher' nor scientist has seen fit to examine the authors' definition and use of the concept of feedback within this framework of behavioristic analysis. The concept of feedback is accepted in the same spirit as it is used - uncritically and intuitively. For the authors, teleological behavior is behavior controlled by nega- tive feedback, and they characterize feedback as follows: ([61, p. 18). in a broad sense, it may denote that some of the output energy of an apparatus or machine is returned as input; an example is an electric amplifier with feedback. The feedback is in these cases positive2 - the fraction of the output which re-enters the object has the same sign as the original input signal. Positive feedback adds to the input signals, it does not correct them. The term feedback is also employed in a more restricted sense to signify that the behavior of an object is controlled by the margin of error at which the object stands at a given time with reference to a relatively specific goal. The feedback is then negative, that is, the signals from the goal are used to restrict outputs which would otherwise go beyond the goal. It is the second meaning of the term feedback that is used here. By non-feedback behavior is meant that in which there are no signals from the goal which modify the activity of the object in the course of the behavior. ([6], pp. 19-20). If the authors are going to define teleological behavior in terms of negative feedback, and simultaneously adhere to their behavioristic assumptions, then they must also be prepared to give behavioristic criteria for when a</page><page sequence="3">THE CONCEPT OF 'FEEDBACK' 243 system uses or contains feedback or negative feedback loops. There are two ways in which this might be done:3 (1) Feedback might be directly observable in the behavior of a system. (2) The presence of some behav- ioral pattern or sequence might entail that the system in question is a feedback system. Since (1) implies (2), but not conversely, and I wish to deny (2), I will concentrate on the second possibility. Rosenblueth, Wiener, and Bigelow have made it eminently clear that they are not interested in the internal structure of a system, but only in its externally observable behavior.4 But even the standard diagrams of feedback systems (see Figure 1) characteristically represent feedback loops as wholly or partially internal features of the system.5 system f orward power boundaries path input input from~ comparrator l mver utput environment l I environment 0 feedback tc0 li detector E stabilizing or l controlling network a . (if it exists) l Lo -j ~~~~~--J feedback E=100 path 80 A ) 1 JAB Fig. 1. Diagram of a generalized single-loop negative-feedback mechanism. (Note: This diagram is taken, in slightly modified form from L. K. Frank, G. B. Hutchinson, W. K. Livingston, W. S. McCulloch, and N. Wiener (eds.), Teleological Mechanisms; Annals of the N. Y. Academy of Sciences, v. 50, art. 4, pp. 187-278 (October 13, 1948). See p. 192. The energy flow of the power input was added to the figure found there.) Diagrams can be misleading however. Fortunately, there are strong grounds which do not depend upon diagrams for saying that no externally observable behavior patterns could entail that the system in question contains feedback loops.6</page><page sequence="4">244 WILLIAM C. WIMSATT In 1943, McCulloch and Pitts proposed a simplified logical model of the neuron, since widely known as the 'McCulloch-Pitts' neuron, (16). This 'neuron' is a generalized logical element of two-valued logic, and the aim of McCulloch and Pitts was to develop a model which bore some resemblance to the biological neuron and which, through its immediate connections with symbolic logic, could be easily manipulated to determine the behavior of interconnected networks of these neurons. Their assump- tions and some examples of simple networks of these neurons are given in Figure 2. Their formal results were corrected and extended in 1956 by S. C. Kleene [9]. Among other things, his work implies that any input-output matrix for finite sequences of discrete events with a definite temporal (a) 1 threshold :2excitatory simple cycles: threshold 2 (endbulbs (e) (t\&amp; 1 positive feedback Ks n 2 inhibitory som rendbulbs, (f 2 negative feedback logical operations: (b) (c) (d) AW A A~B A- negation: conjunction: disjunction: Fig. 2. The McCulloch-Pitts Logical Model of the Neuron. 2a: The generalized McCulloch-Pitts Neuron. It has a 'threshold', k, (1 &lt; k &lt; ox); m 'excitatory endbulbs', (O &lt; m &lt; co); and n 'inhibitory endbulbs', (O &lt; n &lt; co). The laws of behavior of these neurons are as follows: (1) If it fires at all, the neuron fires only at integral values of time, i.e., for t = 1, 2,... (2) The conditions for firing of the neuron at t is as follows: (a) No inhibitory endbulb of a neuron which fired at t -1 ends on its soma, (b) k or more excitatory endbulbs belonging to neurons which fired at t -1 end on its soma. The basic logical operations can be accomplished by interconnected nets of these neurons. Thus, the operation of negation is performed by the net of figure 2b, the operation of conjunction by that of 2c, and the operation of disjunction by that of 2d. From these facts, it follows that any well-formed formula in the propositional calculus can be represented by operations in a net of McCulloch-Pitts neurons. Two particularly simple 'circles' or 'cycles' in nets of these neurons are represented in Figures 2e and 2f. Figure 2e is a case of positive feedback and Figure 2f is a case of negative feedback.</page><page sequence="5">THE CONCEPT OF 'FEEDBACK' 245 starting point such that the events can each be characterized by a finite number of variables, each of which can take only a finite number of values, can be produced by an appropriate net of McCulloch-Pitts neurons.7 This means, essentially, that any 'black box' input-output behav- ior matrix (with some qualifications to be discussed later) can be produced by some net of McColloch-Pitt neurons. Kleene also proved ([9], p. 10, Theorem 1) that any of these input-output matrices can be produced by a net which contains no 'circles'. But 'circles', in McCulloch and Pitts' terminology are what would generally now be called 'feedback loops'. But if any behavior matrix could be realized by a net which contains no such loops, then no input-output matrix entails that the system in question contain feedback loops, either positive or negative. It would thus seem to be impossible to define feedback in behavioristic terms. There are some limitations on this conclusion, none of which seems to be serious: (a) the restriction to a finite number of variables; (b) the restriction of each of these variables to a finite number of values; (c) the assumption that processes are deterministic, rather than probabilistic; (d) the assumption that the event to be described has a well-defined start- ing time; and, (e) the limitation to behavior sequences of finite length. Of these, only (e) (for reasons to be discussed shortly) might be thought to have any connection with the concept of feedback. As a result, there are no reasons to believe that dropping these restrictions would make a behavioristic definition of feedback possible.8 Thus there are intuitive reasons for believing that a behavioristic definition of feedback is im- possible for any class of system - even though it may be difficult or impossible to prove with any rigor. The limitation to behavior sequences of finite length might be thought to be improper for giving a behavioristic definition of feedback for the following reason: The closed nature of a feedback loop makes it possible for the state of the system at a point in the loop to be a causal factor in the state of the system at that place at time A tL later, where A tL is the time it takes for a signal to propagate all of the way around the closed loop. Thus, the presence of a feedback loop establishes a periodic process, where an event at to has effects on the system at times (to+ n A tL) for n = 1, 2, 3 ... - a behavior sequence of potentially infinite length. But on the other hand, there are many systems (of which the simple frictionless</page><page sequence="6">246 WILLIAM C. WIMSATT pendulum is one) whose behavioral description involves a potentially infinite periodic process and which few if any people would say were feedback systems. This alone could thus hardly be a distinguishing feature of feedback systems. Even with the limitations of this result to deterministic discrete-state9 systems and to behavior sequences of finite length, a definite counter- example to the claims that it is possible to define feedback generally in behavioristic terms has been provided. I will assume, on the basis of Kleene's results and the plausibility argu- ments which I have given that it is not possible to define feedback, either positive or negative, in terms of behavioristic criteria alone. What other alternatives are there? II. FEEDBACK AND INTERNAL STRUCTURE In summarizing analyses of goal-directiveness put forth by several writers, Beckner claims ([131, p. 152) that: ...there are differences in detail in the accounts of the organization of goal-directive systems, but the acceptable ones have in common (1) some reference to the power of the system to compensate for environmental changes that might impede the system's progress towards the goal, and (2) some reference to the independence of the variables that define the system and its environment... If conditions (1) and (2) are satisfied, the system is self-regulating by means of feedback. [italics added] He specifically mentions the analyses of Sommerhoff [14] and Nagel [10] in this context, though the characterization given also approximates his own analysis [11 ] and that of Ashby [15]. Most of these authors appear to believe that they have captured the notion of feedback - or more specifi- cally, that of negative feedback. These analyses differ from that of Rosen- blueth, Wiener and Bigelow in that they explicitly make use of general abstract features of the internal organization or structure of systems. Of the two requirements mentioned, the first presumably captures the 'compensatory' behavior of negative feedback systems. The second is intended to rule out compensatory behavior in systems which are too simple to be regarded as feedback systems, such as simple pendulums. This latter condition basically requires that there be two logically inde- pendent but causally related variables in the system in addition to envi- ronmental variables.10 As all of the systems to be considered below meet this requirement of independence, I will not mention it further.</page><page sequence="7">THE CONCEPT OF 'FEEDBACK' 247 There are two phenomena most frequently invoked in analyses of 'goal- directive' systems. While both are characteristic of feedback control systems, I will show shortly that they are also features of simple open systems in their approach to steady-state equilibrium. The first is that a system may be capable of reaching the same set of equilibrium values for its state variables from an arbitrarily large range of different initial values of the state variables. (This is the primary feature of Braithwaite's analysis [18], which will not be discussed further here.)'1 Von Bertalanffy has christened this phenomenon 'equifinality' [19], and both he and Kacser [201 have given formal analyses of this phenomenon for open systems of the general type which I will claim are not feedback systems. The 'compensatory' phenomenon frequently invoked (see Nagel [10], Beckner, [11], Somerhoff [14], and Ashby [15]) is that changes in one (or more) state variable(s) will be partially or wholly compensated for by changes in one or more other state variables in such a way that the original perturbed variable(s) will be wholly or partially restored to their 'normal' equilibrium values.'2 This phenomenon has been described by Kacser [20] as 'buffering' - a word which is a better clue to its real significance than those employed in the analyses mentioned above. These two features are clearly related. The first describes the effect of the second - that equilibrium can be approached from a variety of initial states, or restored if a deviation occurs. The second gives the mechanism by which this 'equifinality' of non-equilibrium states is brought about: some variables 'take the load' from the 'stressed' variables and allow them to partially or completely approach or regain their 'normal' values. These features, as well as others of interest can be demonstrated in a simple hydrodynamic model involving the flow of water into and out of a pair of interconnected tanks. (See Figure 3) Two cases will be discussed: one which is a feedback system and one which is not. Both examples possess the two features mentioned above. The non-feedback system (Figure 3a) consists of two geometrically congruent tanks of constant cross-section, interconnected by an orifice of area a,, with a water input at the top of one of the tanks at rate r, (t) and an output of magnitude ro (t) through an orifice of area a2 at the bottom of the other tank. Water passes through the connecting orifice at rate r" (assumed to be positive if flow is from the first tank to the second). r, is a</page><page sequence="8">248 WILLIAM C. WIMSATT (a) Steady-state equilibrating system: Reaction diagrams for these systems: h e | I input-i-_-V v2 V----- output hi V, h l ____ al a2 (b) Feedback control system: '~ input rate feedback loop control valve r ~~~~~~~k(h h) r Xs s input-XV, _ output VI V2 ,_r o output rate sensing unit Fig. 3. Hydrodynamic models of feedback and non-feedback systems. 3a: A simple steady-state (non-feedback) system of two components with irreversible input and output. 3b: A Feedback system of two components with irreversible input and output. (Note: The reaction diagrams for these systems indicate the identity and direction of the causal relations between state variables of the system and environment. They are directly analogous to reaction diagrams used in chemical kinetics, which may also be taken as 'causal relation' diagrams.) function of the water levels in the two tanks, h1 and h2, the area of the interconnecting orifice, a,, the gravitational force, g, and a constant of the orifice c1.13 Because of the geometry of the tanks, the volumes of water in the two tanks, V1 and V2, is proportional to the water heights, h1 and h2, and this constant of proportionality has been included in c1 and c2. Using conservation of mass, and standard physical assumptions, the rate equations for changes in V1 and V2 are given by: (1) dV1/dt = r,(t) + galclV2 - galclV1, (2) dV21dt = galcl V - ga1cl V2 - ro (t) The rate of water transport between the two tanks, r,, is clearly (3) rs = ga1clV -ga1clV2 =ga1cl (V1 -V2).</page><page sequence="9">THE CONCEPT OF 'FEEDBACK' 249 The condition of equilibrium of this system is that all of the first-order time derivatives of the state-variables are zero, which is to say that all of the state variables have constant values. The state variables V1 and V2 are constant if and only if their inputs equal their outputs, i.e., if: (4) r1= r8= ro. But ro = ga2c2V2, and substituting for ro and rs (from (3) and (4)) yields: (5) r, = ga1c1 (V1 - V2) = ga2C2 (V2), as the condition of equilibrium. The factors a,, a2, c1, c2, and g may be regarded as system parameters which do not vary under the circumstances considered, so that the only variables to consider are r1, ro, rs, V1 and V2. From (5), V2 is proportional to r1, and the ratio (V, - V2)/V2 is constant at equilibrium. For this to be so, V1 must be proportional to V2, and thus also to r1, and (from (4)), to r, and ro.14 Suppose that this system starts in a non-equilibrium state, with water levels ht and hl in Figure 3a. In this case, V2 is greater than V1, although at equilibrium it is less. Thus rs in equation (3) is negative and there will be a net flow from the second tank to the first until V1 = V2, regardless of what values r, and ro have in the meantime. The direction of flow will then reverse and gradually approach its equilibrium value as V1 and V2 approah theirs. This simple open system thus exhibits both of the features supposed- ly characteristic of goal directive or feedback systems15 (1) The system tends to approach equilibrium values from arbitrary non-equilibrium states, and (2) the system 'buffers', as an unusually high value of V2 has been partially compensated for by an increase in V1. Similar things happen if the system is perturbed the other way from equilibrium or if the value of r, or ro is suddenly changed. Although this system meets the criteria of the analysis mentioned above for feedback systems,16 I suggest that it is not a feedback system. First of all, almost any open system will exhibit this behavior and has this mode of organization. To call this feedback would emasculate that concept. Secondly, there is a closely related system which is a feedback system, and the contrast between these two systems illustrates differences in the way in which 'compensation' occurs. I picked this hydrodynamic example in part because it is a specific</page><page sequence="10">250 WILLIAM C. WIMSATT example of a general class of systems in which there are reversible reac- tions between system variables and transport through the system.17 Such systems are so pervasive in nature that this system cannot be considered to be an isolated case. For example, for each hydrodynamic system of interconnected water tanks, there are isomorphic systems in chemical kinetics and electrical networks which exhibit parallel behavior and abstract organization. They too must intuitively be called feedback systems if we attempt to call such a system a feedback system. The system of Figure 3a can be easily modified so that it is a feedback system. In Figure 3b, a pressure sensor which measures h2 (or V2) is connected to a variable input valve which controls r, in such a way that r,=r* +k(h -h2), where h* is some 'reference value', r" is the value of r, for which h* is an equilibrium value in the system without the feedback loop and k is a positive constant 8. In this manner, deviations of h2 and h2 are counteracted by changes in rl, and the system is a negative feedback system. If k is a negative constant, then deviations from h* are amplified by changes in r1, and the system is a positive feedback system. Corresponding feedback systems are found also in chemical kinetics and electrical networks. Open chemical systems which are autocatalytic and auto-inhibitory are positive and negative feedback systems, respec- tively, as are electrical amplifiers and regulators. What is the difference between the types of 'compensation' exemplified in these two classes of cases? I think that the primary difference is that in the former type of case, 'compensation' is always accomplished via causal relations which are simple inverses. In hydrodynamic, chemical, and electrical cases of the first type, there is a 'net flow' or 'net reaction' rate between one tank, chemical component, or store of electrons and another. Transport can occur in either direction between them, and the net flow or reaction rate can be considered, algebraically and physically, to be the sum of the directed transport rates. The purported 'feedback path' is related to the forward path of the system as the reverse reaction is to the forward reaction in a reversible chemical reaction. These reac- tions are distinct (for otherwise it would be impossible to have irreversible reactions!) but are specially related, which I will signify by saying that they are causal inverses and employ the same causal mechanism. The systems which I have called 'feedback systems' are different how- ever. The 'main' path may involve reversible or irreversible reactions, but</page><page sequence="11">THE CONCEPT OF 'FEEDBACK' 251 in either case, the feedback path is distinct, and can operate even if the system is irreversible in the 'main' path. Unfortunately, while the distinctness of forward and feedback paths is a necessary condition for being able to speak of feedback, it does not seem to be a sufficient condition. Consider the system of Figure 4a: It is an open system, with two branches of transport from I ('input') to 0 ('output') - namely, paths IABCO and IADCO. All of these reactions are assumed to be reversible, as in a chemical system, and the normal flow direction is assumed to be from I to 0 along both paths. There are in this system no closed causal (or material transport) ioops.t But now suppose that there are energy inputs along branch IADCO at point C and D, as diagrammed in Figure 4b. This will in general force conversion of some C into D, and some D into A, such that there will be material conversion and tranport in a closed causal loop, ABCDAB... That is, the direction of flow has been reversed in one of the reaction paths so that a loop is formed out of what had been two parallel paths. I submit (more on intuition than anything else) that this also is not a feedback system, in spite of the fact that there is a closed causal loop and that the forward and reverse paths are not simple causal inverses. This is because it is simply a closed loop of material transport. If the system of Figure 4a is analogized to the hydrodynamic system of 4c, then the system of Figure 4b is directly analogous to that of Figure 4d, where pumps are added to reverse the direction of flow in one of the lines. A number of other strategies of definition could and have been tried. I have not discussed two of the more standard approaches here - to define feedback either in terms of control, or in terms of a flow of information. This is in part because of a belief that these notions are themselves parasitic upon that of feedback, and will be of no help in trying to define it.19 There are several other attempts which could be tried, and I am a (fairly) firm believer that some such attempt will work. Nonetheless, I hope to have shown that offering a definition for feedback is not as trivial or straightforward a task as many writers seem to have assumed. Given the difficulty of defining this concept it cannot automatically be assumed that feedback is a single procise theoretical concept and an objective property of a certain class of systems. Thus, it might be that different definitions will have to be offered for</page><page sequence="12">252 WILLIAM C. WIMSATT (a) - ~~~~ Cc I- A ntflo C-*.0 B pumps (+AE) D ' + (b)*- Cd) ( Fig. 4. Some non-feedback mass-transport systems, with and without closed causal loops of mass transport. 4a: Chemical reaction system with net flow from input (V) to output (0) and parallel flow in both branches. 4b: Chemical reaction system with addition of energy in one branch to reverse direction of flow in that branch and generate a closed loop of material transport. 4c: Hydrodynamic system analogous to 4a. 4d: Hydrodynamic system analogous to 4b. (Note: The relative heights of the tanks in Figures 4c and 4d are not intended to be significant - i.e., assume that the bottoms of the four tanks are all at the same level. The heights of the water in the tanks is significant however. The reactions between chemical components in Figure 4a and 4b are assumed to be reversible. The dominant or net direction of the reactions is given by the solid arrow between components. It is the reversibility of these reactions which makes it possible to reverse the direction of flow between components by adding energy in Figures 4b and 4d.) different classes of systems. Alternatively, Dick Levins has suggested and argued (in personal conversations) that feedback is, in effect, no more than an artifact of our mode of representation of systems - that it is not an objective property of the systems themselves. If this were so, the concept would appear to have no more than a rough 'heuristic' or 'Gestalt' status - as a useful guide in describing the behavior and organization of some systems. Whatever the ultimate status of this concept, it is clear that there are disputes in the sciences which presuppose that a distinction between feed-</page><page sequence="13">THE CONCEPT OF 'FEEDBACK' 253 back control and simpler forms of equilibration is tenable. Thus, in ecology there are disputes over whether animal numbers are controlled by some internal regulatory feedback mechanism or whether constancies in population sizes are due to external factors or to some simple equili- brium process operating within the population. The common presupposi- tion of both sides is that if there is true internal regulation of population size, this trait has been selected for, but not otherwise. While I think in fact that this is a dubious assumption, this matter need not be discussed here. It is clear that it apparently makes a difference to scientists whether a system can be classified as a feedback system or not. This in itself should offer sufficient justification and motivation for continued closer analyses of this concept. University of Chicago AC K NOWLEDGEMENT Some of the work presented in this paper was done during the tenure of a Woodrow Wilson Dissertation Fellowship at the University of Pitts- burgh and a post-doctoral research fellowship with the Committee on Evolutionary Biology at the University of Chicago, supported by the Hinds Fund for Studies in Evolution. I gratefully acknowledge their support. BIBLIOGRAPHY [1] Taylor, R., 'Comments on a Mechanistic Definition of Purposefulness', Phil. Sci. 17 (1950) 310-318. [2] Taylor, R., 'Purposeful and Non-Purposeful Behavior: A Rejoinder', Ibid., 327- 332. [3] Taylor, R., Action and Purpose, Prentice-Hall, Englewood Cliffs, N.J., 1966. [4] Scheffler, I., 'Thoughts on Teleology', Brit. J. Phil. Sci., 9 (1959) 265-84. [5] Scheffler, I., The Anatomy of Inquiry, Knopf, New York, 1963, pp. 110-26. [6] Rosenblueth, A., Wiener, N., and Bigelow, J., 'Behavior, Purpose, and Teleology', Phil. Sci. 10 (1943) 18-24. [7] Rosenblueth, A. and Wiener, N., 'Purposeful and Non-Purposeful Behavior', Phil. Sci. 17 (1950) 318-26. [8] Wiener, N., Cybernetics (2nd revised ed.), M.I.T. Press, Cambridge, Mass., 1961. [9] Kleene, S. C., 'Representation of Events in Nerve Nets and Finite Automata' in Automata Studies (ed. by C. E. Shannon and J. McCarthy), Princeton Univ. Press, Princeton, N.J., 1956, pp. 3-42. [10] Nagel, E., The Structure of Science, Harcourt, New York, 1961, Chapter 12. [11] Beckner, M., The Biological Way of Thought, Columbia Univ. Press, New York, 1959. [12] Beckner, M., 'Teleology', in The Encyclopedia of Philosophy (ed. by R. P. Edwards), Macmillan, New York, 1968, pp. 88-91. [13] Beckner, M., 'Function and Teleology', J. Hist. Biol. 2, 151-64.</page><page sequence="14">254 WILLIAM C. WIMSATT [14] Sommerhoff, G., Analytical Biology, Oxford Univ. Press, London, 1950. [15] Ashby, W. R., Design for a Brain, Wiley, New York, 1952 (2nd revised ed.), 1960. [16] McCulloch, W. S. and Pitts, W. H., 'A Logical Calculus of the Ideas Immanent in Nervous Activity', Bull. Math. Biophysics 5 (1943) 115-33. [17] Simon, H. A. and Rescher, N., 'Cause and Counterfactual', Phil. Sci. 33 (1966) 323-40. [181 Braithwaite, R. B., Scientific Explanation, Cambridge University Press, London, 1953, Chapter 10. [19] BertalanfFy, L. von, 'The Theory of Open Systems in Physics and Biology', Science 111, 23-29, and 'An Outline of General Systems Theory', Brit. J. Phil. Sci. 1, 139-64. [20] Kacser, H., 'Some Physico-Chemical Aspects of Biological Organization', printed as an appendix to C. H. Waddington's The Strategy of the Genes, Macmillan, New York, 1957, pp. 191-249. [21] Grodins, F. S., Control Theory and Biological Systems, Columbia University Press, New York, 1963. [22] Weaver, W., 'Recent Contributions to the Mathematical Theory of Communi- cation', in The Mathematical Theory of Communication (ed. by C. E. Shannon and W. Weaver), Univ. of Illinois Press, Urbana, 1949, pp. 95-117. NOTES 1 Richard Taylor ((1), p. 317) is an apparent exception. He raises doubts concerning the distinction between feedback and non-feedback behavior, but does not give any hard arguments or try to resolve them and later ((3), p. 239) appears to abandon them. 2 The term 'positive feedback' clearly applies only to the example of the electric amplifier, not to the 'broad sense' of feedback. Positive and negative feedback are generally understood as species of the general type, 'feedback'. 3 One can of course fairly simply give good inductive grounds for when a system contains what most people would call feedback loops, but these would not do for a definition of feedback. 4 Their definition of behavior quoted above is ambiguous, since it is not clear that "any change of an entity with respect to its surroundings" will always be a "modifi- cation of an object which is detectable externally." Since most of their examples involve spatial movements, they are probably misled into thinking that the two formulations are equivalent. The first is not a behavioristic definition of behavior, while the second is. I will assume here that they are using the second definition. 5 Strictly speaking, feedback loops are not always wholly internal features of the system in question, though this depends in part on how the system is defined. If the system is a thermoregulating mammal, then the relevant feedback loops are entirely inside the system. If the system is a heat-seeking missile in the act of homing on a heat-source, then part of the feedback loop 'passes through' the environment. In this case, if the system is taken to include the missile and the heat source and their causal relationships then the feedback loop is again entirely internal to the system. The choice of just the missile as the system offers little comfort to the behaviorist, however, for part of the feedback loop, (and thus verification that feedback is involved in the heat-seeking behavior) is internal to the missile, and is thus inaccessible to the behaviorist. This point is generalizable: at least part of the feedback loop is always internal to the feedback system.</page><page sequence="15">THE CONCEPT OF 'FEEDBACK' 255 6 Paradoxically, Wiener himself has in effect acknowledged this for internal structural properties in general. His language is quite misleading however, and he may have led himself down the wrong path. Thus, in his book, Cybernetics, ((8), pp. x-xi) he talks about the synthesis of a 'white box' which is an 'equivalent representation' of an un- known 'black box' merely by performing certain operations on the inputs and outputs of the two boxes, and speaks of this procedure as generating an 'analysis' of the black box. Since the white box is a box of known components and structure, this might seem to promise that one could determine the internal structure of a black box without looking inside it. It is clear from context, however, that 'equivalent representation' merely means, 'has the same input-output function' and that the so-called 'analysis' of the black box is merely a mathematical decomposition of the box's input-output function into a number of mathematical terms or components. As Wiener himself says, later on p. xi, "in this manner we are able to construct a multiple white box which, when it is properly connected to a black box and is subjected to the same random input, will automatically form itself into an operational equivalent of the black box, even though its internal structure may be vastly different." [italics added] 7 In general, there are an indefinitely large number of nets of McCulloch-Pitts neurons capable of realizing a given input-output matrix. Kleene merely exhibits a procedure for constructing a net which will do the job when given the input-output matrix. 8 More can be said in support of this statement: (1) Dropping (a), (d), or (e) as a restriction would result in definitions which are not operational. Any behaviorist who was also an operationalist would not consider such a move. (2) Presumably, anyone would be willing to accept (a) and (d) as limitations. (3) Continuous systems and variables can be approximated to any degree of pre- cision for practical purposes by variables having only a finite number of values. Thus, maintaining that (b) was a dangerous limitation would also not be an opera- tionally tenable move. In any case, if classical quantum mechanics is accepted, all natural process are ultimately finitistic. If a behavioristic definition were forthcoming only in terms of continuous variables, feedback would be tied to an approximate view of the world and would not be a part of its ultimate furniture. (4) Condition (c), I think, is clearly irrelevant. 9 To my knowledge no generalization of this rigor exists for continuous systems, though Grodins (21) discusses a number of cases, and claims (p. 99) that "...the form of the differential equation describing a given system does not reveal whether it is a feedback system or not." A consideration of his cases and construction of others along similar lines allows interpretation of the 'form' of the differential equation to include all of its relevant features: (i) whether it is linear or not; (ii) the order of the equation; (iii) the numerical value or algebraic structure of the coefficients, and (iv) the form of the input function. 10 All of these authors appear to eschew talk of causal relation for talk about 'epistemic independence.' This concept was defined by Sommerhoff, ([14], p. 86). Since it can be trivially shown that any set of causally related variables are also mutually epistemically independent, I see no reason to introduce that complication here, and I will talk solely about causal relation. I believe that the latter concept has been appropriately explicated for complex systems by Simon and Rescher [17]. 11 This feature is met not only for simple open systems with a constant input, but also for any closed system. Braithwaite's only additional constraint is that the system</page><page sequence="16">256 WILLIAM C. WIMSATT does not oscillate through the equilibrium point. Braithwaite's analysis is more simplistic than those discussed here, and he makes no claims to have analyzed the concept of feedback. It is not a plausible analysis for goal-directiveness either however. 12 These analyses talk about 'goals', 'goal states' or 'sets of goal states', as if they were other than simple or steady-state equilibrium states, but nothing in the analyses prevents the simpler interpretations, and this is one of the primary defects of such analyses. 13 c, will be assumed to be the same for flow in either direction, and is a hydro- dynamic constant which reflects properties of the fluid (viscosity only, if the fluid is assumed to be incompressible) and geometrical features of the tank and orifice. For cl to be independent of the flow rate, r8, it must also be assumed that flow is always laminar. Similarly, c2 is assumed to be independent of ro, which is a function of h2, a2, g, and C2, 14 The proportionalities here indicate a third feature which Von Bertalanffy ([19], p. 24) suggests is an important kind of independence of the system from its environment: "... the steady-state ratio of the components depends only upon the system constants, not upon the environmental conditions." 15 Actually, these conditions are met only if the equilibria of the system are stable, as they are in fact for the system discussed. 16 In fact, it does not meet Beckner's criteria ([11], Chapter 7). Beckner postulates in addition (a) the presence of an internal energy source, and (b) the presence of a 'special hookup', which if removed leaves the state variables causally related but destroys or changes the 'compensation' mechanism. Beckner may have intended the first as a requirement of 'teleological' systems, and not of feedback systems, and I would deny that it is a requirement of the latter. His second requirement is met if a one-way valve preventing flow from the first tank to the second is added to the above system, repre- senting "removal of the special hookup." (Although a piece of apparatus is added, the causal relation from V1 to V2 is thereby removed.) Since V2 can still affect VI, Beckner's criterion is met, but the system is still not a feedback system. 17 It is also a linear system. An interesting criterion for the special case of feedback in linear systems can be offered, but it appears to break down for non-linear systems, and thus fails to be general. 18 This is not the only possible form of feedback control. The type mentioned above is known as 'proportional control' from the fact that the magnitude of the "restoring force" (given by k(h2*-h2)) is proportional to the deviation from equilibrium (given by (h2* - h2)). If the system is to be stable, it must also be true that k &lt; 1. If k = 1, the system will maintain a stable oscillation, and with k &gt; 1, the system will "over- compensate" and undergo oscillations of increasing magnitude. 19 My claim is that it is appropriate to speak of self-controlling processes or of a closed flow of information when and only when it is appropriate to speak of feedback, and that these concepts must either be explicated in terms of feedback or in more anthropomorphic terms which would be of no use here. The concept of information of course has been given a formal and independent characterization in terms of information theory. But information theory is primarily concerned with the carrying capacity of channels and codes for correcting errors of transmission. It tells nothing about what the information in the feedback loop does to influence the course of the reaction in the main path, or how it does it and this is the feature we need to define feedback. As Warren Weaver [22] says, information theory has nothing to say on how the information is interpreted and what is done with it.</page></plain_text>
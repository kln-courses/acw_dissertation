<plain_text><page sequence="1">Amer. Zool., 40:893-901 (2000) Possible Levels of Animal Consciousness with Reference to Grey Parrots (Psittacus erithacus)1 IRENE M. PEPPERBERG*t2 AND SPENCER K. LYNN*3 ^Department of Ecology &amp; Evolutionary Biology, fDepartment of Psychology and Affliate in Neuroscience, University of Arizona, Tucson, Arizona 85721 and The Media Lab, MIT, Cambridge, Massachusetts 02139 Synopsis. Researchers often study nonhuman abilities by assuming their subjects form representations about perceived stimuli and then process such information; why then would consciousness be required, and, if required, at what level? Argu? ments about nonhuman consciousness range from claims of levels comparable to humans to refutation of any need to study such phenomena. We suggest that (a) species exhibit different levels attuned to their ecological niches, and (b) animals, within their maximum possible level, exhibit different extents of awareness appro? priate to particular situations, much like humans (presumably conscious) who often act without conscious awareness of factors controlling their behavior. We propose that, to engage in complex information processing, animals likely exhibit perceptual consciousness sensu Natsoulas (1978), Le., are aware of what is being processed. We discuss these issues and provide examples suggesting perceptual consciousness. Introduction A little knowledge is a dangerous thing; Drink deep or taste not the Pierian spring: There shallow draughts intoxicate the brain, And drinking largely sobers us again. . . Alexander Pope, Essay on Criticism, pt.ii. The study of consciousness, particularly in nonhumans, is one of science's thorniest current problems. As relative naives to the field, sipping at the aforementioned spring, we find the topic intoxicating but are over- whelmed by its distinctions, disagreements, and controversies. Assertions about non? human consciousness range from claims for emergent levels in Cambrian organisms (Hameroff, 1998), to levels comparable to humans (e.g., Griffin, 1992), to denial of the need to study such phenomena (Ken- nedy, 1992; Blumberg and Wasserman, 1995). Debate centers around two issues, 1 From the Symposium Animal Consciousness: His? torical, Theoretical, and Empirical Perspectives pre? sented at the Annual Meeting of the Society for Inte? grative and Comparative Biology, 6-10 January 1999, at Denver, Colorado. 2 E-mail: impepper@media.mit.edu 3 E-mail: skl@u.arizona.edu neither of which is easily resolved nor spe? cific to nonhumans. The first involves de- fining conscious behavior. How do we de- fine it? How is it related to awareness? To intentionality? To cognitive ability? The second issue is whether we gain anything by positing conscious, in addition to cog? nitive, behavior. Yet even if we deny con? sciousness a role in governing behavior or its existence entirely, we must account for its place in human beliefs. We contend that debate on these issues can advance re? search. Aspects of Consciousness Lacking a consensus definition, we are left with ways people use the term "con? sciousness." It can be described by a con? trast of levels or states, e.g., access versus phenomenal consciousness (Block, 1996); state versus creature consciousness (Rosen? thal, 1993); or reflective, primary and pe? ripheral consciousness (Kihlstrom, 1987). Unconsciousness involves that which is outside of attention or awareness, not ac- cessible to introspection. Comparative psy- chologists and cognitive ethologists who address consciousness in their subjects ex? amine what is usually termed "perceptual consciousness" and "reflective conscious? ness" rather than "phenomenal conscious- 893</page><page sequence="2">894 I. M. Pepperberg and S. K. Lynn ness" (Griffin, 1998). Perceptual con? sciousness encompasses awareness of one's sensory perceptions, e.g., how information provided by the senses is acknowledged, processed, and integrated such that it can be used for several purposes (Natsoulas, 1978). This definition requires an organism to be aware that it is processing informa? tion, possibly of how it is processing infor? mation, but not that it be aware that it is aware of how information is processed. Re? flective consciousness encompasses central monitoring of sensory inputs and mental states, executive control of decision making and voluntary action, awareness of one's own thoughts (being aware that one is aware; Carruthers, 1992) and attribution of mental states to others, and has been impli? cated in some types of deception. Phenom- enal consciousness involves distinctive, unique, subjective aspects of mental states?or qualia, particular qualities of ex? perience (Chalmers, 1996). What, for ex? ample, are qualia corresponding to "red- ness"? Do two beings seeing "red" have identical experiences? The origin and main? tenance of perceptual and reflective con? sciousness can be tied to ecology, natural history, and evolutionary thought by their putative adaptive value. But "red" is not experienced with continuity across species if only because their physiologies of color perception differ. To examine consciousness, scientists at- tempt to simplify, contrast, and isolate its aspects; for example, it has been studied as working memory, controlled (vs. autonom? ic) behavior, and attention (i.e., related to goal selection, vigilance, spatial orientation, or focus). When broken down into such components, consciousness becomes diffi? cult to distinguish from cognitive traits or abilities that must underlie it. Arguments for human consciousness are often based on introspective report (Searle, 1998); in non- humans, for whom we lack such reports, we may question the distinction between cog? nition and consciousness. What do we gain by positing aspects of consciousness, e.g., perceptual awareness or central monitoring/ executive control, beyond saying that sub? jects have cognitive apparatuses sufficient to carry out the experimental task? GOALS OF THIS PAPER We approach these questions by positing simple stances on brain function, evolution? ary continuity, and relationships between some cognitive abilities and awareness in the hope of provoking debate and improv- ing contrast on the issues. We propose that: (1) Perceptual and reflective conscious? ness are functions of a brain's combined as- sociative and representational capacities; the richer those capacities, the greater the scope of an animal's perceptual and reflec? tive consciousness. We argue, however, not that brain homologies, analogs, and evolu? tionary convergences afford evidence for all aspects of consciousness but, as for cog? nitive abilities, only for the possibility of various levels of nonhuman consciousness: We suggest that various species exhibit dif? ferent levels of awareness attuned to their ecological niches (see below). Given that humans, presumably conscious, often act without conscious awareness of factors con? trolling their behavior (e.g., see Berns et al, 1997; Weiskrantz et al, 1974; Nisbett and Wilson, 1977; Siegler and Stern, 1998), we argue that species, within their maximum possible level, exhibit different extents of awareness appropriate to particular situa? tions (see Chalmers, 1996; Allen and Be- koff, 1997; Delacour, 1997). (2) Some cognitive abilities may be iso- morphic with aspects of consciousness: Levels of cognitive transfer, association, and cross-modal integration required in some experimental tasks correspond to lev? els of perceptual and/or reflective con? sciousness. We also contend that perceptual consciousness can be termed "awareness," and that what Pepperberg (1992) has de? fined as complex, higher-order cognition is equivalent to awareness, as an aspect of consciousness. Isolating awareness from other aspects of consciousness is not with? out precedent. For Chalmers (1996, p. 28), awareness is ". . . a state wherein we have access to some information, and can use that information in the control of behavior," but the state need not include phenomenal consciousness because it can exist "... without any particular associated phe-</page><page sequence="3">Possible Perceptual Consciousness in Nonhumans 895 nomenal experience." Chalmers later rede- fines awareness as coherent with conscious? ness (p.219ff), but we believe much can be gained by focusing on awareness. We doc- ument (below) specific behavior patterns that suggest rudiments of perceptual con? sciousness (awareness) in Grey parrots (Psittacus erithacus), without claiming such consciousness matches that of humans. Perceptual and Representational Consciousness and Brain Function: Analogies to Naming and Counting We find parallels between studies of con- sciousness/awareness and those in other cognitive areas that engender similar levels of controversy, and argue that cautions needed?and often ignored?in those areas be applied to the current problem. Specifi? cally, animal consciousness debates recall those on animal "language" and animal "counting." In all cases, some researchers define the trait as whatever animals cannot be shown to do (Fouts, 1973). Such a def? inition has both negative and positive as? pects. Negative aspects are clear: Whatever level of competence animals demonstrate, detractors simply "up the ante," redefming the concept so as to exclude nonhumans. Positive aspects are less clear but related and extremely important: Studies on non? humans have forced researchers to examine in detail just what does constitute language, counting, and now, we hope, awareness and possibly consciousness. We summarize these parallels without giving detailed reviews of either language or counting studies. To call behavior "nam? ing" or "counting" (or "conscious") when it represents a simpler category not only causes confusion and miscommunication, but also may prevent us from determining the full extent of nonhuman abilities: Re? searchers, for example, call a budgerigar's (Melopsittacus undulatus) ability to asso? ciate a symbol and one specific object "naming," without even demonstrating transfer to related items (Manabe et al, 1995). Might the bird be able to label not only a training light as "green," but also transfer that label to all shapes, objects, and instances of that color? By giving the most complex of labels to a low-level action, re- searchers settle for describing only the sim? plest behavior, and risk dissuading further research or missing what might be an ani? mal's highest competence level (Pepper- berg, 1998, 1999). Various hierarchical be? havior levels exist that are related to "nam- ing" in its richest sense; the level actually demonstrated must be specified carefully (Savage-Rumbaugh, 1986; Pepperberg, 1998, 1999). The same argument holds for other aspects of language (e.g., Bickerton, 1990), counting (e.g., Davis and PeYusse, 1988; Pepperberg, 1988) and, we contend, consciousness in any of its senses. We ar? gue that consciousness and awareness, like language and counting, are not unitary phe? nomena, but rather multilevel (Goodyear et al, 2000). Linguistic and counting abilities are present at some level in taxa as diverse as birds and primates; all can exhibit cer? tain, but not necessarily all, aspects in a par? ticular situation (Delacour, 1997). Those abilities must be due to homologous or con? vergent brain evolution, perceptual struc? tures, and learning mechanisms. We pro- pose that a continuity of perceptual con? sciousness?higher order cognition, or "awareness"?can exist across taxa for the same reasons. To whit, animals may exhibit rudiments of awareness as they exhibit ru? diments of language and counting. To ig? nore the presence of such rudiments be? cause their fullest expressions have not been uncovered would not only be as seri? ous an error as using the evidence to claim behavior equivalent to that of humans, but may also miss important intermediate lev? els. We thus argue for extreme care when claiming conscious or nonconscious, aware or unaware behavior in nonhumans (and, for that matter, in humans). A specific ex? ample may explain our position. "Insight" is usually considered a fully unconscious process in which an organism is unaware how current information is processed, what earlier information is accessed, and how multiple sets of information are integrated to arrive at a solution. We, however, suggest how insight can involve some rudimentary awareness: The organism (whether human or nonhuman) is clearly aware of the need to solve a problem and likely has some</page><page sequence="4">896 I. M. Pepperberg and S. K. Lynn awareness of relevant incoming informa? tion. Cognitive Abilities: Why Posit Levels of Awareness? Most researchers study cognitive behav? ior by assuming their subjects form repre- sentations about perceived data and then process such information; why then is con? sciousness or awareness required, and, if re? quired, at what level? Delacour (1997, p. 259), for example, posits consciousness as simply a "... certain style of cognition, characterized by a particular integration of different processes. . . " Two possibilities exist for arguing for awareness, at least, as distinct from both general task-solving abil? ities and other aspects of consciousness. First, we propose that, when engaging in some forms of complex information pro? cessing, animals exhibit "perceptual con? sciousness": are aware of what is being processed, sensu Natsoulas (1978) and con? sistent with Delacour. Complex compara? tive psychology tasks (e.g., transfer, cate? gory formation) require integrating percep- tion, centralized monitoring, and behavioral control; in contrast, simpler associative pro? cesses probably require only perception. We thus argue that awareness (higher order cognition defined, e.g., in Pepperberg, 1992) is required for complex tasks; we provide examples involving the existence of such awareness. Second, although we have yet to find that positing conscious behavior has led us to any fruitful experiments that would not otherwise have been done, we suggest that, for a select few tasks, a purely information-processing account is insuffi? cient to explain the observations complete? ly. Our data do not provide evidence for consciousness equivalent to that of humans, but present limited evidence for some of its elements. Levels of awareness: Examples from laboratory and field studies Some examples may clarify our defini? tions of levels of awareness. Let us posit a task hierarchy roughly paralleling Thomas' (1980, 1996) hierarchy of cognitive behav? ior to determine what level of awareness appears necessary for accomplishing each task. By itself, positing lower awareness levels neither provides explanatory infor? mation nor defines awareness; rather the contrast it provides with higher levels may assist our behavioral analyses. Lower levels of information processing may involve, but do not require, high awareness levels. An organism is startled by a very loud tone. After several exposures, the startle re? sponse begins to wane. We believe that an organism that simply habituates does not require any level of awareness. Such be? havior is exhibited by almost every living creature with a nervous system. A white rat consistently presses a lever at the appearance of a specific green block to obtain a food reward. No other objects are ever introduced and no other responses are ever required. Such behavior can be considered the simplest form of associative learning, and may, but need not, require any level of awareness. The organism most likely responds based on a "habit system" (e.g., Mishkin and Petri, 1984; Squire et al, 1993), which uses a particular neural path? way that stores response tendencies but not neural representations (see Kintsch, 1996 for a detailed summary). The organism needs no representation with which to com? pare the object or indicator, nor any concept of "greenness," "blockness," etc. Such be? havior patterns are not unlike the simplest fixed-action patterns found in certain organ? isms. (Levels of awareness present in more complex forms of associative learning can be inferred from examples given below.) What about an organism that supposedly has learned to "choose nonmatch," i.e., peck a green button when given a red sam? ple and red and green choices? Interesting- ly, pigeons do not learn to choose green, but slowly learn to match and then avoid pecking the match (Zentall et al, 1981). A pigeon need not be aware of anything spe? cific about the green sample, nor that it is being trained with respect to oddity, nor of any concept of redness. We suggest that the pigeon has the first level of awareness: the ability to follow a simple rule involving perception of a specific item and its avoid? ance. The pigeon need not necessarily be aware of devising or following the rule. If it were indeed aware of the rule, it could</page><page sequence="5">Possible Perceptual Consciousness in Nonhumans 897 transfer immediately to a task using vertical and horizontal samples; if aware of "red- ness" it would easily transfer to a task where red was now correct.... but such is not the case in this instance. Possibly a pi- geon's difficulty in learning this behavior stems from its unnaturalness: To avoid peb- bles mixed with grain, a pigeon would not learn to recognize pebbles but would pref? erentially learn to recognize grain. In con? trast, a response to Batesian mimicry, which usually involves one-trial learning, would suggest a higher-order awareness (see below). What about an animal that has developed a "learning set"? The organism, having been given a series of discrimination prob? lems, each using a new object pair, acquires a win-stay/lose-shift response (at 80-90% accuracy) after ?200 problems (Macphail, 1982). We suggest the organism has a sec? ond level of awareness: knows not only that a rule exists with respect to "likeness/fa- miliarity" (first level), but is aware enough of the rule to transfer it across situations. If, however, the organism were truly aware of using the rule, it would, when transferred to a win-shift/lose-stay paradigm, readjust after only a very few trials; most organisms do exhibit a savings in trials from the initial acquisition, but do not transfer quickly (Rumbaugh and Pate, 1984). In nature, many foragers likely have such awareness (e.g., hummingbirds that fully empty a flower's nectar in nature?i.e., win-shift? transfer across inflorenscences but do not transfer quickly to win-stay in an operant setting; Cole et al, 1982). What about a chimpanzee that has ac? quired a concept of category? The subject, after learning to sort samples into "food" and "not food" without eating samples dur? ing the sort, can sort a new pile appropri- ately (Savage-Rumbaugh et al, 1980). It must sort items not only with respect to the category rule, but also respond to a new set based on prior data: Which of these items have been previously found edible? The subject must integrate two different sets of stored information, which we suggest re? quires third level awareness. Whether the actual integration is performed consciously or not, the animal likely has some represen- tation or memory of what was edible in the past, and has learned to sort based on this representation, not on any specific physical quality (e.g., color). Animals that engage in a wide variety of foraging strategies likely exhibit this awareness level. An animal that can respond on the basis of relative class concepts (e.g., bigger/smaller) has this awareness level: must sort based on a rule that involves no intrinsic properties of a specific object, and must compare items to determine which fits the concept and thus, again, integrate two different sets of infor? mation. What about a parrot that examines a tray of blue and green blocks and balls and in response to a specific query labels the num? ber of blue blocks (Trick and Pylyshyn, 1989; Pepperberg, 1994)? Some represen? tations of blueness and blockness must be formed and integrated to enable a search, and this representation must be maintained during the enumeration process, which it? self draws on some representation of num? ber. The bird, however, may not consciously be engaged in the enumeration process (e.g., may use an alternative perceptual mechanism; Davis and Perusse, 1988). We suggest a fourth level awareness. Possibly wild birds that determine their course of ac? tion by recognizing which neighbor is sing? ing, which song is being sung (i.e., integrate representations of specific bird and specific song, like blockness and blueness versus other combinations), and the number of rep- etitions of the song (e.g., Beecher et al, 1996; Smith and Smith, 1996), exhibit such an awareness. What about organisms that not only solve a complex Piagetian object permanence task, but also demonstrate knowledge of the specific item that was hidden (Funk, 1996; Pepperberg et al, 1997)? Here an object is placed in a small container; the container is then passed under successive screens until the item is hidden in the designated site, whereupon the researcher shows the empty initial cover, then passes it under another screen, and finally leaves the initial cover in an accessible site that varies in each trial. An additional, untouched screen is present to see if the subject examines only screens handled by the researcher. A subject shows</page><page sequence="6">898 I. M. Pepperberg and S. K. Lynn it is not using a "go to last place item was seen" or "go to last place researcher touched" rule by ignoring the initial cover. The order of movement varies among trials. On occasion, a researcher tricks the subject by showing that a particularly desirable item is being hidden, but hides something else. Here the subject must have some level of awareness of and memory for the iden? tity of the hidden item to respond with "surprise" (see below) when a less desir? able one is found; the subject must also be actively tracking the item's movement to in? fer when and where it was hidden, and re? member the site and how to extract the item from the site, because simple rules will not provide the answer. An organism may not be aware of its use of these multiple rep- resentations, but must be aware of these representations and the cognitive disso- nance arising when its representation is not matched. We thus argue for fifth level awareness: Natsoulas' (1978) perceptual consciousness. Birds in nature that remem? ber not just where they cached an item, but when and the specific nature of the item (Clayton and Dickinson, 1998) presumably need to demonstrate such awareness. What about a parrot who, given 7 items of various colors, shapes, and materials and asked to label the color of the one that, for example, is wood and square, on occasion successively provides each of 6 possible wrong answers, then repeats the wrong an? swers, thus avoiding the correct answer on 12/12 trials (Pepperberg, 1992)? A chance explanation is not supported by statistics. And, unlike the pigeon that used identity to respond to what researchers assumed was oddity, the parrot is not performing a fa? miliarity match: It sees 7 items, and must use a recursive mechanism to decode a symbolic query to remember and provide the designated attribute (which must in turn be symbolically encoded) of the one item defined by conjunction of two other attri- butes: provide the color label of the one item symbolically labeled wood and square from an array of other items that are wood or square, but not both. The bird must have a representation of the labels of all attri- butes, integrate that information with a search for the appropriate item (which re- quires combining representations of two at? tributes), encode the correct attribute label, then specifically avoid uttering that label to produce all other relevant labels for 12 tri? als. We suggest some awareness drives this behavior. The level may not go beyond that of perceptual, and we hesitate to argue for one comparable to that of humans, but do argue for at least level five. Possible advantages of positing awareness and other aspects of consciousness To return to our earlier question, what are the benefits of positing consciousness or awareness rather than cognitive behavior? Two possibilities exist. First is that testing for consciousness or awareness leads to ex? periments that would not otherwise be per? formed. Such is the case for positing com? plex information processing in animals (see Balda et al, 1998). In no instance, however, were the studies described above designed to test for consciousness or awareness. Sec? ond is that an information-processing ex? planation cannot completely account for the behavioral data. We hesitantly suggest such may be the case for results of the last two experiments. In the object permanence study, parrots react with surprise and anger (e.g., odd yips, beak-banging) when the hidden item is other than the expected one (Pepperberg et al, 1997). The standard argument is that the subject has a representation of what is hidden, and reacts to the difference (the cognitive dissonance) between the observed item and its representation. The birds' re? actions also suggest they do not expect that item A can routinely "turn into" B. But why is the observed reaction one of surprise and anger, not continued search or immo- bility? Their behavior differs strikingly from that of a very young child who pre- dictably looks longer at a situation that vi- olates its expectations (e.g., Baillargeon et al, 1985), or the standard, expected disha- bituation response (Mishkin and Petri, 1984). As far as we know, a computer, the ultimate information processor, assuming it can be programmed to perform the infer- ential searching task, would (unless pro? grammed for this specific eventuality) react with an "error message," and freeze. We</page><page sequence="7">Possible Perceptual Consciousness in Nonhumans 899 can, of course, argue that anger and surprise are the "error messages" emitted by a non? human. We do not suggest that dissonance in cognitive processing requires or must be indicated by emotions; a glance at any daily newspaper would be enough to argue that "gut-level" emotional responses often short-circuit cognitive processes in humans; might the anger of a parrot be a short-cir- cuiting of the logical response to continue searching? Is it logical or illogical to con? tinue searching when all logic points to the item being "there"? What is the logical re? sponse? All we can suggest is that the an? imal must be aware of this cognitive dis? sonance and the immutability of items, at the level described by Natsoulas, or it would not exhibit such emotion-driven sur? prise at the outcome. Nevertheless, lack of a specific surprise reaction might not be telling. Allen (1997) would argue that our birds' reactions indeed indicate awareness because they differ, for example, from the slow extinguishing of lever pressing in an unaware animal whose expectations are vi- olated. We would like to accept Allen's ar? gument, but cannot: Given operant experi? mental design, researchers would not ob- serve any initial surprise reaction in the supposedly unaware animal, and its slow extinguishing is not so different from hu? man reactions when food does not come, as expected, from a vending machine: We have all watched humans repeat their button presses numerous times. Can we argue for awareness based on positive reactions when absent reactions need not denote unaware- ness? What about arguments that suggest re? actions of anger and surprise in such cases require a level of awareness implying proto- consciousness, similar to levels of proto? language and proto-counting? Is it because the bird lacks or because it has full aware? ness that it does not immediately respond with, for example, prolonged search? One bird did continue to search, but only after displaying anger. Is that behavior smart, aware, or stupid? Positing higher-order in? formation processing or even awareness leads us only to expect a reaction indicating cognitive dissonance, not the nature of the reaction or any explanation of the reaction that occurs. Interestingly, positing the ad? dition of conscious processing leads to an unexpected end. For some researchers, a specific feature of consciousness is the existence of "... noncomputable, seemingly random, conscious choices with an element of un- predictability. . . " (Hameroff, 1998; also Barinaga, 1996; Allen and Bekoff, 1997). Our birds' behavior in the above example appears to fit this mode. Thus we are led to the somewhat surprising conclusion that a subject is most conscious when normal cog? nitive processes fail and it must access something else to decide how to proceed (Allen and Bekoff, 1997). This "something else" is not necessarily logical and can be an emotional state. Have we circled back to Mishkin and Petri's "habit state"? Let us look at the second level-five ex? ample, the successive wrong responses, for information. Might an organism be con? scious if it knows why it should respond in a given way yet opts to respond differently? A human who recognizes that excessive an? ger at authority figures is not a logical re? sponse to being stopped for speeding but stems instead from rebellion against over- controlling parents can inhibit inappropriate levels of anger at a policeman writing a ticket. Is the process similar, if reversed, for a bird who gives the wrong answers? It rec? ognizes that a correct response yields a spe? cific reward, but chooses to inhibit that re? sponse to elicit some other caretaker reac? tion. The correct answer is logical; the bird chooses to respond in an intentionally illog- ical manner. We argue, again hesitantly, that the bird is aware not only of what it needs to answer wcorrectly, but also of how to use its knowledge to affect its trainers' be? havior for its own ends, and is thus above level five. We again seem to see "... non? computable, seemingly random, conscious choices with an element of unpredictabili- ty. . . " But what do we gain by positing consciousness beyond awareness? Conclusions We find ourselves in an interesting quan- dary. We began by looking at information processing, argued that the higher orders (previously defined as cognitive processing,</page><page sequence="8">900 I. M. Pepperberg and S. K. Lynn Pepperberg, 1992, 1998) appeared to re? quire some awareness about what is being processed sensu Natsoulas (1978), but found a need to acknowledge noncognitive (or not necessarily logical) processes when we attempted to interpret our data to incor- porate consciousness. Thus we suggest that researchers studying higher order process? ing?objective aspects of animal behav? ior?may arrive at more detailed explana? tions by invoking perceptual consciousness (awareness) but will likely gain little by positing other aspects of consciousness; we also suggest that awareness can be defined as higher-order cognitive processing and vice versa, because both are defined with respect to accessing information that is then used in the control of behavior. In contrast, we find that, in agreement with Dawkins (1993), consciousness (or proto-conscious- ness) may assist in examining subjective, i.e., emotional, aspects of animal behavior and the boundary between the subjective and objective. We suggest that conscious? ness depends on certain cognitive abilities, but has some existence apart from them. Although the internal, subjective nature of consciousness means that little evidence ex? ists for its presence other than, for humans, as individual reports about integrative pro? cesses involving awareness, we posit that the evolutionary homologies/convergences across taxa in brain function that lead to continuity (but not necessarily isomor- phism) in cognitive processing also allow for (but do not necessarily lead to) conver? gence (but not necessarily isomorphism) with respect to consciousness. We end by cautioning and admonishing fellow scien? tists to avoid superficial forays into the realm of consciousness and to recognize both limitations and advantages of positing consciousness, depending upon the focus of their research. ACKNOWLEDGMENTS This material is based upon work sup? ported by the National Science Foundation under Grant No. 9603803 and contributors to The Alex Foundation. The authors thank NSF and the Society for Integrative and Comparative Biology (SICB) for support of this symposium, and Pamela Banta, Diana May, symposium participants, and members of the University of Arizona Consciousness Studies Discussion Forum for comments and discussion of the material. References Allen, C. 1997. Animal cognition and animal minds. In P. Machamer and M. Carrier (eds.), Philosophy and the sciences ofthe mind, pp. 227-243. Pitts- burgh University Press and the Universitatsverlag Konstanz, Pittsburgh, PA and Konstanz, Germany. Allen, C. and M. Bekoff. 1997. Species of mind. MIT Press, Cambridge, MA. Balda, R. P, I. M. Pepperberg, and A. C. Kamil. (eds.) 1998. Animal cognition in nature. Academic Press, London. Baillargeon, R., E. S. Spelke, and S. Wasserman. 1985. Object permanence in five-month-old infants. Cognition 20:191-208. Barinaga, M. 1996. Neurons put the uncertainty into reaction times. Science 274:344. Beecher, M. D., P. K. Stoddard, S. E. Campbell, and C. L. Horning. 1996. Repertoire matching be? tween neighbouring song sparrows. Anim. Behav. 51:917-923. Berns, G. S., J. D. Cohen, and M. A. Mintun. 1997. Brain regions responsive to novelty in the absence of awareness. Science 276:1271-1275. Bickerton, D. 1990. Language and species. University of Chicago Press, Chicago, IL. Block, N. 1996. How can we find the neural correlates of consciousness? Trends Neurosci. 19:456-459. Blumberg, M. S. and E. A. Wasserman. 1995. Animal mind and the argument from design. Amer. Psychol. 50:133-144. Carruthers, P. 1992. The animals issue: Moral theory in practice. Cambridge University Press, Cam? bridge, UK. Chalmers, D. J. 1996. The conscious mind: In search of a fundamental theory. Oxford University Press, New York. Clayton, N. S. and A. Dickinson. 1998. Episodic-like memory during cache recovery by scrub jays. Na? ture 395:272-274. Cole, S., F. R. Hainsworth, A. C. Kamil, T. Mercier, and L. L. Wolf. 1982. Spatial learning as an ad? aptation in hummingbirds. Science 217:655-657. Davis, H. and R. Perusse. 1988. Numerical compe? tence in animals: Definitional issues, current evi? dence, and a new research agenda. Behav. Brain Sci. 11:561-615. Dawkins, M. S. 1993. Through our eyes only? WH. Freeman/Spektrum, Oxford, UK. Delacour, J. 1997. Object perception and recognition: A model for the scientific study of consciousness. Theory &amp; Psychol. 7:257-262. Fouts, R. S. 1973. Capacities for language in the great apes. Proc. 9th Int'l Congr. Anthropological and Ethnological Sciences. Mouton, The Hague. Funk, M. S. 1996. Development of object permanence in the New Zealand parakeet (Cyanoramphus au- riceps). Anim. Learn. &amp; Behav. 24:375-383. Goodyear, B. G., D. A. Nicolle, G. K. Humphrey, and</page><page sequence="9">Possible Perceptual Consciousness in Nonhumans 901 R. S. Menon. 2000. fMRI response of early visual areas to perceived contrast in human amblyopia. J. Neurophysiol. 84:1907-1913. Griffin, D. R. 1992. Animal minds. University of Chi? cago Press, Chicago, IL. Griffin, D. R. 1998. From cognition to consciousness. Anim. Cogn. 1:3-16. Hameroff, S. R. 1998. Did consciousness cause the Cambrian evolutionary explosion? In S. R. Ham? eroff, A. W. Kazniak, and A. C. Scott (eds.), To? ward a science of consciousness II: The second Tucson discussions and debates, pp. 421?437. MIT Press, Cambridge, MA. Kennedy, J. S. 1992. The new anthropomorphism. Cambridge University Press, Cambridge, UK. Kihlstrom, J. 1987. The cognitive unconsciousness. Science 237:1445-1452. Kintsch, W. 1996. Mental representations in cognitive science. In W. Battmann and S. Dutke (eds.), Pro? cesses of molar regulation of behavior, pp. 17? 33, Pabst Scientific, Scottsdale, AZ. Macphail, E. M. 1982. Brain and intelligence in ver? tebrates. Clarendon Press, Oxford, UK. Manabe, K., T. Kawashima, and J. E. R. Staddon. 1995. Differential vocalization in budgerigars: To? wards an experimental analysis of naming. J. Exp. Anal. Behav. 63:111-126. Mishkin, M. and H. L. Petri. 1984. Memories and hab- its: Some implications for the analysis of learning and retention. In L. Squire and N. Butters (eds.), Neuropsychology of memory, pp. 287-296. Guild- ford Press, New York. Natsoulas, T. 1978. Residual subjectivity. Amer. Psychol. 33:269-283. Nisbett, R. E. and T. D. Wilson. 1977. Telling more than we can know: Verbal reports on mental pro? cesses. Psychol. Rev. 84:231-259. Pepperberg, I. M. 1988. Studying numerical compe- tencies: A trip through wonderland? Behav. Brain Sci. 11:595-596. Pepperberg, I. M. 1992. Proficient performance of a conjunctive, recursive task by an African Grey parrot (Psittacus erithacus). J. Comp. Psychol. 106:295-305. Pepperberg, I. M. 1994. Evidence for numerical com? petence in an African Grey parrot (Psittacus eri? thacus). J. Comp. Psychol. 108:36-44. Pepperberg, I. M. 1998. The African Grey parrot: How cognitive processing might affect allospecific vo? cal learning. In R. P. Balda, I. M. Pepperberg, and A. C. Kamil (eds.), Animal cognition in nature, pp. 381-409. Academic Press, London. Pepperberg, I. M. 1999. The Alex studies. Harvard University Press, Cambridge, MA. Pepperberg, I. M., M. R. Willner, and L. B. Gravitz. 1997. Development of Piagetian object perma? nence in a Grey parrot (Psittacus erithacus). J. Comp. Psychol. 111:63-75. Rosenthal, D. M. 1993. State consciousness and tran- sitive consciousness. Conscious. Cogn. 2:355- 363. Rumbaugh, D. M. and J. L. Pate. 1984. Primates learn? ing by levels. In G. Greenberg and E. Tobach (eds.), Behavioral evolution and integrative levels, pp. 221-240. Erlbaum, Hillsdale, NJ. Savage-Rumbaugh, E. S. 1986. Ape language: From conditioned response to symbol. Columbia Uni? versity Press, New York. Savage-Rumbaugh, E. S., D. M. Rumbaugh, S. T. Smith, and J. Lawson. 1980. Reference: The lin? guistic essential. Science 210:922-925. Searle, J. R. 1998. How to study consciousness sci- entifically. Philos. Trans. R. Soc. Lond. B 353: 1935-1942. Siegler, R. S. and E. Stern. 1998. Conscious and un- conscious strategy discoveries: A microgenetic analysis. J. Exp. Psych.: Gen. 127:377-397. Smith, W. J., and A. M. Smith. 1996. Information about behavior provided by Louisiana water- thrush, Seurus motacilla (Parulinae), songs. Anim. Behav. 51:785-799. Squire, L. R., B. Knowlton, and G. Musen. 1993. The structure and organization of memory. Ann. Rev. Psychol. 44:453-495. Thomas, R. K. 1980. Evolution of intelligence: An ap? proach to its assessment. Brain Behav. Evol., 17: 454-472. Thomas, R. K. 1996. Investigating cognitive abilities in animals: Unrealized potential. Cog. Brain Res. 3:157-166. Trick, L. and Z. Pylyshyn. 1989. Subitizing and the FNST spatial index model. University of Ontario, COGMEM #44. Weiskrantz, L., E. K. Warrington, M. D. Sanders, and J. Marshall. 1974. Visual capacity in the hemian- optic field following restricted occipital ablation. Brain 97:709-728. Zentall, T. R., C. A. Edwards, B. S. Moore, and D. E. Hogan. 1981. Identity: The basis for both match- ing and oddity learning in pigeons. J. Exp. Psychol.: Anim. Behav. Proc. 7:70-86.</page></plain_text>
<plain_text><page sequence="1">The Machine Orchestra: An Ensemble of Human Laptop Performers and Robotic Musical Instruments Ajay Kapur,*Ť Michael Darling,* Dimitri Diakopoulos,* Jim W. Murphy,*1 Jordan Hochenbaum,* Owen Vallis,** and Curtis Bahn** * California Institute of the Arts 24700 McBean Parkway Valencia, California 91355 USA ajay@karmetik.com mdarling@calart s . edu {ddiakopoulos, jim.w.murphy, о wens vallis } @gmail . com ŤNew Zealand School of Music at Victoria University of Wellington PO Box 2332 Wellington, 6140 New Zealand jhochenbaum@gmail . com ** Rensselaer Polytechnic Institute 110 8th Street Troy, New York 12180-3590 USA crb@rpl.edu This article introduces the Machine Orchestra, a mixed ensemble of human and robotic performers. The Orchestra is coordinated through technical and musical classes at the California Institute of the Arts (Cal Arts), where the pedagogical focus is to combine the musical elements of a laptop orchestra with the technical skills required to create a robotic ensemble. As of this publication, seven electromechanical instruments have been developed by members and collaborators of the Orchestra. The ensemble has given notable international premieres and performances at venues including the Roy and Edna Disney/CalArts Theater (REDCAT) in Los Angeles and 01 S J, the biennial music and arts festival in San Jose, California. Well-known researchers and performers are invited to participate in the Orchestra to bring novel technical, musical, and collaborative ideas to the ensemble. In this article we describe the design and production of seven robotic instruments, details on the visual and sonic aesthetic of the ensemble, technical considerations of the computer network employed in performance, and information on an assortment of compositions in the current repertoire. Computer Music Journal, 35:4, pp. 49-63, Winter 2011 © 201 1 Massachusetts Institute of Technology. Histoiy, Influences, and Curriculum This section traces the history of the Laptop Orchestra as a teaching laboratory and performance ensemble, and the integration of these concepts into the robotic-design curriculum in the CalArts Music Technology Program. Evolution of the Laptop Orchestra In 2006, Dan Trueman and Perry Cook unleashed the Princeton Laptop Orchestra (PLOrk; Trueman et al. 2006), revealing a new paradigm for teaching, composing, and performing live interactive com- puter music. Previous ensembles performing live with multiple networked laptops, such as The Hub, generally had fewer than five performers on stage, significantly fewer than the 16 to 25 members of PLOrk. The latter ensemble championed the idea of a laptop orchestra as a learning laboratory of musical interaction design, networked performance, and musical composition, revolutionizing the audi- tory display and human-computer interfaces used in large electroacoustic ensembles. In PLOrk, each performer's instrument includes a standardized suite of hardware and software: an Apple laptop, a hemispherical speaker, and several devices for gestural input (Wang et al. 2008). Kapui et al. 49</page><page sequence="2">Figure 1. Machine Orchestra with human-robot relationship. [Editor's note : the humanoid icons in this article represent humans, not robots.] And thus began the "Age of the LOrk." In 2008, Ge Wang, a pivotal member of the original PLOrk, joined the Stanford Center for Computer Research in Music and Acoustics and founded the first LOrk on the west coast, The Stanford Laptop Orchestra (SLOrk). Inspired by the original Princeton model, other laptop orchestras have been forming around the world. Direct collaboration with SLOrk and PLOrk led to the creation of the Oslo and Boulder laptop orchestras. Other groups unaffiliated with educational institutions have also started to emerge, including the Moscow Cyberlaptop Orchestra, the Tokyo Laptop Orchestra, and the Seattle Laptop Orchestra. In 2009, The Virginia Institute of Technology founded the first LOrk created fully through open source technology, aptly named the Linux Laptop Orchestra, L2Ork. The concept of a LOrk has also transitioned to mobile devices, with the first mobile phone orchestra (MoPho) performing in 2008 (Wang, Essi, and Penttinen 2008). Since then, other networked ensembles of phones have surfaced, including the Michigan Mobile Phone Orchestra, The Helsinki MoPho, and the Berlin Mobile Phone Orchestra. (See the Appendix for a full listing of the ensembles and their respective Web sites.) Following in the footsteps of other LOrks, and influenced by robotic orchestras such as Eric Singer and Paul Lehrman's Ballet Mécanique Automated Orchestra and Pat Metheny's Orchestrion, the Machine Orchestra has endeavored to create a laptop orchestra with a robotic dimension (see Figure 1). Adding to the pedagogical disciplines and experience of established laptop ensembles, the Machine Orchestra focuses on teaching students a bottom-up approach to musical robotics, going through mechanical engineering for actuators, acoustic engineering for instrument design, and electrical engineering and computer science for human-machine interaction design. The Orchestra and related classes form the core of the upper- level Music Technology curriculum, combining the resources from CalArts' School of Music and School of Theater. CalArts Robotic Design Curriculum The robotic instruments built by the Machine Orchestra began out of a collaboration between CalArts7 School of Music and the School of Theater and the subsequent formation of an interdisciplinary class entitled Robotic Design, first run in the spring of 2008 (Kapur and Darling 2010). The class begins with a survey-style introduction to the history of musical robotics and interactive electromechanical sculpture (Kaneda et al. 1999; Singer et al. 2004; Solis et al. 2004; Weinberg, Driscoll, and Thatcher 2006; MacMurtrie 2010; Raes 2010; Focke 2011). After the first month, students begin shop training and are presented with basic engineering concepts through the fabrication of small, nonfunctional prototypes 50 Computer Music Journal</page><page sequence="3">of actuator assemblies. In this period, students are given instruction on the drill press, mill, and lathe, and are provided with short courses on welding and plasma cutting. Immediately following this is a workshop-style introduction to circuit design, intended to give students a thorough knowledge of the circuits and operating principles behind solenoids, stepper motors, servos, and direct current (DC) motors. The electronics section is taught exclusively using the Arduino microcontroller, and preaches the necessity of comprehensive design and documentation. The majority of robotic-design students concurrently take a class on musical interface design that teaches the use of different sensors for expressive musical and robotic control. After it is established that all of the students in the class possess a baseline set of skills, the remaining time is spent in the shop. The first assignment is to build a set of CalTron drum strikers. Designed by Machine Orchestra co-creator Michael Darling, the CalTron is a mechanically simple mallet mechanism for use on percussion instruments. Specifically developed to arm students with the advanced skills necessary to fabricate a variety of other electromechanical mechanisms, the final product is a fully working solenoid- based beater made primarily out of aluminum and acrylic. In fabricating the CalTron, the students are introduced to the concept of producing not only a functional, but also a visually appealing, mechanism. Mechanically, the CalTron operates on the principle of converting linear motion to rotational motion using a spring-loaded wheel onto which the beater is located, giving the mechanism a noticeable and unique action. Following the CalTron assignment, students em- bark on a collaborative design period in which they are expected to produce concepts and ideas for new robotic instruments. Based on the general interest and feasibility of two or three selected designs, several student groups form. Some class time is spent dumpster-diving, exploring junkyards, and shopping at surplus stores for materials that could be used as a basis for an instrument, or to otherwise introduce an interesting shape or design charac- teristic into one of the robotic frames. During the building process, some students emerge as experts on particular components presented in the class (e.g., fabrication, instrument design, electronics), and are given assignments based on those strengths. Many of the Technical Direction students who are already familiar with fabrication act as peer-mentors to their Music Technology counterparts, and vice versa with the Music Technology students' existing expertise in electronics. Robotic Instruments This section describes the robotic musical instru- ments that were built through several offerings of the robotic-design class (2008, 2009, and 2010) and sub- sequently used in Machine Orchestra performances. Each of the seven named robots is summarized with a description of its construction and musical char- acteristics. Each robot has a separate Arduino-based USB control module and power supply. All actuators are attached to the control module via Molex-brand connectors. Additional technical information on these robots can be found at the Karmetik Web site (www.karmetik.com/labs/robotics). Tammy At six feet tall, Tammy is physically the largest robot in the Orchestra (see Figure 2). The name Tammy is derived from the initials of the first names of the robotic-design class's teachers: Trimpin, Ajay Kapur, and Michael Darling. Tammy was built as a cooperative project between three groups of students, each designing an instrument attached to its spine-like frame. Tammy comprises a marimba, a plucked-string instrument, and five found-object bells. The single-octave pentatonic marimba is hand- crafted from Honduran rosewood and struck from the anterior side by push solenoids. Push solenoids were selected due to the adaptability of the springs used in their actuation,- each solenoid was tuned for maximal speed, permitting the performance of rhythmically dense clusters of notes. Tammy's bell section is made of aluminum fence caps and rotary dial phone bells. The bells are suspended above the base and struck with rotary solenoids. Kapur et al. 51</page><page sequence="4">Figure 2. Tammy onstage at REDCAT. The plucked-string instrument uses a DC motor whose threaded shaft plucks a sitar string. Two push solenoids mounted perpendicular to the string are used to create percussive sounds. Raina Raina (see Figure 3) is a kinetic rainstick constructed from a six-foot-long segment of modified polyvinyl chloride pipe. The pipe has been bisected and filled with more than 50 helically arranged wooden rods that are struck by pebbles, lentil beans, and BB-gun pellets. The pipe is attached via a chain drive to a large alternating current motor operating at a fraction of its rated voltage. The underpowered motor turns slowly, gently spinning the pipe on a ball-bearing axle. Immediately preceding concerts, Raina is activated, providing a subtle noisescape underlying each composition. MahaDeviBot MahaDeviBot (MDB; see Figure 4) serves as a model and as a proof-of-concept robot for various Figure 3. Raina , a simple motor-driven rainstick. methods of solenoid-based electromechanical percussion techniques. MDB has an assortment of twelve traditional Indian percussion instruments, including four frame drums, finger cymbals, a gong, several sets of bells, and wood blocks. MDB also features a bouncing anthropomorphic head attached to a spring-loaded solenoid used to convey tempo. More comprehensive documentation on MDB can be found in Kapur (2008). GanaPatiBot GanaPatiBot (GPB; see Figure 5) was conceived of as a successor to MDB. Like MDB, GPB features three frame drums and an assortment of other percussive noisemaking devices. Each of GBP's frame drums can be struck with two solenoids for the possibility of inhumanly fast drum rolls. These solenoids are mounted on bendable gooseneck assemblies, designed to be positioned in various configurations around the drumhead for timbrai flexibility. Additionally, GPB has a 6-in. metal gong, three rotary solenoids which click against the boťs frame, a shaker, and a metal rattle. Unlike MDB, GBP's actuators and instruments are oriented toward the audience for optimal visibility. In performances, both MDB and GBP are suspended from the ceiling, hovering approximately 6 feet off the ground. Robotic Reyong Robotic Reyong (see Figure 6) is an instrument that uses an array of solenoids to play a reyong, a 52 Computer Music Journal</page><page sequence="5">Figure 4. MahaDeviBot suspended on stage at REDCAT. Figure 4. Figure 5. GanaPatiBot suspended on stage at REDCAT Figure 5. Kapur et al. 53</page><page sequence="6">Figure 6. Robotic Reyong (left) in concert with CalArts Gamelan (right). traditional Balinese gamelan instrument composed of inverted metal pots. The reyong is set up beneath a metal frame, upon which short-travel push solenoids are attached. The push solenoids are capable of very fast operation, allowing for experimental and extended composition techniques, including the use of sustained tones. The Robotic Reyong has performed alongside a traditional Balinese gamelan ensemble. Breakbot Breakbot (see Figure 7) originated from several students' desires to see robotic instruments perform electronic dance music. The basis of the robot is a used drum set that was disassembled, retrofitted with a variety of motors, servos, and solenoids, and reassembled as a hanging kinetic sculpture. Breakbot has four main components: a kick drum, a snare drum, and two cymbals. The kick drum has two large pull solenoids which can be fired sequentially, allowing for fast poly rhythmic patterns. The snare drum was fitted with a DC motor-based mechanism which moves the drumstick to different points on the snare's head, varying the timbrai quality. A similar setup was utilized for the snare's brush mechanism. A variety of methods for manipulating the cymbals are used on Breakbot: The cymbals can be dampened and struck with an assortment of configurable mallets, wooden sticks, and plastic rods. Each of the elements on Breakbot was designed to be discretely installed and hung in different locations throughout a space. Glockenbot Glockenbot (see Figure 8) was built much as a team- oriented collaborative project, much like Tammy. Glockenbot utilizes 13 CalTron solenoid beater assemblies, 3 DC motors, 3 pull solenoids, and 5 push solenoids. Like Tammy, the robot contains three separate instruments: a metallophone with timbres similar to a glockenspiel, a solenoid- activated washboard percussion device, and a three- string plucking mechanisms with solenoid-activated slides. The aluminum bars are tuned chromatically from D to D. Each of the string mechanisms has a DC motor equipped with four guitar picks designed to produce extended string drones. 54 Computer Music Journal</page><page sequence="7">Figure 7. Detail shot of Breakbot. Top left: snare brush. Top right: beaters on a cymbal. Bottom left : actuator on the bass drum. Bottom right : rotary mechanism for snare brush. Design Elements This section describes fundamentals of the vi- sual and sonic aesthetic of the ensemble, stage configuration, and technical considerations of a performance-ready network. Interaction Throughout the conceptualization and realization of the Machine Orchestra, it was of prime importance to create a compelling performance with both visible and audible human-human and human-robot interaction. Following the paradigm established by Trueman, Bahn, and Cook (2000), and Wang's design for SLOrk, the use of ten hemispherical speaker arrays (hemis; see Figure 9) allowed for precise sound localization of each performer. Employing the hemis allowed each laptop to be accentuated by a sound field not afforded by conventional two-channel stereo configurations. In performance, hemis bridge the separation between the acoustic instruments on stage and the electronically generated sound from the performers. Due to the frequency limitations of the hemis, it is necessary to selectively reinforce certain performers with additional speaker systems including 15-in. and 17-in. woofers and subwoofers. Although the localization of sound significantly improved the connection between performer and musical action, further emphasis was placed on visual elements to underline certain actions or reac- tions. Specifically, several robots were paired with a number of small cameras. The cameras provide a live video stream of various actuators and are pro- jected across three custom-built screens. By being Kapur et al. 55</page><page sequence="8">Figure 8. Glockenbot. Figure 8. Figure 9. Hemispherical speaker arrays with 6-in. Polk Audio drivers. Figure 9. 56 Computer Music Journal</page><page sequence="9">Figure 10. Machine Orchestra stage configuration #1. (Robots and piano not pictured.) Figure 10. Figure 11. Machine Orchestra stage configuration #2. Figure 11. explicitly shown the actions of the robots on a larger scale, the audience is able to appreciate the complexity of performer-robot interaction regard- less of any technical knowledge of the ensemble. In combination with many of the gestural (now musical) interfaces used by the performers, this approach allows the audience to quickly gain a familiarity between the actions of the performers and the reactions of the robots. Stage Design The custom, often gestured, controllers and inter- faces played by the performers command visual attention. The stage configuration is designed to support the visual display of each performer and his or her controller as the performers interact with the robots. In our first configuration (see Figure 10), the performers were positioned on a series of two-tiered platforms in a terrace-style arrangement. The piano and the gamelan ensemble are both positioned at the base of the stage. This arrangement proved successful by perceptually segregating each per- former on a separate tier while maintaining a sense of communication via proximity. Although this con- figuration works well in large performance spaces, a second setup was necessary to accommodate smaller performance venues. The second stage configuration (see Figure 11) is optimized for portability and ease of setup. In this configuration, the sitar and dilruba players were placed on risers on each side of the stage. The robotic musical instruments were placed in the center of the stage, and laptop musicians performed on their own risers upstage of the robots. Network Design Throughout the past few decades, networked com- puter music has been examined by a number of research groups and ensembles. Ensembles such as the League of Automatic Composers and the Hub have explored, on a technical and musical level, how performers can pass, process, and act on real-time Kapur et al. 57</page><page sequence="10">Figure 12. Overview of network communication. messages sent between members of a group. More recently, the idea of networked composition and per- formance has exerted significant influence on laptop orchestras such as PLOrk and SLOrk (Trueman et al. 2006). The development of the OpenSoundControl (OSC) protocol has opened up the possibility of building robust and easy-to-implement networks of musical performers with little developmental overhead. Based primarily on OSC, The Machine Orchestra has devised a client-server architecture allowing for the dynamic addition of performers to the network, MIDI clock synchronization, and monitored access to the actuators on each of the robots (see Figure 12). A thorough description of the client-server model in comparison with other types of network topologies for performance is presented by Weinberg (2005). In performing with robotic instruments that inherently have a built-in mechanical delay, we found it necessary to build a network that could provide adequate low-latency throughput. Low- latency communication is a prime objective in order to maintain a musically cohesive sound. An analysis of wireless communication for performance is presented in Cerqueira (2010). Our own preliminary experiments, using an off-the-shelf wireless Linksys 802.11g router, revealed that a wireless latency between 30-50 msec was perceptually inadequate for our needs in relation to performer-to-performer and performer-to-robot communication. Additionally, the work presented by Cerqueira concludes that wireless performance significantly degrades with more than 15 clients on a single router, mostly due to packet loss. The Orchestra uses a standard switch-based network (an Extreme Networks 200E Gigabit switch) to mitigate these problems. With a wired switch, we were able to achieve stable sub- millisecond latency across 18 or more performers, with no performance penalty. Until 2011, the server and client platform was based on a prototype ChucK-based framework de- veloped by PLOrk. Server and clients communicate directly through OSC, where the client acts as an OSC-to-MIDI converter. A number of modifications to the client-side ChucK executable were necessary to implement stable MIDI clock synchronization, a feature used in many compositions. One performer acts as a master clock on the network, sending a clock stream to the server, which then broadcasts to all connected clients. Each client is equipped with a function to receive MIDI synchronization messages without requiring the master clock to stop and sub- sequently restart, normally a limitation of the MIDI protocol when used in the context of a network. Machine Orchestra performances and rehearsals rely on a single dedicated computer to run the server 58 Computer Music Journal</page><page sequence="11">software. Connected to the Ethernet switch, the server utilizes ChucK for client communication and synchronization, and a Java-based graphical user interface (GUI) and serial protocol translator for communicating directly with the robots. Used primarily in debugging and testing, the GUI affords an at-a-glance overview of the clients and robots. Composition and Performance Music for the Machine Orchestra is composed and rehearsed by students, faculty, and collaborators during weekly class time, separate from robotic design. Time is divided between writing musi- cal material and developing software systems for performer-machine interaction. The notion of a robotic orchestra as a compositional resource has led to the involvement of various electronic musi- cians, dancers, and world music masters including Trimpin, Curtis Bahn, Perry Cook, Tomie Hahn, Ustad Aashish Khan, and I. Nyoman Wenten. These guests are expected to perform a solo piece intended to highlight a new technological or compositional process that has not been previously explored by the Orchestra. The following section describes several pieces exploring a representative set of the current compositional and performance capabilities of the Machine Orchestra. Voices Voices is a structured improvisation created to high- light new musical interfaces developed by members of the ensemble. Each performer is tasked with exploring vocal synthesis and vocal sample manip- ulation using his or her controllers. As the piece evolves during performance, dialogs between differ- ent performers are expected to emerge, culminating in a large-scale controller-defined gestural conversa- tion. This improvisational process was influenced by early systems described by Kapur et al. (2008). Interfaces such as the Arduinome (Vallis, Hochen- baum, and Kapur 2010), Helio (Murphy, Kapur, and Bürgin 2010), and the Multi-Laser Gestural Interface (Wiley and Kapur 2009) have regularly been featured in Voices. Mechanique Mechanique follows the process developed for Voices , but extends it to direct human-robot control, once an audience is familiar with each performer and his or her controller. Mechanique takes advantage of the clock- synchronization capabilities of the client-server architecture to mediate a tight, highly rhythmic performance. Each performer is granted control over three to four robotic actuators and expected to spontaneously generate new rhythmic and polyrhythmic sequences using his or her controller. Structurally, the piece begins with each performer generating sequences for a single actuator. As the piece progresses, performers use more assigned actuators, culminating in a rhythmic cacophony with a sudden and unexpected ending. Digital Sankirna Digital Sankirna is a solo piece by Ajay Kapur, having roots in his PhD research on musical robotics. In the piece, Kapur performs the raga Jog with his eSitar hyperinstrument (Kapur et al. 2004). Triggered by sensors and real-time analysis of his eSitar performance, streams of rapid-fire notes on selected robotic instruments are initiated with every musical gesture. The piece begins with subtle triggering and dynamic control of various percussion actuators; Kapur has termed this the "butterfly" technique: solenoids that are triggered rapidly with very low velocity so as not to make full contact with an instrument. Abhyasa Abhyasa is a solo piece by Curtis Bahn, a regular collaborator with the Orchestra. Bahn has been active in developing frameworks for human-robot improvisation using his computer-extended instru- ments: sitar and dilruba. Abhyasa is a Sanskrit word referring to persistent effort and practice over a long period of time, and represents the idea of the long- term interaction between the ensemble's humans and robots in developing a compelling musical relationship. In Abhyasa, rhythmic textures evolve Kapur et al. 59</page><page sequence="12">Figure 13. pikapika (Tomie Hahn) bringing the robots to life in performance. across the robots in a sort of digital counterpoint to Bahn's performance. Dovetailing with phrases of his performance, algorithms using an analysis of his pitch, rhythm, and amplitude invoke a dynamic rhythmic musical response. This evolving musical texture can be shaped by continuous control gestures from the accelerometer mounted on his sensor bow. The piece begins with slow evolving phrases in raga Khamaj and, after a period of time, a gentle rhythmic figure enters and the subtle exchange between the robots and dilruba continues metrically. The interaction and shaping of the robotic textures is completely spontaneous and algorithmic. pikapika Bahn and dancer Tomie Hahn have created an adaptation of their piece pikapika as an interactive robotic performance (see Figure 13). Although the development of the interactive sonic character and sensor interface for pikapika has been described previously (Hahn and Bahn 2002), significant to this writing is that their new version of this composi- tion develops the notion of theatrical interaction between live dancers and robots. This piece is also a completely spontaneous and algorithmically "improvised" interaction between performer and robotic ensemble. Analysis of the performer's ges- tures drives the selection of different sonic palettes, rhythmic generation, dynamics, and large-scale phrasing. Computer Music Computer Music is a percussion piece by Trimpin. The piece does not utilize any existing robots, but instead consists of an array of six laptop computers struck with rotary solenoids. The laptops, collectively called the Computer Percussion Ensemble, are Trimpin's personal com- puters dating from the mid 1980s through the mid 2000s. Audience members see a progression of tech- nology in various stages of obsolescence as each laptop is transformed into a passive tool for percus- sion. Computer Music focuses on the polyrhythmic structure of each computer being struck. During the performance, Trimpin physically places the laptops and beaters around the stage, connecting each one individually over a 10-min. period. A central server registers the connection of individual beaters and 60 Computer Music Journal</page><page sequence="13">Figure 14. World premiere of the Machine Orchestra at REDCAT Walt Disney Hall, Los Angeles, California, 21 January 2010. plays pre-programmed rhythms. The piece ends in a surprise as Trimpin hurriedly rushes to the central server and unplugs it. Untitled Compositions by Trimpin In addition to Computer Music, Trimpin has per- formed two untitled pieces as part of the Orchestra. The first features an array of custom record turnta- bles fitted with motor drive speed controls. Using a musical controller consisting of a cello equipped with infrared sensors, Trimpin controls playback speed and direction of the records on each turntable. Trimpin's cello interface controls not only the turntables but also the full ensemble of robotic instruments playing pre-programmed sequences. Trimpin's second untitled piece for the Orchestra consists of a concert grand piano prepared with a collection of solenoids and DC motors. This piece focuses on emphasizing the harmonic resonances within the piano through the application of motor- driven bows on the strings. In addition to the bowed strings, small solenoids were used to strike strings in the piano's upper register. The resultant composition was performed by Trimpin and Jim Murphy, with Murphy controlling the percussive aspects of the piece and Trimpin manipulating the motors. Tari Topeng Dalem Arsa Wijaya With the large presence of Indonesian musical talent at CalArts, led by I. Nyoman Wenten and Robotic Reyong, a large body of work fuses live electronics and gamelan. This presents unique challenges, such as keeping time with the robots while following all the changes in timing from a traditional gamelan orchestra. Tari Topeng Dalem Arsa Wijaya, a collaboratively composed piece for Robotic Reyong and a human gamelan ensemble, premiered at the Machine Orchestra's 2010 REDCAT performance (see Figure 14). Conclusion The Machine Orchestra is an experimental labo- ratory incorporating ideas from a vast number of Kapur et al. 61</page><page sequence="14">fields and disciplines to form a cohesive whole. Traditional notions of musicianship, composition, improvisation, and ensemble performance are re- defined through robotics, new instrument design, and networked performance. An open framework for students and guest collaborators, the ensemble has explored innovative pieces where social, musi- cal, and technological factors meet on a practical level, demanding that members rethink notions of performance in a robotic age. Acknowledgments Special thanks to Trimpin for his exceptional mentorship, training the authors and students to think in new ways. Thanks to Owen Vallis, Meason Wiley, Jim Murphy, Jordan Hochenbaum, Jeremiah Thies, Dimitri Diakopoulos, Carl Bürgin, Tyler Yamin, Jeff Lufkin, Mark Taylor, Steven Rusch, Christopher Adams, John Aspinall, Elizabeth Eggert, Lesley Fairman, Daniel Goldenshtein, Jason Jahnke, Roger Marcelo, Rodrigo Restrepo, Thomas Velluet- Draper, Benjamin Womick, Duncan Woodbury, Jordan Woods-Wahl, Nyoman Wenten, Perry Cook, Curtis Bahn, and David Rosenboom. References Cerqueira, M. 2010. ,ä Synchronization over Networks for Live Laptop Music Performance. " Master's Thesis, De- partment of Computer Science, Princeton University. Focke, Anne, ed. 2011. Trimpin : Contraptions for Art and Sound. Seattle: University of Washington Press. Hahn, T., and С. Bahn. 2002. "Pikapika - The Collabora- tive Composition of an Interactive Sonic Character/7 Organized Sound 7(3): 229-238. Kaneda, T., et al. 1999. "Subject of Making Music Per- formance Robots and Their Ensemble/7 In Proceedings of the ASEE/IEEE Frontiers in Education Conference, vol. 2, pp. 12B4/1-12B4/6. Kapur, A. 2008. Digitizing North Indian Music: Preserva- tion and Extension using Multimodal Sensor Systems, Machine Learning and Robotics . Saarbrücken: VDM Verlag. Kapur, A., and M. Darling. 2010. "A Pedagogical Paradigm for Musical Robotics/7 In Proceedings of the Inter- national Conference on New Interfaces for Musical Expression, pp. 162-165. Kapur, A., et al. 2004. "The Electronic Sitar Controller.77 In Proceedings of the International Conference on New- Interfaces for Musical Expression, pp. 7-12. Kapur, A., et al. 2008. " Collaborative Composition for Musical Robots.77 In Proceedings of the International Conference on Digital Arts (pages unnumbered). MacMurtie, C. 2010. "Amorphic Robot Works.77 Available on-line at amorphicrobotworks.org/works/index.htm. Accessed July 201 1 . Murphy, J., A. Kapur, and C. Bürgin. 2010. "The Helio: A Study of Membrane Potentiometers and Long Force Sensing Resistors for Musical Interfaces.77 In Proceedings of the International Conference on New Interfaces for Musical Expression, pp. 459-462. Raes, G. W. 2010. " Automations by Godfried-Willem Raes.77 Available on-line at www.logosfoundation.org. Accessed July 201 1. Singer, E., et al. 2004. "LEMUR7s Musical Robots.77 In Proceedings of the International Conference on New Interfaces for Musical Expression, pp. 181-184. Solis, J., et al. 2004. "Learning to Play the Flute with an Anthropomorphic Robot.77 In Proceedings of the International Computer Music Conference, pp. 146- 151. Trueman, D., C. Bahn, and P. Cook. 2000. " Alternative Voices for Electronic Sound: Spherical Speakers and Sensor-Speaker Arrays (SenSAs).77 In Proceedings of the International Computer Music Conference (pages unnumbered). Trueman, D, et al. 2006. "PLOrk: The Princeton Laptop Orchestra, Year l.77 In Proceedings of the International Computer Music Conference, pp. 443-450. Vallis, O., J. Hochenbaum, and A. Kapur. 2010. "A Shift Towards Iterative and Open-Source Design for Musical Interfaces.77 In Proceedings of the International Conference on New Interfaces for Musical Expression, pp. 1-6. Wang, G., G. Essi, and H. Penttinen. 2008. "Do Mobile Phones Dream of Electric Orchestras?77 In Proceedings of International Computer Music Conference, pp. 24-29. Wang, G., et al. 2008. "The Laptop Orchestra as Classroom.77 Computer Music Journal 31(1 ):26- 3 7. Weinberg, G., 2005. "Interconnected Musical Networks: Toward a Theoretical Framework.77 Computer Music Journal 29(2):23-39. Weinberg, G., S. Driscoll, and T. Thatcher. 2006. "Jam7aa - A Middle Eastern Percussion Ensemble for Human and Robotic Players.77 In Proceedings of the International Computer Music Conference, pp. 464- 467. 62 Computer Music Journal</page><page sequence="15">Wiley, M., and A. Kapur. 2009. "Multi-Laser Gestural Interface: Solutions for Cost-Effective and Open Source Controllers/7 In Proceedings of the International Conference on New Interfaces for Musical Expression, pp. 43-44. Appendix: Web Sites of Laptop Orchestras The Hub: en.wikipedia.org/wiki/The_Hub .(band) Princeton Laptop Orchestra: plork.cs. princeton .edu Stanford Laptop Orchestra: slork.stanford.edu Oslo Laptop Orchestra: fourms.wiki.ifi.uio.no/ Oslo_Laptop_Orchestra Boulder Laptop Orchestra: cismat.org/blork.html Moscow Laptop Cyber Orchestra: cyberorchestra .com Tokyo Laptop Orchestra: laptoporchestra.net Seattle Laptop Orchestra: www.laptoporchestra .com Virginia Tech Laptop Orchestra: l2ork.music.vt .edu/main Michigan Mobile Phone Orchestra: mopho.eecs .umich.edu Helsinki Mobile Phone Orchestra: www.acoustics . hut . f i/pro ) ec t s /helsinkimopho Kapur et al. 63</page></plain_text>
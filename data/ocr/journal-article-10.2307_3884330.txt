<plain_text><page sequence="1">Amer. Zool., 40:835-846 (2000) Animal Consciousness: Some Philosophical, Methodological, and Evolutionary Problems1 Matt Cartmill2 Department of Biological, Anthropology and Anatomy, Box 3170, Duke University Medical Center, Durham, North Caroline 27710 Synopsis. No consensus exists concerning the mechanisms, distribution, or adap? tive significance of consciousness. Agreement on any one of these issues would aid in resolving others. Given a reliable behavioral or neuroanatomical test for con? sciousness, we could map its distribution and describe its evolution. Conversely, if we knew its distribution, we could assess its adaptive value and look for similarly distributed neuroanatomies to help us get at its mechanisms. Morgan's Canon?the rule that we should avoid attributing humanlike mental states to other animals whenever possible?impedes the use of the comparative method in unraveling this knot. If interpreted in this context as a parsimony cri- terion, Morgan's Canon is logically equivalent to epiphenomenalism. It is parsi? monious if and only if conscious mental events play no causal role in human be? havior and human consciousness has no adaptive significance. Rejecting this con? clusion entails rejecting the parsimony interpretation of Morgan's Canon. The Problems of Consciousness The phenomemon of consciousness has been a central issue in much of post-Car- tesian philosophy and psychology, and the amount of attention devoted to it by philos- ophers and scientists has increased mark? edly in recent years. During the past de? cade, a growing number of specialists on the subject have published dozens of books on the problems of consciousness (e.g., Ed- elman, 1989, 1992; Penrose, 1989, 1994; Hannay, 1990; Sommerhoff, 1990; Dennett, 1991; McGinn, 1991; Flanagan, 1992; Ro- senfield, 1992; Humphrey, 1992; Searle, 1992, 1997; Herbert, 1993; Kirk, 1994; Strawson, 1994; Tye, 1995; Carruthers, 1996; Chalmers, 1996; Hobson, 1996; Ly- can, 1997; Baars, 1997; Norretranders, 1998). Innumerable journal articles, meet? ings, and proceedings of symposia have fo? cussed on the ontology, epistemology, mechanisms, and distribution of conscious awareness, and learned journals devoted to the topic (Journal of Consciousness Stud- 1 From the Symposium Animal Consciousness: His? torical, Theoretical, and Empirical Perspectives pre? sented at the Annual Meeting of the Society for Inte? grative and comparative Biology, 6-10 January 1999, at Denver, Colorado. 2 E-mail: matt_cartmill@baa.mc.duke.edu ies, Consciousness and Cognition) have come into being. Despite all this thoughtful attention, the phenomenon of consciousness is still curi- ously slippery and resistant to scientific study. No other biological phenomenon has remained so persistently ensnarled in fun? damental philosophical and semantic tan- gles. As long as we avoid thinking about it, the concept of consciousness seems intui- tively clear. The ebb and flow of conscious? ness is a familiar, everyday fact of human experience: we lose consciousness every night when we fall asleep, and regain it ev? ery morning when we wake up. Under or- dinary circumstances, we are not in doubt about whether we are conscious or not. We even have little difficulty in determining when other people lose or regain conscious? ness. But when we try to describe just what it is that they have lost or regained, we find ourselves wandering in a maze of gray ar? eas, circular definitions, and neurological and behavioral blind alleys. The mechanisms of consciousness re? main profoundly obscure in a way that the mechanisms of other biological phenomena are not. To be sure, it is clear that con? sciousness depends on the operations of the brain. Consciousness fades or vanishes when the normal patterns of waking neural 835</page><page sequence="2">836 Matt Cartmill activity in the brain are replaced by the pat? terns characteristic of epilepsy or sleep, or when the tissues of the brain are infiltrated by intoxicants or injured. Injury or distur? bance of other organs engenders no such loss, unless the brain is secondarily affected by their disruption. But we have no expla? nation of how brain activity produces con? sciousness. Worse yet, we lack any real model of what such an explanation might look like. We are not thus handicapped in the case of other persistently mysterious bi? ological phenomena. For example, we do not yet have any convincing account of how life came into being; but we can see in principle what steps would be necessary to transform assemblages of nonliving or? ganic molecules into self-reproducing sys? tems. In the case of consciousness, we do not even see in principle "how technicolor phenomenology can arise from grey soggy matter" (McGinn, 1989). Some people have given up and reached various despairing conclusions. Block (1995) concludes that consciousness cannot be defined other than circularly, via rough synonyms ("awareness," etc.) or ostensive- ly, through examples. Chalmers (1995) con- tends that consciousness eludes scientific definition because conscious awareness, like mass, charge, and space-time, is an el? emental component of the universe not sus- ceptible to further dissection or analysis. Skeptics like Nagel and the so-called "new mysterians" (Flanagan, 1991, p. 313) doubt that consciousness can ever be explicable in naturalistic terms, and intimate that to at? tempt such explanations involves a fallacy akin to the naturalistic fallacy in ethics? that it is just as logically impossible to squeeze first-person experience out of a se? ries of third-person statements as it is to squeeze a moral imperative out of a string of facts. And both metaphysical skeptics on the one hand (Nagel, 1974; p. 437) and hard-nosed behaviorists on the other some? times say that consciousness is not a proper subject for scientific investigation, because science is incapable of dealing with subjec- tive, first-person phenomena. Giizeldere (1997, p. 25) states the general problem in this way: Consciousness just does not seem to be the kind of phenomenon that is amenable to the sort of scientific explanation that works so well with all other biological phenomena, such as digestion or repro? duction. The facts that would settle the question of whether some organism?an animal or a fellow human being?is di- gesting do not seem to be available in the same way when it comes to the question of consciousness in others, especially in the case of organisms phylogenetically distant from ourselves . . . These are the limitations of the third-person perspec? tive: from the outside, first-hand explo- ration of the consciousness of others just seems to be out of the reach of ordinary scientific methods, others' experiences being neither directly observable nor noninferentially verifiable. As far as human consciousness is con? cerned, the first-person problem may be something of a red herring. A scientific ap? proach to the world is perfectly compatible with accepting the reality of subjective ex? perience. It has to be compatible, because all experience is subjective?or, to put it an? other way, all observations are necessarily from the standpoint of some observer. What science demands of experiences that claim the name of evidence is not that they be "objective" in the sense of being observer- independent, but that they be replicable. Science refuses to credit unique or privi- leged experience. (For this reason, science is fundamentally anti-authoritarian.) But it has no difficulty dealing with subjective ex? perience per se. Scientific experiments are not necessarily public events. They are sim? ply experiences that any of us can have if we follow the directions; and the fact that an experience is ontologically private does not exclude it from scientific investigation. For example, any observer with normal vision who looks fixedly at the letter "a" in Figure 1 for about 20 see and then looks over at the letter "b" will see a circular gray afterimage surrounding the "b." Such afterimages are reliably replicable and per? fectly amenable to scientific study. Their physiological basis is reasonably well un? derstood; they result from the saturation or</page><page sequence="3">Animal Consciousness: Problems 837 Fig. 1. When one looks at the letter "b" after gazing fixedly for 20 see at the letter "a," one sees a circular gray afterimage surrounding the "b." In the present state of our knowledge, the afterimage is a private event; nevertheless, such afterimages can be reliably reproduced and studied scientifically. bleaching of retinal photopigments under intense or prolonged illumination (Brindley, 1963). Yet although afterimages have intel- ligible physical causes, and may even allow us to "see" details not discernible in the primary visual image (Adelson, 1982), the afterimage of the gray disk is an illusion that corresponds to no gray object "out there" in the world of noumena. Moreover, the fact that we see it is not something that we could have inferred from the facts about photopigment saturation. After all, our vi? sual system might have evolved to elimi? nate afterimages by correcting for such sat? uration, as it eliminates and fills in the "blind spot" corresponding to the optic disk on the retina. In the present state of our knowledge, afterimages are therefore ontologically subjective phenomena. Although the replication of ontologically subjective phenomena is not dependent on behavioral criteria of their occurrence, iden- tifying it as replication depends on verbal behavior?namely, the public sharing of similar reports on the results of similar pro? cedures. We accept such shared reports as evidence for the recurrence of subjective experiences like ours in other minds be? cause the brains and behavior of other adult humans are similar to our own. If you re? port seeing a circular gray afterimage sur? rounding the "b" in Figure 1, and I tell you that I see the same thing, each of us will ordinarily be willing to take the other's word for it without having other operational criteria for the occurrence of an afterimage, or a theory of how the operations of the eye and brain produce the effect. But we hesi- tate to make inferences about subjective ex? perience in cases where we lack either un? derlying similarities of structure or verbal reports of experience (or both). The first case, where we have humanlike verbal be? havior without brains or retinas, is the sit? uation we confront in dealing with the issue of artificial intelligence. The converse case, in which we encounter humanlike brains and retinas but find no verbal behavior, is the situation we encounter in the question of animal consciousness. Doubts Concerning Animal Consciousness Doubts about the consciousness of ani? mals occasionally surfaced even in classical antiquity. Augustine (City ofGod, 12.4) ar? gued that nothing can be perceived without reason, which is needed to judge and clas- sify sensations, and that beasts, lacking rea? son, therefore "lack understanding, sensa- tion, and life altogether" (vel intellectu vel sensu vel vita omnino) (Green, 1966, v. 4, pp. 16-17). However, pre-scientific philos- ophers, like most people, generally accept? ed without question the commonsense be- liefs that a kicked dog feels pain and a re- peatedly kicked dog suffers. The reality of animal consciousness was first called into serious question at the beginning of the sci? entific revolution by Descartes, who was also responsible for giving the phenomenon of consciousness its central place in the his? tory of modern philosophy. Descartes regarded animals as probably non-sentient automata. By Descartes' anal? ysis, we perceive things consciously only because we are conscious that we perceive things (Malcolm, 1973). Since animals lack language, we can feel reasonably sure that they cannot reflect on their sensations; therefore, they cannot be aware of them. Descartes concluded that the beasts have sensations only in the sense that a mouse- trap has a "sensation" of a mouse nibbling on its baited trigger. In both cases, there is stimulation of a sensor and a mechanical response, but there is no subjective aware? ness. Later Cartesians accepted Descartes'</page><page sequence="4">838 Matt Cartmill view as a demonstrated fact. As Male- branche wrote in 1689: In dogs, cats, and other animals, there is neither intelligence nor a spiritual soul in the usual sense. They eat without plea- sure; they cry without pain; they believe without knowing it; they desire nothing; they know nothing; and if they act in what seems to be an intelligent and pur- posive manner, it is only because God has made them fit to survive, and has constructed their bodies in such a way that they can organically avoid?without knowing that they do so?everything that might destroy them and that they seem to fear. (Translated from Huxley, 1896, pp. 218-219) This view has persisted down to our own time, with natural selection replacing God as the agent of design. Perhaps the leading exponent of this position today is Daniel Dennett, who describes consciousness as an illusion from which non-human animals do not suffer. To quote Dennett (1999, pp. 292-293): . . . What [our] early education produces in us is a sort of benign "user-illu- sion"?I call it the Cartesian Theater: the illusion that there is a place in our brains where the show goes on, towards which all perceptual "input" streams, and whence flow all "conscious intentions" to act and speak. I claim that other spe? cies?and human beings when they are newborn?simply are not beset by the il? lusion of the Cartesian Theater . . . In or? der to be conscious?in order to be the sort of thing it is like something to be? it is necessary to have a certain sort of informational organization that endows that thing with a wide set of cognitive powers (such as the powers of reflection and re-representation). This ... is an or? ganization that is swiftly achieved in one species, ours, and in no other. Although Dennett is by no means alone in this belief, most of the scientists and phi- losophers who write about these issues re? gard our close animal relatives as having some sort of conscious mental life, but one which is defective and qualitatively inferior Fig. 2. Three examples of non-verbal concepts: an anatomical feature (A), an artifact (B), and a written symbol (C). (From Cartmill, 1996) to our own. Most of these people think that language makes the crucial difference be? tween human and animal consciousness, though they offer different reasons for thinking so. Some insist that language is necessary for conceptual thought. Animals, they ar? gue, can form no general concepts because they lack words. "Any thoughts [animals] express are particular, not general, and con? cern the present or future, not the past," contends Jonathan Bennett (1988, p. 204). "My hunch is that only through language can one show that one has thoughts that are not about what is present and particular." Speechless beasts are therefore compelled to think (if that is the correct term) wholly in terms of particular individuals, like someone condemned to speak a language consisting entirely of proper nouns (Pfungst, 1911; Adler, 1967). One difficulty with this view is that many of our own concepts do not carry linguistic labels. Figure 2 presents three examples: an anatomical structure, an artifact, and a writ? ten symbol. Although anatomists, novelty salesmen, and typographers no doubt have names for these things, most of us have no idea what they are called. Nevertheless, we instantly recognize them as representing fa? miliar classes of entities that we are accus- tomed to dealing with. We therefore have wordless concepts. Other animals may have them as well (Cartmill, 1990, 1996). Another supposed defect in animal men-</page><page sequence="5">Animal Consciousness: Problems 839 tation is often expressed by saying that beasts, lacking language, must of necessity lack self-awareness. Different writers make this claim in different words, implying that animals have primary consciousness but not higher-order consciousness (Edelman, 1989), or that they have perceptual con? sciousness but not reflective consciousness (Griffin, 1992, p. 10-11), or creature con? sciousness but not state consciousness (Ro- senthal, 1997), or phenomenal conscious? ness but not access consciousness (Block, 1995), or consciousness of qualia but not of information flow, or experiential sensitivity but not informational sensitivity (Flanagan, 1992, p. 147). What is asserted (roughly) by all these formulations is that although some nonhuman animals probably perceive things, none perceive themselves as per- ceiving them. Animals can feel (say) pain as an unconceptualized "raw feel" (Rorty, 1979, p. 24); however, they do not know that they are in pain, because they have no concept of "I" and no capacity for assess? ment of their own mental states. These abil? ities are supposedly conferred by the con? ceptual apparatus of language, which is necessary to allow self-representation?that is, thinking of one's self as an object. In Bickerton's words: What seems to us most striking about our kind of consciousness is its self-reflexive nature. We can perform a series of ac? tions and at the same time observe our- selves performing them, so to speak . . . This feeling of subjective consciousness is, of course, 'What it is like to be a hu? man', and language contributes to it in a variety of ways. The most basic of these lies in providing the infrastructure for consciousness. You can't look at the spot you're standing on now if there is no- where else for you to stand. A minimal prerequisite for self-consciousness is a place . . . from which a part of you can look at another part of you. The second? ary representational system [of language] is such a place. (Bickerton, 1990; pp. 208-209) Some psychologists and philosophers (e.g., Smith, 1986) claim or intimate that such reflexivity is a minimal condition for consciousness of any sort?that, in Rosen- thal's (1993) words, consciousness is a re- flexive feature of mental states, and that ev? ery conscious mental state must be in part about itself. The Darwinist's Dilemma The opposite school of thought holds that language contributes little to consciousness, and that as Charles Darwin put it, "there is no fundamental difference between man and the higher mammals in their mental faculties" (Darwin, 1889, p. 66). This claim, which we will call anthropopsych- ism, is often condemned as unscientific, sentimental, or anthropomorphic. However, it has also been put forward by many sci? entific materialists as a rebuff to Christian or Cartesian dualisms that posit a profound spiritual difference between human beings and the beasts. Darwin and many of his early followers held anthropopsychic views for just such strategic reasons. In the mid-19th century, the supposedly unbridgeable psychological and spiritual gap between people and beasts was generally perceived as an important ob- jection to the thesis that human beings had evolved from apes. Darwinians accordingly labored to narrow that gap, both by exag- gerating the humanlike characteristics of beasts and by promulgating racist stereo- types of "savages" as quasi-simian inter? mediates "bridging the psychological dis? tance which separates the gorilla from the gentleman" (Romanes, 1889, p. 439). Summarizing his own labors to that end, Darwin looked backward to the 18th-cen- tury vision of the Scala Naturae, laterally to the recapitulationism of von Baer and Haeckel, and forward to some of the central issues in 20th-century debates on these sub? jects: . . . The difference in mind between man and the higher aiiimals, great as it is, cer? tainly is one of degree and not of kind. We have seen that the senses and intui- tions, the various emotions and faculties, such as love, memory, attention, curios- ity, imitation, reason, &amp;c, of which man boasts, may be found in an incipient, or even sometimes in a well-developed con-</page><page sequence="6">840 Matt Cartmill dition, in the lower animals ... If it could be proved that certain high mental powers, such as the formation of general concepts, self-consciousness &amp;c, were absolutely peculiar to man, which seems extremely doubtful, it is not improbable that these qualities are merely the inci? dental results of other highly-advanced intellectual faculties; and these again mainly the result of the continued use of a perfect language. At what age does the new-born infant possess the power of ab- straction, or become self-conscious, and reflect on its own existence? We cannot answer; nor can we answer in regard to the ascending organic scale . . . That such evolution [of mental and moral fac? ulties] is at least possible, ought not to be denied, for we daily see these faculties developing in every infant; and we may trace a perfect gradation from the mind of an utter idiot, lower than that of an animal low in the scale, to the mind of a Newton. (Darwin, 1889, pp. 126-127) Darwin's theory of evolution by natural selection provides a model of how the mind of a Newton might evolve from that of an ape by imperceptible stages. Unfortunately, it also raises doubts about the significance of the expressive behaviors that Darwin pointed to as signs of "the various emotions and faculties . . . in the lower animals." To a consistent Darwinian, expressive behaviors demand explanations that extend beyond their proximate causes to their evo? lutionary origins. For example, grief is one proximate cause of human weeping; but this does not explain why we express grief in this particular way, or indeed why we express it at all. Why should we weep when we grieve? It seems counterproductive. (Why waste energy in sobbing, or lose body fluid by shedding tears?) To answer such questions in Darwinian terms, we must be able to attach some selective advantage to these expressive behaviors. But if a behav- ior's surface properties render it selectively advantageous, we can explain its origin and occurrence without reading any underlying mental events into it. We can reliably infer subjective pain from the yelp of a kicked dog only if the yelp serves no objective purpose. If it can be seen as adaptively use? ful?say, by serving to alert nearby kin to danger?then we can argue with Male- branche that God or natural selection has simply endowed dogs with a mechanical squeaker to enhance their reproductive fit? ness, and that "if they act in what seems to be an intelligent and purposive manner, it is only because God has made them fit to survive." Darwinian anthropopsychism thus con? tained the seeds of its own denial. If ex- pressive behaviors have no adaptive value, then natural selection cannot account for them. But if expressive behavior is adap? tive, then it cannot furnish evidence for an? imal awareness. Epiphenomenalism and Morgan's Canon Thomas Huxley evaded this dilemma by embracing epiphenomenalism?that is, the doctrine that the neural events that cause the behavior also cause the accompanying mental states, and that the mental events themselves are mere epiphenomena that have no effect on the behavior. As a Dar? winian, Huxley was unwilling to believe that consciousness is a uniquely human property with no animal antecedents. How? ever, published studies of the behavior of brain-damaged people convinced him that complex, even distinctively human, behav? ior is possible in the absence of conscious awareness. He concluded that in both beasts and people, consciousness is a functionless side effect of the true neurological causes of behavior. In Huxley's (1896, pp. 240, 244) words: The consciousness of brutes would ap? pear to be related to the mechanism of their body simply as a collateral product of its working, and to be as completely without any power of modifying that working as the steam-whistle which ac- companies the work of a locomotive en- gine is without influence upon its ma? chinery. Their volition, if they have any, is an emotion indicative of physical changes, not a cause of such changes . . . [And] it seems to me that in men, as in brutes, there is no proof that any state of</page><page sequence="7">Animal Consciousness: Problems 841 consciousness is the cause of change in the motion of the matter of the organism. The most influential rejection of Darwin? ian anthropopsychism was offered by the British psychologist C. Lloyd Morgan, who in 1894 articulated the principle known as Morgan's Canon: ?In no case may we interpret an action as the outcome of the exercise of a higher psychical faculty, if it can be interpreted as the outcome of the exercise of one which stands lower in the psychological scale. (Morgan, 1977, p. 53) Succeeding generations of experimental psychologists have adopted this dictum as a fundamental axiom in the study of animal behavior. Morgan's Canon is sometimes re- garded as a special case of Occam's Razor, the principle that "It is vain to do with more what can be done with less" (New- bury, 1954; Sober, 1998; Staddon and Zan- utto, 2000). If we can explain an animal's behavior as, say, a conditioned operant, then Morgan's Canon forbids us to interpret it as the outcome of the exercise of such "higher" faculties as volition or delibera- tion. Because Morgan's assumption places the burden of proof on the anthropopsych- ists in any argument about animal con? sciousness, it is perhaps the single most fundamental point at issue in our sympo? sium. Why should this point be at issue? Be? cause it is not clear why Morgan's Canon is supposed to be parsimonious. On the face of it, it seems uneconomical to explain an animal's behavior in one way and a similar human behavior in a different way. Indeed, some argue that if we are going to invoke mental phenomena in accounting for our own actions, it is maximally parsimonious to explain other animals' behavior in simi? lar terms whenever we can (Regan, 1983; Rollin, 1990; Bekoff and Allen, 1997). Surprisingly, Morgan agreed that it would be simpler to do just that. He justi- fied his Canon with reference not to the principle of parsimony, but to the fact of evolution, which he saw in characteristical- ly 19th-century terms as the story of life's ascent through successive stages from the primordial ooze up to the lofty condition of man. The key to understanding Morgan's Canon is that phrase "lower in the psycho? logical scale." For Morgan, "lower" did not mean "neurologically simpler." (A neu- rological criterion of simplicity would be of little use in practice, since in most cases the neurological causes of behavior are un? known.) Rather, "lower" for Morgan meant "historically prior," with specific reference to the story of human evolution. "Higher" here thus turns out to mean "distinctively human," and "lower" to mean "shared with other species." Therefore, the true, un? derlying implication of Morgan's Canon is that we are forbidden to interpret an ani? mal's actions as the outcome of humanlike mental events, if we can find any other way of explaining them. This reformulation shows us more clearly what is wrong with Morgan's Canon. The problem here comes into sharper focus if we transfer our attention from the brain to, say, the kidney. A urological version of Morgan's Canon would forbid us to inter? pret an animal's urine as the outcome of humanlike renal events?if we can find any other way of explaining it. If Morgan's Canon represents a parsimonious assump? tion, so does the urological version. But it seems obvious that the urological version is ridiculous. No physiologist would urge the adoption of such a rule to maximize parsi? mony and avoid the temptations of anthro- porenalism. On the face of it, Morgan's Canon has nothing to do with parsimony. Because hu? mans are known to have conscious mental states, denying them to other animals saves nothing; it leaves us with the same number of entities on the bottom line of our overall ontological ledger (Newbury, 1954). If mental events sometimes cause human be? havior, then positing different, non-mental- istic causes for similar behavior in other an? imals also saves nothing?unless we have independent reasons for thinking that those animals lack mental lives. And if we have such reasons, then Morgan's Canon is not needed to rule out mentalistic explanations of animal behavior. Can Morgan's Canon be justified as a corollary of Occam's Razor? I think that it</page><page sequence="8">842 Matt Cartmill MUSCULOSKELETAL EVENTS (BEHAVIOR) NEUROLOGICAL EVENTS INVOLVING PHENOMENOLOGY NEUROLOGICAL EVENTS WITHOUT PHENOMENOLOGY STIMULUS SITUATION Fig. 3. Categories of psychological events and their causal linkages. Arrows run from cause to effect. Mor? gan's Canon is parsimonious if and only if the dashed arrow is fictitious?that is, if states of consciousness never cause behavior. can, but that there is a high price to be paid?namely, accepting epiphenomenal? ism. If conscious states have no effect on human behavior, it becomes parsimonious to leave consciousness out of the picture when explaining similar behavior in other animals. Figure 3 makes this point in graph- ic form. Stimuli cause neurological events of which we are not aware. These events can cause behavior directly (as in a reflex), or cause other neurological events that are associated with conscious awareness. These conscious states may in turn produce chains of neurological effects that result in behav? ior. But if the dashed arrow in Figure 3 is wholly mythical?that is, if (in Huxley's words) states of consciousness never cause changes in the motion of the human body? then it does finally become parsimonious to simplify our models by denying conscious? ness in nonhuman animals. The parsimony interpretation of Morgan's Canon is there? fore logically equivalent to Huxley's epi? phenomenalism. This is not necessarily a defect. Epiphe? nomenalism is a respectable theory, backed up with powerful arguments by formidable proponents. As many of these proponents have noted, the fact that conscious states are correlated with our behavior does not im? ply that they cause it. If conscious states are physical phenomena, then we do not need to drag their subjective aspect into our explanations of behavior. And if they are not physical phenomena, then they cannot cause physical movement. But epiphenomenalism also carries a high price tag. It does serious violence to our intuitive sense that our thoughts at least sometimes affect the things we do. And there is also a biological price to be paid for epiphenomenalism. If our conscious thoughts have no effect on our behavior, then they have no adaptive value?and so the evolution of consciousness cannot be accounted for in Darwinian terms (Allen and Bekoff, 1997, pp. 140-141). Behavioral Criteria of Consciousness Sober (1998) offers to justify Morgan's Canon by reinterpreting Morgan's words "higher" and "lower" in terms of logical rather than evolutionary priority. He pro- poses that we should call one psychological faculty or internal mechanism "higher" than another "... if and only if the behav? ioral capacities entailed by the former prop- erly include the behavioral capacities en? tailed by the latter" (Sober, 1998, p. 236). For any two alternative faculties or mech? anisms A and B, if the behaviors permitted by A (A-behaviors) are a subset of those made possible by B (B-behaviors), then B is a "higher psychological faculty" in So? ber's sense than A is. Accordingly, if an organism consistently demonstrates a ca? pacity for A-behaviors but never displays B-behaviors, then we should not assume that its A-behaviors are produced by the B mechanism?even if there are other organ? isms in which the B mechanism produces A behaviors. This principle seems sound, but its ap- plicability is much more restricted than that of Morgan's Canon. As Sober himself points out, psychological faculties are not always concentrically nested. They often partially overlap. For example, vision al? lows me to estimate an object's size, shape, and color, whereas touch allows me to es? timate its size, shape, and temperature. It follows that neither vision nor touch is "higher" than the other by Sober's criteri- on, even though vision is a "higher psy? chological faculty" in the evolutionary sense in which Morgan's Canon was origi? nally intended.</page><page sequence="9">Animal Consciousness: Problems 843 For similar reasons, mental events cannot be "higher" in Sober's sense than uncon- scious neural processes. If the epipheno- menalists are right, then unconscious neural processes cause all of our behavior, and are therefore as a class "higher" than mental events. Even if the epiphenomenalists are wrong, it is nevertheless clear that some be? haviors (e.g., visual accommodation) result exclusively from unconscious neural pro? cesses. No matter what assumptions we make, the behaviors permitted by uncon? scious processes do not constitute a subset of those permitted by conscious mental events. Therefore, mental events cannot represent a "higher" internal mechanism (in Sober's sense) than unconscious neural processes. Sober's more sophisticated ver? sion of Morgan's Canon thus fails to justify the methodological assumption that non- human behavior should be attributed to un? conscious or nonmental causes whenever possible. The best reason for thinking that an an? imal lacks some psychological faculty is that it never exhibits behaviors that are uniquely associated with that faculty (So- ber, 1998). To operationalize this principle with respect to animal consciousness, we need to know what behaviors are uniquely associated with consciousness. Unfortu? nately, comparative evidence is not useful here, since human beings are the only ani? mals universally admitted to be conscious. However, since humans are not always con? scious, we can at least ask what we can do when we are conscious that we cannot do when we are knocked out, anesthetized, or asleep. This seems like an easy question to an? swer. As a rule, unconscious people are limp and passive and do not get up and walk around. When we are not sure whether a limp, passive person is conscious, we may run tests to see whether the person responds to stimuli in an intelligible and adaptive fashion (by answering questions coherently, pushing away the smelling salts, and so on). Our intuitive sense that most animals are aware of the world stems in part from the fact that they pass such tests by moving about and responding to non-verbal stimuli in an intelligible and adaptive fashion. If these were decisive tests, we could teil whether an animal was conscious by pinch- ing it. But these tests are not decisive, for at least two reasons. First, all animals re? spond adaptively to some stimuli; but most of them have nervous systems that seem too simple or diffuse (or even absent, as in the case of Protozoa) to be vehicles for con? scious awareness. Second, people some? times move about and respond to stimuli in a more or less adaptive fashion when they are not conscious?for example, in sleep- walking. One can dispute whether sleepwalkers are unconscious. I have heard it argued that they must be conscious in some sense of the word, because they perceive and re? spond to the world and carry out complex tasks requiring the integration or "binding" of multiple sensory modalities. However, sleepwalkers usually claim that they have no awareness or recollection of what hap- pens during their sleepwalking episodes. This claim is supported by electroencepha- lographic data. Sleepwalking usually begins during deep sleep (Stage 4) with slow-wave EEG rhythms. The EEG waves shift to higher frequencies during the sleepwalking episode. If the episode lasts 40 see or less, the EEG resembles that seen in partial arousal from sleep; but longer-lasting epi? sodes exhibit the EEG rhythms normally seen in light sleep and dreaming (REM) sleep (Jacobson et al, 1965; Gastaut and Broughton, 1965; Broughton, 1968; Crisp et al, 1990). A rarer form of sleepwalking that begins during REM sleep is sometimes distinguished as REM sleep disorder. Its as? sociated behaviors are generally similar to those seen during typical sleepwalking with Stage 4 onset (Ishigooka et al, 1985). In cats, a syndrome resembling REM sleep disorder, in which locomotion, grooming, and even predation occurs during REM sleep (with alpha-rhythm EEGs), can be in? duced surgically by lesions of the nucleus ceruleus in the caudal brainstem (Sastre and Jouvet, 1979). Typically, sleepwalkers open their eyes, sit up in bed with a blank facial expression, pluck aimlessly at the bedclothes, and then get up and walk. As a rule, they manage to move around without bumping into things,</page><page sequence="10">844 Matt Cartmill but they usually ignore the objects and peo? ple they encounter (Kales et al, 1966; Reite et al, 1990; Thorpy, 1990). Their actions are usually slow and aimless. More ener? getic and purposeful behaviors during sleep may include running, jumping, throwing things, driving automobiles, cursing, mak? ing simple responses to questions, and at- tacking bedmates and family members with fists or weapons (Yellowlees, 1878; Hart? mann, 1983; Oswald and Evans, 1985; Bar- tholomew, 1986; Tarsh, 1986; Schenck et al, 1989; Mahowald et al, 1990). When forcibly awakened, sleepwalkers display in? tense anxiety, confusion, and no recollec- tion of how they got where they are (Whit- lock, 1975; Thorpy, 1990). These facts suggest at least two general behavioral deficiencies associated with the absence of consciousness in humans. The first is a deficiency in social skills. Sleep? walkers typically ignore the people they en? counter, and the rare interactions that occur are perfunctory and clumsy, or even vio- lent. The other major deficit in sleepwalk- ing behavior is linguistic. Most sleepwalk? ers respond to verbal stimuli with only grunts or monosyllables, or make no re? sponse at all (Pai, 1948; Gastaut and Broughton, 1965). Spontaneous utterances during sleep rarely exceed one or two words. More complex sentences or even conversations sometimes occur during the lighter stages of sleep (stage 1 non-REM sleep) at the beginning and end of the sleep cycle (Arkin, 1978), but these are uncom- mon and not associated with sleep walking. In short, unconscious humans, like animals and very young children, are as a rule in- capable of any verbal behavior beyond what Bickerton (1990) calls protolanguage: short, grammar-free utterances in which signs are used with referential meaning but syntax is absent. These two apparent deficiencies may be significant. As noted above, it is sometimes claimed that syntactic language is a prereq- uisite for consciousness. This claim would be supported by a demonstration that lin? guistic behavior during sleep is restricted to protolanguage. And the deficiencies in so? cial skills and behavior seen in sleepwalkers corroborate Humphrey's (1986, 1987) the- sis that consciousness is a social adaptation, valuable chiefly because it facilitates the construction and perception of other minds. More detailed studies of the behavior of un- conscious humans may provide decisive tests of these and other theories about the behavioral correlates of consciousness. If we can identify behaviors that are uniquely associated with consciousness in our own species, we may be able to draw some in? ferences about which animals lack it. Prospects and Conclusion From a scientific standpoint, the most im? portant question to be asked about con? sciousness is "What brain mechanisms pro? duce conscious awareness?" This question remains singularly refractory. But other questions about consciousness can be ad? dressed without understanding its machin- eries; and because all these issues are log- ically interconnected, answering any of those other questions will contribute to an eventual solution of the central problem. If we had a physical account of the mecha? nisms of consciousness, we could deter? mine its distribution in other animals and study its evolution. Conversely, given a re? liable behavioral test for the presence of consciousness in other animals, we could start mapping its distribution and looking for similarly distributed neurological cor? relates to help us understand its mecha? nisms. If we knew something about the dis? tribution and behavioral correlates of con? sciousness, we could utilize the compara? tive method to investigate its adaptive value. If consciousness has adaptive value, then philosophical epiphenomenalism is a mistake. Once this knot is loosened at any one of these points, it will begin to come apart every where. These are not unresolvable questions. Scientific inquiry has already yielded infor? mation about the presence or absence of consciousness in nonhuman organisms. It seems clear that organisms that lack a ner? vous system are unconscious Cartesian au- tomata. There are empirical reasons for thinking that this may also be true of most other organisms. On the other hand, there is growing evidence, much of which is summarized by the other contributors to</page><page sequence="11">Animal Consciousness: Problems 845 this symposium, that some non-human ver? tebrates have cognitive, social, and linguis- tic abilities that resemble our own in vari? ous ways. That accumulating body of evi? dence refutes certain claims about the uniqueness of human mentation. Although the problems of animal consciousness are not likely to be resolved completely until the mechanisms of human consciousness are understood, we know some relevant facts. We can reasonably expect to know more in the future if we avoid the tempta- tions of skepticism. References Adelson, E. H. 1982. The delayed rod afterimage. Vi? sion Res. 22:1313-1328. Adler, M. J. 1967. The difference of man and the dif? ference it makes. Holt, Rinehart and Winston, New York. Allen, C and M. Bekoff. 1997. Species of mind: The philosophy and biology of cognitive ethology. MIT Press, Cambridge. Arkin, A. M. 1978. Sleep talking. In A. M. Arkin, J. S. Antrobus, and S. J. Ellman (eds.), The mind in sleep: Psychology and psychophysiology, pp. 513-532. Lawrence Erlbaum Associates, Hills- dale, NJ. Baars, B. J. 1997. In the theater ofthe mind: The work- space of the mind. Oxford University Press, Ox? ford. Bartholomew, A. A. 1986. On serious violence during sleep-walking. Brit. J. Psychiatry 148:476-477. Bennett, J. 1988. Thoughtful brutes. Proc. Amer. Phi- losoph. Assoc. 62:197-210. Bekoff, M. and C. Allen. 1997. Cognitive ethology: Slayers, skeptics, and proponents. In R. W. Mitch? ell, N. S. Thompson, and H. L. Miles (eds.), An- thropomorphism, anecdotes, and animals, pp. 313-334. State University of New York Press, Al- bany. Bickerton, D. 1990. Language and species. University of Chicago Press, Chicago. Block, N. 1995. On a confusion about a function of consciousness. Behav. Brain Sci. 18:227-287. Brindley, G. S. 1963. Afterimages. Sci. Amer. 209(Oc- tober): 84-91. Broughton, R. J. 1968. Sleep disorders: Disorders of arousal? Science 159:1070-1078. Carruthers, P. 1996. Language, thought, and con? sciousness: An essay in philosophical psychology. Cambridge University Press, Cambridge. Cartmill, M. 1990. Human uniqueness and theoretical content in paleoanthropology. Int. J. Primatol. 11 : 173-192. Cartmill, M. 1996. Do horses gallop in their sleep? Consciousness, evolution, and the problem of An? imal Minds. Sixty-Sixth James Arthur Lecture on the Evolution of the Human Brain. American Mu? seum of Natural History, New York. Chalmers, D. J. 1995. Facing up to the problem of consciousness. J. Consciousness Stud. 2:200-219. Chalmers, D. J. 1996. The conscious mind. Oxford University Press, Oxford. Crisp, A. H., B. M. Matthews. M. Oakley, and M. Critchfield. 1990. Sleepwalking, night terrors, and consciousness. Brit. Med. J. 300:360-362. Darwin, C 1889. The descent of man, and selection in relation to sex. 2nd ed. Appleton, New York. Dennett, D. 1991. Consciousness explained. Little, Brown and Co., Boston. Dennett, D. 1999. Animal consciousness: What mat- ters and why. In A. Mack (ed.), Humans and other animals, pp. 281-300. Ohio State University Press, Columbus. Edelman, G. 1989. The remembered present: A bio? logical theory of consciousness. Basic Books, New York. Edelman, G. 1992. Bright air, brilliant fire: On the matter of the mind. Basic Books, New York. Flanagan, O. 1991. The science of mind. MIT Press, Cambridge. Flanagan, O. 1992. Consciousness reconsidered. MIT Press, Cambridge. Gastaut, H. and R. Broughton. 1965. A clinical and polygraphic study of episodic phenomena during sleep. Ree. Adv. Biol. Psychiatry 7:197-221. Green, W. M. (ed.) 1966. St. Augustine: The city of God. Harvard University Press, Cambridge. Griffin, D. R. 1992. Animal minds. University of Chi? cago Press, Chicago. Guzeldere, G. 1997. The many faces of consciousness: A field guide. In N. Block, O. Flanagan, and G. Guzeldere (eds.), The nature of consciousness: Philosophical debates, pp. 1-67. MIT Press, Cam? bridge. Hannay, A. 1990. Human consciousness. Routledge, London. Hartmann, E. 1983. Two case reports: Night terrors with sleepwalking?a potentially lethal disorder. J. Nerv. Mental Disease 171:503-505. Herbert, N. 1993. Elemental mind: Human conscious? ness and the new physics. Dutton, New York. Hobson, J. A. 1996. Chemistry of conscious brain states: How the brain changes its mind. Little, Brown, Boston. Humphrey, N. 1986. The inner eye. Faber, London. Humphrey, N. 1987. The uses of consciousness. Fifty- Seventh James Arthur Lecture on the Evolution of the Human Brain. American Museum of Natural History, New York. Humphrey, N. 1992. A history ofthe mind. Simon and Schuster, New York. Huxley, T. H. 1896. Method and results. Collected es- says. Vol. 1. Appleton, New York. Ishigooka, J., F. Westendorp, T. Oguchi, A. Takahashi, A. Sumiyoshi, and M. Inami. 1985. Somnambu- listic behavior associated with abnormal REM sleep in an elderly woman. Biol. Psychiatry 20: 1003-1008. Jacobson, A., A. Kales, D. Lehmann, and J. R. Zwei- zig. 1965. Somnambulism: All-night electroen- cephalographic studies. Science 148:975-977. Kales, A., A. Jacobson, M. Paulson, J. D. Kales, and</page><page sequence="12">846 Matt Cartmill R. D. Walter. 1966. Somnambulism: psychophys- iological correlates. I. All-night EEG studies. Arch. Gen. Psychiatry 14:586-604. Kirk, R. 1994. Raw feeling. Claredon Press, Oxford. Lycan, W. 1997. Consciousness and experience. MIT Press, Cambridge. Mahowald, M. W., S. R. Bundlie, T. D. Hurwitz, and C. M. Schenck. 1990. Sleep violence?forensic science implications: Polygraphic and video doc- umentation. J. Forensic Sci. 35:413-432. Malcolm, N. 1973. Thoughtless brutes. Proc. Amer. Philosoph. Soc. 46:5-20. McGinn, C. 1989. Can we solve the mind-body prob? lem? Mind 98:349-366. McGinn, C. 1991. The problem of consciousness. Blackwell Publishers, Oxford. Morgan, C. L. 1977. An introduction to comparative psychology. In Daniel N. Robinson (ed.), Signifi? cant contributions to the history of psychology, Series D, Vol. 2. University Publications of Amer? ica, Washington, D.C. Nagel, T. 1974. What is it like to be a bat? Philosoph. Rev. 83:435-450. Newbury, E. 1954. Current interpretation and signifi? cance of Lloyd Morgan's Canon. Psychol. Bull. 51:70-74. Norretranders, T. 1998. The user illusion: Cutting con? sciousness down to size. Viking Penguin, New York. Oswald, I. and J. Evans. 1985. On serious violence during sleep-walking. Brit. J. Psychiatry 147:688- 691. Pai, M. N. 1948. Sleepwalking and sleep activities. J. Mental Sci. 92:756-765. Penrose, R. 1989. The emperor's new mind. Oxford University Press, Oxford. Penrose, R. 1994. Shadows of the mind: A search for the missing science of consciousness. Oxford Uni? versity Press, Oxford. Pfungst, O. 1911. Clever Hans: A contribution to ex? perimental animal and human psychology. Henry Holt, New York. Regan, T. 1983. The case for animal rights. University of California Press, Berkeley. Reite, M. L., K. E. Nagel, and J. R. Ruddy. 1990. The evaluation and management of sleep disorders. American Psychiatric Press, Washington. Rollin, B. E. 1990. How the animals lost their minds: Animal mentation and scientific ideology. In M. Bekoff and D. Jamieson (eds.), Interpretation and explanation in the study of animal behavior. I: Interpretation, intentionality, and communication, pp. 375-393. Westview Press, Boulder, Colo. Romanes, G. J. 1889. Mental evolution in man: Origin of human faculty. Appleton, New York. Rorty, R. 1979. Philosophy and the mirror of nature. Princeton University Press, Princeton. Rosenfield, I. 1992. The strange, familiar, and forgot- ten: An anatomy of consciousness. Vintage, New York. Rosenthal, D. M. 1993. Thinking that one thinks. In M. Davies and G. W. Humphreys (eds.), Con? sciousness: Psychological and philosophical es- says, pp. 197-223. Blackwell, Oxford. Rosenthal, D. M. 1997. A theory of consciousness. In N. Block, O. Flanagan, and G. Guzeldere (eds.), The nature of consciousness: Philosophical de- bates, pp. 729-753. Cambridge University Press, Cambridge. Sastre, J.-P. and M. Jouvet. 1979. Le comportement onirique du chat. Physiol. Beh. 22:979-989. Schenck, C. H., D. M. Milner, T. D. Hurwitz, S. R. Bundlie, and M. W. Mahowald. 1989. A polysom- nographic and clinical report on sleep-related in? jury in 100 adult patients. Amer. J. Psychiatry 146:1166-1173. Searle, J. 1992. The rediscovery of the mind. MIT Press, Cambridge. Searle, J. 1997. The mystery of consciousness. New York Review of Books, New York. Smith, D. W. 1986. The structure of (self-)conscious- ness. Topoi 5:149-156. Sober, E. 1998. Morgan's canon. ln D. D. Cummins and C. Allen (eds.), The evolution of mind, pp. 224-242. Oxford University Press, New York. Sommerhoff, G. 1990. Life, brain and consciousness. North Holland, Amsterdam. Staddon, J. E. R. and B. S. Zanutto. 2000. In praise of parsimony. In C. D. L. Wayne and J. E. R. Stad? don (eds.), Models for action: Mechanisms for adaptive behavior. Lawrence Erlbaum Associates, New York. (In press) Strawson, G. 1994. Mental reality. MIT Press, Cam? bridge. Tarsh, M. J. 1986. On serious violence during sleep? walking. Brit. J. Psychiatry 148:476. Thorpy, M. J. 1990. Disorders of arousal. In M. J. Thorpy (ed.), Handbook of sleep disorders, pp. 531-549. Marcel Dekker, New York. Tye, M. 1995. Ten problems of consciousness. MIT Press, Cambridge. Whitlock, F. A. 1975. Sleep disturbances and psychi- atric disorders. In A. D. Clift (ed.), Sleep distur? bances and hypnotic drug dependence, pp. 181? 205. Excerpta Medica, Amsterdam. Yellowlees, D. 1878. Homicide by a somnambulist. J. Mental Sci. 24:451-458.</page></plain_text>
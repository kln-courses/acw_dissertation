<plain_text><page sequence="1">A Theory of Decision Support System Design for User Calibration George M. Kasper Department of Information Systems and Quantitative Sciences, College of Business Administration, Texas Tech University, Lubbock, Texas 79409-2101 kasper@acm.org A theory is proposed for designing decision support systems (DSS) so that the confidence a decision maker has in a decision made using the aid equals the quality of that decision. The DSS design theory for user calibration prescribes properties of a DSS needed for users to achieve perfect calibration. Relevant calibration, decision making, and DSS literatures are syn thesized; and related behavioral theories are borrowed to identify the properties of expressive ness, visibility, and inquirability as requisite components of the DSS design theory for user calibration. (Decision Support Systems; Design Theory; Information Systems Design; Decision Confidence Calibra tion; Judgment) "It's not what we know that gives us trouble, it's what we know that ain't so!" Will Rogers 1. Introduction What we believe to be true is often quite different from reality. Likewise, one's belief in the quality of a decision is often quite different from the objective quality of the decision. One's belief in the quality of a decision is known as decision confidence. It denotes confidence in a specific event, a decision, as opposed to self-efficacy (Bandura 1977), inherent trust in technology, or other types of confidence. Although decision confidence is subjective, in many situations its accuracy can be objec tively assessed. The best known objective measure of the accuracy of one's decision confidence is calibration. The most popular measure of calibration is the square of the difference between pairings of decision confi dence, expressed as a probability, and decision quality, expressed as the proportion correct, averaged over a se ries of pairings (Lichtenstein et al. 1982, Clemen and Murphy 1990, Keren 1991). The notion of calibration, however, is neither formula-specific nor is it limited to a particular number of decisions; it can be based on one's belief in the quality of a decision associated with a series of events or a single decision. For the purpose of this discussion, calibration is simply a measure of the correspondence between the subjective decision confi dence one assigns to a decision and the objective quality of that decision. Perfect calibration exists when one's belief in the quality of a decision equals the objective quality of the decision; otherwise, miscalibration exists as either underconfidence or overconfidence. Calibration has been the topic of many behavioral studies. Collectively, the behavioral literature docu ments miscalibration (Einhorn and Hogarth 1978, Lich tenstein et al. 1982, Brown and Gould 1987). By far, the most pervasive finding in the area of realism in decision confidence is that overconfidence abounds (Juslin 1993). People seem to have great confidence in their fal lible judgement (Einhorn and Hogarth 1978, 1981) and are often quite confident in very poor decisions (Tver sky and Kahneman 1974). The term decision support systems (DSS) is used here as defined by Scott Morton (1984) to include all forms of information systems (IS) and technologies designed to assist one or more decision makers in making a de cision or choosing a course of action in a nonroutine, 1047-7047/96/0702/0215$01.25 Copyright © 1996, Institute for Operations Research and the Management Sciences Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="2">KASPER Decision Support System Design episodic situation that requires judgment. Although the nature of the support provided by DSS ranges from pas sive to active (Keen 1987, Luconi et al. 1986, Henderson 1987, Humphreys 1986, Remus and Kotteman 1986) and from individual to group (DeSanctis and Gallupe 1987, Olson and Olson 1991), the goal in designing all DSS is to improve decision quality. The notion that the design of a DSS can affect user/ decision-maker calibration is hereinafter referred to as user calibration} The need for user calibration is indi cated by the suggestions that systems such as ELIZA (Weizenbaum 1966) have engendered overconfidence and that some users of Expert Systems exhibit under confidence (Teach and Shortliffe 1981, Muir 1987, Carrol and McKendree 1987). The consequences of a DSS en gendering under/overconfidence in a decision can be catastrophic; examples abound and include the USS Vincennes' downing of an Iranian Airbus2 and the Keg worth Boeing 737-400 crash.3 Underconfidence in a de cision can mean foregoing a good decision; overconfi dence can result in committing to a poor decision. Be cause people make decisions, user calibration can be critical. Ultimately, calibration depends upon the user's in terpretation of the quality of a decision. From this per spective, a DSS must not only improve decision quality, it must also support and facilitate the user's interpre tation of the quality of the decision he or she makes using the aid. By encouraging the exploration of a prob lem domain, DSS usage may improve decision quality but actually produce underconfidence as one becomes overly concerned with the perils of a potential course of action. Conversely, the computational efficiency of a DSS may lull some into a false sense of security, engen dering overconfidence in the quality of a potential course of action (Freeman 1984, Huff 1986). Despite its 1 The phrase user calibration parallels those of user satisfaction, user interface, and other "user" notions of the relationship between IS de sign and user/decision-maker performance, beliefs, and attitudes. 2 The symbols displayed on screens of the Aegis battle management system may have contributed to the decision to down the Iranian Air bus (Aviation Week &amp; Space Technology, July 18, 1988, p. 23). 3 A major contributor to this 1989 UK airline crash was reported to be that "the pilots misunderstood (or did not trust)" the information dis played (Booth 1991, p. 70). importance, very little is known about designing DSS for user calibration. This paper develops a DSS design theory for user calibration. The DSS design theory for user calibration prescribes properties of a DSS needed for users to achieve the goal of perfect calibration. This requires designing a DSS so that the confidence a user/decision-maker has in a de cision made using the aid equals the quality of that de cision. Although the theory borrows from and synthe sizes selected behavioral theories and research, its focus is on DSS design for user calibration; individual differ ences and organizational factors that may influence cal ibration are not considered, per se. The presentation follows the general outline sug gested by Walls et al. (1992) for the development of de sign theory for IS. Sections 2 and 3 discuss relevant em pirical and theoretical literatures, respectively. Next, the goal and properties needed to achieve the goal of the DSS design theory for user calibration are developed, and examples of the properties are provided. Some op erational and methodological issues involved in testing the theory are cited in §5. The paper ends with a sum mary and concluding remarks. 2. IS Related Decision Confidence and Calibration Literature Why should DSS designers and researchers be con cerned with a user's belief in the quality of a decision made using a DSS? The power of one's beliefs to influ ence is undeniable. The Hawthorne and placebo effects and the phenomenon of the self-fulfilling prophecy demonstrate this power (Einhorn and Hogarth 1978, Einhorn 1986). Similarly, one's belief in the quality of a decision can affect both the selection and implementa tion stages of the decision-making process (Russo and Schoemaker 1992). Overconfidence can result in the se lection of a decision that might otherwise have been dis missed or the overcommitment of resources and inad equate precautions against failure when implementing a decision. Conversely, underconfidence can mean that either an otherwise good opportunity is overlooked or that too few resources are devoted to implementing a decision. If DSS are to improve decision making, DSS designers and researchers must be concerned with user calibration. Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="3">KASPER Decision Support System Design In the IS literature, attributes such as decision time and decision quality have been the focus of much re search. Decision confidence has also been included in many management information systems (MIS) and DSS studies, but only as an incidental measure. Although decision confidence and calibration have been largely ignored by IS researchers (see Benbasat and Nault 1990 for a review of DSS studies), the limited empirical evi dence suggests that the design of both the information dimensions (quantity, form, format, etc.) and the in quiring system play key roles in user calibration. In one of the earliest MIS laboratory studies, Cher vany and Dickson (1974) investigated the effects of in formation overload on decision confidence, quality, and time. They found that those using statistically summa rized data outperformed those using raw data, but took longer and were less confident in their decisions. Com menting on these results they wrote, The results with respect to decision time and confidence are troublesome. Even though the SSD (statistically summarized data) subjects did better, the increased average time and re duced average confidence lead to the tentative conclusion that they did not realize they had a 'handle' on the problem (Cher vany and Dickson 1974, p. 1342). Using clinical psychology case studies, Oskamp (1965) also found that increasing the quantity of infor mation provided to decision makers produced miscali bration because it increased their decision confidence, but did not improve their decision quality. "As they [decision makers] received more information, their con fidence soared . . . entirely out of proportion to the ac tual correctness of their decisions" (Oskamp 1965, p. 264). These results were more recently replicated by Paese and Sniezek (1991) as part of a larger study. Comparing different forms of presenting informa tion, Bell (1984) also found a divergence between deci sion confidence and decision quality. Decision confi dence based on information presented as text was greater than that for information presented in numeric form, but subjects found it easier to identify inconsis tencies when the information was presented in numeric form rather than in textual form. In addition to the quantity and form in which infor mation is presented, the limited literature suggests that DSS usage also affects calibration. Mclntyre (1982) found that the calibration of subjects using a DSS was worse than that of their unaided counterparts. Com menting on these results, he speculated that the DSS may have contributed to miscalibration (in the form of underconfidence) because it led subjects to believe that much better decisions existed than those from which they had selected. Investigating the effect of specific DSS design fea tures, Davis et al. (1991) and Davis and Kottemann (1994) hypothesized that the use of a "what-if" inquiry design creates an "illusion of control"4 causing users to overestimate the effectiveness of the what-if DSS design. Results of their research support this contention. De spite performance feedback to the contrary, and the availability of tools whose recommendations would have led to much better decisions, subjects continued their use of the what-if design feature. In other words, subjects maintained their overconfidence in the efficacy of the what-if inquiry design feature despite negative feedback and the availability of better tools. Davis and his coauthors concluded that an illusion of control was created by using the what-if feature of the DSS and that this illusion overwhelmed any negative feedback, in cluding poor performance, in formulating the subject's attitude about the efficacy of the what-if DSS design fea ture. The "illusory" benefits of using a DSS have also been suggested by Aldag and Powers (1986). In their study, subjects analyzed strategic management cases and, as suming the role of consultant, made written recommen dations. Although the recommendations of those that used the DSS were judged no better than their unaided counterparts, the DSS-aided subjects reported more confidence in their recommendations than did those that were unaided, again resulting in miscalibration. Commenting on these findings, Aldag and Powers (1986, p. 584) wrote, "If computerized decision aids generate illusory benefits, they may be of questionable value." These illusory benefits have also been found when the aid is an expert system (Wills 1992). How and what DSS design features contribute to these illusory benefits are unclear. 4 Einhorn (1986) introduces the "illusion of lack of control" and dis cusses its implications for decision making. Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="4">KASPER Decision Support System Design Providing subjects with performance feedback in the form of computer-generated output does not seem to affect decision confidence (Sharp et al. 1988). Yet, self generated feedback, with or without the help of a computer-based decision aid, has been shown to affect confidence in output (Northcraft and Earley 1989). Taken together, these results suggest that it is the human-computer interaction involved in the generation of output, rather than the output itself, that affects user calibration (Zakay 1992). Again, how and what DSS de sign features affect user interaction with a DSS in the generation of output is largely unknown. The level of interaction among members of a group has been shown to affect decision confidence, and the group is a well-known and often invoked metaphor to consider issues involving the interaction between hu mans and intelligent machines (Newell and Simon 1972, Woods and Roth 1988). Groups have been found to be more confident in their decisions than individuals (Sni ezek and Henry 1989), but individuals often make bet ter decisions than groups (Boje and Murnighan 1982). Commenting on these results, Boje and Murnighan propose that decision confidence is affected by both the novelty of a problem and by the level of one's interac tion with other members of the group during the decision-making process. The use of group DSS (GDSS) has also been shown to cause miscalibration, but the direction is unclear. For example, Gallupe et al. (1988) found that the use of GDSS improved decision quality, but the aided groups reported less confidence in their decisions than did their unaided counterparts. Sharda et al. (1988) also found that DSS-aided groups performed better, but found no difference between the aided and unaided groups in terms of decision confidence. On the other hand, Steeb and Johnston (1981) found no difference between the GDSS-aided and unaided groups in terms of decision quality, but the aided groups re ported more confidence in their decisions than did the unaided groups. Because Steeb and Johnston also found that the GDSS-aided groups conducted much more extensive analyses, they speculated that the in creased decision confidence reported by the aided groups resulted from the more extensive analysis they performed to decide which of the alternative deci sions to select. In a review of the relevant psychology literature, Faust (1986) concluded by identifying a series of rules or necessary conditions for improving calibration. In summary form, his rules are: (1) decrease information overload and misleading, illusory data; (2) present ev idence that disconfirms and refutes one's position; (3) distinguish between knowledge and speculation, be tween knowledge and metaknowledge; and (4) gener ate competing alternative hypotheses. These parallel the literature reviewed above suggesting that the design of both the information (overload, misleading, disconfirm ing, speculative) and the inquiring system (generate competing alternative hypotheses) play key roles in user calibration. Despite literature suggesting that the design of the information dimensions and inquiring system of a DSS may affect user calibration, the specifics are unclear. In formation dimensions such as quantity and form of pre sentation have been shown to have differing effects on decision quality than on decision confidence, producing miscalibration. Increasing the quantity of information increases decision confidence, even when the quantity of information exceeds the information overload thresh old, the point where decision quality characteristically decreases. Information presented as text results in greater decision confidence than does information pre sented numerically, but numerical presentation results in better decision quality. In terms of DSS, the literature on decision confidence is even more limited and confusing. DSS-aided subjects have reported significantly more and less confidence in their decisions than their unaided counterparts. They have also reported levels of decision confidence far higher and lower than those warranted by the quality of their decisions. Some have suggested that the use of a DSS contributes to miscalibration in the form of un derconfidence by distorting one's perception of the set of viable decision alternatives or because one becomes more aware of the perils of a specific course of action. Others have speculated that using a DSS produces "il lusory" benefits leading to miscalibration in the form of overconfidence. Some of this confusion can be attributed to method ology problems such as decision settings that, from the subject's perspective, mislead or misrepresent the situ ation (Juslin 1993,1994; Bjorkman in press). Moreover, Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="5">KASPER Decision Support System Design most IS studies simply compare the sample means for decision confidence with those for decision quality; cal ibration at the decision-maker level is not investigated. The need for appropriate methodology is essential, but a more compelling shortcoming of research in this area is the absence of theory. Without theory, empirical re search is reduced to "playing combinatorics" with sets of variables, and scientific progress is, at best, haphaz ard (Weber 1987). The first step toward a DSS design theory for user calibration is to consider selected theo ries relevant to user calibration. 3. Theories Relevant to User Calibration Research on calibration has been criticized for its atheo retical foundation (Lichtenstein et al. 1982, Gigerenzer et al. 1991). Despite this general criticism, theories have been suggested for the role of calibration in decision making and mental representation in miscalibration. For user calibration, these theories indicate the impor tance of calibration in decision making and provide a basis for building the DSS design theory for user cali bration. 3.1. The Role of Calibration in Decision Making Russo and Schoemaker (1992) argue that separating "deciding" from "doing" is key to understanding the different roles played by calibration in decision making. "Deciding requires realism. But in implementing the decision, the motivational benefits of overconfidence frequently out weigh its dangers" (Russo and Schoemaker 1992, p. 16). Overconfidence has been justified as a functional ad aptation to motivate the implementation of decisions (Trull 1966, Hogarth 1980, Russo and Schoemaker 1992). Decision confidence affects the amount of re sources one is willing to devote to a course of action in pursuit of an outcome (Stevick et al. 1991). Unfortu nately, the same overconfidence that motivates can be disastrous for the individual, as the literature on esca lation to commitment and any manager that has "thrown good money after bad" will testify (Staw 1976, 1981). Calibration also plays a key role in the selection stage of decision making, in deciding from among viable al ternative decisions. As stated earlier, miscalibration can mean that an otherwise good decision is overlooked or that a poor decision is unwittingly selected over alter natives with greater decision quality. Because the focus of DSS is decision quality, the DSS design theory for user calibration is primarily concerned with the realism needed for deciding on a decision. 3.2. Mental Representation and Calibration Until recently, the mental mechanism underlying cali bration was largely ignored. One class of calibration theories focuses on the importance of the decision maker's mental representation of the problem. A com plete review of calibration theories and models can be found in McClelland and Bolger (1994). Focusing on the effect of (mis)information in the form of misleading stimuli, May (1986) was perhaps the first to suggest that miscalibration results from a distortion in one's mental representation (map and reasoning) of the problem. Consistent with her contention, one class of theories is based on the notion that calibration is crit ically dependent upon the decision-maker's mental rep resentation of the problem (Gigerenzer et al. 1991, Bjorkman in press). One's mental representation of a problem consists of both memory (i.e., knowledge re trieved from memory) and inference based on syllogis tic reasoning (i.e., speculating on an unknown by ex trapolating from a known situation that is otherwise similar). In normal situations, people combine and use infer ence and memory interchangeably. In fact, the evidence indicates that in most situations people do not and can not distinguish between memory and inference in their recollection of an event (Neisser 1981). As a result, one often considers the "information" from either source as equally valid. Although one's memory can be wrong, and one's inference can be correct, inference is inher ently less reliable, and failure to distinguish between memory and inference means that inference is not ap propriately discounted. Because of this, as the propor tion of inference in one's mental representation of a problem increases, the likelihood of miscalibration in creases (Wagenaar 1988, Gigerenzer et al. 1991, Mc Clelland and Bolger 1994). As one might expect, and current evidence indicates, characteristics of the problem dictate the proportion of inference to memory one must use to formulate a mental Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="6">KASPER Decision Support System Design representation of a problem (Wagenaar 1988, Juslin 1993, 1994). The proportion of inference to memory used to formulate a mental representation is one deter minant of problem novelty. Low problem novelty sug gests that a low proportion of one's mental representa tion of a problem is based on inference, whereas high problem novelty implies that a large proportion of one's mental representation of a problem must be inferred. It is clear that mental representation of a problem plays a key role in calibration. Mental representation has also been shown to play a key role in problem solv ing. That representation is essential for both problem solving and calibration is to be expected; calibration is by definition a function of the correspondence between decision confidence and decision quality; and calibra tion is itself a problem to be solved. The relationship between mental representation and problem solving is articulated in the theory of symbolic representation in problem solving. 3.3. The Theory of Symbolic Representation in Problem Solving Developed by Kaufmann (1980, 1985) and Helstrup (1987), the theory of symbolic representation in prob lem solving contends that problem solving is based on symbolic representation and reasoning. Arguing that cognition cannot be separated from its symbols and symbol-generating actions, the theory uses the term "symbolic representation" to include both static inter nal codings and active reasoning (Kaufmann 1985). This distinction between codings and reasoning paral lels that of memory and inference based on syllogistic reasoning discussed in §3.2. According to the theory of symbolic representation in problem solving, the symbols and methods of reasoning in problem solving are: linguistic representation, visual imagery representation, and exploratory reasoning. Lin guistic symbols are firmly organized and convention ally established elemental units of knowledge that rep resent a kind of least common denominator of shared knowledge, a kind of cognitive "establishment" so to speak. Visual imagery symbols are more idiosyncratic, varied, and flexible, bringing together fragments of knowledge so that they can be examined simulta neously as a unified whole. Both linguistic and visual imagery symbols are to some extent based on experi ence. To address problems that transcend the upper threshold of one's experience, exploratory reasoning is a purposeful, hypothesis-guided inquiry in which a new mental representation is created. The theory holds that the locus of symbolic representa tion for problem solving varies from linguistic to visual imagery representation to exploratory reasoning with problem novelty. In most problem-solving situations, various combinations of linguistic and visual imagery representations and exploratory reasoning are needed because they complement and support each other. The locus of symbolic representation for problem solving defines the predominant or controlling focus in solving a problem. The relationships proposed by the theory of symbolic representation in problem solving are illus trated in Figure 1. Figure 1 shows how the locus of symbolic represen tation for problem solving varies with problem novelty from linguistic to visual imagery representation to ex ploratory reasoning. If problem novelty is low, linguis tic symbols predominate as a means of problem solving, with visual imagery and exploratory reasoning playing important but supporting roles. As problem novelty in creases, visual imagery and exploratory reasoning in crease relative to linguistic representation. As problem novelty transcends the upper threshold of one's expe riential knowledge, exploratory reasoning predomi nates because one must resort to constructing a repre sentation of the problem. According to the theory, the quality of mental acts (including calibration) depends upon matching the appropriate symbolic representation and reasoning to problem novelty. Locus of Symbolic Representation in Problem Solving in Re lation to Problem Novelty (Modified from Kaufmann (1980, 1985)) Problem Novelty Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="7">KASPER Decision Support System Design Problem novelty is not a perception. Often problems that seem "familiar" are in fact the ones most suscep tible to inference that can be illusory (Kaufmann 1980, Mahajan 1992). According to the theory, problem nov elty is the degree and type of abstractions needed to gen erate an accurate representation of a problem. Type of ab straction ranges from analytic to wholistic. The analytic type of abstraction requires decomposition and detail, whereas the wholistic type of abstraction requires ag gregate and heuristic processing. Degree of abstraction ranges from none to total, re flecting the proportion of inference contained in one's mental representation of a problem. Degree and type of abstractions combine to define problem novelty in sit uations requiring high-level cognition. If problem nov elty is low, a low proportion of one's mental represen tation of the problem is based on inference, and analytic abstraction is likely to be more useful than wholistic abstraction. Conversely, if problem novelty is high, a high proportion of one's mental representation of the problem is based on inference, and wholistic abstraction is likely to be more useful than analytic abstraction. In addition to improving decision quality, the role of calibration in decision making makes it clear that a DSS must be designed so that the decision maker recognizes the quality of a decision he or she makes using the aid. Calibration is based on mental representation. Deter minants of one's mental representation of a problem in clude the degree and the type of abstractions. Degree and type of abstractions combine to define problem novelty in the theory of symbolic representation in problem solving. The theory of symbolic representation in problem solving argues that a decision maker has symbols and methods of reasoning (linguistic, visual imagery, and overt exploratory), that problem novelty determines the locus of symbolic representation for problem solving, and that the appropriate employment of these symbols and methods of reasoning in response to problem novelty dictates the effectiveness of one's problem-solving activities, including calibration. 4. A DSS Design Theory for User Calibration Designing DSS for user calibration has been ignored by the IS research community, despite warnings of the dan gers inherent in this neglect (Weizenbaum 1966, Mason 1969). To begin to consider how to design a DSS for user calibration, a theory is needed to guide this research. Representation is believed to be key to problem solv ing, including calibration. Representation is also consid ered fundamental to all computer science (Newell and Simon 1976) and essential to problem solving in artifi cial intelligence (Norman 1991). Likewise, Johnson Laird (1980) described his notion of a mental model as "an internal representation of external reality." Simi larly, representation is well known as a concept for de signing DSS (Sprague and Carlson 1982, p. 96). As a result, the DSS design theory for user calibration is based on the notion that user calibration depends upon designing a DSS so that it effectively supports the user's symbolic representation in problem solving, and it con tends that DSS designs for user calibration depend upon problem novelty. The presentation and development of the DSS design theory for user calibration follows the outline suggested by Walls et al. (1992) for the development of design theory. Design theories are prescriptive theories that show how normative and explanatory perspectives can be put to practical use to achieve a goal. The goal, the conceptual properties, and interaction among the prop erties in specific situations needed to achieve the goal of the DSS design theory for user calibration are intro duced and developed below. 4.1. The Goal of the Theory As stated earlier, calibration plays a key role in both deciding on a decision and implementing the decision. Deciding on a decision is the essence of DSS (Scott Mor ton 1984). To decide on a decision, the decision-maker's belief in the quality of a decision must equal the quality of the decision (Russo and Schoemaker 1992). Deciding requires the realism of perfect calibration. Thus, the goal of the DSS design theory for user calibration is to pre scribe the DSS properties needed for users to achieve perfect calibration. 4.2. The Properties of the Theory If the DSS design theory for user calibration is to achieve the goal of building DSS so that users exhibit perfect calibration, the properties of the DSS must be designed to respond to the symbols and methods of reasoning that the user employs to interpret the quality of a decision. Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="8">KASPER Decision Support System Design One approach would be to design the symbols and ac tions of a DSS so that they correspond to the user's/ decision-maker's natural system of symbolic represen tation in problem solving. By definition, user calibration must consider deter minants of both decision confidence and decision qual ity. Decision quality is dependent upon what one knows (Bonczek et al. 1982, p. 70). One's belief in the quality of a decision, decision confidence, is based on what one thinks one knows. If decision confidence is to equal de cision quality, one must understand what one knows and what one does not know (Russo and Schoemaker 1992). In terms of symbolic representation in problem solving, knowing what one knows is primarily based on one's linguistic and visual imagery; knowing what one does not know requires inquiry that is primarily based on exploratory reasoning. From a DSS perspective, two sources of knowledge exist: the user and the aid. These correspond to two forms of representation: cognitive and computer dia logue, respectively. Cognitive representation was dis cussed above in the theory of symbolic representation in problem solving. A computer dialogue is an "observable two-way exchange of symbols and actions between human and computer" which takes place through some sort of inter face (Hartson and Hix 1989, p. 8, emphasis added). Sym bols explicitly and actions tacitly engender accurate or inaccurate beliefs about the functioning and functionality of a system. This distinction between symbols and ac tions parallels the distinctions made earlier between cod ings and reasoning, and between memory and inference, as well as the design of information presentation and inquiring system. Based on this, the symbols of represen tation and the actions of inquiring are both considered key to designing a DSS for user calibration. One approach to developing a two-way exchange be tween human and computer is to begin by designing the symbols and actions of the computer dialogue to parallel those of the user's/decision-maker's natural system of symbolic representation. Based on this premise, the lim ited literature, and the material discussed above, the DSS design theory for user calibration asserts that the DSS symbols and actions needed for users to achieve the goal of perfect calibration are prescribed by the properties of: expressiveness, visibility, and inquirability. Expressiveness, visibility, and inquirability define the requisite properties, the symbols and actions of the DSS design theory for user calibration. Expressiveness, vis ibility, and inquirability parallel and engender feelings through the user's linguistic representation, visual im agery representation, and exploratory reasoning, re spectively. Expressiveness recognizes that the tone, the way in which symbols are expressed (e.g., condescending, matter-of-fact, supportive, directive, etc.) can engender feelings and beliefs such as decision confidence. Visibility recognizes that DSS symbols (icons) and symbols-in action (animation) engender feelings. Visibility helps the user better "see" both the problem and the DSS by ob serving the DSS work and at work on a specific problem and over a series of problems. Inquirability recognizes that actions engender feelings because they tacitly sug gest functioning and functionality. Inquirability reflects the design of the inquiring system that governs DSS ac tions. Collectively, expressiveness, visibility, and in quirability define properties for designing the symbols and actions of a DSS so that decision makers using these aids are perfectly calibrated. Designing DSS symbols (expressiveness and visibility) and actions (inquirabil ity) so that they engender decision confidence equal to decision quality is the goal of user calibration. Expres siveness, visibility, and inquirability are developed in more detail below. 4.2.1. Expressiveness. Expressiveness is the tone in which dialogue symbols are presented. The tone of a dialogue can be, for example, condescending, matter of-fact, supportive, or directive. Expressiveness is cur rently conveyed to the user either through print or au dio media. In the latter case, expressiveness can also be monotone and monotonous or melodic and overly melodramatic, each engendering different feelings in the user. "One computer system may be capable of sophisticated rea soning but so limited in what it can. . . express that to a human user it appears to be only the simplest of dialogue partners. Another computer may be severely limited in its reasoning abil ities but may give the impression of considerable intelligence through sophisticated forms of expression. Examples of the for mer are expert systems . . . An example of the latter is the ELIZA program . . (Edwards and Mason 1988, p. 141). Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="9">KASPER Decision Support System Design It is often difficult for a listener to separate a speaker's dialect from his or her message and intelligence.5 One's choice of words and dialect often dominate the impres sion others have of the quality of the message and the speaker's intelligence. As the statement by Edwards and Mason suggests, expressiveness plays a similar role for user calibration. Some expressiveness dimensions that might affect user calibration include the dialogue's rhetorical strat egy, framing, connectiveness, and message construc tion. Rhetorical strategy defines the DSS dialogue's overall design for eliciting and presenting symbols. Rhetorical strategy can engender feelings such as cred ibility and confidence (Brown and Yule 1983, p. 148). Framing refers to the phrasing used to elicit and pre sent symbols. To the author's knowledge, the effect of framing on calibration has not been studied directly. However, limited evidence suggests that framing affects decision quality and decision confidence differently. Framing is a well-known determinant of choice (Kah neman and Tversky 1979), but Sniezek et al. (1990) re port that decision confidence is not affected by "posi tive" ("What is the probability that your answer is cor rect?") or "negative" ("What is the probability that your answer is wrong?") elicitation frames. Presenta tion framing may also affect user calibration, but it too has not been studied. An example of a positive presen tation frame is: "Under these conditions, 75% of the time X happens"; the corresponding negative presen tation frame would be: "Under these conditions, 25% of the time X does not happen." In addition to framing, expressiveness includes con nectiveness. Connectiveness refers to the connections among symbols such as reference to symbols already presented (anaphoric) and to symbols to be presented (cataphoric). A dialogue that exhibits connectiveness can affect user calibration by giving the user the impres sion that the DSS is intelligent. In fact, much of ELIZA's ability to engender overconfidence was attributed to the connectiveness of its dialogue (Weizenbaum 1966). Expressiveness also includes message construction. The frustration that can result from messages that are 5 Separation of the computer dialogue from the underlying system is an objective of user interface management systems (Hartson and Hix 1989). too cryptic is well known to all users of computer-based systems. On the other hand, some evidence suggests that anthropomorphic phrasing is counterproductive because users feel threatened and intimidated by mes sages that they perceive as condescending and wordy (Shneiderman 1987, pp. 322-325, 1992, pp. 312-314; Buchheit and Moher 1990). Rather than engaging, ex pressiveness designed to exhibit anthropomorphic phrasing distances the user from the decision by de creasing his or her feeling of responsibility for the de cision (Quintanar et al. 1982). According to Shneider man (1992, p. 313), "the anthropomorphic interface. . . deceives, misleads, and confuses." ELIZA remains one of the best known examples of the potential of expressiveness. Although dated, and crude by today's standards, ELIZA's expressiveness was very effective. A more futuristic example of ex pressiveness was depicted by the ultraintelligent com puter system HAL in Arthur C. Clarke's and Stanley Kubrick's 1968 classic science fiction screenplay "2001: A Space Odyssey." HAL's anthropomorphic expressive ness was central to much of the movie's dramatic effect. Collectively, it is clear that . . the words and phrases used in designing a computer dialogue can make important differences in people's perceptions, emotional reactions, and motivations" (Shneiderman 1987, p. 323, 1992, p. 312). Because of this, expressive ness must be considered when designing a DSS for user calibration. How to design rhetorical strategy, framing, connectiveness, phrasing, message construction, and other aspects of expressiveness for user calibration re main to be investigated. 4.2.2. Visibility. "Seeing is believing." Visibility recognizes that symbols engender feelings. Visibility in volves the design for user calibration of symbols (e.g., realistic/abstract, emphasizing an analytic/wholistic type of abstraction, etc.) and symbols in action (e.g., tim ing, alteration, transition, etc.) as they relate to "seeing" both the specific problem and the DSS (Lohse et al. 1994, Stasko 1993, Veryard 1986). There is a growing recognition of the importance of visibility for creativity and problem solving (West 1991), and information technologies are playing an in creasingly important role in the visual depiction of com plex situations (Keller and Keller 1993). Because of this, Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="10">KASPER Decision Support System Design visibility is receiving increasing attention in the human computer interaction literature (Veryard 1986, Shnei derman 1992, Keller and Keller 1993, Lohse et al. 1994, Stasko 1993). Shneiderman (1992, p. 169, emphasis added) recognizes the need for visibility in DSS when he writes, Expert systems . . . tax the user with complexity, lack of visi bility of the underlying process, and confusion about what func tions the system can and cannot handle. Visibility requires that the user see the DSS work and at work, that the user see the logical operations per formed by the DSS and their application to a specific problem (Veryard 1986). This requires increasing the observability of the DSS and its behavior. For user cal ibration, a DSS must not only work, it must be seen working. This means that the DSS must facilitate the user's understanding of its logical behavior by effectively depicting this behavior. Effective depiction is one of the challenges of information visualization and other forms of visual computing. The notion of visibility also includes the user's visual imagery of the problem as discussed in the theory of symbolic representation in problem solving. Visibility has been recognized as a "cognitive imperative" (Mc Cormick et al. 1987, p. 7), central to the development of the next generation of computer dialogues (Mandelkern 1993). "The ability to visualize data is absolutely essen tial to ensure the integrity of analysis, to provoke in sights, and to communicate those insights to others" (McCormick et al. 1987, p. 7). Ensuring the integrity of the analysis requires seeing the DSS at work; provoking insight requires seeing the problem; and communicat ing those insights to others requires seeing the work of the DSS. Each of these is essential for user calibration and critically dependent upon the design of visibility. For many problems, DSS design for user calibration depends upon the user's ability to visualize the problem and to see the DSS work and at work through an effec tive presentation of symbols and symbols in action. The more visible the problem and observable and under standable the DSS's behavior, the better able the user is to interpret the quality of a decision made using the aid, resulting in better calibration. Information visualization promises to provide the visibility needed to ensure the integrity, provoke insight, and communicate the visual information needed for user calibration. 4.2.3. Inquirability. Churchman (1971, p. 275) con cluded that the design of an inquiring system must con sider both "knowing" and the "feeling of knowing." Knowing is the essence of decision quality and the feel ing of knowing is decision confidence. By recognizing the importance of both decision quality and decision confidence, Churchman implies that an inquiring sys tem should be designed for user calibration. The term inquirability is used here to indicate how well the inquiring system is designed for user calibra tion. Inquirability reflects the effectiveness of the actions of a DSS to help identify and resolve differences be tween linguistic representation and expressiveness, and between visual imagery representation and visibility. It recognizes that actions engender feelings by tacitly re vealing system functionality. Inquirability indicates how well the actions of a DSS engender an accurate feel ing of knowing. Inquirability is a continuum of designs for DSS ac tions ranging from the servile and illusory that lulls to the contrarian that engages and continuously chal lenges. Actions that are servile and illusory are designed to please, to unquestioningly provide data that supports the decision-maker's position(s) and assumption(s). Little, if any, metaknowledge is identified or resolved by a DSS that is servile and illusory. At the other ex treme, DSS actions designed to be contrarian, engage and challenge the decision-maker's positions and as sumptions to identify and resolve metaknowledge through the dialectic process of contrasting, debating, and resolving differences. A number of designs for in quirability exist between servile and contrarian. Near the servile end of the inquirability continuum, the actions of a DSS can be designed to generate data that justifies or supports a position, a set of assump tions, or a decision that the user has already made. Jus tifying a decision that the user has already made has been reported as a major reason for using a DSS (Alter 1977). The limited evidence suggests that decision mak ers that surround themselves by servile systems, "yes men" that voice no criticism, fail to make good deci sions in crisis situations (Dunbar and Goldberg 1978). Servile inquirability fails to inform because it simply presents data that is in accord with the decision-maker's position. As might be expected, data that agrees with one's decision does not improve calibration (Koriat et al. Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="11">KASPER Decision Support System Design 1980). This suggests that inquirability designed or used to justify or support a position, a set of assumptions, or a decision that the user/decision-maker has already made will not improve calibration. Between servile and contrarian designs, inquirability includes highlighting, prompting, and other actions that direct, give advice, and suggest choices. Using these de signs for inquirability, the DSS recommends a response to the user, providing varying degrees of explanation to support its recommendation. In the extreme but not un common case, the DSS is incapable of providing any evidence to support its recommendation. Even in some of the most sophisticated systems, the DSS seems inca pable of providing the user with anything more than a very superficial explanation for its recommendation. In general, inquirability designs that simply recommend a response with little or no justification do not improve user calibration because they fail to expose assumptions or bring to the user's attention information on the crit icality of assumptions, nor do they suggest to the user new and alternative views of the situation. Advice giving systems encourage miscalibration because they place the user in the paradoxical and extremely difficult role of monitoring, and overruling when appropriate, the recommendations of a machine whose competence is presumed to exceed that of the user (Muir 1987). In fact, the evidence suggests that ratification of a rec ommended action, such as occurs when a DSS dialogue highlights, prompts, or otherwise directs or gives advice to the user, is particularly detrimental to calibration be cause it both increases overconfidence and decreases decision quality (Sniezek et al. 1990, Block and Harper 1991). In other words, those cued to a particular deci sion are likely to be less calibrated than those not cued to a decision. This suggests that inquirability such as highlighting and prompting, and perhaps even the rec ommendation of specific decisions by expert systems, may actually contribute to miscalibration because they place the user in the position of having to evaluate the quality of a recommendation that he or she has had little or no part in developing and was made by a machine touted as having more expertise than he or she. Near the contrarian end of the inquirability contin uum, the actions of a DSS are designed to engage and challenge the decision-maker's positions and assump tions to identify and resolve metaknowledge through the dialectic process of contrasting, debating, and re solving differences. In dialectic inquirability, the actions of a DSS are designed to identify and resolve meta knowledge by comparing a plan (thesis) and counter plan (antithesis), and debating their merits (Mason 1969). Because of this, dialectic inquirability results in better decisions (Cosier and Schwenk 1990, Mason 1969). It may also be the best method to use when prob lem novelty is great (Cosier and Schwenk 1990), and it has been shown to affect decision confidence (Buyuk kurt and Buyukkurt 1991). The literature also suggests that dialectic inquiry im proves calibration. Several of the rules reviewed earlier for improving calibration imply dialectic inquiry (i.e., the generation of competing alternative hypotheses and the presentation of the resulting disconfirming evidence help one distinguish between knowledge and specula tion). Similarly, Koriat et al. (1980) found that generat ing and listing items that disconfirm, challenge, or con tradict one's decision improves calibration. Justifying one's decision in writing has also been shown to im prove calibration (Arkes et al. 1987). Each of these var iants of dialectic inquiry improve calibration by gener ating competing hypotheses that result in the listing of evidence that challenges, refutes, and/or disconfirms one's mental representation of a problem. The identifi cation and resolution of differences, characteristic of di alectic reasoning, are essential for user calibration, es pecially when problem novelty is great. Inquirability based on the dialectic model of reasoning is perhaps the most effective for user calibration. Nevertheless, very little is known about how to design dialectic inquira bility despite its long recognized importance as a topic of IS research (Mason 1969, Nelson 1973). Ultimately, user calibration depends upon the user's interpretation of the quality of decisions he or she makes using the DSS. For user calibration, this means that the DSS must support and facilitate the user's in terpretation of the quality of decisions made using the aid. At a minimum, the symbols and actions of a DSS should coincide with those of the user's natural system of problem solving. Expressiveness, visibility, and in quirability define DSS symbols and actions that parallel those theorized to constitute the user's mental represen tation in problem solving. The DSS design theory for user calibration contends that user calibration can be Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="12">KASPER Decision Support System Design achieved by the appropriate design and judicious ap plication of expressiveness, visibility, and inquirability. The application of expressiveness, visibility, and in quirability in terms of their relation to problem novelty is developed in more detail below. 4.3 Problem Novelty and the Properties of the Theory In addition to defining the properties, a design theory must consider how these properties work in a specific problem situation, in this case a specific DSS, to achieve the desired goal. The DSS design theory for user cali bration contends that the locus of the DSS design pro cess needed to produce a specific DSS whose users are perfectly calibrated varies with problem novelty from expressiveness to visibility to inquirability. Problem novelty differs from problem structure. Problem structure implies something about the problem (Simon 1960, Gorry and Scott Morton 1971). Problem novelty reflects something about the user/decision maker in relation to the problem. Because calibration is based on the decision-maker's belief in the quality of a decision, it, too, reflects something about the decision maker in relation to the problem. As defined here, prob lem novelty reflects the proportion of the user's mental representation of the problem that is based on syllogis tic inference and the relative usefulness of analytic to wholistic abstraction. Thus, problem novelty is a more accurate description of the role played by the problem in user calibration than is problem structure. Defining problem novelty as consisting of type and degree of ab stractions is also consistent with the dimensions used by others to define the distinctions among problem solving domains (Rouse and Morris 1986). Intuitively, problem novelty would seem to play a role in the DSS design theory for user calibration. Prob lem novelty plays a role in problem solving, and cali bration is a function of the subjective and objective mea sures of the quality of a decision. Moreover, type of ab straction has been suggested as a criterion for designing DSS (Hollnagel and Woods 1983, Dalai and Kasper 1994), and degree of abstraction has been shown to af fect miscalibration (Wagenaar 1988, Gigerenzer et al. 1991, McCelland and Bolger 1994). Accordingly, the DSS design theory for user calibration asserts that prob lem novelty determines the locus of the DSS design pro cess for user calibration. The locus of the DSS design process for user calibration varies with problem novelty in a systematic way from expressiveness to visibility to inquirability. In most situations, various combinations of expressiveness, visibility, and inquirability are needed because they complement and support each other. The locus of the DSS design process identifies the principal property of the theory contributing to user cal ibration. The locus of the DSS design process for user calibration is illustrated in Figure 2. Figure 2 shows that the locus of the DSS design pro cess for user calibration varies with problem novelty from expressiveness to visibility to inquirability in ac cordance with linguistic and visual imagery represen tation, and exploratory reasoning in problem solving (Figure 1). If problem novelty is low, the user's sym bolic representation of the problem is largely linguistic, requiring expressiveness. In this case, expressiveness must be the locus of the DSS design process for user calibration, with visibility and inquirability playing im portant roles, roles perhaps critical to perfect calibra tion, but roles that support expressiveness because it reflects the user's symbolic representation of the prob lem. If problem novelty increases and the user's sym bolic representation of the problem is visual imagery, the locus of the DSS design process for user calibration moves to visibility, with expressiveness and inquirabil ity supporting visibility. Likewise, as problem novelty approaches the upper limits of the user's experiential knowledge and the user must resort to exploratory rea soning for problem solving, the locus of the DSS design process for user calibration is inquirability, with ex pressiveness and visibility supporting inquirability. Figure 2 Locus of the DSS Design Process for User Calibration in Re lation to Problem Novelty Problem Novelty Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="13">KASPER Decision Support System Design An example of expressiveness as the locus of the DSS design process might be based on a scene from the clas sic screenplay "The Wizard of Oz." Near the end of the movie, the Scarecrow is given a doctorate of "thinkol ogy" by the Wizard as an indication of his intellect. The Scarecrow then melodramatically and emphatically mis states the Pythagorean theorem. (The Scarecrow, per haps making a syllogistic reasoning error, attributed the Pythagorean theorem to isosceles triangles.) The Py thagorean theorem is a linguistic representation of a geometric image, but visual imagery of a right triangle is of little help here. Responding to the user's linguistic representation, the locus of the DSS design process for user calibration must be expressiveness that conveys to the user, in this example, that the Pythagorean theorem does not apply to isosceles triangles. Here, expressive ness is the locus of the DSS design process for user cal ibration because it corresponds to the user's error in lin guistic representation. How best to reify cognitive activ ity so that errors can be detected is a major concern of those designing computer-aided instruction systems (Reusser 1993). If problem novelty is so high that the user lacks any experiential knowledge, the locus of the DSS design process for user calibration is inquirability, and visibil ity and expressiveness must support inquirability. The user might first assess the aid, inquiring into its domain of expertise, history of performance, and performance over a range of tasks within its domain of expertise (Muir 1987), and then begin formulating a belief in the quality of a decision by debating the hypotheses (the ses) and competing hypotheses (antitheses), the prem ises and assumptions guiding the creation of his or her mental representation of the problem. If users are to achieve perfect calibration, expressive ness and visibility must accurately convey the function ing and functionality of the DSS in relation to problem novelty, and expressiveness, visibility, and inquirability must accurately reflect and respond to problem novelty. For example, if the DSS is capable of sophisticated, di alectic reasoning, but problem novelty is low, user cal ibration is primarily dependent upon expressiveness ac curately conveying the functioning and functionality of the DSS in relation to problem novelty, not in relation to the sophistication of the DSS. Conversely, if problem novelty is high but the DSS has limited inquirability, expressiveness and visibility may help the user recog nize the limitations of the DSS, but they cannot com pensate for the needed inquirability. In this way, ex pressiveness, visibility, and inquirability work together as a system in response to problem novelty, and are equally important for user calibration either because they accurately convey the applicability or inapplicabil ity of the DSS, or because they accurately reflect and respond to problem novelty. Examples of expressiveness and visibility abound. Advances in audio and video technologies for graphical and multimedia systems and video games are well known. Yet, how the symbols produced by these tech nologies affect users is largely unknown. Even less is known about inquirability. Inquirability has received comparatively little research or development attention, and advances have been much less conspicuous and have come at a much slower pace. Futuristic systems depicting various forms and sys tem combinations of expressiveness, visibility, and inquirability have been proposed by the computer in dustry. One of the best known of these is the video "The Knowledge Navigator: Technologies to Get Us There and Beyond" produced by Apple Computer in 1990. Another film that depicts several futuristic forms of the theory's properties is "Multimedia Technology" produced by Southwestern Bell Telephone in 1991. Both of these promotional videos show very ad vanced levels of expressiveness, visibility, and in quirability by portraying ultraintelligent systems ca pable of asking challenging questions, anticipating and suggesting alternatives, and recognizing and syn thesizing spoken language with multimedia visual display capabilities. Table 1 summarizes the components of the DSS de sign theory for user calibration. Expressiveness, visibil ity, and inquirability define the requisite DSS design properties needed for users to realize the goal of perfect calibration. Designing a Specific DSS for user calibra tion, the locus of the design process varies with the nov elty of the problem from expressiveness to visibility to inquirability. Discussion of how this is reflected in spe cific design methods is beyond the scope of this paper. However, matching the DSS design method to the de mands of the problem remains key to effective design (Ginzberg and Stohr 1982). Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="14">KASPER Decision Support System Design Table 1 Components of the DSS Design Theory for User Calibration Design Product Goal Design properties Prescribe the requisite properties of a DSS needed for users to realize perfect calibration. Expressiveness Visibility Inquirability Example Attributes Tone Rhetorical Strategy Framing Connectiveness Message Construction Realistic/Abstract Images Timing Alterations Transitions Level of Dialectics (Servile to Contraian) Design Process Design method Locus of the design process varies with problem novelty from expressiveness to visibility to inquirability 5. Testing the Theory To be useful, a design theory must be subject to refu tation (Walls et al. 1992). Some of the issues related to testing the DSS design theory for user calibration are discussed below. Space limitations prevent anything more than a brief discussion. Design theories predict that an artifact will achieve its goal to the extent that it possesses the properties pre scribed by the theory (Walls et al. 1992). The DSS design theory for user calibration is a design theory and not a theory of calibration: the issue is that "the proper func tioning of a mental algorithm depends on (and seems particularly sensitive to) the way in which information is represented" (Gigerenzer 1994, p. 142, parentheses added), and not the inherent calibration or miscalibra tion of human beings per se. The DSS design theory for user calibration suggests numerous hypotheses and empirical studies involving various forms and combinations of expressiveness, vis ibility, and inquirability. The most fundamental of these, however, is that DSS users will achieve the goal of perfect calibration to the extent that the DSS possesses requisite properties of expressiveness, visibility, and in quirability, and that the locus of the design process for a specific DSS varies with problem novelty from ex pressiveness to visibility to inquirability. To test specific DSS design properties, problem nov elty is an important variable. Despite recognition of its importance by both calibration (May 1986, Bjorkman in press, Juslin 1993,1994) and MIS/DSS researchers (Ma son and Mitroff 1973, Gorry and Scott Morton 1971, Dickson et al. 1986) alike, very few researchers report on the salient attributes of the problem(s) they use in their studies. For user calibration, problem novelty con sists of type of abstraction (the analytic to wholistic re quirements of the problem in relation to that of the sub ject) and degree of abstraction (the proportion of infer ence based on syllogistic reasoning contained in the subject's mental representation of a problem). Hypotheses testing for design theory requires con struction of a prototype or development of a facade that mimics the artifact so that the subjects believe and be have as if it were real. The latter may be more practical for investigating some advanced designs of expressive ness, visibility, and inquirability. It should also be noted that the procedures typically used by MIS/DSS re searchers to measure decision confidence are inconsis tent with those used by calibration researchers. More over, most MIS/DSS research that captures decision confidence and decision quality never computes cali bration. For a discussion of these issues, the interested reader is directed to reviews and recent works by Bjork man (1992, in press), Juslin (1993,1994), Kasper (1996), Keren (1991), Wagenaar (1988), Wallsten et al. (1993), and Yates (1994). 6. Summary and Conclusions The effect of DSS symbols and actions on decision con fidence and calibration has been neglected by both re searchers and designers. Thirty years ago, Weizenbaum (1966, p. 42-43) warned of the danger of this neglect when he wrote, The whole issue of the credibility (to humans) of machine out put demands investigation. Important decisions increasingly tend to be made in response to computer output . . . ELIZA shows, if nothing else, how easy it is to create and maintain the illusion of understanding, hence perhaps of judgement deserv ing of credibility. A certain danger lurks here. Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="15">KASPHR Decision Support System Design To begin to address this danger, a DSS design theory for user calibration was developed. Fundamentally, the DSS design theory for user cali bration assumes that the design of DSS symbols and actions can affect the user's belief in the quality of a decision he or she makes using the aid. Synthesizing relevant literatures and theories, the DSS design theory for user calibration predicts that a DSS will achieve the goal of perfect calibration to the extent that it possesses requisite properties of expressiveness, visibility, and in quirability, and that the locus of the DSS design process for user calibration varies in a systematic way with problem novelty from expressiveness to visibility to in quirability. No claim is made that expressiveness, visibility, and inquirability are mutually exclusive or collectively ex haustive. Nevertheless, the DSS design theory pre scribed here has significant implications for DSS re search and design. Chief among these is the recognition of perfect calibration as an important DSS design goal. Moreover, the theory developed here provides a well grounded foundation for investigating the efficacy of specific tools and different DSS designs for user calibra tion. Making specific recommendations for the design of DSS for user calibration is premature. Much empirical work remains to be done before specific recommenda tions can be made. Nevertheless, the theory recognizes the importance of user calibration and asserts that ex pressiveness, visibility, and inquirability are essential to the design of DSS for user calibration. As DSS are increasingly applied in situations where problem novelty is high, DSS design for user calibration becomes increasingly important. How the specific fea tures of a DSS design affect user calibration is unknown. The DSS design theory for user calibration prescribes the properties of expressiveness, visibility, and inquir ability as requisite for building a DSS so that a user's belief in the quality of a decision made using the aid equals the quality of that decision.6 6 The author would like to thank the Associate Editor and three anon ymous reviewers for their invaluable comments. References Aldag, R. J. and D. J. Powers, "An Empirical Assessment of Computer Assisted Decision Analysis/' Decision Sci., 17, 4 (1986), 572-588. Alter, S., "Why is Man-Computer Interaction Important for Decision Support Systems?," Interfaces, 7, 2 (February 1977), 109-115. Arkes, H. R., C. Christensen, C. Lai, and C. Blumer, "Two Methods of Reducing Overconfidence," Organizational Behavior and Human Decision Processes, 39,1 (February 1987), 133-144. Aviation Week &amp; Space Technology, "Aegis Data Processing Reviewed in Navy Probe of A300 Downing," 129, 3 (July 18, 1988), p. 23. Bandura, A., "Self-efficacy: Toward a Unified Theory of Behavioral Change," Psychological Review, 84 (1977), 191-215. Bell, J., "The Effect of Presentation Form on Judgement Confidence in Performance Evaluation," ]. Business Finance and Accounting, 11, 3 (1984), 327-346. Benbasat, I. and B. R. Nault, "An Evaluation of Empirical Research in Managerial Support Systems," Decision Support Systems, 6, 3 (1990), 203-226. Bjorkman, M., "Knowledge, Calibration, and Resolution: A Linear Model," Organizational Behavior and Human Decision Processes, 51, 1 (1992), 1-21. , "Internal Cue Theory: Calibration and Resolution of Confidence in General Knowledge," Organizational Behavior and Human Deci sion Processes, (in press). Block, R. A. and D. E. Harper, "Overconfidence in Estimation: Testing the Anchoring-and-Adjustment Hypothesis," Organizational Be havior and Human Decision Processes, 49, 2 (1991), 188-207. Boje, D. M. and J. K. Murnighan, "Group Confidence Pressures in Interactive Decisions," Management Sci., 28,10 (1982), 1187-1196. Bonczek, R. H., C. W. Holsapple, and A. B. Whinston, Foundations of Decision Support Systems, Academic Press, New York, 1982. Booth, P., "Errors and Theory in Human-Computer Interaction," Acta Psychologica, 78 (1991), 69-96. Brown, P. S. and J. D. Gould, "An Experimental Study of People Cre ating Spreadsheets," ACM Trans. Office Information Systems, 5, 3 (1987), 258-272. Brown, G. and G. Yule, Discourse Analysis, Cambridge University Press, London, 1983. Buchheit, P. and T. Moher, "Response Assertiveness in Human Computer Dialogue," International J. Man-Machine Studies, 32, 1 (1990), 109-117. Buyukkurt, B. K. and M. D. Buyukkurt, "An Experimental Study of the Effectiveness of Three Debiasing Techniques," Decision Sci ences, 22,1 (1991), 60-73. Carrol, J. M. and J. McKendree, "Interface Design Issues for Advice Giving Expert Systems," Comm. ACM, 30,1 (1987), 14-31. Chervany, N. L. and G. W. Dickson, "An Experimental Evaluation of Information Overload in a Production Environment," Manage ment Sci., 20,10 (1974), 1335-1344. Clemen, R. T. and A. H. Murphy, "The Expected Value of Frequency Calibration," Organizational Behavior and Human Decision Processes, 46,1 (1990), 102-117. Churchman, C., The Design of Inquiring Systems, Basic Books, New York, 1971. Cosier, R. A. and C. R. Schwenk, "Agreement and Thinking Alike: Ingredients for Poor Decisions," Acad. Management Executive, 4,1 (1990), 69-74. Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="16">KASPER Decision Support System Design Dalai, N. J. and G. M. Kasper, "The Design of Joint Cognitive Systems: The Effect of Cognitive Coupling on Performance," International J. Man-Machine Studies, 40, 4 (1994), 677-702. Davis, F. D., J. E. Kottemann, and W. E. Remus, "What-if Analysis and the Illusion of Control," Proc. Twenty-Fourth Annual Hawaii Inter national Conf. System Sciences, 3 (1991), 452-460. and , "User Perceptions of Decision Support Effectiveness: Two Production Planning Experiments," Decision Sciences, 25, 1 (1994), 57-78. DeSanctis, G. and R. B. Gallupe, "A Foundation for the Study of Group Decision Support Systems," Management Sci., 33, 5 (1987), 589 609. Dickson, G. W., G. DeSanctis, and D. J. McBride, "Understanding the Effectiveness of Computer Graphics for Decision Support: A Cu mulative Experimental Approach," Comm. ACM, 29 (1986), 40 47. Dunbar, R. L. M. and W. H. Goldberg, "Crisis Development and Stra tegic Response in European Corporations," in C. F. Smart and W. T. Stanbury (Eds.), Studies on Crisis Management, Butterfield &amp; Company, Toronto, Canada, 1978,140-149. Edwards, J. L. and J. A. Mason, "Evaluating the Intelligence in Dia logue Systems," International J. Man-Machine Studies, 28,2/3 (Feb ruary/March 1988), 139-173. Einhorn, H. J., "Accepting Error to Make Less Error," }. Personality Assessment, 50,3 (1986), 387-395. and R. M. Hogarth, "Confidence in Judgment: Persistence of the Illusion of Validity," Psychological Rev., 85, 5 (1978), 395-416. and , "Behavioral Decision Theory: Processes of Judgement and Choice," Annual Rev. Psychology, 32 (1981), 53-88. Faust, D., "Learning and Maintaining Rules for Decreasing Judgement Accuracy," J. Personality Assessment, 50,4 (1986), 585-600. Freeman, R. M., "A Slip of the Chip on Computer Spreadsheets Can Cost Millions," The Wall Street Journal, 205,35 (August 20,1984), 14. Gallupe, R. B., G. DeSanctis, and G. W. Dickson, "Computer-Based Support for Group Problem-Finding: An Experimental Investi gation," MIS Quarterly, 12, 2 (1988), 277-296. Gigerenzer, G., "Why the Distinction between Single-event Probabil ities and Frequencies is Important for Psychology (and Vice Versa)," in G. Wright and P. Ayton (Eds.), Subjective Probability, Wiley, New York, 1994. , U. Hoffrage, and H. Kleinbolting, "Probabilistic Mental Models: A Brunswikian Theory of Confidence," Psychological Rev., 98, 4 (1991), 506-528. Ginzberg, M. J. and E. A. Stohr, "Decision Support Systems: Issues and Perspectives," in M. J. Ginzberg, W. Reitman, and E. A. Stohr (Eds.), Decision Support Systems, North-Holland, Amsterdam, 1982. Gorry, G. A. and M. S. Scott Morton, "A Framework for Management Information Systems," Sloan Management Rev., 13, 1 (1971), 55 70. Hartson, H. R. and D. Hix, "Human-Computer Interface Develop ment: Concepts and Systems for Its Management," Computing Surveys, 21,1 (1989), 5-92. Helstrup, T., "One, Two, or Three Memories? A Problem-solving Ap proach to Memory for Performed Acts," Acta Psychologica, 66 (1987), 37-68. Henderson, J. C., "Finding Synergy Between Decision Support Sys tems and Expert Systems Research," Decision Sciences, 18,3 (1987), 333-349. Hogarth, R. M., Judgement and Choice: The Psychology of Decision, Wiley, New York, 1980. Hollnagel, E. and D. D. Woods, "Cognitive Systems Engineering: New Wine in New Bottles," International J. Man-Machine Studies, 18, 6 (1983), 583-600. Huff, S. L., "DSS Development: Promise and Practice," Decision Sup port Systems, 1 (1986), 8-21. Humphreys, P., "Intelligence in Decision Support," in B. Brehmer, H. Jungermann, P. Lourens, and G. Sevon (Eds.), New Directions in Research on Decision Making, Elsevier Science Publishers B.V. North-Holland, Amsterdam, 1986. Johnson-Laird, P. N., "Mental Models in Cognitive Science," Cognitive Science, 4,1 (1980), 71-115. Juslin, P., "An Explanation of the Hard-Easy Effect in Studies of Re alism of Confidence in One's General Knowledge," European J. Cognitive Psychology, 5,1 (1993), 55-71. , "The Overconfidence Phenomenon as a Consequence of In formal Experimenter-guided Selection of Almanac Items," Or ganizational Behavior and Human Decision Processes, 57 (1994), 226-246. Kahneman, D. and A. Tversky, "Prospect Theory: An Analysis of De cision Under Risk," Econometrica, 47, 2 (1979), 263-291. Kasper, G. M., "Measuring User Calibration in DSS Design Research," Working Paper, Texas Tech University, Lubbock, TX, 1996. Kaufmann, G., Imagery, Language and Cognition: Toward a Theory of Sym bolic Activity in Human Problem-solving, Universitetsforlaget, Nor way (printed in North America by Columbia University Press, New York), 1980. , "A Theory of Symbolic Representation in Problem Solving," J. Mental Imagery, 9,2 (1985), 51-70. Keen, P. G. W., "Decision Support Systems: The Next Decade," Deci sion Support Systems, 3 (1987), 253-265. Keller, P. R. and M. M. Keller, Visual Cues: Practical Data Visualization, IEEE Computer Society Press, Los Alamitos, CA, 1993. Keren, G., "Calibration and Probability Judgements: Conceptual and Methodological Issues," Acta Psychologica, 77 (1991), 217-273. Koriat, A., S. Lichtenstein, and B. Fischhoff, "Reasons for Confidence," J. Experimental Psychology: Human Learning and Memory, 6, 2 (1980), 107-118. Lichtenstein, S., B. Fischhoff, and L. Phillips, "Calibration of Probabil ities: The State of the Art to 1980," in D. Kahneman, P. Slovic, and A. Tversky (Eds.), Judgment Under Uncertainty: Heuristics and Bi ases, Cambridge University Press, Cambridge, England, 1982. Lohse, G. L., K. Biolsi, N. Walker, and H. H. Rueter, "A Classification of Visual Representation," Comm. ACM, 37,12 (1994), 36-49. Luconi, F. L., T. W. Malone, and M. S. Scott Morton, "Expert Systems: The Next Challenge for Managers," Sloan Management Review, 27, 4 (1986), 3-14. Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="17">KASPER Decision Support System Design Mahajan, J., "The Overconfidence Effect in Marketing Management Predictions," J. Marketing Research, 29,3 (August 1992), 329-342. Mandelkern, D., "Graphical User Interfaces: The Next Generation," Comm. ACM, 36,4 (1993), 36-39. Mason, R. O., "A Dialectical Approach to Strategic Management," Management Sci., 15, 8 (April 1969), B-403-B-414. and I. I. Mitroff, "A Program for Research on Management In formation Systems," Management Sci., 19, 5 (January 1973), 475 487. May, R. S., "Inferences, Subjective Probability and Frequency of Cor rect Answers: A Cognitive Approach to the Overconfidence Phe nomenon," in B. Brehmer, P. Jungermann, and G. Sevon (Eds.), New Directions in Research on Decision Making, Elsevier Science Publications B.V. (North-Holland), Amsterdam, 1986. McClelland, A. G. R. and F. Bolger, "The Calibration of Subjective Probabilities: Theories and Models 1980-94," in G. Wright and P. Ayton (Eds ), Subjective Probability, Wiley, New York, 1994. McCormick, B. H., T. A. DeFanti, and M. D. Brown, "Visualization in Scientific Computing," Computer Graphics, 21,6 (November, 1987) entire issue. Mclntyre, S., "Experimental Study of the Impact of Judgement-Based Marketing Models," Management Sci., 28,1 (January 1982), 17-33. Muir, B. M., "Trust Between Humans and Machines, and the Design of Decision Aids," International J. Man-Machine Studies, 27, 5 (1987), 527-539. Neisser, U., '7ohn Dean's Memory: A Case Study," Cognition, 9 (1981), 1-22. Nelson, J. A., "Dialectic Information Systems: A Methodology for Planning and Decision Making," unpublished Ph.D. dissertation, University of Pittsburgh, Pittsburgh, PA, 1973. Newell, A. and H. A. Simon, "Computer Science as Empirical Inquiry: Symbols and Search," Comm. ACM, 19, 3 (1976), 113-126. and &gt; Human Problem Solving, Prentice-Hall, Englewood Cliffs, NJ, 1972. Norman, D. A., "Approaches to the Study of Intelligence," Artificial Intelligence, 47,1-3 (January 1991), 327-346. Northcraft, G. B. and P. C. Earley, 'Technology, Credibility, and Feed back Use," Organizational Behavior and Human Decision Processes, 44,1 (August 1989), 83-96. Olson, G. M. and J. S. Olson, "User-Centered Design of Collaborative Technology," Organizational Computing, 1,1 (1991), 61-83. Oskamp, S., "Confidence in Case-Study Judgements," J. Consulting Psychology, 29,3 (June 1965), 261-265. Paese, P. W. and J. A. Sniezek, "Influences on the Appropriateness of Confidence in Judgement: Practice, Effort, Information, and Decision-Making," Organizational Behavior and Human Decision Processes, 48, 1 (February 1991), 100-131. Quintanar, L. R., C. R. Crowell, J. B. Pryor, and J. Adamopoulos, "Human-Computer Interaction: A Preliminary Social Psycholog ical Analysis," Behavior Research Methods &amp; Instrumentation, 14, 2 (1982), 210-220. Remus, W. E. and J. Kotteman, 'Toward Intelligent Decision Support Systems: An Artificially Intelligent Statistician," MIS Quarterly, 10, 4 (1986), 403-418. Reusser, K.; "Tuitoring Systems and Pedagogical Theory: Represen tational Tools for Understanding, Planning, and Reflection in Problem Solving," in S. P. Lajoie and S. J. Derry (Eds.), Computers as Cognitive Tools, Lawrence Erlbaum Associates, Hillsdale, NJ, 1993. Rouse, W. B. and N. M. Morris, "On Looking into the Black Box: Pros pects and Limits in the Search for Mental Models," Psychological Bull., 100, 3 (1986), 349-363. Russo, J. E. and P. J. Schoemaker, "Managing Overconfidence," Sloan Management Rev., (Winter 1992), 7-17. Scott Morton, M. S., "The State of the Art of Research," in F. W. McFarlan (Ed.), Information Systems Research Challenge, Harvard Business School Press, Cambridge, MA, 1984. Sharda, R., S. H. Barr, and J. C. McDonnell, "Decision Support System Effectiveness: A Review and an Empirical Test," Management Sci ence, 34, 2 (1988), 139-159. Sharp, G. L., B. L. Cutler, and S. D. Penrod, "Performance Feedback Improves the Resolution of Confidence Judgments," Organi zational Behavior and Human Decision Processes, 42, 3 (1988), 271-283. Shneiderman, B., Designing the User Interface: Strategies for Effective Human-Computer Interaction. (Second Edition) Addison-Wesley, Reading, MA, 1992. —, Designing the User Interface: Strategies for Effective Human-Computer Interaction. Addison-Wesley, Reading, MA, 1987. Simon, H. A., The New Science of Management Decision. New York: Har per &amp; Row, 1960. Sniezek, J. A. and R. A. Henry, "Accuracy and Confidence in Group Judgment," Organizational Behavior and Human Decision Processes, 43,1 (February 1989), 1-28. , P. W. Paese, and F. S. Switzer III, "The Effect of Choosing on Decision Confidence Choice," Organization Behavior and Human Decision Processes, 46, 2 (August 1990), 264-282. Sprague, R. H. and E. D. Carlson, Building Effective Decision Support Systems, Prentice-Hall, Englewood Cliffs, NJ, 1982. Stasko, J. T., "Animation in User Interfaces: Principles and Tech niques," in L. Bass and D. Prasun (Eds.), User Interface Software, Wiley, New York, 1993. Staw, B. M., "Knee-deep in the Big Muddy: A Study of Escalating Commitment to a Chosen Course of Action," Organizational Be havior and Human Performance, 16,1 (1976), 27-44. , "The Escalation of Commitment to a Course of Action," Acad. Management Rev., 6 (1981), 577-587. Steeb, R. and S. C. Johnston, "A Computer-Based Interactive System for Group Decisionmaking," IEEE Trans. Systems, Man, and Cy bernetics, 11, 8 (1981), 544-552. Stevick, R. A., K. Martin, and L. Showalter, 'Importance of Decision and Postdecision Dissonance: A Return to the Racetrack," Psycho logical Report, 69, 2 (1991), 420-422. Teach, R. and E. Shortliffe, "An Analysis of Physician Attitudes Re garding Computer-Based Clinical Consultation Systems," Com puters and Biomedical Res., 14 (1981), 542-58. Trull, S. G., "Some Factors Involved in Determining Total Decision Success," Management Sci., 12, 6 (1966), B-270-280. Information Systems Research Vol. 7, No. 2, June 1996</page><page sequence="18">KASPER Decision Support System Design Tversky, A. and D. Kahneman, "Judgement under Uncertainty: Heuris tics and Biases/' Science, 185,4157 (September 1974), 1124-1131. Veryard, R., "The Role of Visibility in Systems," Human Systems Man agement, 6, 2 (1986), 167-175. Wagenaar, W. A., "Calibration and the Effects of Knowledge and Re construction in Retrieval from Memory," Cognition, 28 (1988), 277-296. Walls, J. G., G. R. Widmeyer, and O. A. El Sawy, "Building an Infor mation System Design Theory for Vigilant EIS," Information Sys tems Res., 3,1 (1992), 36-59. Wallsten, T. S., D. V. Budescu, and R. Zwick, "Comparing the Cali bration and Coherence of Numerical and Verbal Probability Judgements," Management Sci., 39,2 (1993), 176-190. Weber, R., "Toward a Theory of Artifacts: A Paradigmatic Base for Information Systems Research," J. Information Systems, (Spring 1987), 3-19. Weizenbaum, J., "ELIZA—A Computer Program for the Study of Nat ural Language Communication between Man and Machine," Comm. ACM, 9,1 (1966), 36-45. West, T. G., In the Mind's Eye, Prometheus Books, Buffalo, NY, 1991. Wills, R., "Individual Differences in the Performance and Use of an Expert System," International J. Man-Machine Studies, 37, 2 (1992), 173-190. Woods, D. D. and E. Roth, "Cognitive Engineering: Human Prob lem Solving with Tools," Human Factors, 30, 4 (1988), 415 430. Yates, J. F., "Subjective Probability Accuracy Analysis," in Wright, G. and P. Ayton (Eds.), Subjective Probability, Wiley, New York, 1994. Zakay, D., "The Influence of Computerized Feedback on Overconfi dence in Knowledge, Behaviour and Information Technology, 11, 6 (1992), 329-333.</page></plain_text>
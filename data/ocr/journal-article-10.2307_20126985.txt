<plain_text><page sequence="1">ARTICLES POST HOC, ERGO PROPTER HOC JOHN WOODS AND DOUGLAS WALTON I XT is strange that the informal fallacies should strike us as such obvious breaches of thinking and advocacy, yet should have met with such little success in finding a respectable home within mature logical theory.1 It might seem that respectable and mature logical theory is most mature and most respectable in the theory of propo sitions, and that its maturity and respectability in the other logical domains rapidly diminish in inverse proportion to the susceptibility of those domains to be reduced to the logic of propositions. But we are not anxious to promote so severe a view of theoretical ac complishment, and we shall suppose that, at the very least, the informal fallacies have a degree of systematicity that will at once advance our understanding of them nicely beyond the level of intui tive impressions, and also place into retirement the hopelessly inade quate accounts that litter too many otherwise admirable textbooks. In the case o? false cause, however, the theoretical orphanhood seems easily explained. We have heretofore lacked a causal logic.2 Common experience attests that the fallacy of post hoc is one of the most insidious and pervasive systematic misdemeanors of everyday argumentation: one need only reflect upon the conceptual mess attend ing such practically brutal realities as the causes of inflation or the causes of cancer. In fact, the special problem posed is this: is it possible to say something theoretically constructive about false cause without running afoul of general problems in the analysis of the causal 1 C. L. Hamblin, Fallacies (London: Methuen, 1970). See also John Woods and Douglas Walton, "On Fallacies," The Journal of Critical Anal ysis, IV (1974), pp. 103-112, and "Towards a Theory of Argument," Metaphilosophy, forthcoming. 2 But see the following: 1) Patrick Suppes, A Probabilistic Theory of Causality (Amsterdam: North Holland, 1970); 2) Arthur Burks, "The Logic of Causal Propositions," Mind, LX (1951), pp. 363-382, and Cause, Chance, and Reason, forthcoming; 3) I. J. Good, "A Causal Calculus," The British Journal for the Philosophy of Science, Part I, XI (1961), pp. 305-318 &amp; Part II, XII (1962), pp. 43-51.</page><page sequence="2">570 JOHN WOODS AND DOUGLAS WALTON relation? With a circumspection appropriate to the task, we here offer some thoughts about the structure of the post hoc. II We do not presume to offer a wholly uncontroversial or com plete explication of the causal relation, and we do not say that a complete and conclusive causal theory is a necessary component of an improved understanding of the causal fallacies. Nonetheless, a gen eral characterization of some basic aspects of causation will be of some benefit to our project. It is, of course, always well to keep in mind the distinction between causation and the functions, correla tions, equations, and graphs that constitute a part of the evidence for causal attributions. We also wish to emphasize the richly practi cal milieu in which the concept of causation is most naturally met. Talk of causation is an utterly familiar, accepted, and useful part of the language of the applied sciences in such fields as medicine, engineering, political science, economics, and psychiatry, all the more so where our interest is in the production or prevention of effects. Accordingly, we shall construe causal statements as arrayed against an assumed background of empirical and theoretical information that is not always statistically articulable. Statisticians often speak of this element in such terms as "common sense." So regarded, attributions of causality are bound by an understanding of ceteris paribus, in which reference is made to background information which is often empirical, yet not always explicitly statistical, and yet which plays an essential role. To accommodate the factor of background information in causal explanation, John Anderson3 introduced the concept of a field. This notion is given a set-theoretical development by Suppes via explicit introduction of random variables.4 Suppes suggests that what is designated as a field is best seen as relative to the conceptual frame work under discussion. Thus, says Suppes, "In one theoretical approach to the causal analysis of phenomena, the field will include only the consideration of macroscopic bodies and their character istics, but in another, it will go deeper and consider as well atomic 3 John Anderson, "The Problem of Causality," Australasian Journal of Philosophy, II (1938), pp. 127-142. 4 Patrick Suppes, op. cit., pp. HOff.</page><page sequence="3">POST HOC, ERGO PROPTER HOC 571 objects and their properties."5 When a given framework of variables is extended by consideration of additional variables, what may have been a genuine causal relationship relative to the first field may turn out to be causally spurious relative to the second, "richer" field. A number of supporting examples can be drawn from learning theory, and they are analyzed in detail by Suppes. So relativized, causal explanation is naturally and usefully regarded as resting not upon laws tout court, but upon quasi-laws.6 Quasi-laws are generaliza tions with tacit qualifications which cannot be fully articulated or spelled out in a finite, manageable set of explicit sentences.7 Let us, in any event, set out, schematically and briefly, various analytic perspectives on the causal relations that have attained some degree of importance in the literature. Our purpose in so doing is to seek for an intuitively satisfying core understanding of causation. It would be priggish to ask for more. The Humean approach is paramount among causally non-familial analyses,8 that is, among analyses set forth in an idiom free of causal locutions. From Hume's remarks9 it is customary to extract this schema: x caused y if, and only if, H(l) x and y occurred in some same close neighbourhood H(2) y succeeded x H(3) occurrences of the #-kind in given close neighbourhoods are succeeded by occurrences of the ?/-kind in those same neighbourhoods. 5 Ibid., p. 75. 6 Nicholas Rescher and Olaf Helmer, "On the Epistemology of the Inexact Sciences," Management Science, XI (1959), pp. 25-52. See also the remarks of Burks, Cause, Chance, and Reason, 7.3.3. 7 The reader is referred to our article, "Argumentum ad Verecunc?am," Philosophy and Rhetoric, VII (1974), pp. 135-153, for remarks on the structure of explanation appropriate to the statistical, causal, and authority-based informal fallacies. 8 True, in the Treatise Hume speaks of cause as "an object precedent contiguous to another, and so united with it, that the idea of the one determines the mind to form the idea of the other, and the impression of one to form a more lively idea of the other." (A Treatise of Human Nature, ed. L. A. Selby-Bigge [Oxford: The Clarendon Press, 1973], p. 170, italics added). However, we share the view that Hume is not here giving truth conditions of "x caused y," but rather of "A believes that x caused y." It is true, of course, that one looks in vain in the Treatise for crisp and entirely satisfactory evidence that Hume intended or recognized this distinction. 9 See the Treatise, p. 73ff.</page><page sequence="4">572 JOHN WOODS AND DOUGLAS WALTON An historically influential perspective, the Humean position, for all its problems, thrives in the contemporary literature. Suppes' theory, for example, briefly mentioned above, is broadly Humean in its orientation. The dense and powerful litany of objections to the Humean view extends from Reid, to Ducasse, to Madden.10 Numerous writers have remarked that Hume, unwittingly perhaps, rules out simul taneous causation. Reid seized on the crucial importance of con trolling the distinction between accidental and genuinely causal corre lations, and Ducasse, many generations later, repeated the objection with even greater force. Then, too, the Humean definition runs into the heavy weather of talk of "kinds" of events, and of the pos sibility of unique happenings, and so on. It would appear that there is little chance of rescuing the Humean account as a satisfactory definition of "x caused y," but there is no doubting its value as a rich source of basic intuitions. Some contemporary views, typically sympathetic to the Humean account, take the form: x caused y if, and only if, L(l) y did not precede x L(2) a statement of the occurrence of y is deducible from the laws of nature together with a description of initial conditions includ ing the occurrence of x L(3) yet a statement of y's occurrence is not deducible either from x's occurrence alone, or the initial conditions alone or from the laws of nature alone. With this, the laws of nature account, problems also rage. For all the intuitive advantage of tying causation to lawful correlations bound by certain restrictions, not all laws are causal (e.g., the Boyle-Charles law). Moreover, on this view, too, if one is not careful, simultaneous causation is ruled out. Also, if we are not careful (in particular, if we model laws after the generalizations of such abstract systems as classical mechanics), we risk committing causation to system-closure and thus risk suppressing the inarticulable background aspects of the 10 Thomas Reid, Essays on the Intellectual Powers of Man (Cam bridge, Massachusetts: M.I.T. Press, 1969 [originally published 1813-15]), C. J. Ducasse, "Critique of Hume's Conception of Causality," Journal of Philosophy, LXIII (1966), pp. 141-148, and Edward H. Madden, "Hume and the Fiery Furnace," Philosophy of Science, XXXVIII (1971), pp. 64-78.</page><page sequence="5">POST HOC, ERGO PROPTER HOC 573 causal idiom and the related susceptibility of causality to manifest itself in quasi-laws. Not least among the difficulties of the laws of nature account is that a philosophically satisfactory specification of "law of nature" is a formidable undertaking indeed. Even a per functory review of the contemporary literature reveals the promi nence of the view that a universally quantified generalization is a law if its truth, if true, is preserved under subjunctive re-expression. Yet, even so, the subjunctive conditional itself stoutly resists the blandishments of philosophical analysis. We will not here trouble the reader with the lively controversies at mid-century and fifteen years, and more, beyond, with the squalls and tornadoes gusting over the familiar landmarks of Chisholm11 and Goodman.12 It suffices to remark that even the relative successes of the later modal analyses of Stalnaker, Lewis, Sobel, Woods, and others, do not leave the laws of nature approach trouble-free. For one thing, a Stalnaker sort of analysis13 commits one to the proposition that, for every A and B, A either subjunctively implies B or subjunctively implies not-B. And in any such modal, or possible worlds approach to subjunctive conditionally, additional difficulties lie in wait. For example, in a Stalnaker sort of theory, A subjunctively implies B in this, the real world W, only if there exists a unique world W* maximally similar to W except that in W* A is true (and so too is whatever follows from A), and B is true in W*. Some writers (Lewis, for example) have queried the justification of supposing W* to be unique. But there is another problem as well. It has to do with the theoretical motivation of world-similarity. Why, we should ask ourselves, is it that the career of the consequent B in similar circumstances should determine the career of "If A were the case, so would B be the case" in present circumstances? What burdens does the similarity relation bear? Very crucial ones, as is evident from the following. Suppose that W*, the world alternative to our world W, were a world which offered its hospitality to generalized accidents but were utterly hostile to causal correlations. In that world the semantic career of B would be irrelevant to the domestic semantic career of "If A were the case, 11 Roderick Chisholm, "Law Statements and Counterfactual Infer ence," Analysis, XV (1954-55), pp. 97-105. 12 Nelson Goodman, Fact, Fiction and Forecast (Cambridge, Massa chusetts: Harvard University Press, 1955). 13 Robert C. Stalnaker, "A Theory of Conditionals," in Studies in Logi cal Theory, ed. Nicholas Rescher (Oxford: Blackwell, 1968).</page><page sequence="6">574 JOHN WOODS AND DOUGLAS WALTON so would B be the case." No, W* must not just be an alternative to W and must not be similar in certain respects; it must be radically similar, differing only in ways having to do with the truth there of the antecedent, A. Thus the theoretical force of "is a world similar, in the theoretically relevant respects, to W" is that the alternative universe not be hostile to causal correlations, that is, that W* be a causally lawful world. So, one is here at the brink of circularity. A law of nature backs its corresponding subjunctive conditional; a subjunctive conditional is true (in this world) whose consequent is true in a world in which the antecedent is true and which differs from our world in no other way (except for what follows from the consequent's truth). Yet such a world is a world of natural laws. Still, the intuition of causal lawfulness is powerful. Perhaps a better analytic expression of it lies elsewhere, in what some writers call the necessity in nature approach:14 x caused y if, and only if, N(l) y did not precede x N(2) # is a complex of events each component xt of which is logi cally necessary for y and xx\Jx2^J . . . xn = x is logically suffi cient for y. But here, too, the problem of simultaneous causation recurs. What is more, there is room for thinking, even if causation does amount to necessary correlation in nature, that logical entailment overexpresses the idea; entailment is just a shade too necessary for causal comfort. Better, then, that we seek a more moderate expression of causal necessity. Burks, indeed, is the classical source. In his causal logic, to which we return below, Burks develops a modal approach, a principal difference of which from the previous approaches is that it is a causally familial analysis. The primitive notion in Burks' analysis is the modality causal necessity, already an idiom of the causal family. It arises by definition that x causes y if and only if the material implication of x by y is causally necessary, where x and y are sentence variables. A principal point about the logic of causal necessity is 14 See, for example, A. C. Ewing, The Fundamental Questions of Philosophy (New York: The Macmillan Co., 1951), Brand Blanshard, Reason and Analysis (LaSalle, Illinois: Open Court, 1962), and Milton Fisk, Nature and Necessity: An Essay in Physical Ontology (Bloomington, Indiana: Indiana University Press, 1974).</page><page sequence="7">POST HOC, ERGO PROPTER HOC 575 precisely that it is weaker than logical necessity. In some versions of it,15 Burks gives a partial expression of this feature by means of the axiom: of which the converse does not obtain. This quickly gives rise to trouble, however; putting "pDp" for &lt;f&gt;, we have it that "D(pDp)" obtains and hence, by this axiom, that " E3 (p^p)" also obtains, and so that p causally implies p. Attributions causa sui are perhaps a trifle too Spinozistic for contemporary ears to compete for serious atten tion. If, in the natural necessity approach, causality is always a matter of logical necessity, then in modal approaches logical necessity is always causal necessity?kinships, in each case, not to be looked upon with favor. How, then, does one characterize this "pushiness" of causa tion? One writer, von Wright,16 among others,17 addresses the matter by means of the following anthropomorphic account. On this view, causation is paradigmatically a matter of someone making some thing happen. In one version characteristic of this position, x caused y if and only if A(l) y did not precede x A(2) someone, P, brought it about that x occurred, whereupon y ensued. Of course, causal attributions are not in fact confined exclusively to the domain of human intervention. It is necessary then that A(2) give way to a more appropriately expansive counterpart. One rea sonable-seeming prospect might be: A(2') Someone, P, had he brought it about that x occurred, there upon y would have occurred. Wherewith the anthropomorphic account defers, to a significant degree, to a subjunctivity account. Still, for all the unsettled state of their frontiers, certain causal intuitions remain relatively unscathed. 15 Arthur Burks, "The Logic of Causal Propositions," Mind, LX (1951), pp. 363-382. 16 G. H. von Wright, Explanation and Understanding (Ithaca, New York: Cornell University Press, 1971). 17 See, for example, a well-known paper by Gasking: Douglas Gasking, "Causation and Recipes," Mind, LXIV (1955), pp. 479-487.</page><page sequence="8">576 JOHN WOODS AND DOUGLAS WALTON Two states of affairs, then, could be said to stand to one another in the causal relation where: 1) the one state, the cause, does not temporally succeed the effect;18 2) cause and effect are reasonably proximate in space or time or both, (for example, often causation is triangulated with some physical process or relation); 3) taken together with a set of other (often unspecified or roughly specified) necessary conditions (none of which is individually sufficient) the cause consti tutes a sufficient condition of the occurrence of the effect for appro priately qualified senses of "necessity" and "sufficiency";19 4) the cause is isolable from the other necessary conditions in the sufficient set by pragmatic criteria having to do with ease of practical manipulation (this involves the question of "pragmatic relevance").20 An extensive new analysis of the causal relation is to be found in recent work by Burks.21 This analysis is given in two parts. First, the formal properties of causal necessity are given by a modal logic of a statement-operator. This logic is presented as an algorithmic struc ture and applied as a model of ordinary and scientific causal discourse. Syntactic structure for the causal modalities is given by Burks through decision algorithms, and an abstract interpretation for the language is yielded by simple modal models. Secondly, a concrete interpretation of the language is given by treating the logic of causal statements as a model of natural language. Non-probabilistic theo retical laws of nature are treated as causally necessary. Some im 18 For a discussion of so-called "simultaneous causation," see Burks, Cause, Chance, and Reason, 7.4.1, and J. L. Mackie, "The Direction of Causation," Philosophical Review, LXXV (1966), pp. 441-466. 19 With a view to greater exactitude than we here venture, Mackie has characterized a cause as a condition that is "an insufficient but necessary part of a condition which is itself unnecessary but sufficient for the result." (J. L. Mackie, "Causes and Conditions," American Philosophical Quarterly, [1965], pp. 245-264, andThe Cement of the Universe [Oxford: The Clarendon Press, 1974], p. 62.) Thus the acronym, "INUS condition." Suppes has given a set-theoretic definition of this concept in terms of probabilities. In general, Suppes has worked out various minimal probabilistic causal algebras that go some way towards meeting the general conditions we have laid down as characterizing the notion of cause, and the reader who desires a more specific account of the causal relation might consult this excellent work. (Cf., Suppes, loc cit.) 20 We will not attempt to isolate these "Pragmatic" factors here. The sort of parameters we have in mind are those discussed at length by H. L. A. Hart and A. M. Honor? in Causation in the Law (London: Oxford University Press, 1969). Gasking, loc. cit., is also helpful in this connection. 21 Burks, "The Logic of Causal Propositions," and Cause, Chance, and Reason.</page><page sequence="9">POST HOC, ERGO PROPTER HOC 577 portant features of causal laws are modelled by means of a relation called by Burks "non-paradoxical causal implication" (npc), defined in terms of causal implication as follows: &lt;/&gt; non-paradoxically causally implies tp if and only if &lt;/&gt; causally implies W, and &lt;j&gt; is logically independent of "9, and &lt;/&gt; is causally possible, and "9 is not causally necessary. This definition drives a wedge between the causal and logical modalities (1) by requiring that the antecedent and consequent of a causal law be logically independent, and (2) by excluding the paradoxes of logical implication and the corresponding paradoxes of causal implication.22 Next, Burks defines a relation of elliptical causal implication (ec) in terms of npc, as follows: 9 elliptically causally implies 6 if and only if there is a true statement (f&gt; that causally implies 0 when conjoined to 9. Readers can now begin to see how Burks' relation of elliptical causal implication adumbrates the intuitive notion of causation sketched above. Burks sets out some basic theorems and properties of these causal relations, and causal notions are extended into inductive con texts in considerable detail, but we shall not outline these matters further here. In general, we shall follow Burks' analysis of the causal rela tion where exact specification of the causal idiom is called for, although most of what we have to say at this stage may informally be couched in the intuitive notion of "cause" set out above. We intend our analysis of the post hoc to coincide with Burks' treatment of causa tion, however. In fact, we look upon our excursus into the post hoc as a potentially interesting application of Burks' causal logic.23 This is not to imply that Burks' system is trouble-free, or the only source of sound analytical counsel. Recent attempts of a sys tematic type, helpfully chronicled by Domotor,24 show that some inter esting work is currently in progress, although results are rather austere and heterogeneous. Few of us are under any illusions about the dif 22 Cause, Chance, and Reason, 6.6 vide (14a) through (15f). 23 Another interesting approach is that of David Lewis, see "Causation," The Journal of Philosophy, LXX (1973), pp. 556-567. This essay is re printed in Causation and Conditionals, ed. Ernest Sosa (London: Oxford University Press, 1975), pp. 180-191. 24 Zoltan Domotor, "Causal Models and Space-Time Geometries," in Space, Time and Geometry, ed. Patrick Suppes (Dordrecht: Reidel, 1973), pp. 1-55.</page><page sequence="10">578 JOHN WOODS AND DOUGLAS WALTON ficulty of the general problem. One new approach, which we shall mention briefly because it seems to us to show special promise, takes as a basis a propositional calculus with classical negation and con junction but utilizes an essentially relational disjunction and condi tional. This is a system designed principally by R. L. Epstein and R. I. Goldblatt25 (in a group project at the Victoria University of Wellington during 1975-76) to provide a more flexible approach to conditional expressions. The early motivation for this approach was some work of Douglas Walton on the logical form of action ex pressions. The system proceeds by adding to the semantics of classi cal PC a relation in propositional variables, r(Pb Pj). r is thought of as expressing a notion o? semantic relatedness, and is symmetric and reflexive, but not (initially, at least) transitive. The "truth table" for -&gt;, the relatedness conditional connective, is set up in such a way that Pi ?&gt; Pj is classical if and only if Pt bears the relation r to Pj. The system closely resembles classical PC, retaining modus ponens and many of the usual theorems?certainly this is one reason why it is so interesting?but it notably lacks the rule of addition (Pi -* (Pj v Pj)), importation ((Pj -&gt; (Pj -* Pk)) -? ((Pj A Pj) -* Pk)), and the De Morgan Equivalences. Disjunctive syllogism is, how ever, preserved. A set of axioms has been given, completeness shown for them, and the system has been extended to include quanti fiers. An advantage of this approach is that it allows us to vary the conditions on r, thus yielding up a more flexible approach to conditionals, and so it provides a new basis for extending condi tionals in the direction of causal contexts. Now somewhat more precisely characterized, we can see how the causal relation gives us at least a tentative basis for proceeding, despite the causal skeptic who argues that causation is an intrin sically incoherent notion. Russell, for example, once argued that the concept of cause is intrinsically unclear and ought to be excluded from the language of science altogether.26 Russell claimed that 25 Monograph in progress. Relatedness semantics arose through the contributions of a number of participants in the Logic Seminar of Victoria University of Wellington and might best be called "Victoria Semantics" or "the Victoria Group Semantics." Material may be obtained by writing Dr. R. L. Epstein, Department of Mathematics, Victoria University of Welling ton, New Zealand. 26 Bertrand Russell, "On the Notion of Cause," Proceedings of the Aristotelian Society, XIII (1913), pp. 1-26. Reprinted in Mysticism and Logic (London: Longmans Green, 1918), pp. 180-208.</page><page sequence="11">POST HOC, ERGO PROPTER HOC 579 "causation" is a term belonging to our "metaphysical" heritage and that it expresses no scientifically useful concept. Scientists, in then more technical moments, at any rate, talk about correlations and functions, but this is not, perhaps, more true, if it is true at all, in the theoretical27 than in the applied areas of science. In these latter areas, causal terms are a familiar and accepted part of the language. This is so because in the applied sciences there are inarticulable elements of background information that are necessary to account for in making rational decisions and predictions. It is the presence of such inarticulable bodies of information in applied scientific ex planations that makes for the particular utility of the concept of causa tion. We shall see this factor reflected in the causal fallacies time and time again. It is specifically recognized in adequacy con dition (3) above. It would seem, in fact, that Russell, conflating the notion of cause with notions such as function, has himself committed a kind of fallacy in blurring the distinction between evidence for causation and causation itself. The urge to commit this fallacy is perfectly understandable in severely abstract theoretical contexts, where causation is not regarded as an essentially practical concept. But once we adopt the latter point of view, the common distinction made by statisticians between cause and function defies conflation. The mathematician is interested in functional relationships for their own sake. But he is also interested in them practically since very often these functional relationships form a good enough approxima tion to practical cases. . . . The thing to be clear about ... is that a functional relationship in mathematics means an exact and pre dictable relationship, with no ifs or buts about it.28 Causal relationships, on the contrary, always have "ifs" and "buts" attached. Herein lies their special value. Thus Russell's point, more soberly interpreted, would seem to be this: the more ab stractly mathematical one's scientific pursuits, the less easy it is to find obvious among the concepts there dealt with any close recon struction of everyday causation. But this is a far cry from saying that modern physics has expunged causation from its repertoire of relations. 27 But see also Suppes' demurrer, op. cit., p. 5. 28 M. J. Moroney, Facts from Figures, 3rd ed., (Harmondsworth, England: Penguin Books, 1956), p. 275.</page><page sequence="12">580 JOHN WOODS AND DOUGLAS WALTON III One might be tempted to conjecture that the fallacy o? post hoc has the following form: (A8) There is a positive correlation between &lt;f&gt; and 9. Therefore (f&gt; causes 9.29 The difficulty, of course, is that this form of argument may, so far as it goes, be inductively correct, for even a single instance of posi tive correlation may, in the total absence of contravening informa tion, be some (not to say very impressive) evidence of causation. In a way, this factor is the albatross of the formal analysis of the post hoc. Ceteris paribus, a correlation is sometimes perfectly good, if minimal, evidence of the existence of a causal connection.30 How ever, we think that a more perspicuous characterization of the fal lacy involves the spurious inflation of the evidential value of the correlation owing to the suppressing or failing to take into account other causally relevant factors of various kinds. To the extent that such causally relevant factors, of the kinds we shall examine, can tentatively be characterized under standardized headings, we suggest that any correct inductive argument from correlation to causation, requires five premise-types, as represented by the following scheme: (PI) There is a positive correlation between &lt;/&gt; and 0. (P2) It is not the case that 0 causes &lt;f&gt;. (P3) It is not the case that there is a third factor, 9, that causes both &lt;f&gt; and 0 where &lt;f&gt; does not cause 9. (P4) There are no relevant instances of &lt;/&gt;-and-not-0. (P5) (f) is pragmatically relevant. Therefore, &lt;t&gt; causes 0. Here, then, is a total of five independent kinds of conditions, represented by (PI) to (P5), against which a claim of causation should 29 Something like this claim often appears in introductory logic texts. Hamblin cites one (op. cit., p. 37), but we shall not attempt to make a list of likely culprits, since the attractiveness of the notion is obvious enough. 30 See the discussion in Hamblin, p. 37f. We might add here that care is needed in making general pronouncements of this kind about causation and correlation. For example, it might seem reasonable to hazard the conjec ture that positive correlation always has some causal evidential power, other factors being held in abeyance. But consider the positive correlation between the stork population and (human) birth rate in an English village. Most of us would think it unlikely that this correlation indicates or even suggests a causal connection. See also note 48.</page><page sequence="13">POST HOC, ERGO PROPTER HOC 581 be tested.31 This suggests that we characterize the fallacy o? post hoc as involving the spurious argument from (PI) to the conclusion by sup pressing one or more of (P2) to (P5). Accordingly, we may distinguish four gross varieties of the post hoc, depending on which of (P2), (P3), (P4), or (P5) is suppressed. We develop this perspective in Sec tion IV. Other ways of expressing something interestingly close to the structure of the post hoc also suggest themselves. For example, Reichenbach ordered events on a world line ("genidentity chain" or "causal chain") by a relation o? approximate spatiotemporal coinci dence.32 Accordingly, one might make use of some such relation to characterize inferences of the following form: (B8) (j) is approximately spatiotemporally coincident with 0. There fore, &lt;/&gt; causes 0. Now such an inference would be invalid within Reichenbach's theory, since other requirements, such as the local comparability of time order and possible connectedness are needed as additional premises. Alternatively, the latter notion of connectibility is defined by Berger33 as a binary symmetric and reflexive relation K of causal connectibility defined on a four-dimensional differentiable manifold. Ensuing from this could be yet another plausible model of post hoc reasoning. (C8) &lt;j&gt; is causally connectible with 0. Therefore, &lt;/&gt; causes 0. For, as Berger points out,34 the claim is that K (&lt;/&gt;, 0) conveys no information about the point (&lt;f&gt; or 0) at which the later (or earlier) event must occur for &lt;j&gt; and 0 to be actually causally related. So understood, the logical blunder would be a modal fallacy of argu ing from possibility to actuality. Space does not permit an attempt here to mesh the frame works suggested above with that of the previous paragraph. Rather, 31 We waive any claim that these five premises constitute a sufficient condition for inductive correctness of this land of causal argument. Our thesis is that each of them is a necessary condition for correctness of this form of argument. 32 For an explanation of these terms, see Bas C. van Fraassen, An Introduction to the Philosophy of Time and Space (New York: Random House, 1970), pp. 176ff. 33 George Berger, "Temporally Symmetric Causal Relations in Minkow ski Space-Time," in Space, Time and Geometry, pp. 56-71. 34 See Berger, op. cit., p. 56.</page><page sequence="14">582 JOHN WOODS AND DOUGLAS WALTON we leave this for the time being as an open problem in the theory of the post hoc. One qualification: we shall, by and large, limit ourselves for ease of exposition to cases where causes or effects are thought of as individual dateable events, &lt;?&gt;, "9, and 0. It is well known that causal language is ambiguous in its capacity to range over "generic events" as the relata of the causal relation. It is often said, for example, that smoking causes cancer (generally) in a manner indicating that no dateable, particular instance of smoking or cancer is exclusively being referred to. Our treatment will not be specifically addressed to these cases; although it is to be hoped that our analysis might usefully be extended in this direction after the method of Burks, it is not a project we attempt here. Our preoccupation will be with singular causal statements rather than causal laws. Norman Swartz has pointed out to us that the scheme repre sented by (PI) to (P5) is more accurately seen as two different causal paradigms, one of which ought to be stated in terms of probability values and the others in the language of correlation coefficients. Readers uninterested in the niceties of form might pass on to Sec tion IV immediately, but for those who require a more exact ap proach to the analysis, we here indicate briefly how our scheme should really be thought of as two schemes, or at least two variants of one superscheme. The first case is that where two variables vary together over a range of values ((PI) is supposed to capture this case), and second, the case where the two variables can take on only binary values ((P2) would cater to this case). An in stance of the first would be plumbing the relationship between the percentage of voter registration in a city and voter turn-out on elec tion day; each variable can take on values between 0 and 1. An instance of the latter would be the ingestion of arsenic (values 0 or 1) and death (again values 0 or 1). Now there may be no cases in which ingestion of arsenic is not followed by death shortly thereafter; we suspect that there is a causal relation here. But if we examine the correlation between the whole series of arsenic-takings over a large population we will get some thing like "0, 0, 0, 0, 0, 1, 0, . . . 0"; the corresponding values for death will be "1, 0, 0, 1, 0, 1, 0, . . . 0." Here we will get a high correlation between the two series, just because there are so many zeroes in the first series and so many zeroes in the second (or, to put it another way, almost all persons who are alive today, will be alive tomorrow). The correlation, however, seems</page><page sequence="15">POST HOC, ERGO PROPTER HOC 583 to be spurious in establishing the hypothesis that ingestion of arsenic causes death. In short, when we are looking at discrete events (binary values) we ought not to be invoking correlation coef ficients. In the latter cases we ought to be looking at probability figures: what is the probability of the ingestion of arsenic being followed by death? Or, what is the relative frequency of death among the class of arsenic users? Since, for one thing, Probability (A, B) need not equal Probability (B, A) while Correlation (A, B) does equal Correlation (B, A), we need to distinguish between the two types of cases generally. And for discrete events, it seems that we shall want to put our scheme in terms of probability values rather than correlation coefficients. Thus, a more precise statement of the scheme represented by (P1)-(P5) would involve two parallel sets of condition depending on whether the variables are continuous or binary. We now turn to a review of the practicalities of the post hoc as a real-life error of argumentation in order to provide substantiation and application of our schematic analysis. In the next section, we deal with some actual instances of argumentative deficiencies often asso ciated with post hoc reasoning. IV It is possible to distinguish within traditional treatments of informal fallacies at least seven significantly distinct causal fallacies, some of which have sometimes been classed under such standard headings as post hoc ergo propter hoc, non causa pro causa, secundum quid, false cause, and the like. We here present a quick sketch of the main thrust of each of these seven sophisms, in each case offering at least one concrete example. The object in each case is to plumb the example in question for the essential wrongfulness of the fallacy it illustrates. 1. Concluding that ^9 was caused by (frjust because ^9 temporally followed (f&gt;. A stock example: (Al) I took a dose of Sinus Blast and a couple of days later my cold cleared right up. The suggested conclusion, namely that taking Sinus Blast caused the cold to disappear, is fallacious: it may be counterclaimed that the cold may well have disappeared just when it did or perhaps even</page><page sequence="16">584 JOHN WOODS AND DOUGLAS WALTON sooner if Sinus Blast had not been taken. A second specimen is exemplified in the behavior of a passenger on board the doomed Italian liner, Andrea Doria. (A2) On the fatal night of Doria's collision with the Swedish ship Grisholm, off Nantucket in 1956, the lady retired to her cabin and flicked the light switch. Suddenly there was a great crash, and grinding metal, and passengers and crew ran screaming through the passageways. The lady burst from her cabin and explained to the first person in sight that she must have set the ship's emergency brake.35 Quite clearly, attributions of a causal connection from a single in stance of a given simple sequence of events greatly risk a fallacy. Single instances have a way of being coincidences. 2. Concluding that *9 was caused by &lt;j&gt;just because there was a positive correlation between some previous instances of &lt;f&gt; and in stances of "9. A stock example: (A3) Near perfect correlations exist between the death rate in Hyder bad, India, from 1911 to 1919, and variations in the membership of the International Association of Machinists during the same period.36 In the absence of further evidence of a causal connection between these remote sets of data, concluding that one is the cause of the other would be absurd. While in certain circumstances a high positive correlation may be good evidence of a causal link, in this case "common sense" informs us that it is extremely unlikely that the two sets of phenomena are causally connected. 3. Reversing cause and effect. (A4) The people of New Hebrides have observed, perfectly accurately, over the centuries, that people in good health have body lice and people not in good health do not. They conclude that lice make a man healthy.37 A little further observation reveals that, whereas lice were the norm among this people, when anyone took a fever and his body became too warm for comfortable habitation, the lice departed. Insofar as there is a causal relation between the lice and good health, the above conclusion reverses cause and effect. The causal relation is non symmetrical; an additional inference would be required to establish 35 David Hacket Fischer, Historian's Fallacies (New York: Harper &amp; Row, 1970), p. 166. 36 Harold L. Larabee, Reliable Knowledge (Boston, 1954), p. 368. 37 Darrell Huff, How to Lie with Statistics (New York: Norton, 1954), p. 98.</page><page sequence="17">POST HOC, ERGO PROPTER HOC 585 which correlate might be the cause of the other. As Huff points out,38 commonly there is a genuine causal relation where it is not evi dent which of a pair of correlates is the cause and which the effect, e.g., the correlation between income and ownership of stocks. Social science methodologists have used the techniques of par tial correlation analysis39 and path analysis40 in identifying errors of causal inference. The types of errors recognized by these methods tend to correspond to the categories of fallacies we are here dis cussing. In particular, a Type D error is defined by Deegan41 as one which occurs when all the variables in a true model are utilized but where a true independent variable is hypothesized to be depend ent, or conversely. The conditions under which this kind of error can arise are: 1) when the theory fails adequately to prescribe the temporal sequence of events or actions; 2) when an investigator fails to grasp the technical requirements of the inquiry; or 3) when the system is assumed to be closed and the analyst chooses as the "correct" model the causal sequence that explains the largest proportion of variance. 4. Concluding that &lt;/&gt; is the cause of 0 when both are the effects of a third factor, ^9. A correlation between &lt;/&gt; and 0 may be indicative not of a causal relation between &lt;?&gt; and 0, 0^0 but of some third factor that causes both &lt;/&gt; and 0, thus account ing for the correlation, A 38 Huff, op. cit., p. 89. 39 H. A. Simon, "Spurious Correlation: A Causal Interpretation," Journal of the American Statistical Association, XLIX (1954), pp. 467 492. H. M. Blalock Jr., "Correlation and Causality: The Multivariate Case," Social Forces, XXXIX (1961), pp. 246-251. 40 David R. Heise, "Problems in Path Analysis and Causal Inferences," Sociological Methodology, Chapter 2 (San Francisco: Josey-Bass, 1969). Sewall Wright, "The Method of Path Coefficients," Annals of Mathematical Statistics, V (1934), pp. 161-215. 41 John Deegan, Jr., "Specification Error in Causal Models," Social Science Research, III (1974), pp. 235-259.</page><page sequence="18">586 JOHN WOODS AND DOUGLAS WALTON The latter state of affairs is called a spurious correlation, and it contrasts with the deceptively similar situation where ? is an inter vening variable between &lt;/&gt; and 0 &lt;/&gt;-^^^0 allowing a genuine causal relation to obtain between &lt;f) and 0.42 In both cases we have ^^0 The defining feature of spurious correlation is that &lt;/&gt; does not cause ^9, although the converse obtains. Two examples will make the contrast clear.43 Example 1: In a survey on factory absenteeism it was found that married women had a higher rate of absenteeism than single women. Later it was found that the absenteeism rate among married women was almost as small as that of single women if both have little or no housework, and that absenteeism among single women was almost as great as that of married women if they too have a great deal of housework. A further survey showed that, as one would expect, married women generally had more housework. We could correctly conclude: getting married -? more absenteeism. But a more complete explanation may be found in the intervening factor of housework: getting married -? more housework -&gt; more absenteeism. Here we have a genuine causal relation mediated by a third factor. Example 2: it was found that married persons ate less candy than single persons. A second look at the data showed that if married and single persons of equal age are compared, the correlation between marital status and candy consumption disappears. Here it would be misleading and incorrect to conclude: getting married -? eating less candy. 42 Providing the causal relation is transitive. Suppes' discussion shows that the assumption of transitivity is questionable. Refusal to grant the assumption will require some modification of the view of intervening causes proposed above. See Cause, Chance and Reason, 3.3. 43 Hans Zeisel, Say it with Figures, 5th ed. (New York: Harper &amp; Row, 1968) Chapter 9. See also H. A. Simon, "Spurious Correlation: A Causal Interpretation," Journal of the American Statistical Association, XLIX (1954), pp. 467-492.</page><page sequence="19">POST HOC, ERGO PROPTER HOC 587 The correct conclusion is that getting older is the operative factor in both increased likelihood of marriage and decreased candy con sumption. Thus: getting older getting married eating less candy. The critical distinction between this case and the previous example is that here it is incorrect to conclude: getting married -? getting older. If we could prevent people from getting married this would still not stop them from getting older. But conversely the causal relation may obtain because if we would stop people from getting older, this would presumably have the effect of reducing the incidence of marriage. It is also interesting to note that even in the case of intermediate causation: &lt;/&gt;-&gt;^-&gt;0 a fallacy can arise through omission of or addition of intermediate factors and through consequent mischaracterization of the nature of the causal relation between &lt;?&gt; and 0. Take the case of Mr. X who, while driving in traffic, repeatedly observes that whenever he applies the brakes, the defroster fan squeaks. He concludes that the brakes are connected to the fan. A more mechanically sophisticated ob server might infer that application of the brakes causes deceleration of the vehicle and tilting of the fan mechanism, which in turn causes the squeak. It is especially revealing to note, as Zeisel44 points out in his analysis of the candy and housework examples, that the final test of the merit of the distinction between the two cases is an essen tially practical matter. If a factory manager were to institute the policy of discouraging female employees from marrying, this policy would effectively tend to reduce absenteeism. Remaining single means less housework and less housework means less absenteeism. But suppose a candy manufacturer were to succeed in discouraging large numbers of people from marrying. Would this lead to an in crease of candy consumption? Clearly not. Keeping people younger 44 Zeisel, op. cit., p. 88.</page><page sequence="20">588 JOHN WOODS AND DOUGLAS WALTON would have the desired effect, but preventing them from getting married would not keep them from getting older. Thus, ultimately, the distinction between "true" and "spurious" causation rests on the practical question of whether &lt;?&gt; is a practically necessary condition of 0. If I stop &lt;/&gt; will 0 stop too? Or can I only stop both &lt;/&gt; and 0 through "9, a third factor? The fallacy in question arises in confusing the two cases below. (1) "9 (2) "9 A (?) 0 &lt;/&gt; 0 intervening variable antecedent mutual cause The result of the confusion is a mistaken equation of the correct inference, (1*) with the incorrect inference on the right, (2*). (1*) ^ (2*) "9 A A 01-&gt;0 (?)\-&gt;0 correct incorrect (1*) is correct, provided the causal relation is transitive. (2*) is in correct: (2*) may, though fallacious, seem correct because the illicit assumption of symmetry of the causal relation, Therefore, &lt;?&gt; -&gt; "9 creates the suggestion of an equivalence with (1*). What distin guishes the fallacious (2*) from the correct (1*) is that [$ ?&gt; "9] fails in the former, but not in the latter. 5. Confusing causation and resemblance. David Hacket Fischer offers a vivid example of this fallacy.45 (A5) The Picts constructed brochs and souterrains that were small, dark, and mysterious. Therefore the Picts themselves were small, dark, and mysterious. The fallacy seems to form the basis of many traditional folk remedies, e.g., that a bloodstone will stop bleeding. A 45 Fischer, op. cit., p. 177.</page><page sequence="21">POST HOC, ERGO PROPTER HOC 589 6. Citing a pragmatically otiose necessary condition. Example: (A6) Smith drowned because he did not learn to swim when he was young. Hence, the causal attribution strikes the ear as far-fetched. Gen erally one would be more interested in more immediate factors, more at hand to possible reversal and more proximately previous to the drowning. However, in a context of a coach's presentation of the benefits of swimming lessons, the causal claim above might not appear quite so remote. Again, causal "talk" is strongly linked to practical production and prevention. Thus, it can be true that &lt;/&gt; is genuinely a necessary condition of V, yet, nonetheless, be a fallacy to conclude that &lt;f&gt; caused ^, where control of (/&gt; is impractical, irrelevant, or impossible. 7. Overlooking or suppressing information that may run coun ter to the apparent trend of the correlation. Example: (A7) It is easy to show by figures that the more it rains in an area, the taller and better the wheat grows. Conclusion: rain is good for the crops. The problem here is that the positive correlation holds up to a point beyond which it takes on a negative significance.46 The fallacy is reminiscent of the familiar abuse of sampling theory in which an unrepresentative sample is selected. An instance of r&lt;/&gt; &amp; ~ ^P1 can overturn a causal allegation of r&lt;?&gt; -? y91; negative correlations must also be considered. Or, as Mill would have put it, the method of agreement needs to be supplemented by the method of difference. V The structure of Section III can be integrated with the sophisms of Section IV in a way that plausibly displays a set of covering rela tionships between premise (PI) and sophism (1) and (2), premise (P2) and sophism (3), (P3) and (4), (P4) and (7), and (P5) and (6). Some discussion of those matchings is now in order. (We omit treatment of (5). Although it is a kind of causal fallacy, we do not regard it as 46 See Huff, op. cit., p. 91.</page><page sequence="22">590 JOHN WOODS AND DOUGLAS WALTON essential to post hoc, but rather as a kind of fallacy of resemblance or analogy.) It is also interesting to note that in (1) and (2) we rejected 4&gt; as a cause of 0, because if 4&gt; had not occurred we believe that 0 might (or would) have occurred anyway. A counterfactual analysis, after the fashion of Lewis,47 might therefore restructure (P4) to read: if (?&gt; were not to obtain then 0 would also not obtain. Our analysis of the post hoc could be adapted to the counterfactual treatment of Lewis', much in the way it was adapted to Burks' analysis, but we do not pursue the point here. Concerning the second premise, (P2) cannot be established without considering an independent correct inductive causal argu ment. In practice, statistics texts often establish (P2) by appealing to the temporal precedence of 4&gt; to 0, or by citing "common sense." It seems to us more realistic explicitly to use the term "cause" in (P2) (and thereby frankly acknowledge that the analysis may be circu lar, or only partially definable, perhaps by appeal to a recursive structure), rather than to try to state a non-causal (P2) that will probably turn out to be inadequate. As elsewhere, however, we wish to avoid causal dogmatism, so we do not exclude this possibility entirely, and commend the problem, along with others we have suggested, as important for further research. A consideration brought to our attention by David Loewen sug gests that the set of premises (P1)-(P5), given the broad conception of causation we began with, may be essentially incomplete, for there may be a situation in which (P1)-(P5) obtain yet in which the causal relation is not warranted. Consider a case of what seems to be a per fectly fortuitous positive correlation such as that between the stork population and the (human) birth rate in a given area. Here (P2) to (P5) may be satisfied, yet we might nevertheless be quite reluctant to presume a causal connection between the storks and the babies.48 It would be premature and ill-advised seriously to entertain any claims of completeness for our analysis of the broad, intuitive notion of causation met with in the opening sections of this paper. Even 47 See note 16. 48 Dick Epstein points out, however, that the storks case may be sus ceptible to analysis as violating (P3). See the discussion in Stephen K. Campbell, Flaws and Fallacies in Statistical Thinking (Englewood Cliffs: Prentice-Hall, 1974), pp. 173ff.</page><page sequence="23">POST HOC, ERGO PROPTER HOC 591 so, perhaps the case of the storks is defeated by the parameters of "pragmatic relevance" cited by (P5). However, since we are not in a position to give an analysis of these factors in any rigorous way, such claims or counterclaims of completeness are best held in abeyance. Both Lewis and Burks also set these apparently slippery questions aside in attempting to deal with the somewhat better behaved core of causality represented roughly by (PI) to (P4), and we shall content ourselves with a kindred diffidence here. VI We have attempted, in Sections III, IV, and V, to say some thing helpful about post hoc from a point of view of the applied logic of the informal fallacies, but without attempting a full-scale anal ysis of the causal relation intuitively adumbrated in Section II. Nevertheless, in describing the fallacy of post hoc as an invalid, incorrect, or deficient argument that deviates from the correct form postulated in Section III, our point is clearly parasitic on some theory of correct causal argument. We, therefore, conclude with some general remarks concerning the relation between our findings here and the larger project. We are inclined to think of a causal argument after the fashion of Burks (Cause, Chance, and Reason, 10.3.2), by way of causal model of standard inductive logic constructed from causal cellular automata.49 The form of a possible causal law is: (L) For all cells and for all times, the occurrence of property &lt;f&gt; in region N(c) at t causes the occurrence of property 9 in cell C at t1. The causal universal (L) deductively implies a corresponding mate rial universal, (U) For all cells and for all times if (?&gt; occurs in region N(c) then 9 occurs in cell c{ at t + 1 (with "if then" here expressing material implication). The material universal, in turn, deductively implies the instance statement, (I) If 0 occurs in region N(Cj) then 9 occurs in cell Ci at t + 1, for each cell-moment (cb ti). 49 Lewis' approach is also based on modal logic, but makes use of a notion of comparative similarity that takes it beyond the framework of Burks.</page><page sequence="24">592 JOHN WOODS AND DOUGLAS WALTON Two argumentative relations that could obtain between I and L are as follows: If I is false then L is false, since L deductively implies I. This is the case of direct refutation. If we were to take up one elementary notion of confirmation, one by which A affords a measure of confirmation to B when the conditional probability, A given B, is greater than the prior probability of A alone then we can see that (P!)-(P5) bears such a relation to the causal conclusion of our scheme. Elsewhere,50 we have tried to show how such a con firmation relation (we call it befortification) can be used to convey a notion of "correct argument" appropriate to the study of the kinds of arguments open to the informal fallacies. Remarks, here, are confined to indicating in only a programmatic way what sorts of theo retical resources might be brought to bear in deepening the analysis of the post hoc. One final foundational comment: we are coming to think that a relatedness semantics has advantages over approaches such as Burks', based as they are on the classical material conditional for PC. Not only does the relatedness method offer greater flexibility, but it avoids the paradoxes in a more natural way. Moreover, as David Lewis has suggested,51 the relation r may be thought of as an assignment to sentences of subject matters such that sentences are related if and only if their subject matter overlaps. We might then think of r as expressing "semantic relatedness." But we would also suggest that r could equally well be thought of as modelling the notion of "spatiotemporal coincidence" or even "causal connectibility," met with earlier, thus giving rise to a practical new application of relatedness semantics to the causal idiom. We reject the thesis, often ventured in the social sciences, that causal arguments are fallacious as such. We suggest instead that certain specific violations of causal reasoning can helpfully be for mulated, and integrated in a theoretically unified approach to the post hoc. To be sure, our analysis is only a start and depends di rectly on the assumption that causal language is coherent and open to logical analysis. The efforts of Suppes, Burks, Lewis, 50 See our article, "Towards a Theory of Argument," Metaphilosophy, forthcoming. Our relation of befortification is intriguingly close to Suppes' concept of prima facie cause. The analogy is brought out particularly clearly by the discussion in Domotor, op. cit., pp. 14ff (see note 17). 51 In a talk given to the Logic Seminar, July 18, 1975, at Victoria Uni versity of Wellington, New Zealand.</page><page sequence="25">POST HOC, ERGO PROPTER HOC 593 Domotor, the Victoria Group, and others to develop various elements of a theory of causality within modal, algebraic, and inductive frame works give us some reassurance, and we are moved to suggest that much of the reluctance to speak of causes stems from an assumption that the causal relation is totally deterministic, that is, from (what we think is a fallacy) a conflation of causation with something like logical entailment.52 A logically adequate essentially probabilistic explica tion of causal language should be welcomed by social scientists as a useful theoretical adjunct to experimental design and data processing techniques. A more pressing need is the advancement of the study of informal fallacies beyond the inchoations and banalities of "The Standard Treatment" offered in introductory logic texts.53 This is an area, crucially important to the pedagogy of logic and philosophy, that has been sadly understudied. Many of the stock examples have, remark ably, come down to us virtually intact from Aristotle. The tradi tional passing-on of unanalysed examples bereft of theory, accom panied by ad hoc systems of classification, has resulted in a body of lore that perpetrates rather more than it explicates the fallacies. Our analysis here is not the final word on the post hoc; we hope rather that it provides a systematic groundwork for the further exploration of causal fallacies.54 University of Calgary and University of Winnipeg. 52 See Douglas Walton, "The Contemporary Relevance of Hume's Remarks on Liberty and Necessity, Journal of Thought, VIII (1973), pp. 183-188. 53 See John Woods and Douglas Walton, uArgumentum ad Verecun diam," Philosophy and Rhetoric, VII (1974), pp. 135-153, uPetitio Principii;' Synthese, XXXI (1975), pp. 107-127, and "Ad Baculum," Gr?zer Philosophische Studien, forthcoming. 54 We should like to thank Professor Arthur Burks for furnishing us with a manuscript copy of his forthcoming book, Cause, Chance and Reason, to appear in 1977, published by the University of Chicago Press. We are grateful to David Loewen and Norman Swartz for comments, and Richard Epstein and Robert Goldblatt for helpful discussions of certain troublesome points.</page></plain_text>
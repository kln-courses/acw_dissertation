<plain_text><page sequence="1">letters to the editor' The Probability of Correct Climate Forecasts in the Absence of Any Forecasting Skill The central thesis of the extensive dialogue between D. V. Hoyt, R. M. Chervin, and T. W. Bettge in the October 1983 issue of the Bulletin is that spatial correlations somehow increase the expected value of skill of seasonal forecasts made from random selection of patterns from the population of "allowed" patterns. They argue that if this is the case, the real skills of seasonal prediction models are likely over stated because the "baseline" artificial skill of random forecasts has been underestimated. We will show that it is possible to underestimate this baseline random skill if careful attention is not paid to the definition of the predictand. However, the spatial correlation of the predictand has nothing to do with the expected value of this reference skill. The lengthy arguments to this effect in Hoyt (1983) and Chervin and Bettge (1983), while appealing, are incorrect. Baseline artificial skill is a function only of the probability distributions of the individual predictands whether they be for stations, gridpoints, climate di visions, or states. In fact, this skill is simply the average of the ex pected values of random forecast skill for the individual predictands. For example, if forecasts of equally likely terciles (below, near, and above normal) are made for different locations, and the class limits for these terciles are carefully defined from long enough records relatively free from anthropomorphic trends, then the expected percent of correct forecasts will be as close to 33.3 as the sample size and tercile estimation technique will allow. Any departures from this number will be a result only of properties of the individual time series, independent of cross correlations between time series. Suppose, for instance, a Gaussian distribution is used to define tercile class limits for each predictand. In this case the expected fraction of correct forecasts will depart substantially from 0.333 only for a) short series, or b) large departures from Gaussian behavior. In both cases, departures from 0.333 are a result of unequal frequencies of actual occurrence of the predictand in the three categories. Precipitation data (which are highly skewed) or data with strong trends cannot be well fit by a normal distribution. A preferred ap proach is to define tercile limits by fitting skewed probability distri butions or by ordering all the data in a time series from largest to smallest and noting the values that divide the list in thirds. With moderately sized samples expected skill will depart from 0.333 only in those situations where equal values of the predictand occur in ad jacent terciles. In order to illustrate some of the foregoing points and demon strate that prediction of only "allowed" patterns will not alter ex pected skill, we have conducted the following simple set of calcula tions: Gaussian distributions were fit separately for each season to 33 years (1950-1982) of seasonal mean temperatures at 109 stations uniformally distributed across the United States. Nine stations whose series least resembled a normal process were eliminated from ' This section of the Bulletin is made available to members who wish to express opinions about problems of concern to the AMS. (For guidelines followed in accepting letters, see "Minutes of the Council," Bulletin of the American Meteorological Society, 51, p. 40, f4; 51, p. 434, f 7.) The opinions expressed in "Letters to the Editor" are those of the writers and do not represent the official position of the American Meteorological Society. Bulletin American Meteorological Society consideration. For each remaining station i tercile limits were de fined for each season j from the fitted Gaussian distribution, and each year's seasonal mean temperature was classified below, near, or above normal (B, N, or A) according to these definitions (i.e., temperatures more than 0.4308 standard deviations below the sta tion mean were classified B, and so forth). In the notation of Chervin and Bettge the probability/&gt;,, of A,N, or B is simply Pi](X) = UX/33 X=A,N,otB. (1) Thus the probability of a correct forecast Pij(C) randomly chosen from this distribution is Pu(C) = [pv (A)]1 + [p.AN)]2 + [Pij(B)f. (2) This will exceed 0.333 according to the poorness of fit of the Gaussian distribution and the sampling error of the mean and standard deviation. The range of P,j( C) over all stations and seasons is 0.333 to 0.357. The expected probability of correct random forecasts for each sea son is then (again in the notation of Chervin and Bettge) 1 100 ^(0 = â€”E P,AC). (3) 100 ;= 1 These numbers for spring through winter respectively are 0.3411, 0.3397, 0.3399, and 0.3418. We now make "random" forecasts from "allowed" maps for each set of seasonal maps separately by scoring every map against every map (including itself). This is equivalent to using the 33 maps replicated an infinite number of times as an estimate of the population and then randomly drawing and matching a large number of pairs from this set. In this procedure all "forbidden" patterns are excluded as forecasts, because only observed patterns are used. The only constraint imposed is the one implied by the original definition of the terciles, namely that at every location the three terciles are equi-probable or as nearly so as the procedure allows. The average skills of these forecasts turn out to be exactly those predicted by (3) and listed in the previous paragraph. Moreover, the same kind of result (although numerically different and presumably closer to 0.333) would occur with 3300 years of data instead of 33. What then is the flaw in the elaborate arguments of Hoyt and Chervin and Bettge? In the former, strips with three boxes (locations) are envisaged that can be assigned equi-probable tercile forecasts A, N, and B. There are then 27 (i.e., 33)such patterns, and if they were all equi-probable, then A, N, and B would be equi-probable for each box. But Hoyt argues that only 17 of these patterns are "allowed" because the remaining 10, he claims, do not occur in practice. Ifall of these remain equi-probable the probabilities of A, N, and B become distorted; for example, they become 0.235, 0.53, 0.235 respectively for the middle box. Therefore, for every box to have equi-probable A, N, and B, some of the 17 allowed patterns must be more probable than others. Thus, the fundamental constraint in any Monte Carlo simulation of this problem is that A, N, and B remain equi-probable at every forecast location. Otherwise, equi-probable terciles are not the predictand. Hoyt instead conducts his Monte Carlo experiment with the constraint that the average total area of A,N, and B for forecast and 847</page><page sequence="2">848 Vol. 66, No. 7, July 1985 observed maps be equal. This is apparently done (details are not given) without regard to frequency of occurrence of A, N, and B location by location. It is easy to see how this might fail to preserve the assumed probability distributions locally. Chervin and Bettge were unable to resolve this last point with their analysis. They presented an equation similar in form to (2) but with subscripts removed and all terms erroneously referring to map totals. If this equation were correct, each term on the right-hand side would have to equal (0.333)2 and P(C) 0.333 with the constraint imposed by Hoyt in his experiment, namely that total forecasts and observations be equally distributed among A, N, and B. This contradicts Hoyt's result that P(C) = 0.355. The reason for this double paradox is that the correct equation for P(C) is actually (3), and the correct constraint for the Monte Carlo experiment, of course, is a local one. Although it is clear that spatial correlation has no effect on the expected value of random forecast skill, it certainly has an impact on the variability of this skill. For a given number of forecast locations the skill distribution broadens as cross correlation of locations increases (Livezey and Chen, 1983, discuss this phenomenon at length). As it broadens, the probability of any single skill exceeding some value in excess of 0.333 increases. Thus the question of "allowed" versus "forbidden" patterns is not totally academic. Unfortunately, here again Hoyt's discussion misleads. Consider again adjacent boxes in a strip. Hoyt argues that a B cannot occur next to an A. However, this entirely depends on the scale of the boxes and the location of their borders and is generally untrue. Inspection of seasonal temperature maps cast in terciles reveals numerous examples of transitions from A to B over relatively short distances on the order of a few hundred kilometers. If verification locations are spaced on a scale larger than the scale of these transitions (as they usually are), then the JVzone will frequently not be sampled. Hoyt further suggests that coast-to-coast A, B, or N are also "forbidden." Here once again he is wrong; the most recent example of this kind of pattern is the coast-to-coast tercile A across the northern half of the United States for the El Nino winter of 1982-83. In addition to the above points we take issue with Hoyt's con cluding assertion that the forecast models of Bryson (Dr. Reid Bryson of the University of Wisconsin) and the Old Farmer's Almanac "all obtain correct answers about 38-41% of the time." Verifications of the former by Harnack and Sammler (1982,1983) and corroborated by one of us (REL)and of the latter by Walsh and Allen (1981 ) indi cate that their skills are actually statistically indistinguishable from 0.333. As for the other forecast "models" mentioned by Hoyt of Namias (Dr. Jerome Namias of Scripps Institution of Oceanog raphy) and the National Weather Service, some of the difficulties in specifying tercile class limits alluded to above probably have led to slight inflations of significance of these skills. Nevertheless, these ef fects have been shown to be small (A. James Wagner, personal communication), and a considerable margin of skill remains after accounting for them. More importantly, this skill represents an av erage over all regions, seasons, and years, and for certain times of the year and certain areas, long-term skill has been zero or even nega tive, but for other large areas at other times of the year skill has been quite high. There is reason to believe that these areas and seasons of higher skill are not all statistical accidents (see the discussion in Kal nay and Livezey, 1985), making slight distortions of random forecast probability distributions of only minor interest. To conclude this letter, we would like to underscore the difficulties inherent in properly evaluating a set of marginally skillful forecasts. The methods of time series and multivariate analysis, coupled with a sense of the temporal and spatial properties of real climate data sets, are essential ingredients for an objective evaluation. The subtle na ture of some of the effects that have to be accounted for should be sufficient motivation for a reader to approach verification studies cautiously and critically. References Chervin, R. M., and T. W. Bettge, 1983: Response. Bull. Amer. Meteor, Soc., 64, 1173-1174. Harnack, R. P., and W. R. Sammler, 1983: Corrections and addi tions to verification study of performance of 1976 University of Wisconsin model. Bull. Amer. Meteor. Soc., 64, 611-613. , and , 1982: Performance of the 1976 University of Wis consin model for United States long-range forecasts made for 1976-80. Bull. Amer. Meteor. Soc., 63, 23-28. Hoyt, D. V., 1983: The probability of correct climate forecasts in the absence of any forecasting skill. Bull. Amer. Meteor. Soc., 64, 1172-1173. Kalnay, E., and R. Livezey, 1985: Weather predictability beyond a week: An introductory review. Turbulence and Predictability in Geophysical Fluid Dynamics and Climate Dynamics, M. Ghil, R. Benzi, and G. Parisi, Eds., North-Holland (in press). Livezey, R. E., and W. Y. Chen, 1983: Statistical field significance and its determination by Monte Carlo techniques. Mon. fVea. Rev., Ill, 46-59. Walsh, J. E., and D. Allen, 1981: Testing the Farmer's Almanac. Weatherwise, 34, 212-215. Anthony G. Barnston and Robert E. Livezey Climate Analysis Center, NMC, NWS, NOAA W/NMC51 Washington, DC 20233</page></plain_text>
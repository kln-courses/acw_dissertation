<plain_text><page sequence="1">Philosophia Reformata 58 (1993) 173-186 BEING HUMAN IN THE "INFORMATION SOCIETY" David Lyon With their methodical attention to detail, their tirelessness, their immunity to boredom, and their very high speed, all coupled now with reasoning power and information, machines are beginning to produce knowledge, often faster and better — "smarter" — than the human who taught them.1 By promising (or threatening) to replace man, the computer is giving us a new definition of man, as an "information processor," and of nature, as "information to be processed." It is not that we cannot live without computers, but that we will be different people because we live with them.2 Will the arrival and diffusion of new information technologies oblige us to revise our conception of what it means to be human? Do the above statements about the emerging relationships between people and machines point to significant social and existential realities? Will the coming of this so-called information society actually diminish our humanness in some way? Or will the new technologies give us such mastery over natural, political, and economic processes that we shall be able to realise in a fuller way our humanity? The trouble with so much of the debate in this field is that it is couched in the language of futurology or of abstract speculation. In this paper I try to relate the question of a "new view of humanness" to actual social processes. If computers and new communication technologies are really to redefine the modes of our human existence, then we have to look at concrete areas in which this takes place. After outlining the origins of the idea of computers as "defining technology" — and attempting to make this somewhat more sociological — I look at three areas of social life where the implications of information technology are strongly felt. They are, the workplace, education, and in communications. I draw some conclusions from these case studies, and make some proposals about appropriate responses. I ought to say right at the outset that I believe the concept of an "information society" is rather unsatisfactory.3 The idea is mistaken that the advanced societies are entering a phase of human existence which is quali tatively different from what has preceded it. Those who propose that such an epochal transformation is taking place usually have ideological axes to grind. 1 Edward A. Feigenbaum and Pamela McCorduck, The Fifth Generation: Artificial Intelligence and Japan's Computer Challenge to the World (London: Pan, 1984), p. 59. 2 David Bolter, Turing's Man: Western Culture in the Computer Age (London: Duckworth, 1984), pp. 13,10. 3 See my The Silicon Society (Tring: Lion/Grand Rapids: Eerdmans, 1986); "From Postindustrialism to Information Society: A New Social Transformation?" Sociology, 1986; The Information Society: Issues and Illusions (Cambridge: Polity Press, 1988); The Electronic Eye: The Rise of Surveillance Society (Cambridge UK: Polity Press, Minneapolis: University of Minnesota Press, 1994).</page><page sequence="2">174 D. LYON They tend (among other things) to minimise the continuing imbalance of power (between nations, social classes, ethnic groups, and genders) and thus the persistent nature of exploitation within societies which develop the new technologies. At worst, the "information society" slogan is used by those who would catapult us into such a new era in the name of efficiency, profit, progress or competitiveness. At best — and this is why I allow myself to use it here — it is a shorthand to point to the cluster of issues raised by the analysis of the "social dimensions of information technology." Understood in this way, I believe it gives us a handle on some of the most crucial and far-reaching changes (alongside bio-technology) of our day. Failure intellectually and practically to grasp its consequences will set back our efforts to "salt the earth" in a way that is relevant for our generation. 1. On "Defining Technologies" Lewis Mumford observes that the key artifact of the industrial era is the clock.4 It is the typical symbol and the ubiquitous fact. This conjuction of science and technology, which made possible precise measurement (and stimulated more accuracy in other areas as well), Mumford rightly sees as contributing to what one might call the "clockwork image" of humanness. The world, and indeed the universe could be seen as a large, self-regulating, interdependent machine. Other historians have often hinted that the heat engine (or steam engine) was really the crucial technological symbol of industrialism. Here we have an instrument for harnessing inanimate sources of power to drive machines. David Bolter sees both the clock and the steam engine as "defining tech nologies." They play a part within the change in the role between humans and nature. In terms of Christian thought, one notes that while clocks helped people see the world as an ordered creation of God, accessible to human reason, when it came to humanness, in the hands of a Leibniz, the clockwork image has distinctly deterministic overtones. By the twentieth century, the clock certainly had become extremely important for the ordering of human life. We now eat, sleep, work, catch trains and planes, or watch television, by the clock. The revolt against subjection to abstract, measured chunks of time also becomes more apparent in the twentieth century. Hans Castorp, in Thomas Mann's The Magic Mountain, throws away his watch as a sign of his hatred of time-bound life. The heroes of the film Easy Rider crush theirs under their boots. Others make pleas for a renewed appreciation of play and leisure than is often permitted by the Tyranny of Time.5 David Bolter's argument, however, is that a new defining technology is taking over from the clock. In a manner more analogous to the way that the spindle or potter's wheel once united art and science, the computer is now emerging as the defining technology of the future. As far as humanness is concerned, the new image is that of "information processor." Why? Because 4 Lewis Mumford, Technics and Civilization (New York: Hartcourt, Brace, 1934), p. 14. 5 See, e.g. Robert Banks, The Tyranny of Time (Exeter: Paternoster, 1983).</page><page sequence="3">BEING HUMAN IN THE 'INFORMATION SOCIETY' 175 the computer "can reflect the versatility of the human mind as no previous mechanism could do."6 Thus he claims that the new notions of time, space and language will become accessible and impressive to a vast new audience because those ideas are embodied in a machine.7 It is not hard to see how such a state of affairs might indeed come about. Computers influence children from a young age.8 There is a growing aware ness of new technology's contribution to leisure pursuits through computer games, video cassette recorders and so on. One encounters the "computer cults" of hobbyists and designers.9 Even more significantly, we observe the massive computerisation of factories, offices, governments, and police, which touches us all in our everyday lives. But this is not exactly what Bolter discusses. His book remains at the level of fairly abstract reasoning and the history of ideas. Let us return to the clock. Assuming it is correct to think of it as a "defining technology," how did it become such? Not merely because people accepted it, cognitively or intellectually, within a Cartesian or Leibnizian framework! Part of the way in which the clock became so immensely significant was by actually defining the parameters of human existence, and not just because it provided a handy analogy (for those looking for one) of the human mind. With the conjunction of the clock and modern industrial capitalism, time took on a new significance. Anthony Giddens calls this its "double existence." Universal, abstract, quantifiable time began to predominate over the "qualitative organisation of time processes characteristic of all non-capitalistic forms of society."10 As the shift was made into industrial life, people were obliged to think of their lives as being divided between "working time" and "one's own time." "Work-time," now a commodity, was sold to the employer in return for wages. But to maintain control of the new processes of production, employers began to draw together empoyees under one roof, thus helping to create a spatial change alongside the temporal: the division of "home" and "work-place." These social phenomena all depended upon the clock. These are factors ignored by Bolter yet which appear to be highly pertinent to any concept of a "defining technology." Another way of approaching the issue is to step back and take an even longer historical view. Norbert Elias's theory of the "civilizing process" gives us the clues at this point. People have never intentially civilized themselves and produced today's nation states. Rather, over long periods of time, the power of the community to restrain behaviour gave way to more self-control. Simultaneous with this, of course, is the increasing differentiation of society, the division of labour and tasks, which led to greater interdependence.11 6 Bolter, op.cit., p. 40. 7 Ibid., p. 33. 8 Some advocate giving a computer to a baby from birth! See Frederick and Victoria Williams, Teach Your Baby to Use a Computer (New York: Bantam, 1986). 9 See David Sudnow, Pilgrim in the Microworld (New York: Basic Books, 1982) and Tracy Kidder, The Soul of a New Machine (Harmondworth: Penguin, 1982). 10 Anthony Giddens, Central Problems in Society Theory (Stanford CA: Stanford University Press 1979), p. 134. 11 Norbert Elias, The Civilizing Process: State Formation and Civilization, trans. Edmund</page><page sequence="4">176 D. LYON Changing technology is an integral part of this process. For instance, as horses came to be used for haulage, using the shoulder-harness and horse-shoes, so transport and communication over far greater distances became possible. The closed sphere of the estate became less viable as the crucible of human activity; interdependence and differentiation increased. As social relationships were more stretched over time and space, self-discipline became more necessary. But later, as machines were used to reduce the unreliability of the human factor, self-discipline itself underwent change. As Elias notes, there have always been differences in restraint and disci pline between social classes, although those differences have been partially ironed out by the universal spread of regulated employment. But the progressive replacement of human skill by machines (to put things crudely) has the effect of regulating people in a new way. One could argue that as community-regulation and restraint gave way to self-discipline, so in turn machine-regulation and control will become dominant. Helga Nowotny makes the connection between Elias and new technology by suggesting that contemporary technical systems, if they are to interact successfully with human beings, must have built-in assumptions about how the human beings operate. The automatic bank teller in High Street is installed on the assumption that people prefer the convenience of unlimited access to personal contact with a bank employee. The automation of tasks within production, on a computer-controlled lathe for instance, assumes that people contribute only their dexterity or their eye for detail to the process in question. In fact many enjoy personal contact with bank employees, or put more of "themselves" into their labour. Nowotny pessimistically concludes that "Eventually, this reified image of the human being acquires the compelling force of a new social norm, to which actual social beings will have to learn to adapt in an approximation process."12 So what are we to make of all this? Bolter is not necessarily wrong to propose that information technology — above all the computer — is a new "defining technology." Rather, his reasons for saying this are too limited. He operates too exclusively within the "history of ideas," and thus focusses upon the explicit human self-image of "information processor." By exploring the notion further, in relation to our actual social experience, (that is, by engaging in a more sociological analysis) I hope to show that what Bolter ignores is in fact tremendously important. The implicit assumptions within the routines of everyday life may in fact be far more pervasive and significant than the explicit philosophical discussions about humanness and information processing. I offer a context for the more philosophical task. 2. Information Technology and Humanness: Case Studies Our experience of everyday life is deeply affected by our relation to the world of work and employment, to the educational process, and to the means by which we communicate with others. Each area is currently undergoing Jephcott (Oxford: Basil Blackwell, 1982). 12 In N. Bjorn-Andersen et al. eds., Information Technology: for Richer, for Poorer (Amsterdam: North Holland, 1982), p. 100.</page><page sequence="5">BEING HUMAN IN THE 'INFORMATION SOCIETY' 177 profound change as information technology is introduced. Computer-aided design and manufacture, word processors and office information systems are becoming commonplace in the sphere of employment. Closely related to that, computers have been introduced both as a tool for learning and as an aspect of study in schools. And new communication technologies are rapidly making obsolete older distinctions between media (for example, voice and print may now be carried by the same electronic means). What challenges for our humanness are thrown up by such changes? 2.1. Labour If the clock once contributed to the control of the labour force, imposing time-discipline in order to maximise efficiency and profit, then could the computer take this a step further? It is quite clear that the attractiveness of computers to companies and organizations is bound up with the enhance ment of coordination and control of people and processes. Since the reduction in size and price of computerised systems made possible by the silicon chip, automation has been making strides. A huge debate has arisen over the effect of computers in design, in machine tools, in office information systems, and so on. The main fear expressed is that the process of "deskilling," already a trend within industrial society, will be augmented within the emerging social order based on information-handling. Will tasks increasingly be drained of their former skills? And, on the other side of the coin, will management (and employers in general) become more powerful as they retain control — using the new technologies — of production and organization? The classic case is computer numerical controlled machine tools, instru ments used for shaping metal to desired specifications. Once they were set up by craftsmen, then latterly they were programmed to repeat performances by punched cards. These machines now have micro-computers built into them. In some systems this simply makes redundant the craftsmanship of the machine tool operator. So who now exercises skill? The machines may now be programmed direct from the designer's desk-top computer. So decision-making and responsibility is removed to the office. The focus of the debate has been the work of Harry Braverman.13 Written from a Marxist standpoint, his studies were widely welcomed as a revitalising of Marxist analysis as opposed to more arid theoretical wrangling. He argued that the automation of the workplace represented a simple extension of Taylorist principles of "scientific management." Taylor advocated the sub-division of tasks to their simplest component, and the separation of their "conception" (mental labour, best suited to management) from their "execution" (the actual "hands-on" job). Computerisation en hances this division by permitting the further extraction of skills from tasks, and the creation of greater distance between management control and worker operations. If Braverman is correct, we may expect that levels of responsibility and autonomy at work will increasingly be lowered among the mass of workers, 13 Harry Braverman, Labor and Monopoly Capital: The Degradation of Work in the Twentieth Century (New York: Monthly Review Press, 1974).</page><page sequence="6">178 D. LYON and that decision-making and control of work-situations will rise to the tops of organizations. This clearly has "human" implications, at least if we assume that an aspect of our humanness is to be engaged in responsible, creative activity. Could we be moving towards the situation suggested by Elias' analysis, whereby machine control takes over where self-discipline and community-constraints left off? The "if," however, carries much freight. While he has put his finger on some significant processes associated with the spread of new technologies, Braverman is incorrect in perceiving a "general trend" towards deskilling within contemporary capitalism. Numerous criticism have been levelled at his work.14 The most telling of these are that he treats different social groups in different ways. Employers are seen self-consciously working out their purposes, systematically adopting Taylorist principles (which they manifestly do not). Workers are seen as relatively passive, on the other hand, malleable to the predominant interests of the employers. The effects of their resistence tot new technology, and of wider constraints upon the whole process of new technology adoption, are neglected. This does not mean that the deskilling fears are unfounded. Rather, it means that this very real threat should be faced wherever it is manifest. In some areas (computer numerical machine tools being one) computerisation does not necessarily deskill, although even then, it depends upon the kind of company and so on. In others, however, (notably clerical work using new office information systems and word processors) deskilling does occur. Typists and secretaries find they have less real "responsibilities" and more merely "routine" tasks to perform. And as office automation is one of the major trends affecting occupations and work-patterns in the advanced societies, this is very significant. In certain important ways, then, many new machines with which people have to work have built-in assumptions about the kinds of human per formances they can expect. While computerisation undoubtedly brings a rise in skills levels for some, for others the machine expects only a low level of responsible decision-making, and a minimal level of skills. There is an "image" of humanness present here. There is a sense in which computers may be a "defining technology." And it is all-too-often an unwelcome "image" and "definition." 2.2. Education What, then, of education? Here is another area (not least because of its increasingly prominent but somewhat ironic task of "preparing for employ ment") in which computers have gained a high profile. The arrival of com puters in schools has been extremely rapid — a phenomenon of the 1980s — and teachers and students alike are only just beginning to understand some of their implications. It is remarkable, at a time of such financial stringency in so many recession-bound countries, that "computer studies" and their accompanying machines have found such a strong place in the budget. 14 See Stephen Wood et al. eds., The Degradation of Work (London: Hutchinson, 1982).</page><page sequence="7">BEING HUMAN IN THE 'INFORMATION SOCIETY' 179 However, it is no accident. With the growth of state power over education, state priorities become educational ones. It is widely assumed that we are entering the "information society" phase, and that therefore its citizens should be computer literate. The supposed solution to our economic ailments — microelectronics and information technology — becomes part of an educational necessity. A British government report gave a mandate to the Microelectronics Education Programme to "help schools prepare children for life in a society in which devices and systems based on microelectronics are commonplace and pervasive."15 To some, this may appear altogether reasonable. Why not take seriously the task of trying to prepare children for the kind of world they can expect to find when they grow up? Fair enough. But how far should economic criteria guide the content of education, and what will be the long term effect of this on more traditional aspects of the educational process? What kind of self- and social understanding is acquired by working with computers from a young age? Even if the assumption is correct that microelectronics-based systems will become a pervasive feature of society, is the actual school-instruction preparing students in appropriate ways for that? And how can equity of access to school computers be ensured? All these questions have a bearing on the issues of humanness, but they are not questions that one frequently hears. To raise them is to court derision as a "Luddite," or as someone who simply wishes to "hold back progress." It is also to question both educational policy and the advocacy of computer enthusiasts. Seymour Papert's best-selling Mindstorms, for instance, while it contains some small print warnings, is intended to win readers over to the delights of LOGO.16 Learning by discovery, using computers, appears in Papert to solve a multitude of educational problems accross the curriculum.17 Not only this, but Papert assures us that children will "gain self-confidence through their relationship with the machine"! Sherry Turkle's research into what she calles the "subjective computer"18 includes studies of school children exposed to computers. She believes that these machines are "entering into social life and psychological development" and "affecting the way we think, especially the way we think about our selves."19 In general, she does not seem to worry about any possible adverse implications of this, as she focusses in a fairly narrow way on children's inter action with the hardware. She sees information technology as friend and ally, as computers become our "second selves." But she does see that new philo sophical questions are raised, as children define themselves "not with respect to their differences from animals, but by how they differ from computers."20 15 Microelectronics Education Programme: The Strategy (London: Department of Education and Science, 1981), p.3. 16 Seymour Papert, Mindstorms: Children, Computers, and Powerful Ideas (New York: Basic books, 1980). 17 See a critique of this in Ronald Ragsdale, "An Alternative Analysis of Computers in Education: A Response to Edward Sullivan Interchange," OISE, 16(1985), nr. 3,19-36. 18 Sherry Turkle, The Second Self: Computers and the Human Spirit (New York: Simon and Shuster, 1984). 19 Ibid., p. 3. 20 Ibid., p. 313.</page><page sequence="8">180 D. LYON In a quite different vein, educational researcher Pam Linn criticises the "technicist inversion" which seems to take place when computers are intro duced in education. Often, she says, computer design is so dedicated that users have little choice, only "restricted oppertunities to exercise their unique ly human characteristics."21 Consumers become more like their machines in consequence. At the same time, machines are accorded superhuman powers. Anthropomorphic language of "artificial intelligence," "user friendliness," and "knowledge-based systems" gives the impression that we are dealing with humanoid superiors. The great boom in home micros for children seems to have dissipated somewhat now. Parents acted as they did in the belief that computers wer associated with "cleverness," with being "smart." Yet what did the machines do? Space Invaders, until the craze tired. They then began to gather dust. Where the craze has not tired, however, other questions should be asked. Here Joseph Weizenbaum's critique is highly pertinent.22 Weizenbaum worries deeply about the effects of exposing youngsters to many of the "games" on the market. The film War Games makes the point well. A young computer hobbyist manages to obtain electronic access into American Missile Command, where the real war games are played in earnest. The gap between "model" and "reality" is blurred. The conputer model leaves out almost everything present in the real thing, so that the sense of responsibility for actions is steadily diminished if the things left out remain unremarked. Moreover, it would be unsurprising it such "other factors" were lett out ot account, for the simple reason that computers arrived in schools before teachers were prepared to teach computer studies. The upshot of this, fears Weizenbaum, is that more and more children will be unleashed upon the world who are willing to foist on others technological fixes. If they have been taught computational modelling without a corresponding understanding of its severe limitations, this is indeed what we may expect. Thus the computer may be a contributor to the dulling of a sense of responsibility. At a time when the world is becoming fearfully aware of the long-term and global effects of technological decisions, this is sobering, to say the least. The neglect of "other factors" is also visible in the treatment of "language" and "intelligence" in education. If "language" comes to be thought of in terms of computer language — that is, sets of rules — then might not articulate expression in mother tongues suffer?23 Human language is sets of meanings embedded in history and society which — optimistic claims notwithstanding — may not be computerised. Similarly with "intelligence." Computer-based knowledge and so-called expert systems will always be devoid of the other characteristics which comprise human knowledge. As veteran cultural critic 21 Tony Solomonides, éd., Compulsive Technology: Computers as Culture (London: Free Association Books, 1985), p. 61. 22 Joseph Weizenbaum, Computer Power and Human Reason: From Judgement to Calculation (San Francisco: Freeman 1976). 23 See Michael Young, "Information Technology and the Sociology of Education: Some Preliminary Thoughts," British Journal of Sociology of Education 5(1984) nr. 2 205-211, and Kevin Robins and Frank Webster, The Technical Fix (London: MacMillan, 1989).</page><page sequence="9">BEING HUMAN IN THE 'INFORMATION SOCIETY' 181 of computing, Humber Dreyfus points out, human knowledge cannot be cut loose from its context of emotions, feelings, and senses.24 In these ways and others, then, computers and information technology in general may indeed come to be "defining technologies." Not just that people "see themselves" in artificially reduced terms, but that that way of seeing is itself embedded within power relations in society, and has deep social and political ramifications. It is precisely some of those factors beyond the constraints of instrumental reason which should be guiding the development of computing in schools. Love of neighbour, care of the created world — these are the kinds of factors I have in mind. Curiously enough, it is within educational use of computers that one does find evidence against one fear commonly expressed about information technology, namely that it tends towards social isolation. Experience has shown that clusters of students, along with their teachers, may well be drawn together in a mutual learning experience using computers. Whether this is a long- or short-term occurrence, and how much it depends upon the relative novelty of computer studies, is as yet impossible te tell. 2.3. Media of Communications I turn, thirdly, to an area in which the last named concern — isolation — has often been aired; the media of communications. Just as work (along with rest and play) and education (as the process of learning about the world and each other) are crucial aspects of humanness, so is communication. No meaningful human relationships are possible without the presence of some medium for transmitting and receiving symbolic information from each other. "In the beginning was the Word." Information technology is in large measure about communication. Com puters themselves are used for communication, as databases. But the notions of "information technology" — or l'informatique — involves the marriage of computers with new forms of telecommunications. It is that marriage, that convergence of technologies which is helping to "define" humanness in new ways. Or so I am arguing. Both at the commercial, domestic, and productive level, new communica tions media are making possible new patterns of human social interaction. Offices are connected together internally and externally by "local area net works." On a global scale, capital never ceases to flow around the world on the great financial networks, using satellites. Satellite pictures are also re ceived directly into living rooms from stations which are continents away. And cable television is also bringing new concepts of local, narrowcast transmission whereby specific audiences and interest groups can be targetted. Using the same cables (or satellites) however, different content can be carried — whether voice, image, or numerical data. New means of communication contribute to alterations in what is com municated, to whom, and how we communicate. Face-to-face verbal commu nication of a traditional kind holds possibilities for a certain openness, 24 Hubert Dreyfus, What Computers Can't Do (New York: Harper and Row, 1972).</page><page sequence="10">182 D. LYON immediacy, transparency, honesty, intimacy, and depth. Can these possi bilities be sustained when electronic communications media are the order of the day? Optimists maintain not only that it is possible, but that undreamt-of levels of very personal interaction will be possible using new media. New vistas for democratic participation open up.25 Badly needed cooperation would become feasible as the "network revolution" is established.26 History is not on their side, however. James Carey highlights this contra diction. As massive and wondrous webs of electronic communication have been developed during the twentieth century, so ongoing social fractures and fissures have continued to be the source of conflict and organised violence. The nineteenth century, which saw the first truly international systems of communication in telegraphy and the underwater cable, ended with the clash of rabid nationalism in the First World War. Carey laconically comments: "It seems as if the ability to convert knowledge into forms that can be trans mitted and utilized by highly technological systems dries up the interpretive capacity to understand other people."27 Carey's perspective owes much to Canadian historian Harold Adams Innis, who also insisted on this negative relation; reliable physical communications networks on the one hand, and the difficulty of maintaining meaningful face-to-face relationships, on the other. He suggested that "time-binding" forms of communication — above all writing — tend to hold people together around common beliefs and traditions. Whereas "space binding" communication — such as the stretching of cables and satellite beams around the globe — erodes this. Not only that, but it tends to centralise and monopolise the means of communication, and, by extension, the content of communication and what passes as "information" or "knowledge" (which connects with the previous section). This in turn could produce privileged "classes" of communicators. If Carey and Innis are right, we would expect minority and deviant forms of knowledge increasingly to be marginalised and discounted, as well as for affective interpersonal relationships to be more constrained. Even if one siphons off Innis' slightly romantic image of traditional society, plus his somewhat deterministic account of the impact of new communications technologies, significant insights remain. As we begin to appreciate the huge power of the transnational corporations concerned with informatics, and as we feel the encroachment of electronic media not only over space but now eating into time — 24 hours TV transmissions and so on — this whole sphere comes more clearly into focus as a crucial arena for debate on a human future. Empirical research seems to confirm the fears of Carey and Innis. The effects of computer-mediated communication are far from negligible. Of course, the promoters of electronic mail and computer networking emphasise technical matters like speed, efficiency, and the adaptability of the written 25 Ithiel de Sola Pool, Technologies of Freedom (Cambridge, Mass.: Harvard University Press, 1983). 26 Jacques Vallee, The Networking Revolution (Harmondsworth: Penguin, 1982). 27 James Carey, "High Speed Communication in an Unstable World" The Chronicle of Higher Education (1983) July 27, p. 48.</page><page sequence="11">BEING HUMAN IN THE 'INFORMATION SOCIETY' 183 text. But deeper study reveals other aspects. The lack of social context information (smiles, eye-contact, tone, and other signals which tell you if your message is understood and/or accepted) means that the coordinating and comprehension of messages becomes hard. Social standards becomes less important, and the message less personal because of rapid text-exchange, lack of social feedback, and the absence of norms governing the interaction. More anonymity, less self-regulation (recall the earlier discussion following Elias), and reduced self-awareness means ther are less "meaning clues" in communi cation.28 Neither this, nor anything else in my paper should be taken as a picture of unrelieved gloom regarding the new technologies. Changes in communica tion as computer mediation becomes more important could include a greater chance for minority views to be heard, as social influence between communicators becomes more equal due to the diminishing social signs of status. But it does seem that whatever the specific and long-term impact of computer-mediated information, the personal and social factors which have been significant within more traditional forms of communications are increasingly constricted. Human practice is being defined in novel ways. It is not clear that this is a desirable trend. 3. Defining Technologies, Idolatry, and Liberation I have tried to show how computers and telecommunications are indeed becoming new "defining technologies." Not only in the sense suggested by David Bolter or Sherry Turkle, that we see ourselves in different ways, but in the sense that we allow ourselves to be constrained by the expectations of the machine, the expert system, and the media of communications. Our choices are narrowed even as in other respects they widen. Oppertunities to express the whole spectrum of human attributes are restricted by our own technological choices. There are two sides to this. On the one hand we make machmes which are accorded with authority and whose adoption is a priority. (Computer predic tions of elections are taken very seriously; computers find their way into schools which are crying out for spending on other resources.) Computeri sation is associated with progress, progress in rationality and economic progress. On the other hand, we forfeit the chance to take responsible decisions. We become dependent upon a dominant source of communication to define knowledge for us. We exchange direct, personal and affective communications for the impersonal, the long-distance. We magnify the machine, and we shrink our humanness. Have we not heard such complaints before? From Herbert Marcuse, the idea of "one dimensional man." From Jurgen Habermas, the notion that technocratic reason prevails, pushing out questions of ethics from political life. From Lewis Mumford, who views the movement to electronic techno logies as a steadily increasing denial of any human purpose but those yoked with the quest for power, particularly military power. From Jacques Ellul, 28 Sara Kiesler et al., "Social Psychological Aspects of Computer-Mediated Communica tion," American Psychologist 39(1984) 1123-1134.</page><page sequence="12">184 D. LYON who sees this process in a similar way, but concludes that la technique is itself infused with demonic power; its conquest relentless. So what is new? In one sense, nothing. But the issues acquire a new urgency with the development of the silicon chip, or rather with its applications. For the defining technology is now capable of affecting a far greater proportion of people, far more rapidly. With the arrival of informatics we are witnessing an accentuation — in specific but significant areas — of existing trends. What was true for a minority before (for instance exposure to computerised systems at work or at school) is becoming true for the majority. If it is appropriate to extend Norbert Elias' analysis, we may expect an increasing manifestation of machine-control. Not only do the issues acquire a new urgency as the pace of change accelerates, but the nature of the critique also invites overhaul. In particular ther is a need to obtain a clear perspective on the alternative understanding of humanness, such that truly human priorities may guide the development of information technology. The kinds of critique available at present — valuable as they undoubtedly are — emanate from sources which underestimate the extent of the problem. Libertarian Marxism, liberal cultural pessimism, radical technology, ecology, feminism and the peace movements, these are the foremost critics of new technology. They each in their way point in the right direction — away from technocratic domination — but having made a good beginning are unable to take things further. Such critiques even discern the crucial clue, and put it to good use within their anti-technology polemic. Joseph Weizenbaum, a humane liberal, could scarcely put it better than when he affirms: "... the computer is a powerful new metaphor for helping us understand many aspects of the world, but... it enslaves the mind that has no other metaphors and no resources to call on."29 Pam Linn's hope as Marxist is to "move towards providing the means by which social theorists can assist in dethroning the computer idol."30 Again and again one hears echoes of the prophetic biblical denunciations of idolatry within the "secular" critique of informatics. Religious worship of computer and telecommunications has become blatant. Return for a moment to the masterful philippics of Jacques hllul. He too sees clearly that la technique is an idol. Since the 1950s he has been issuing urgent warnings about the dangers of idolatrous technology to freedom and humanity. As a Judeo-Christian theist he sees such idolatry as an alternative to properly directed faith in God. More recently Michael Shallis proposed that "The computer, seen as the current pinnacle of technological development, is inherently anti-human because it redefines man at a such a lowly level and with such power."31 The computer obscures our human qualities as being "of God" (or, biblically, the "image of God"). Idolatry, then, is a key to understanding modern technology in general, and informatics in particular. As Bob Goudzwaard indicates, it helps to explain the contradictory attitudes held towards new technology.32 On the 29 Joseph Weizenbaum, op. cit., p. 277. 30 Tony Solomonides éd., op.cit., p. 100. 31 Michael Shallis, The Silicon Idol (Oxford: Oxford University Press, 1984), p. 167. 32 Bob Goudzwaard, Idols of our Time, forew. by Howard A. Snyder, trans. Mark Vander</page><page sequence="13">BEING HUMAN IN THE 'INFORMATION SOCIETY' 185 one hand is the adoring worship of those who believe m informatics for national economic salvation, or simply because they are entranced by the machines. On the other is fear. In our case it would be fear of surveillance by police and government, fear of job-loss or deskilling, fear of accidental nuclear war due to computer failure. Even more specifically, this yields an interpretation of why we (con sciously or unconsciously) allow ourselves to be shaped by new technology. As the biblical psalmist says of idols, "those who make them will be like them" (Psalm 135: 18). Our idols define us. We become like them rather than like the Creator. Today's defining technologies become such as inordinate emphasis is placed on the process of l'informatisation, such that individuals, groups and nations get carried along by misplaced faith. Which means that the "technicist inversion," real and deplorable though it is, cannot simply be cured by a reassertion of "human values." I was careful to say that idolatry is a key to understanding today's tech nology, It is not the key, as Ellul seems to imply. For if it were the key, then little chance remains for its transformation, or of its being yoked to human liberation. In the Judeo-Christian account, technology must be seen as an aspect of the human task of caring for the creation, and opening up its resources for human benefit.33 Technological idolatry represents a derailing of this purpose. The Christian gospel, of forgiveness and new life in Christ, is the signpost indicating the way out of the self-made maze of idolatry. From this perspective, while critique is a vital part of the response to new technology (although this is by no means limited to negative critique), it is also imperative to go on from there to alternative practice. Factories and offices may be (partially) automated without evacuating skills or personnel, and without eroding responsibility (and without going bankrupt.34 Com puters may be introduced into schools, in a measured, critical fashion, and by teachers who highlight the limitations of the machines perhaps even more than what they can do.35 Perhaps the area of new communications tech nologies is more difficult. Maybe more resistence is required in this case. Positively, efforts should be made to ensure that people whose lives and communities could be enhanced by new technology have that opportunity. The criteria which govern the development of information technology should be ones deriving from an understanding of humanness as the imago Dei. This means that care of creation and love of neighbour take precedence over hardware and software decisions. Justice and truth must be rescued from their false subordination to instrumental reason in its latest guise of digital information. To be human in "information society" is to recognise and to resist the "defining technology," and to define and develop information tech nology according to human — but not humanly derived — characteristics. Vennen (Downers Grove, 111.: Intervarsity Press, 1984), pp. 21-3. 33 See Egbert Schuurman, Technology and the Future (Toronto: Wedge, 1980), or, more succinctly, Paul Marshall, "Is Technology out of Control?" Crux, (1984), sept., 3-9, and David Lyon, "Tubal-Cain and High Tech," Christian Arena, March 1987. 3&lt;* New Technology: Society, Employment and Skills, (London: Council for Science and Society, 1981). 35 I refer to this as "computer incompetence awareness."</page><page sequence="14">186 D. LYON 4. Coda As we approach the third millennium, the question of the computer as defining technology becomes more pressing. Applications proliferate, from artificial intelligence to artificial life and from virtual reality to global net working. Information technology as a mental prothesis, with which we interact, brings science fiction down to earth, for instance in the cyborg.36 The question of what is human, and how this relates to religious conceptions, is raised constantly.37 The difficulty of the question is heightened by the present "postmodern" context of such debates, which cast doubt on the possibility of clarifying the human in any universal sense.38 The burden of this paper, however, is that it is crucial to go beyond the level of speculation about "minds and machines" to examine sociologically the practical everyday life ways in which computers may become a "defining technology." Only then can this technology properly be analysed, its origins unravelled, and its consequences evaluated.39 Even now, opportunities exist to redefine information technologies according to criteria derived from a Judeo-Christian understanding of the human task.40 Shutting our eyes to these contemporary realities will mean that computers will go on being allowed to become defining technologies by default. 36 See Donna Haraway, Simians, Cyborgs and Women: The Reinvention of Nature (New York: Routledge, 1991). 37 See Benjamin Woolley, Virtual Worlds (London: Blackwell, 1992); David Barnard and John Stackhouse, "What is this Quintessence of (Carbon-Based) Dust? Reflections on Artificial Life," Perspectives, November, 1993. 38 See David Lyon, Postmodernity (London: Open University Press, Minneapolis: University Press of Minnesota, forthcoming). 39 See e.g. Diana E. Forsythe, "Engineering Knowledge: the Construction of Knowledge in Artificial Intelligence," Social Studies of Science 23(1993), 445 - 477. 40 See, e.g. H. Thimbleby and others, "Concepts of Co-operation in Artificial Life," Stirling University (UK) Dept. of Computing Science and Mathematics, 1992.</page></plain_text>
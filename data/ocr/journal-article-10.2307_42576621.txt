<plain_text><page sequence="1">Anatol Rapoport* TECHNOLOGICAL MODELS OF THE NERVOUS SYSTEM IT quires is not an often astonishing that a up-to-date-ness. book written in This another does happen age suddenly when some ac- quires an astonishing up-to-date-ness. This does happen when some prophecy suddenly passes from the realm of the fantastic to the realm of the imminent. Such a prophecy was contained in the book Erewhon by Samuel Butler, written in 1872. The prophecy has to do with the evolution of machines, particularly machines endowed with a prop- erty which has seldom been attributed to machines - intelligence. As stated by Butler in rather poetic terms, the prophecy envisages a world in which the machine becomes the dominant system of organiza- tion (in the way living things are systems of organization) . Like living things, the machines of the future metabolize, reproduce, maintain themselves, and in general seem to have an aim in life. The one frightening thing about the genus machina is its parasitic dependence on the genus homo . the mechanism of natural selection is supposed to function in such a way on that form of "life" as to select those varia- tions which are especially capable of catering to the compulsions of human beings - namely, their compulsions of caring for machines. Gradually, what had started as a symbiosis between man and machine passes into parasitism, so that finally man becomes domesticated by the machine. Almost the same prophecy is stated in more realistic terms by N. Wiener in his Cybernetics (New York, 1948). Wiener envisages the Second Industrial Revolution ushered in by machines able to perform From Et cetera , Vol. XI, No. 4. * Presented at the regional research conference of the American Psychiatric Association held at the National University of Mexico, Mexico City, March 10-12, 1954. 312</page><page sequence="2">Technological Models of the Nervous System 313 tasks requiring an average intelligence with the resulting dislocations and crises similar to those which followed the First Industrial Revolu- tion, when the "stupid" machines first appeared on the scene of history. Our purpose here is not to discuss the merits or the limitations of these prophecies, but rather to point out that the sudden dramatic revival of the "intelligent machine" idea (be it a metaphor or a myth or a profound insight) is indicative of a really significant historical event - a major intellectual revolution. Like the Second Industrial Revolution, of which Wiener writes, this intellectual revolution is also the second in recent times. The first one occurred in the 17th century with the creation of mathematical physics. Perhaps I should make clear what I mean by an intellectual revolution. I think of such revolutions metaphorically as crystalliza- tions of thinking around new, powerful concepts. In the 17th cen- tury these central concepts were those of mechanics - force, momen- tum, particularly energy. They became the central concepts of classical physics and of technology which came into being during the First In- dustrial Revolution. The second intellectual revolution, now occurring, brought forward another powerful new concept, that of "quantity of organization," a concept of high degree of sophistication and bearing within it the seeds of extremely far-reaching consequences It is this concept, also called negative entropy and "amount of information," which makes the anthropomorphic conception of the machine especially intriguing, particularly because through it the common features of "intelligent" or purposeful" behavior of the higher animals and "automatic" behavior of "higher machines" are made apparent. Now the personification of machines and "mechanization" of organisms are not new. The former has mythological roots in the medieval legends of the Golem and the Homunculus. The latter appears, for example, in the writings of Descartes. The question "Are living beings machines?" has long been treated as a metaphysical question, presumably answerable on metaphysical grounds. Since metaphysics is more or less a lost art, we must learn to look at that question somewhat more critically, that is, with seman- tic awareness. We must translate it into other questions, such as, "To what shall the name 'living thing' be applied?" and "To what shall the name 'machine' be applied?" "Is there an overlap among the referents of the two terms?" Putting the question this way, we see that the answers to the first are relatively clear, while the answers to the second are not nearly so clear. Barring certain borderline cases (viruses, etc.) we have no difficulty recognizing the class of objects to which the name "living thing" can be unambiguously applied. Not so with machines. This</page><page sequence="3">314 Et cetera â€¢ FALL 1983 is so because living things are "given." They have remained about the same for as long as we can remember. But machines have evolved rapidly within the span of human history. We realize keenly that there are machines today which our grandfathers could not have dreamed of, and, by extrapolation, we feel that we can't really say what the limits of the world of machines may be. If we think about the matter a little more, we realize that machines in their evolution undergo "mutations" of tremendous magnitudes. Where it takes eons for a new biological species to develop, a new technological "phylum" has on occasion come into being within a generation. By a technological phylum I mean something similar to a biological phylum. If the latter is defined by a very general plan of organiza- tion in a wide class of living things, the latter is defined in terms of a principle of operation. We can, if we wish, distinguish four technological "phyla," which came into being successively. The first phylum we could call Took. Tools appear functionally as extensions of our limbs and they serve primarily for transmitting forces whch originate in our own muscles. In the transmission of force, sometimes a mechanical advantage is gained, as in the crowbar, a screw, or a pulley. However, the work done by a machine of this sort is actually work done by our own muscles. Therefore a machine of this kind, a tool, does not give the impression of "independent" action, and so it did not occur to any one to compare tools to living things. (1) With the second phylum it is a somewhat different story. This second phylum of machines we could call Clockworks. In a clockwork a new principle of operation is at work, namely, the storing of mechanical energy. A typical clockwork is wound up, that is, potential mechanical energy is stored in it, which may be released at an arbitrary later time and/ or over a prolonged period to time. A clockwork does give the impression of autonomous activity, and doubtless this crude resemblance of a clockwork to a living thing (residing in its quasi- autonomous activity) gave the craftsmen of the late Middle Ages and of the Renaissance ideas of constructing mechanical dolls and animals. Perhaps the first ideas of automata sprang from the same sources. Characteristically, Descartes speculated on the possibility that animals were elaborate clockworks and, equally characteristically of his age, excluded humans from this class, as possessors of "souls." We may observe in passing that the bow and the catapult are also clockworks by our definition, since mechanical energy is stored in these machines to be released later (in the case of the crossbow, it may be released much later). However, the "autonomous" action of these machines is so brief that they do not give even the appearance of being "alive." The first comparison of living things to machines, therefore, was</page><page sequence="4">Technological Models of the Nervous System 315 made with regard to clockworks. It is not surprising that this metaphor was not particularly fruitful for the understanding of the living process. We know now, of course, that energy is stored in living things, but this energy is not stored in the form in which it is stored in clockworks (mechanical stress) and so was not recognized as such. Living things are not wound up to keep going, and this absence of the most essen- tial characteristic of a clockwork in living things made the early mechanical interpretation of life a sterile one. This comparison got a new lease on life with the appearance of the third phylum of machines. This phylum includes primarily the Heat Engines. Again an entirely new principle enters into their opera- tion. As with tools and clockworks, the output of the heat engine is an output of energy which had been put into it. But whereas the energy put into the earlier classes of machines was in the form of mechanical stress, which is obviously associated with our own muscular effort, the energy put into a heat engine is contained in a fuel. Consider the vital difference between the two situations. It is obvious even to a child that the tool is not autonomous, because the tool is geared at all times to muscular effort. A child or a very primitive person may believe that a clockwork is autonomous, but it is still easy to convince him that it is not, because the winding up is still a result of some one else's muscular effort. No such effort is apparent in the fuel. Fuel is "fed" to the heat engine. The analogy to living things (which also need to be fed in order to operate) becomes ever stronger. The comparison between heat engines and organisms passed beyond the metaphorical stage and bore real scientific fruits. It became apparent that fuel is in a very real sense the food of the engine and equally apparent that food eaten by organisms likewise functions as "fuel." The principle of energy conservation was shown to hold in living things - a serious blow to the contentions of the vitalists, which sent them on their long and tortuous retreat. Biochemistry was born. More and more processes characteristic of life were shown to be in- stances of processes reproducible in a chemical laboratory. An analogous revolution was occurring in technology. In fact, it would be not inaccurate to say that the First Industrial Revolution occurred when it became apparent that machines could be constructed which did not need to be "pushed" but only "fed" in order to do the work. Driven out of physiology, the vitalists took refuge in psychology. Here, in the realm of thought and purpose, of emotion and insight, they felt they would remain safe from the onslaught of the mechanists materialists, determinista, and reductionists. The label "nothing-but- ism" was derisively pinned on the philosophical outlook of those who believed that even the most complex manifestations of the living process, including the intricacies of men's psyche could somehow be</page><page sequence="5">316 Et cetera â€¢ Fall 1983 described in terms of analyzable behavioral components which, in turn, could be related to observable events in space and time. And so the focus of the battle between the vitalists and the physicalists shifted to psychology, where it remains at this time. The line between the two camps is, of course, not sharply drawn. Like the political spectrum ranging from extreme left to extreme right, the range of convictions concerning the nature of mental processes stretches from extreme behaviorism to vitalism or mysticism. The gestaltists can, perhaps, be assigned intermediate positions. I am sure you all know the main outlines of the controversy. The opening offensive was undertaken by the behaviorists, the champions of what in some circles bears the unattractive name of S - R psychology. The method has a strong physiological bias. Technological analogies are frequently invoked. The earliest of these was the "telephone switchboard" model of the central nervous system. The environment was supposed to act on the organism by a series of stimulus configurations, which activated combinations of receptors, which initiated impulses, which traveled along nerve fibers, passed through the central nervous system to other nerve fibers and into the effectors, whose activity accounted for the overt behavior of the organism, which was proclaimed to be a sole legitimate object of study in psychology. Behavior was viewed as a grand collection of units called reflexes. The model was seen to be inadequate from the start. If to every configuration of stimuli there corresponded a definite set of responses, how was learning (the acquisition of new responses to the same stimuli) possible? However, this seemingly embarrassing question proved a blessing in disguise, for the discovery of the conditioned stimulus by physiological means strengthened the reflex theory of behavior. It was shown that the paths of the impulses could be systematically changed. The switchboard model was shown to be still useful. Learning was accounted for by the "switchings" of the connections. Hot on the heels of the behaviorists' successes, however, came a more serious critique, called g estaltism. Gestaltism deserves serious attention, because its ideas were the direct precursors of a new approach to the theory of the nervous system, which is the subject of the present discussion. The gestaltist critique was not simply a reiteration of the vitalist faith and did not confine itself to derisive labels like "nothing-but-ism" directed against behaviorism. It was much more specific and constructive and was based on at least two clearly identifiable characteristics of behavior, which did not seem to fit into the behaviorist scheme, namely, the recognition of "uni- versais" and the equi-finality of response. The recognition of universais means the following. Suppose an</page><page sequence="6">Technological Models of the Nervous System 317 organism learns to respond to the sight of a particular square in a certain way and to a particular circle in a different way (say open a box marked with a square but not with a circle) . The phenomenon is clearly an instance of conditioning. A strict behaviorist (telephone switchboard) explanation would have to rest on the assumption that the stimuli originating from the receptors activated by the sight of the square are "switched" by the conditioning process to paths leading to the proper effectors for opening the box. However, it is known that the conditioned stimulus can be varied considerably after the condi- tioning has been established and still elicit the response. For example, if the original conditioning was to a white square on a black background, it can be subsequently changed to a black square on a white background, which, at least in the retina, excites the com- plementary receptors, i.e., precisely those which were not involved in the conditioning process. Roughly speaking, the organism responds to the square as a "square," regardless of the receptors involved. Hence the emphasis on the term g estalt (the configuration perceived as a whole, rather than a complex of elementary stimuli) . The gestaltists maintained that the behaviorists' emphasis on the stimulus response pathways detracted from the importance of "universais" or abstrac- tions in the act of perception. (If a counter-argument is offered to the effect that in the percep- tion of a geometric figure only the receptors affected by the edges of the figure are involved, it can be countered by other interesting evidence, such as the well-known phenomenon where familiar maps are not recognized if the continents appear in blue and and oceans in yellow, or the still more baffling phenomenon that the shapes of objects can be recognized regardless of position, size, or orientation.) The equi-finality of response argument is even more powerful. It has been observed that once an animal has learned to perform a task (say to run a maze to a reward) it will perform that task with whatever means are available to it. If its legs are amputated, it will roll through the maze. Clearly, such behavior cannot be explained in terms of a series of reflexes, each setting off the next, since the performance may involve totally different effectors each time. This equi-finality of response naturally leads one to talk of pur- poseful behavior, in which only the goal is relevant and not the particular configuration of neural events which come into play. This seeming inevitability of invoking teleological notions opens the door to more vitalist arguments. The notion of "purpose" seems to resur- rect the ancient classification of causes into "efficient" and "final" and to give new life to the ailing idea that the behavior of living and non- living things cannot possibly be governed by the same set of laws. It is at this point that the concepts associated with the fourth phylum</page><page sequence="7">318 Et cetera â€¢ Fall 1983 of machines become exceedingly important. We recall that the first phylum (tools) operated primarily as force transmitters; the second phylum (clockworks) as storages of energy resulting from mechanical stress; the third phylum (heat engines) as transformers of different forms of energy into mechanical energy. Now the fourth phylum of machines operates on the principle of storing and transmitting something called information. Already the telephone switchboard model of the nervous system employs a technological analogy with a communication device rather than a conventional engine. The primary concern of psychology is not so much with "what makes the organism active?" as "how does it know what to do?" Not the source, the transformation, or the utiliza- tion of energy by the organism is of prime significance but its organized disposition. What the psychologist actually studies is not how much activity has been performed but the sequence of specifically directed acts, which when organized one way may give one set of results and organized in another way (or randomly performed) may give an entirely different set, even though the amount of energy expended remains the same. To give a homely example, consider the difference between closing the door and then turning the key and turning the key and then closing the door. The machines of our fourth phylum are primarily concerned with systematizing operations in which utiliza- tion of energy is involved. The amount of energy used is not important. The "power" of these machines is not "muscular" power but "mental." The giants among them are capable of receiving, transmitting, and storing complex sets of directions, i.e., large amounts of "informa- tion." This is why technological analogies with these machines are of particular interest in psychology. These machines simulate not muscular effort (like their ancestors did) but human intelligence. Just as the concept of energy and its transformations was able to explain the "activeness" of organisms, which could not be explained on the basis of externally applied stress (as tools are activated) or by internally applied stress (as clockworks are activated), so the concept of "information" promises to do the same for a much larger area of the living process, namely, the "intelligent" and "purposeful" aspects of living behavior. What is this thing called information? There is now a wealth of literature on the subject and it is not within the scope of this presen- tation to develop the ideas of this literature. I think, however, that a reasonably good idea of the nature of "information" can be given by a few examples. I will not attempt to make these ideas precise. I will try to appeal to intuitive understanding, even at the risk of being vague. Information bears a similar relation to energy as organization to</page><page sequence="8">Technological Models of the Nervous System 319 effort. One can best see this in an example where the inadequacy of a theory based on energetic considerations alone is obvious. Consider the automobile traffic in a large city. Suppose the proverbial man from Mars decided to study this traffic. He might measure the rate of flow of cars along the city's arteries. He would correctly relate that flow to the speed with which the cars traveled and, being a good physicist, he would relate the speed to the power of the engines. And so he would be satisfied, perhaps, in explaining the rate of flow by energetic considerations. Next suppose that all the traffic lights failed. Certainly the speed of the cars and thus the rate of flow of traffic would be reduced. Sup- pose our Martian stuck to his conceptualization in terms of energetics. He would then have to ascribe the reduced flow (or speed) to some failure of the automobile engines, and he would be wrong. The failure is not of the engines but of the traffic lights. True, it takes energy to activate the traffic lights, but it is negligible compared with the energy it takes to move the cars. Energy has therefore little to do with the traffic problem under consideration. The key concept is not that energy but of directions for the utilization of energy (commands "stop" and "go" properly patterned), i.e., a matter of information. If the traffic lights are not functioning, the driver of a car does not know what to expect at each intersection and, playing safe, he slows down. The accumulated slow-downs of all cars at all intersections turn out to have a greater effect on the over-all slowing of traffic than the occasional full stops at the red lights. In the case of regulated traffic lights, set for certain speeds, the flow of traffic is most efficient. The cars are, in effect, "organized" or bunched up along the roads in such a way that the bunches on one system mesh with the empty spaces on the system perpendicular to it, and the flow is continuous without stops. Examples can be multiplied at will. Children well- trained in fire drills leave a burning building in a surprisingly short time, while a disorganized mob may never leave it. The success of a military action depends both on fire power and on proper coordination of the units. Fire power is measurable in terms of energy units, but coordination is measurable in terms of something else: the rate of flow of informa- tion and the precision of timing in carrying out the sequence of necessary steps. Productivity of an industry depends on the amount of power available (energetics) but to no less extent on the skill of the workers (coordination of activity within the individual) and the skill of management (coordination of activity of the several workers) . While it was traditionally assumed that these coordinating functions must be performed by "reasoning beings," i.e., men, it became gradually apparent that a great many of them could be performed</page><page sequence="9">320 Et cetera â€¢ Fall 1983 automatically (by traffic lights instead of policemen, IBM machines instead of filing clerks, automatic steering mechanisms instead of helmsmen, electronic computers instead of human calculators) . There arose then the intriguing idea that there may be a general "psychology" applicable both to the behavior of these devices and at least to cer- tain aspects of human behavior. Now let us pause for a moment and take stock of what we have said. Historically the technological analogies purporting to explain the behavior of living things have been geared to prevailing techno- logical concepts. As technology became more involved, the analogies could be extended to more facets of behavior. We are now entering a new technological era - the era of "intelligent machines," called automata and servo-mechanisms. The understanding of the principles on which these machines are constructed and operate promises to extend our understanding of the living process still further. We must, however, if we are to say something significant, indicate more specifically where that promise lies. We have two pieces of evidence in support of our rather optimistic view. The first is the tremendous stride forward in the understanding of the living process, which resulted from the previous discovery of just one far-reaching principle - that of transformation of energy. The second is the progress being currently made in the analysis of the vague teleological and vitalistic notions of "purpose" and "intelligence." Let us recall, at the risk of becoming repetitious, why the understanding of the living process presents difficulties. Living things seem to differ from non-living in three fundamental respects (immedi- ately apparent to the naive observer). 1 . They seem to be "autonomously" active (i.e. , the motive power seems to come from the inside rather than be impressed from the out- side as in the case of moving inanimate objects). 2. They seem to be guided by purpose and intelligence. 3. They maintain their integrity, grow, and reproduce. The first technological analogy (with the clockwork) attempted to explain only the first of these characteristics and it did so very poorly. A clockwork is, to be sure, activated from the "inside" for a while, but there is no question about what the source of this activation is. The clockwork simply gives a delayed response to a stress (a push) impressed on it. It is different with a heat engine. There is no obvious push there. The engine is fed in a very real sense and is activated by the food it "eats." The analogy to a living organism is in the case of a heat engine far from superficial. But the "muscular effort" of the engine is still externally directed. The locomotive is guided by the rails; the boat by the rudder. A simple engine is "told what to do" at every step</page><page sequence="10">Technological Models of the Nervous System 321 of the process. Here the analogy with the living organism fails. Now it is clear why the development of automata and servos naturally extends the analogy. The mechanisms of control are now built into the machine. We now want machines to behave "purpose- fully" and intelligently and since we have to design the machines, we have to analyze the notions of purposefulness and intelligence into component parts. Really no sharp distinction can be drawn between intelligence and purposefulness. Any definition of one is sure to involve the other. Let me therefore describe very roughly the present status of "intelligence" and/or "purposefulness" in our machines which will then naturally lead me to the concluding remarks on the modern ideas of the nervous system. I view "intelligent" machines as consisting of two kinds, automata and servo-mechanisms. The only distinction I make between them is that the automaton is guided by a program of discrete steps or directions fed into it, while the servo-mechanism is guided by observing the effects of its action on the outside world. Thus a juke box which plays a number of selections in the order selected by the customer (in response to the buttons pushed) is an automaton, and so is an electronic computer. A target-seeking torpedo, on the other hand, or a gyroscope, I would call a servo-mechanism. Both exhibit "purposefulness" and "intelligence," although if we adhere to the intui- tive popular meanings of these terms, the servo-mechanism seems to specialize in purposefulness and the automaton in intelligence. This seems so, because the automaton seems to be able to follow explicit directions, "When so and so, then so, unless so or so, in which case so ... " (the program), while the servo seems to be guided by a goal. This difference is only apparent. To an outsider, the automaton may well seem to be guided by a "goal" ("Find the solution of this equa- tion") while some one intimately familiar with the operation of a servo can describe its operation in terms of a program. This equivalence of "program" and "goal" is the principal idea of the modern theories of the nervous system. One point must be kept in mind, however. Program and goal may be logically equivalent, but it does not by any means mean that a description of an operation of an organism or a machine is equally convenient in terms of one or the other. Let us take a trivial example. We wish a ball in a cup to "seek" to come to rest at a particular point. Here the desired behavior of the ball is described in terms of a "goal," and nothing is simpler than to design a device which will exhibit just such behavior. Take a cup of any convex shape and place it so that the desired point is the lowest. To describe the same kind of behavior in terms of a "program" would necessitate an infinite number of statements, each of which tells which</page><page sequence="11">322 Et cetera â€¢ Fall 1983 way the ball is supposed to move if it finds itself in a particular posi- tion. Such a description in terms of discrete statements (an explicit program) is, of course, out of the question. A description of "inter- mediate complexity," howeve, can be given, namely, as a set of differ- ential equations of motion which imply a stable equilibrium at the desired point. Of the three descriptions clearly the first "stating the goal" of the ball is the simplest. What enables us to realize this "goal" by a mechanical device is our ability to see the problem as a whole. Similar considerations apply, I believe, to the theory of the nervous system. The first attempt to account for gestalt phenomena in strictly behaviorist terms was made by McCulloch and Pitts in 1943. They showed that any pattern of behavior which could be described by a program was realizable in an automaton of a specified construc- tion and (herein lies the importance of their idea) they gave an "algorithm" for the construction of the automaton based on the pro- gram. Automata, of course, operate on the same principle. The limita- tions of this approach, however, are immediately evident. The whole difficulty is to describe the action of the nervious system in terms of a program of discrete elementary steps. The task looks more hopeful if "goal seeking" steps are allowed in the description of the program. If, for example, the construction of a mechanism for keeping a certain muscle tone constant is known, one of the directions in the program may read, "Plug in that mechanism." Thus with one stroke an immense number of elemen- tary steps is "described." The value of information theory in this approach to the nervous system is now apparent. The McCulloch-Pitts picture represents behavior in terms of firing patterns of individual neurons. With 1010 neurons in the buman body, there are 210" such possible patterns at each instant of quantized time. This number is utterly unthinkable. Nothing whatsoever can be said of a system with that many distinguishable states where nothing is known about how the states are to be classified. To put it in another way, the amount of information per unit time needed to describe such a system is 1010 bits (the amount of informa- tion coming over an ordinary telegraph wire is considerably less than 5 bits per unit time) . It is quite another matter, however, when sub- systems are "organized" to work in prescribed ways, when touched off by proper signals. The amount of organization of such subassemblies reduces the amount of information necessary to transmit over the channels. This consideration leads to two complementary conclusions. Rigidity of behavior in organisms requires smaller capacities of channels over</page><page sequence="12">Technological Models of the Nervous System 323 which information flows. Contrariwise, greater channel capacities allow for greater flexibility of behavior. We are thus led to ideas of the nervous system which involve not minute blueprint structures (a hopeless approach because of the tremendous complexity of the nervous system) but which involve over- all statistical concepts such as channel capacity, storage capacity, and other parameters familiar to the modern communication engineer, such as redundancy, signal-to-noise ratios, etc. They are concepts analogous to the over-all concepts in terms of which the operation of the "muscle engines" is understood: power, efficiency, compression ratios, etc. It is the development of the corresponding over-all concepts of com- munication and complexity which made intelligent machines possible and which gives us promise of future understanding of living behavior, particularly of the functions of the nervous system. I need not, I hope, emphasize that none of these considerations are relevant to the question of whether thinking machines "really think." I admit I do not understand the question. The really pertinent ques- tion is whether similar abstractions can be utilized in both the theory of intelligent machines and in the theory of living behavior, particu- larly that governed by the nervous system. We know that both organisms and machines receive, transmit, store, and utilize information. The question of how information is "utilized" is particularly interesting. We now know what food is used for: three things, namely, as a source of heat, a source of locomotive and chemical energy, and a source of materials for growth and restoring worn-out tissues. All these elements are being constantly dissipated by the organism: heat by conduction and radiation, energy by motion, materials through break down and excretion. Can it be that besides energy in the form of food and sunlight, organisms also feed on something called "information," which serves to restore the order, which is constantly being dissipated in accor- dance with the Second Law of Thermodynamics? The formal mathematical equivalence between entropy (the measure of disorder in a physical system) and information (as defin- ed mathematically) was commented on by Shannon, Wiener, MacKay, and others. Can it be that this is no mere formal mathematical equivalence, such as obtains between an oscillating mechanical system and the analogous electrical one, but a more fundamental equivalence such as that between heat and energy or between energy and matter? Can it be that 1.98 calories per degree mole (the difference in entropy between two moles of two separated perfect gases and two moles of their mixture in equilibrium) is actually equivalent to 6.06 X 1023 bits of information - the amount it would take to separate the mix-</page><page sequence="13">324 Et cetera â€¢ FALL 1983 ture into the constituent parts in terms of yes-no decisions? If there is such a conversion factor, how do the information- receiving, information-transmitting, and information-storing organs operate to convert information into negative entropy or its concomi- tant "free energy" and, perhaps, vice versa? The intriguing nature of these questions has stimulated some of us to undertake the study of communication nets from the information- theoretical point of view. This approach necessitates the description of such nets not in terms of detailed structure but rather in terms of gross statistical parameters. The flexibility and far-reaching adapta- bility of of the behavior of higher organisms almost demands this sort of approach. Perhaps the most fundamental characteristic of living behavior as distinguished from that of man-designed machines is in the sacrifice of precision for safety. It is not important that a response be precise but rather than an equivalent response be given under a great variety of conditions or handicaps. It is more important to be "roughly" correct in practically every case than be "precisely" cor- rect in every case but one and altogether wrong in that one. It is necessary to relate totally new situations approximately to situations already experienced, and it is necessary to leave certain portions of the nervous system "uncommitted," so that new behavior patterns to meet new situations can be organized. When machines are built possessing these characteristics, we may expect an even closer analogy to the workings of actual nervous systems. That the day is not far off can be inferred from the fact that mathematicians like von Neumann already do not shirk from theoretical investigations aimed at throwing light on the most typical of life processes - reproduction. I am referring to his recent calculations on the number of elements required in an automaton which can not only perform specific tasks assigned to it but also is able to reproduce itself, given a mixed-up aggregate of its elementary constituents. An actual materialization of such a machine would, of course, give startling reality to the prophecy in Butler's Erewhon. Such is the state of the present studies, which are extensions of the technological analogies of the living process, particularly of the integrating functions of the nervous system. It is hoped that these studies are now approaching a level sufficiently sophisticated to yield enlightening and lasting results. NOTES AND REFERENCES 1. However, personification of weapons does occur. Note also the legend of the Sorcerer's Apprentice.</page></plain_text>
<plain_text><page sequence="1">Testing the Interactivity Model: Communication Processes, Partner Assessments, and the Quality of Collaborative Work JUDEE K. BURGOON, JOSEPH A. BONITO, BJÖRN BENGTSSON, ARTEMIO RAMIREZ, JR., NORAH E. DUNBAR, AND NATHAN MICZO Judee K. Burgoon is Professor of Communication and Director of the Center for the Management of Information at the University of Arizona. She is the author or coau- thor of seven books and nearly two hundred articles and chapters on topics related to interpersonal and nonverbal communication, deception and credibility, mass media, and new communication technologies. Her current research focuses on interactivity, adaptation, and attunement in communication. Joseph A. Bonito is Assistant Professor of Communication at the University of Arizona. His articles have appeared in Communication Yearbook and Computers in Human Behavior. His research interests include computer-mediated communication, small- group processes, message production processes, and research methods. Bjorn Bengtsson is a graduate student of computing science and cognitive science in the Department of Computer Sciences, Umea University, Sweden. His research deals with virtual communication - a cross-disciplinary area involving computer-medi- ated communication, human-computer interaction, and virtual reality. Artemio Ramirez, Jr., is a doctoral candidate in the Department of Communication at the University of Arizona. His interests include interpersonal communication and new technologies. Norah E. Dunbar is a doctoral candidate in the Department of Communication at the University of Arizona. Her research interests include interpersonal communication, relational conflict, and nonverbal communication in mediated contexts. She is cur- rently working on her dissertation on power in marital conflicts. Nathan Miczo is a doctoral candidate in the Department of Communication at the University of Arizona. His research interests include interpersonal communication. Abstract: A major consideration in designing and adopting new communication technologies is their impact on communication processes and outcomes. One way to understand this impact is according to the principle of interpersonal interactivity. Findings from two investigations are reported here that address how properties of task-related communication conducted with differing interfaces relate to perceptions Journal of Management Information Systems / Winter 1999-2000, Vol. 16, No. 3, pp. 33-56 © 2000 M.E.Sharpe, Inc. 0742-1222 / 2000 $9.50 + 0.00.</page><page sequence="2">34 BURGOONETAL. of interaction partners and the outcomes of their collaborative work. Study 1 manipu- lated the interface affordances of mediation, contingency, and modality richness. Study 2 examined the affordance of mediation. Results show that interfaces that promote higher mutuality and involvement lead to more favorable perceptions of partners' credibility and attraction, and those perceptions are systematically related to higher-quality decisions and more influence. Discussion focuses on the relation between user perceptions, design features, and task outcomes in human-computer interaction and computer- mediated communication. Key words and phrases: collaborative work, communication interfaces, computer- mediated communication, decision making, human-computer interaction, interactivity. Rapidly developing technology now affords individuals, organizations, and institutions of learning a cornucopia of options for communication and informa- tion exchange. Computer-mediated communication (CMC) is becoming ubiquitous in such text-based forms as e-mail and computerized group support systems as well as in multimedia forms such as Microsoft's NetMeeting, audio- and videoconferencing. Augmenting these is human-computer interaction (HCI), in which computer inter- faces, which come in a variety of guises (e.g., the Microsoft "office assistant"), con- duct part or all of a transaction with individuals. Through technological advances in voice recognition software, voice synthesis, and computer animation, interactions with these "intelligent" computer agents are becoming increasingly anthropomor- phic so that they, too, resemble interactions with humans. The accelerating adoption of these technologies has important ramifications for communication in work and educational contexts. Two central issues are (1) how various CMC and HCI interfaces affect the character of the communication process itself among users and (2) how resultant communication patterns affect such desir- able outcomes as positive interpersonal relationships among collaborators, accurate information exchange, and high-quality collaborative work. These issues are ad- dressed here via the principle of interpersonal interactivity (hereafter referred to simply as interactivity). This principle, elaborated momentarily, posits the (decep- tively) simple proposition that Human communication processes and outcomes vary systematically with the degree of interactivity that is afforded and/or experienced. To investigate the nature and consequences of interactivity, we have begun to decompose interactivity into its relevant properties and to test experimentally the individual and collective impacts of those properties. Reported here are two initial studies, one manipulating the properties of contingency, mediation, and modality richness in HCI and one manipulating mediation in CMC. The interface manipula- tions are reported elsewhere [3, 4, 8]. Our primary objective in this companion report was to ascertain how experiential qualities of interactive communication during</page><page sequence="3">TESTING THE INTERACTIVITY MODEL 35 collaborative tasks relate to users' judgments about partners and to task outcomes. We demonstrate that the degree to which users perceive high interactivity - reflected in indicators of interaction involvement and a multidimensional construct called mutuality - is strongly related to how positively users judge their partner's credibil- ity and attractiveness. In turn, we show that these assessments strongly relate to partner influence, decision quality, and accurate information exchange. The analy- ses offer insights into why various interfaces sometimes facilitate and sometimes impair group communication and accomplishments. Further, consistent with the prin- ciple that media and communication formats should be matched to such situational demands as the tasks to be performed, the group's well-being, and support for indi- vidual group members [16, 17], results offer guidance as to what facets of communi- cation processes contribute to achieving desired outcomes. Structural Affordances and Experiential Properties of Interactivity Some champions of new technologies argue that HCI and CMC will eventu- ally supplant face-to-face (FtF) communication in the workplace. Others are con- vinced that some level of FtF interaction must be retained, especially if tasks are complex, involve statistical information or sophisticated inferences and judgments, or depend on trusting and solid interpersonal relationships (see, e.g., [19, 30]). We believe that at issue is not FtF interaction per se but the properties of interactivity that are associated with FtF interaction. Our theoretical goal therefore is to decom- pose interactivity into its constituent properties. We begin with the assumption that interactivity is value-neutral: that is, the pres- ence of these qualities can be either beneficial or detrimental. For example, limited interactivity might undercut trust, enable undue influence by mediated sources, or produce more understanding and rapport among participants [34, 35]. High interactivity might be distracting, promote ready acceptance of dubious information, or facilitate idea generation. Deciding which communication formats - HCI, CMC, FtF - are most or least advantageous under what circumstances and why depends, then, on understanding the role of interactivity. Although the meaning of interactivity may seem self-evident, the term has been applied to widely divergent phenomena. One way to conceptualize interactivity is according to the structural properties, or affordances, that are present in a given communication format. Some of these distinctive features have emerged from analy- ses of various electronic media (e.g., [17, 25, 33, 36]). We began our analysis instead by identifying intrinsic properties of FtF communication that might be retained, supplemented, amplified, or suppressed in HCI and CMC formats (see [4, 13] for further elaboration). We theorize that these affordances individually and/or collec- tively account for observed differences in cognitions, communication, and outcomes observed across mediated and nonmediated, human-human and human-computer interaction. The various analyses of affordances can be integrated into an extensive set of properties. Chief among them are the following:</page><page sequence="4">36 BURGOONETAL. {.Participation (the extent to which senders and receivers are actively engaged in the interaction as opposed to giving monologues, passively observing, or lurking), 2. Mediation (whether the communication format is mediated or not), 3. Contingency (the extent to which one person's queries, responses, and com- ments are dependent on the prior ones of the cointeractant), 4. Media and information richness (whether the format utilizes one or more modalities such as text, audio, visual, or touch, and the extent to which it supports symbol variety to present "rich" or "poor" social information), 5. Geographic propinquity (whether users are physically colocated or distributed), 6. Synchronicity (whether interaction is same-time, which permits immediate bidirectional feedback, or asynchronous, which permits rehearsability and editability), 7 . Identification (the extent to which participants are fully identified, partially identified, or anonymous), 8. Parallelism (whether the format permits concurrent communication and mul- tiple addressees, as in the case of electronic brainstorming, or only permits serial messages), and 9. Anthropomorphism (the degree to which the interface simulates or incorpo- rates humanlike characteristics). A second way to conceptualize interactivity is according to the qualitative experi- ences that users equate with interactivity. These properties are what make a mode of communicating or information exchange look and feel interactive. These qualities can be conceptualized as the mediating communication processes through which structural properties exert their impact. Our theorizing about what properties create the experience of interactivity is in its early stages, but there are three that we believe are salient: I. Interaction involvement (the degree to which users perceive they are cognitively, affectively, and behaviorally engaged in the interaction), 2. Mutuality (the extent to which users perceive and create a sense of relational connection, interdependence, coordination, and understanding with one an- other), and 3. Individuation (the extent to which users perceive they have a rich, detailed impression of the other's identity and personalizing information). This report centers on the first two properties of involvement and mutuality. In the context of communication, interaction involvement concerns the extent to which users experience high cognitive, sensory, visceral, and motor engagement in an inter- action - that is, the interaction creates a sense of presence, of "here and now." Nonverbally, involvement may be expressed through such behaviors as close prox- imity, frequent eye contact, facial and vocal expressivity, coordinated conversation, attentiveness, fluent speech, and moderate relaxation. Verbally, it may be expressed through linguistic choices and personal disclosures [7, 15].</page><page sequence="5">TESTING THE INTERACTIVITY MODEL 37 Mutuality also has multiple facets. Among the essential preconditions for commu- nication to occur are a mutual other-orientation and belief in shared background (see [26]). Psychologically, mutuality may take such forms as feeling connected and similar to others. Cognitively and affectively, it may take the form of group members perceiving they share common meanings, are responsive to one another, and are understood. Behaviorally, it may take the form of users' actions being interdepen- dent and mutually influential and their verbal and nonverbal communication within and across episodes being coordinated and harmonized with others. An important objective in many interpersonal and group interactions is that col- laborators regard one another as competent, reliable, trustworthy, attractive, and use- ful contributors [2]. To the extent that greater involvement and mutuality lead to favorable judgments of credibility and attractiveness, they may also promote such outcomes as greater productivity, better decision making, and more accurate under- standing of messages that are exchanged. Hence, involvement and mutuality may have an indirect impact on other group outcomes by virtue of their direct impact on perceptions of group members. Figure 1 illustrates this hypothesized set of relationships. In our initial HCI experimental test [4], we hypothesized that FtF interaction and highly anthropomorphic computer interfaces would be more influential. Instead, we found the opposite: Computer agents using only text or text and voice (rather than still images or animated faces) achieved higher decision quality and were more influ- ential than human partners. In other words, creating highly anthropomorphic features yielded less influence and lower quality decisions. On social judgments, however, FtF interaction created more favorable perceptions of the partner's credibility than did the computer conditions, on average. These counterintuitive results led us to undertake the additional analyses reported here. Specifically, we tested the model in figure 1 by correlating ( 1 ) users' self-reported experiences of involvement and mutu- ality, (2) judgments of partner and/or format credibility, attractiveness, and utility, and (3) the outcomes of influence, decision quality, and accuracy. Relationship of Involvement and Mutuality to Partner/Format Assessments If participant involvement and mutuality are necessary (but not necessar- ily sufficient) preconditions for effective communication and group outcomes dur- ing collaborative work, then interfaces that enable greater involvement and mutual- ity between collaborators should promote attraction and credibility. Conversely, interfaces that are distracting, that create a sense of distance and detachment between participants, or that make users feel "unplugged" from the interaction may lead them to judge the partner or interface more harshly. Research on FtF interaction, for ex- ample, has shown that senders communicating under a high-participation format were perceived as more involved, dominant, pleasant, and believable [10], and par- ticipative receivers achieved greater understanding than did eavesdropping observ-</page><page sequence="6">38 BURGOON ET AL. ~ Social ~ . Processes ~ judgments Outcomes ~ . ^juTask attraction kr ~jt Influence | A Involvement k^" / ''/l Structural V ^ Credibility fc-~)(^ Decision qualità] affordances ' / 'ç x /v p Mutuality j^ ' /x'' ^*^ Utility f- qP| Accuracy | Figure 1. Hypothesized relationships among experiential properties of interactivity, social judgments of partners/format, and interaction outcomes ers [24]. These findings imply that involvement and mutuality relate systematically to social judgments and outcomes. It may seem peculiar to think of judging computers or computer agents in the same manner as humans. But computers, by virtue of their participation, functionality, and appearance, may be responded to in fundamentally social ways by users and are subject to the same kinds of communication evaluations that are commonly reserved for humans (e.g., [23, 28, 291). They may be thought of, for example, as more or less competent, engaging, or influential. Mass media research has demonstrated that people ascribe high credibility to the media (e.g., [20]). It may be that mediated communica- tion forms in general are accorded a positivity bias such that users assume whatever is delivered through a mechanical or electronic medium has already been authenti- cated and so is, defacto, regarded as credible. There is also evidence of credibility rising as a medium becomes "richer" in the sensory channels that are engaged and the amount of social information it supplies [31]. Relationship of Partner/Format Assessments to Task Outcomes A FAMILIAR THREAD IN COMMUNICATION RESEARCH IS THAT INTERACTION OUt- comes are often a function of the credibility and attractiveness of the source [9]. Credible and attractive sources are usually more persuasive. By the same token, users routinely base their satisfaction with new technologies on how useful and user- friendly they are. When the interface is a surrogate human, as is sometimes the case in HCI, then the utility judgment becomes basically another social judgment, much as one would judge how helpful a human partner is in achieving one's work objectives. The prediction that greater credibility and attraction foster influence, accuracy, and decision quality, although straightforward when applied to humans, may seem a bit strained when applied to computer agents. However, if one thinks about such appli- cations as search engines, web agents, filtering devices, and decision support systems (i.e., the kinds of tools that will surely become commonplace very soon), then the</page><page sequence="7">TESTING THE INTERACTIVITY MODEL 39 application may seem more plausible. For many kinds of communication transac- tions, users may neither need nor expect highly contingent interaction or the sense of social presence that multiple modalities are intended to afford [25]. Thus, it stands to reason that interfaces that are perceived as more useful, attractive, or credible should produce better outcomes on collaborative tasks. If this is true, then the higher decision quality, influence, accuracy of understanding, and credibility that Bengtsson et al. [4] found in text- and voice-based versions of HCI should be attributable partly to these mediating assessments. Conversely, formats or interfaces that are perceived as less user- friendly, believable, or attractive should be associated with lower-quality outcomes. Casting possible doubt on this prediction is the further Bengtsson et al. finding [4], in which the HCI conditions were, on average, more influential but also less credible than FtF interaction on judgments of truthfulness, sociability, and dynamism. Among the HCI interfaces, the text-only condition, rather than more anthropomorphic ones, received the most consistently favorable ratings. This raises the possibility that credibil- ity might be unrelated or negatively related to interaction outcomes in the special case of HCI. If so, when selecting or designing interfaces, might one achieve gains on influ- ence and decision quality at the expense of positive regard for coactors, or vice versa? The answer to this question resides in the correlations among the credibility and attraction dimensions and the other outcome measures. We reasoned that there might be enough variability within and between HCI conditions that, despite the mean ratings between conditions not comporting with the predicted association between credibility and attraction on the one hand, and influence, decision quality, and accu- racy on the other, those individuals who judged the partner or interface to be compe- tent, trustworthy, dependable, and useful might be more influenced by their partner than those who held their partner or the interface in low regard. Put differently, analyses conducted at the individual level, via correlations, might reveal patterns that had failed to emerge at the between-groups level due to heterogeneity within and across the HCI modalities. We also anticipated that the gain in statistical power achieved by examining data from all seven conditions might pay dividends in terms of achieving more statistically reliable findings. Experimental Tests: Study 1 Method Participants and Confederates Details of the method and experimental conditions are given more fully in [4].1 In brief, participants (N= 70) were male undergraduate students in the social sciences at Umea University, Sweden, who were paid approximately $10 (100 Swedish crowns) to engage in a study of alternative problem-solving methods. Participants were ran- domly assigned to one of seven experimental conditions in which they conducted a decision-making task with a human or computer partner. Two male confederates served as the human partners.</page><page sequence="8">40 BURGOONETAL. Experimental Conditions and Procedures The experimental conditions varied the "humanness" of the partners with whom participants were paired. In the five computer conditions, which ranged from a text- only interface to a human-like image with synthesized speech and matching lip synchronization, the computer output was preprogrammed. In the remaining two FtF conditions, human confederates presented the same scripted responses as in the HCI conditions but either adhered strictly to the script (noncontingent interaction) or interacted "freely" (i.e., in a normal, contingent turn-taking fashion) while still intro- ducing the same information supplied in the script. The task - the Desert Survival Problem - asked participants to imagine that their jeep has crashed in the Kuwaiti Desert, with no sign of potable water but some salvageable items from the wreckage. They then rank-ordered twelve items for their survival value (e.g., a gun, matches, a flashlight, a magnetic compass). This task was selected because it allows a fair amount of experimental control while still approxi- mating features of normal conversation. Unlike some tasks that would stretch credu- lity among computer-savvy participants, it is also amenable to use in both HCI and CMC contexts (as well as immersive virtual environments, where additional exten- sions of the work are being conducted). This same task was used in Study 2. In Study 1, participants first completed their own rankings of the twelve items then interacted with their partner (computer or human). During this task discussion, par- ticipants and confederates (human or computer) alternated giving their rankings and reasons on each of the twelve items. Unbeknownst to the participants, confederate rankings and reasons were based on ones arrived at previously by groups of experts. Participants then reranked the items and completed a survey instrument that queried them about their partner and the interaction itself. The instructions, description of the Desert Survival Problem, initial rankings, postrankings, and all other postmeasures were collected on the World Wide Web via a Macintosh computer. Interaction Measures To measure interaction involvement, participants rated perceived involvement with two Likert- format items taken from Burgoon and Hale's [11] Relational Communication Scale (coefficient alpha reliability = 0.71). To capture the range of possible perceptions that might correspond to mutuality, participants also rated partners on receptivity and similarity subscales from the RCS (reliabilities = 0.64 and 0.87, respectively). To these measures were added Aron, Aron, and Smollan's [1] pictorial instrument, which uses seven increasingly overlapping circles to depict degrees of perceived connect- edness and fifteen items from Cahn and Shulman's [14] Feelings of Understanding/ Misunderstanding Scale (reliability = 0.80). To further facilitate interpretation, these measures were also all averaged together to create an overall mutuality score. Social Judgments and Outcome Measures Assessments of the partner and format were created from several previously validated measures, including utility and liking scales from [28]; credibility and dominance</page><page sequence="9">TESTING THE INTERACTIVITY MODEL 4 1 measures found in [12, 32]; and an attraction measure reported in [27]. In the original Bengtsson et al. study, these scales were utilized to measure utility, six dimensions of credibility, and task attraction. However, to reduce multicollinearity and increase interpretability, we used principal components factor analysis with varimax rotation to reduce these data to a smaller subset of composite measures. The composites were created by averaging the unit-weighted items. The factor analysis on the semantic differential items produced five measures - dominance, expertise, dependability, sociability, and trust - with respective reliabilities of 0.66, 0.82, 0.87, 0.74, and 0.71. Dominance was comprised of the qualities of dominant, confident, and energetic. Expertise incorporated such attributes as expertise, competence, and experience. Dependability combined elements of the character and competence dimensions of credibility with format qualities related to utility; it included such attributes as reli- able, helpful, clever, useful, intelligent, and efficient. Sociability combined being sociable and friendly. Trust was measured by such attributes as truthful, trustworthy, high character, and very credible. Task attraction was measured separately because it utilized a Likert format. It included the partner showing the participant different ways to view the situation, approaching the task with professionalism, being satis- fied with the partner's contribution and enjoying working with the partner. Decision quality, absolute influence, and relative influence were calculated from participants' rankings of the salvaged items prior to interaction ("prerankings") and following the interaction ("postrankings"). Decision quality was measured as the mean absolute discrepancy between participant and confederate (expert) rankings on the twelve items. A small score thus indicates high decision quality, that is, close correspondence to the expert rankings. Influence was computed as the distance par- ticipants moved toward the confederate's position by calculating differences be- tween (a) each person's preranking and partner preranking and (b) each person's postranking and partner postranking. A large score reflects a substantial shift. Three measures were utilized to tap actual understanding. Accuracy of recall was assessed by asking participants to record the partner's ranking for the three top-ranked and three bottom-ranked items. It was scored as number of correct matches. Deviations from partner ranking fthe absolute distance from actual partner ranking) were also calculated to capture close but not perfect matches. A small distance indicated high accuracy. Content understanding was measured by asking participants to paraphrase what they believed to be their partner's position and reasoning on the six middle-ranked items (selected because they might be less obvious and less biased by subjects' own preferences). These responses were rated by two independent coders (interrater reliabil- ity r = 0.92). Individual ratings were averaged to produce a single score. Results Correlation Analysis Table 1 presents the correlations among involvement, mutuality, and partner/format assessments. The correlations between involvement and social judgments strongly</page><page sequence="10">42 BURGOONETAL. Table 1. Correlations of Involvement and Mutuality with Credibility, Utility, and Attraction Judgments, Study 1 Mutuality: Mutuality: Mutuality: Perceived Feeling Mutuality: Involvement Similarity Receptivity Understood Connectedness Credibility/utility Dominance 0.249* 0.212* -0.180 -0.108 -0.050 Expertise 0.291** 0.027 0.104 0.165 -0.073 Dependability 0.446** 0.413** 0.086 0.230* 0.180 Sociability 0.175 0.226* 0.229* 0.291** 0.258* Trust 0.440** 0.258* 0.027 0.142 0.011 Task attraction 0.375** 0.341** 0.252* 0.180 0.170 */7&lt;O.O5; **/?&lt;0.01. supported predictions both in terms of the number of significant correlations and the magnitudes of the correlations. Involvement correlated positively with dominance, expertise, dependability, trust, and task attraction (i.e., all dimensions except socia- bility). Thus, partners perceived as more involved were judged as more credible and attractive to work with. Mutuality was also positively associated with credibility and attraction. The more participants felt their partners were similar to them, the more they rated the partner as reliable, useful, friendly, dominant, trustworthy, and attrac- tive to work with. The more they saw the partner as receptive and understanding, the more they judged the partner as friendly, dependable, and/or task-attractive. And the more they felt connected to the partner, the more they liked the partner. Table 2 presents the correlations among all of the foregoing measures and the outcome variables. Involvement and mutuality had more limited direct effects on outcome measures. Involvement was unrelated to decision quality, influence, or ac- curacy of understanding. Of the mutuality measures, similarity was positively associ- ated with decision quality: Those who felt more similar to their partner selected rankings closer to those advocated by their partner (which were the expert rankings). Receptivity was also associated with understanding but negatively so - that is, those who perceived their partner as most receptive to their own viewpoints actually had the least accurate recall of the content of the partner's arguments. Mutuality, then, had a positive impact when it took the form of the participant being influenced by the partner to adopt the expert-based rankings, but it had a detrimental impact when it took the form of participants feeling their own inexpert judgments held sway with their partner. Comparatively, outcomes were far more affected by credibility, utility, and attrac- tion (which were themselves affected by the qualities of the communication process). The strongest relationship was with the combined dependability and utility measure. Participants achieved the highest decision quality, the most accurate recall of partner's rankings (i.e., the smallest deviations from correct answers), and the most accurate understanding of the content of partner's messages when they interacted with a part-</page><page sequence="11">TESTING THE INTERACTIVITY MODEL 43 Table 2. Correlations of Involvement, Mutuality, and Social Judgments with Outcome Measures, Study 1 Decision Accuracy: quality deviation Accuracy: deviation: from total Accuracy: Relative from best correct correct content influence solution answers answers understanding Involvement 0.079 -0.043 -0.083 0.059 0.144 Mutuality Similarity -0.027 -0.229* -0.048 0.090 0.146 Perceived receptivity 0.148 -0.099 0.051 0.011 -0.221* Feeling understood --0.095 -O.100 -0.131 -0.179 0.093 Connectedness -0.102 0.036 0.176 -0.135 0.026 Credibility/utility Dominance 0.046 -0.010 -0.093 -0.108 0.054 Expertise 0.183 -0.098 -0.339** -0.054 0.419** Dependability 0.217* -0.229* -0.296* 0.210 0.218* Sociability 0.060 -0.196 -0.099 0.205 -0.003 Trust 0.083 -0.115 -0.284* -0.040 0.252* Task attraction 0.449** -0.508** -0.065 0.069 0.040 *p&lt; 0.050; **/?&lt; 0.010. ner or interface that they judged to be useful and reliable. In addition, participants were more accurate in processing and understanding the information exchanged if the partner or interface was viewed as trustworthy and expert. Finally, participants who found the partner or computer agent more attractive to work with were more influenced by the partner and moved closer to the partner's recommended rankings. Overall, judgments related to utility and dependability were particularly valuable in discriminating more from less successful task outcomes. Judgments related to expertise, trust, and task attractiveness also were associated with outcomes, making these measures helpful in predicting which interfaces were most beneficial. By con- trast, judgments related to the sociability or dominance of the interface or partner had no association with outcomes. In other words, whether or not the interface was judged as friendly and dominant made no difference to how well the participant processed information, was influenced, or arrived at a high-quality decision. Comparisons Among Conditions Given that mutuality had some relationship to outcome measures and both involve- ment and mutuality related to social judgments, it becomes useful, first, to consider which interfaces are most or least likely to promote involvement, mutuality, and resultant positive social judgments. Insights can be gleaned from the mean ratings for the seven experimental conditions, which are displayed for all variables in Table 3. It should be noted that high scores for influence indicate that participants shifted their attitudes in favor of the position advocated by the partner; low scores on decision</page><page sequence="12">44 BURGOONETAL. Table 3. Means for All Measures by Condition, Study 1 Condition text+ text+ text text+ voice voice+ voice+ FtF, non- FtF, only voice +still animation animation contingent contingent Involvement 5.35 4.75 5.45 5.60 5.10 5.40 4.70 Mutuality Similarity 3.47 3.90 3.53 3.83 3.97 3.40 3.80 Receptivity 2.70 2.90 2.00 2.70 2.90 2.50 3.80 Feeling underst. 0.62 0.74 0.47 1.09 1.19 .62 1.55 Connectedness 1.80 2.10 1.80 2.40 3.00 2.40 3.20 Credibility Dominance 5.23 4.47 4.63 4.85 5.10 4.65 4.93 Expertise 4.62 4.32 4.55 4.72 4.58 4.08 5.05 Dependability 4.84 4.68 4.95 4.99 5.36 4.85 5.04 Sociability 4.60 4.05 3.75 4.05 4.10 4.65 5.10 Trust 4.78 4.73 4.85 4.90 5.20 4.83 5.13 Task attraction 4.68 4.96 4.61 4.88 5.29 4.04 4.40 Influence Relative influence 0.20 0.26 0.24 0.21 0.23 0.22 0.12 Decision quality 3.14 2.87 3.23 3.24 3.15 3.34 3.54 Accuracy Deviation from correct ans. 5.70 5.10 5.20 5.80 5.10 4.30 Total correct ans. 3.00 3.00 3.40 3.50 2.80 3.30 Content recall 4.80 5.00 5.10 5.18 4.88 5.08 quality represent smaller distances from the "best" decision; and low scores on devia- tions from the correct answers represent higher accuracy. Statistical tests parallel to those conducted in [4] were conducted on the involve- ment, mutuality, and new social judgment measures. Although the means for involve- ment are suggestive of participants finding interactions with computer partners equipped with voice and animation as the most involving, statistical tests failed to establish significant differences among conditions. Contrast tests conducted between contingent FtF and the combined HCI conditions did, however, produce significant differences (with one-tailed probability levels) for three measures: feeling under- stood t(63) = 2.17,/? = 0.03; perceived receptivity i(63) = 2.59,/? = 0.01; connected- ness t(63) = 1.73, p = 0.045. FtF interaction created more sense of receptivity, connection, and being understood than the HCI conditions. Among the HCI condi- tions, adding animation also increased mutuality on two of the same measures: feel- ing understood f(63) = 1.88, p = 0.03, and perceived connectedness f(63) = 1.73, p = 0.045. By contrast, the addition of the still image reduced rather than enhanced perceived receptivity, t(26.5) - -1.86, p &lt; 0.10.2 Thus, the addition of dynamic, hu- manlike qualities to the interface created greater connectedness and felt understand- ing with the partner, but simply adding a fixed facial image (as might occur with</page><page sequence="13">TESTING THE INTERACTIVITY MODEL 45 avatars) detracted from mutuality. Among the FtF conditions, the loss of contingency significantly reduced mutuality on two measures: feeling understood ¿(63) = 2.16, p = 0.03; receptivity f(63) = 2.24, p = 0.01 . In sum, mutuality (but not involvement) was greater with contingent FtF interac- tion and with dynamic, anthropomorphic computer interfaces; it was jeopardized by reducing contingent responses between partners or by interjecting a fixed image. As for social judgments, the strong associations between outcome measures and the social judgments of dependability/utility, expertise, trust, and task attraction make the analyses on these measures most instructive. Of these dimensions, only expertise yielded statistically significant differences. Contingent FtF interactions, which earned the highest rating on this measure, conferred greater expertise on part- ners than did noncontingent responding, t(63) = 2.21, p = 0.03. Other suggestive differences are also worth noting for future research because they might become statistically significant with a larger sample size and more powerful tests. Within the HCI conditions, highest ratings on dependability/utility and trust went to the text+voice+animation interface, which was also rated highest on task attraction. Lowest ratings tended to be given to the text+voice interface, or text+voice+still image, or the noncontingent FtF partner, but no single interface was consistently the lowest. Although sociability and dominance were not strongly associated with outcomes, they did differ by condition. On average, humans engaged in contingent FtF interac- tion were seen as far more sociable than computer agents, f(63) = 2.82, p &lt; 0.01, and adding voice to text made the computer partner seem less dominant, t(63) = -1.77, p = 0.04. Put differently, computer agents suffered relative to humans in terms of being friendly, and they were seen as most dominant in the text-only interface (fol- lowed closely by the text+voice+animation condition). Discussion This first study was undertaken to see if interrelationships among the interactive qualities of involvement and mutuality, social judgments, and task outcomes would provide insights into the findings from [4]. It will be recalled that Bengtsson et al. showed that structural properties of interactivity exert direct impact on interaction outcomes. Participants were more influenced by computer agents than human part- ners, yet humans scored higher than computer partners on select credibility dimen- sions. Although not statistically significant, there were also indications of higher decision quality with the HCI interfaces, especially the least anthropomorphic ones, but more acurate recall with human interaction. These results implied that different pro- cesses were at work in accounting for influence and decision quality as opposed to credibility and recall and that these processes might not be working uniformly within each interface, thus making it important to delve into the processes themselves. The current results begin to explain those processes. They reveal that influence, decision quality, and information processing accuracy are partly a function of the experiential properties of interactivity (i.e., involvement and mutuality) and partly a function of the social judgments that are activated. Consistent with the model ad-</page><page sequence="14">46 BURGOONETAL. vanced here, properties of interactivity largely exert indirect rather than direct influ- ence on task outcomes by affecting social judgments. Achieving desired outcomes, then, depends to some extent on the level of interactivity that participants experi- ence as well as the structural properties that various interfaces afford. Consider first the impact of involvement. If partners were viewed as interested and engaged, they were more likely to be judged favorably on dependability, expertise, dominance, trustworthiness, and task attraction. Higher perceptions of dependability in turn were associated with more influence, better decisions, and higher accuracy; favorable judgments of expertise were associated with more accuracy; and favorable judgments of task attractiveness were associated with more influence and better decisions. Interfaces that promote involvement, then, are likely to be ones that gener- ate not only more favorable social judgments but also better task outcomes. Which interfaces do so? Curiously, none emerged as consistently superior or infe- rior, although the voice+animation condition earned the highest rating. It is possible that the novelty of interacting with a computer agent, combined with its perceived dynamism, made this condition especially involving. But apart from the specific interfaces tested here, the very strong relationship of involvement to social judg- ments and task outcomes signifies the importance of this aspect of interaction being taken into consideration in designing and selecting interfaces. Next, consider the role of mutuality, which was indexed by four different measures. The first is similarity. The more participants viewed themselves as similar to their partner, the more they rated the partner and/or interface as attractive, useful, and credible on all measures except expertise. This relationship can also be viewed in the converse: The more dissimilarity that participants perceived, the less attractive, cred- ible, and useful they found the partner or interface. This suggests that anthropomor- phism at some level may be beneficial when the objective is to maximize favorable social judgments and to derive the task benefits that these judgments promulgate. However, if the main concern is conveying expertise, then similarity is an unneces- sary consideration. As for which interfaces would be most or least likely to foster similarity, there was more variability within than between conditions, so that no definitive claims can be made about the specific interfaces used here. Some of the perception of similarity may be a function of individual differences rather than sys- tematically related to interface affordances. Still, the significance of similarity in promoting or inhibiting key social judgments makes further exploration of similarity worthwhile. The second measure of mutuality, receptivity, had weaker associations with social judgments. It only correlated positively with sociability and task attraction and actually correlated negatively with accurate understanding. Since sociability was unrelated to task outcomes, and the goal is usually to achieve more rather than less understanding, one might conclude that giving the impression of receptivity to the partner is inconsequential or even undesirable. Such a conclusion wouid be war- ranted unless one was concerned with generating positive long-term relationships and high morale among users. Under such circumstances, creating perceptions of friendliness among users might be the objective in itself, in which case receptivity</page><page sequence="15">TESTING THE INTERACTIVITY MODEL 47 could be valuable. Which interfaces created the most perceived receptivity? Contin- gent face-to-face interaction. Thus, FtF communication might be indispensable for purposes of creating and maintaining social relationships. The least receptivity was fostered by the noncontingent FtF condition. If this finding is generalized to medi- ated forms of interaction, it suggests that noncontingent formats such as broadcast messages or noncontingent computer agents may be least helpful in promoting good interpersonal relationships. The third measure, feeling understood, was positively associated with dependabil- ity and sociability. Like similarity, interfaces that promote this form of mutuality will gain the benefits of influence, decision quality, and accuracy that come with in- creased credibility and utility. Given that feeling understood was highest in contin- gent FtF and animated HCI conditions and lowest under noncontingent FtF interaction, interfaces most likely to engender feelings of being understood are those that are contingent, anthropomorphic, and/or unmediated. The final measure, connectedness, correlated only with sociability and hence might be dismissed as less important than the other aspects of mutuality. However, the fact that it was a single-item measure with a restricted range may have limited the ability of statistical tests to find strong associations. A sense of connection with the partner was strongest under contingent FtF interaction and in HCI conditions that included the animated face and synthesized voice, that is, those that were more anthropomorphic. Achieving humanlike qualities in the interface, then, has benefits in terms of enhancing mutuality and positive views of the partner as sociable and friendly. As for the relationships of the new social judgment composite measures to task outcomes, the correlation results revealed that dependability, expertise, trust, and task attraction had the strongest associations with task outcomes. The implication is that these judgments about partners and interfaces are especially key in predicting outcomes such as influence, decision quality, and accuracy of information process- ing. Creating circumstances in which these judgments are maximized should have payoffs in terms of maximizing desired outcomes. Conversely, information and com- munication formats that undermine these judgments should have adverse effects on task outcomes. One somewhat inexplicable finding was that judgments of expertise were unre- lated to influence; they were only related to accuracy. This might seem to challenge our argument that the reason computer agents are more influential than human part- ners is that users attribute more credibility to media and computers. We are not prepared to abandon this explanation just because our measure of expertise failed to predict influence. For one, it is possible that the wording of our expertise measure was insufficient to capture the authoritative status that we believe users ascribe to mediated communication forms. The adjectives used in our measure - experienced, expert, competent, insightful, responsible - may have been inadequate to capture the sense of the computer agent as infallible and being the ultimate authority. Or the wording may have seemed peculiar to apply to computers. Anecdotal reports from our labora- tory assistants indicated that some users had difficulty applying such judgments to</page><page sequence="16">48 BURGOONETAL. computers in similar tasks. This suggests that these scale items may not have been the ideal choices for judging computers as opposed to humans. Alternatively, these facets of computer credibility may have been better captured in the dependability measure, which included such attributes as intelligent, reliable, and useful. One might almost think of these as "quality assurance" characteristics, hence our choice of the label of "dependability." These may be the characteristics that make computers highly credible. And the dependability measure was the one that predicted all three outcomes of influence, decision quality, and accurate infor- mation processing. This set of associations thus offers confirmation for our theoriz- ing that users treat computer agents as having the most accurate, valid information, which may account for why users defer to the judgments computers offer. As noted in [4], this process of deferring to computers may be beneficial when the objective is to have users place high trust in the information they receive via mediated delivery systems. The downside is that users may fail to make critical judgments of informa- tion and arguments, leading to poor and potentially disastrous decision making. To the extent that humans mindlessly accept whatever information is presented via computer agents, the design and implementation of these technologies must be un- dertaken with great discretion and caution. No single investigation should ever be regarded as definitive, especially when dealing with novel technologies tested in single encounters. The next investigation therefore was intended to replicate the same task and measures but under conditions of CMC between human partners. Experimental Tests: Study 2 Study 2 was designed to examine human-human interaction under medi- ated and nonmediated conditions. Because the noncontingent FtF condition in Study 1 had created interaction patterns that were unnatural and unrealistic, it was elimi- nated in Study 2. In its place, we created an offset control group in which two naïve participants conducted the same task face-to-face. This condition was intended to serve as a benchmark for how users would conduct and experience this task when permitted to interact freely in the absence of experimental controls on the communi- cation process itself. The other two conditions represented contingent, unmediated FtF interaction and contingent CMC among colocated participants, respectively. Like computerized group support systems, the latter condition retained the proxim- ity of FtF interaction but introduced mediation in the form of text-based interaction. Participants sat beside one another but could not talk during completion of the task. Participants and Confederates Participants (N = 68: 34 males, 34 females) were undergraduate students recruited from organizational communication courses that are largely populated by business and public administration students. They were compensated with class credit in</page><page sequence="17">TESTING THE INTERACTIVITY MODEL 49 exchange for their participation. Confederates were one male and one female under- graduate student in communication who were of similar age and attractiveness. The confederates received extensive training and conducted numerous practice sessions to insure that they maintained consistency in verbal and nonverbal performance between themselves and across sessions. Experimental Conditions and Procedures The experimental task, instructions, and measures were identical to those from Study 1, except that the accuracy data were not obtained due to a programming malfunction in the sequencing of the Web pages. All task instructions, the description of the task, and pre- and postinteraction questionnaires were delivered via an IBM computer. Upon arrival at the experimental site, participants entered a waiting room where they filled out consent forms, were given preliminary information regarding the experi- ment, and were introduced to a same-sex partner. Participants were randomly as- signed to ( 1 ) the face-to-face control group, in which two naive participants con- ducted the task orally and face-to-face, with no restrictions placed on the content, pace, or length of interaction; (2) contingent face-to-face interaction, in which par- ticipants were paired with a same-sex confederate who followed the script as closely as possible but was given the latitude to respond to questions, concerns, or digres- sions initiated by the participant; or (3) computer-mediated communication, in which participants were paired with a confederate and conducted the discussion via a syn- chronous Windows-based online chat program. Confederates followed the script closely but were allowed to respond quickly and relevantly to contingencies initi- ated by the participant. Participants and partners were seated at a table in front of a small computer terminal and keyboard. Computers and chairs were positioned obliquely toward one another so that interactants could see one another easily but were still visible frontally through the one-way mirror (to enable videotaping of their interactions, with their consent). The computers were angled so that neither the confederate nor the participant could see each other's terminal. Interactants read the Desert Survival Problem and con- ducted initial rankings on their respective computers (see Study 1 ), then discussed the problem face-to-face or via the chat program. Following discussion of all twelve items, participants completed the Web-based questionnaires; confederates feigned responding so as to conceal their true roles. Participants were then debriefed and thanked for their participation. Interaction and Partner Assessments and Outcome Measures The same measures were used as in Study 1, with these exceptions: The utility items asked specifically about the partner's helpfulness and so were clearly associated with the partner rather than the format, and recall data were not collected, so there was no measure of accuracy. Factor analysis was again used to form composite measures. The resultant measures and their reliabilities were: involvement, 0.71; similarity, 0.93;</page><page sequence="18">50 BURGOON ET AL. feeling understood, 0.93; receptivity, 0.55; dominance, 0.70; dependability, 0.91; expertise, 0.73; trust, 0.80; sociability, 0.84; task attraction, 0.82. Relational con- nectedness was a single-item measure.3 Results Correlational Analyses Table 4 shows the correlations among the interactivity variables of involvement and mutuality on the one hand and social judgments of credibility and attraction on the other. As predicted, involvement and mutuality were positively correlated with so- cial judgments. Greater involvement corresponded to more favorable judgments of the partner's expertise, dependability, sociability, dominance, and task attractiveness (but not trust). Greater mutuality corresponded to more favorable judgments of the partner's expertise, dependability, trustworthiness, sociability, and task attractive- ness (but not dominance). Table 5 shows that the primary variables directly affecting the outcome measures of influence and decision quality were dominance, expertise, and task attraction. Partners perceived as more dominant, expert, and attractive to work with were the most influential and moved the participant toward the "best" decision. Also, higher involvement contributed to being influential. Thus, the model we proposed was supported. Involvement and mutuality exerted strong impact on social judgments and ensuing task outcomes. The experiential aspects of inter- activity - involvement and mutuality - were less likely to affect outcomes directly than indirectly, although involvement directly affected influence. Comparisons Among Conditions To compare text-based CMC with FtF communication, planned comparisons were conducted between the experimental groups and the control group and between the FtF and CMC experimental conditions on all measures. Means appear in Table 6. In addition to the previous finding of the experimental groups achieving more influ- ence and high-quality decisions than the control group [8], experimental partners were judged as more dominant than control group partners, ¿(64) = 2.04,/? = 0.04. The comparison between the CMC and FtF experimental conditions produced no signifi- cant differences on involvement, mutuality, and credibility but did produce one on task attraction, t(64) = -1 .99, p = 0.02. CMC earned higher ratings. Thus, not only did the CMC condition not suffer on interpersonal judgments related to involvement, mutuality and credibility, it gained ground on task-related perceptions. Discussion The second study extended the first by examining the experiential properties of interactivity in a CMC context. Much like Study 1, examination of correlations revealed that important features of interactivity, including mutuality and involve- ment, operate as expected across CMC and FtF conditions. Social judgments were, in</page><page sequence="19">TESTING THE INTERACTIVITY MODEL 5 1 Table 4. Correlations of Involvement and Mutuality with Credibility and Attraction Measures, Study 2 Mutuality: Mutuality: Mutuality: Connected- Mutuality: Feeling Overall Involvement Similarity ness Receptivity Understood Mutuality Dominance 0.391** 0.028 0.169 0.100 0.149 0.119 Dependability 0.300** 0.533** 0.485** 0.398** 0.461** 0.604** Expertise 0.414** 0.384** 0.232* 0.313** 0.409** 0.461** Sociability 0.289** 0.304** 0.394** 0.378** 0.366** 0.418** Trust 0.125 0.412** 0.423** 0.176 0.304** 0.450** Task attraction 0.455** 0.070 0.093 0.533** 0.249* 0.354** */7&lt;O.O5; **/7&lt;0,01. Table 5. Correlations of Involvement, Mutuality, and Partner Assessments with Influence and Decision Quality, Study 2 Influence Decision quality Involvement 0.211* -O.051 Mutuality Similarity -0.078 0.003 Connectedness -0.089 0.004 Receptivity 0.070 -0.015 Feeling understood -O.021 -O.031 Overall mutuality 0.01 1 -0041 Credibility/utility Dominance 0.261* -0.275* Dependability 0.106 -0.150 Expertise 0.262* -O.207* Sociability 0.000 -0.042 Trust -0.025 0.01 1 Task attraction 0.367** -0.266* */7&lt;O.O5; **/?&lt;0.01. turn, positively related to task outcomes; more credible and more involved partners were more persuasive. Finally, comparisons between FtF and CMC conditions re- vealed that only task attraction was significantly different, with the CMC condition rated higher than FtF interaction. One might speculate that the physical proximity of partners offset any negatives associated with being unable to talk. Also, the novelty of the CMC condition may have contributed to its attraction - participants are unlikely to have experience with proximal, synchronous chat situations. But this is not unimportant when one consid- ers that task attraction is positively associated with several features of mutuality, which in turn are related to task outcomes. These results are suggestive, if one's interest is in first increasing mutuality among participants. Since task attraction might be greater for novel modalities, one way to create a sense of mutuality is to</page><page sequence="20">52 BURGOON ET AL. Table 6. Means and Standard Deviations for All Measures, by Experimental Condition, Study 2 Condition Face-to-face, Face-to-face, Face-to-face, unmediated mediated text unmediated experimental experimental control group group group Mean S.D. Mean S.D. Mean S.D. Involvement 5.84 1.10 5.67 1.13 5.78 1.46 Mutuality similarity 4.13 1.40 3.96 1.52 4.12 1.28 connectedness 4.00 1.46 3.40 1.64 4.10 1.74 receptivity 5.67 0.91 5.38 1.16 5.37 1.44 feeling understood 2.13 1.06 1.75 1.24 1.72 1.30 overall mutuality 4.34 0.80 3.96 1.19 4.19 0.96 Credibility dominance 4.51 1.13 4.93 0.70 5.03 0.73 dependability 5.45 0.83 5.45 0.73 5.59 1.01 expertise 5.05 0.70 5.04 0.67 5.29 0.82 sociability 6.05 0.81 5.70 0.92 6.08 0.80 trust 5.45 0.81 5.20 0.84 5.57 0.72 Task attraction 5.04 1.09 4.91 1.43 5.73 1.24 Influence 0.05 0.25 0.25 0.19 0.23 0.38 Decision quality 3.53 1.35 2.96 1.34 2.98 1.50 have participants first interact via an unfamiliar medium. Once mutuality is estab- lished, other kinds of media may then be incorporated, ones that are more conducive to producing desirable instrumental outcomes. Of course, interfaces such as comput- erized group systems that can be used with colocated participants may be one of the rare options in which mediation still entails other properties of interactivity. The preceding speculations aside, these results bolster the model of interactivity as applied to mediated communication. It is clear that many of the processes associated with communication in general work in similar ways across media. The interesting question concerns the comparability of mediated and FtF interaction (excluding the control group). Each seems to provide the affordances associated with interactivity in relatively equal ways. This is likely due to the fact that the experimental condi- tions had much in common. Communication in each was synchronous, proximal, and provided a sense of rhythm to the interaction (in the sense that one could hear the speed and force with which his or her colleague typed). In fact, the main difference between the two conditions was that participants could speak in one and could not in the other. The conclusion is that speech (and some of its relevant nonverbal charac- teristics) is not always necessary to provide optimal conditions for interactivity as long as other features of FtF interaction are maintained. This finding is important for systems that support real-time interaction. Group</page><page sequence="21">TESTING THE INTERACTIVITY MODEL 53 support systems, for example, are designed specifically to facilitate efficient group interaction by removing factors responsible for "process loss," thus forcing the group to consider ideas, issues, and solutions rather than the people who produce them. It does, in a sense, remove some aspect of the "human moment" that Hallowell [19] argues is, and ought to remain, an important feature of interaction. However, since the interaction is proximal, synchronous, and rhythmic, group support systems may well preserve features of interactivity that in turn allow for members to be influential and for members to build and maintain positive social relationships. General Discussion and Summary New technological innovations, while opening up entirely new forms and arenas for communication, carry potential risks of misunderstandings, distrust, and poor decision making if used without regard to their suitability to different goals and tasks or their impact on interpersonal relationships between users. Conversely, they may achieve unanticipated benefits if users creatively adapt them to meet their own and their organization's objectives. The pair of studies presented here offers some insights into these issues by examin- ing how aspects of interactivity relate to user perceptions and those perceptions relate to task outcomes. As designers build systems that amplify or attenuate specific characteristics of interactivity, they will be well advised to consider which properties achieve outcomes that are most desirable for both providers and users. For example, anthropomorphic interfaces and interfaces that support mutuality would have an advantage if successful task achievement depends on users collaborating to pool and judge critical information. Such interfaces would seem appropriate for building trust and strong interpersonal relationships because respondents tend to rate their partners and interactions higher when more human features are provided. To date, these inter- faces are still an unachieved goal except in the futuristic prophesies of MIT computer scientist Michael Dertouzos [18] and the virtual butler in Apple Computer's Knowl- edge Navigator video, but advancements in computer technology undoubtedly will increase the capability to introduce more anthropomorphic features. In other cases, such as obtaining standard information from an online investment company, there may be no real gain in designing an interface to appear more like a human. The challenge for interface designers is to resist the temptation of burdening users with an overloaded interface not matched to the desired task or outcome. Future research ought to focus on two areas. The first concerns mapping specific features of interfaces and software for supporting mediated communication onto characteristics of interactivity. Our attempts to do so for HCI did not manifest them- selves in increased assessments of partners, at least not as predicted and certainly not linearly. What might those features be? First, and most obviously for HCI, is to make the interface appear more human in appearance and behavior than the software and graphics used here. Less obviously, making the interface appear more "intelligent" in the sense that it is able to respond relevantly and cogently to interactional contin- gencies may realize the kinds of gains in interactivity that were hypothesized here.</page><page sequence="22">54 BURGOONETAL. Suchman's [32] work is important in this respect; she detailed features of interaction in general and then showed how humans adapted to interaction when anticipated moves were not forthcoming from the machine. Reducing the need to adapt might amplify interactivity and stimulate the processes associated with task outcomes. Recent thinking about social interaction research has led to models that recognize the possibility of multiple sources of influence on relevant behavioral or attitudinal outcomes. Work by Kenny and his associates [21, 22] has been particularly instru- mental in noting that a person's own behavior and cognitions are affected not only by his or her previous behavioral or cognitive states, but that they might also be affected by a partner's states. The former is referred to as the "actor effect," whereas the latter is called the "partner effect," and the two are often not the same. For example, in a study of group participation, Bonito [6] found that evaluations of one's own participation were differentially affected by the substantive contributions of self and others such that there was a positive actor effect (i.e., self-assessments of participation increased the more self contributed substantively to discussion) but no partner effect - contri- butions by others had no effect on self-assessments of participation. However, when considering participation ratings of others by self, there was a negative actor effect and a positive partner effect, indicating that ratings of others were positively associ- ated with the amount of others' contributions, and negatively associated with the amount of self's contributions. We believe such models can be fruitfully applied to CMC, particularly when con- sidering partner effects. An interesting empirical question is whether perspective changes as a function of interface design. It is possible that the actor's perspective will not change but the partner's will, depending on the medium (e.g., proximal or not, synchronous or asynchronous, or featuring an avatar). If this is the case, actor effects ought to be consistent across media, but partner effects ought to change accordingly as a function of how the interaction is affected by affordances of interactivity. CMC in some respects changes the ground rules for interaction; the ways in which communicators influence or affect each other ought to be similarly affected. Notes Acknowledgments: Portions of this research were supported by funding from the U. S. Army Research Institute (Contract #DAS W01 -98-K-009). The views, opinions, and/or findings in this report are those of the authors and should not be construed as an official Department of the Army position, policy, or decision. 1 . The text-only condition utilized separate windows on the screen for presenting the computer's and the participant's responses. In the conditions employing vocal cues, text-to-speech synthesis software developed by KTH was used. In the animation conditions, an animated face, moving its lips and facial skin synchronized with the speech, and occasionally flashing its eyelashes was presented. The animation software used in this study was developed by Jonas Beskow and Magnus Lundeberg at KTH (Royal Institute of Technology), Stockholm, Sweden, and is further described in [5]. The computer image was named "Holger." The same image was used in the still- image condition. In the noncontingent FtF condition, which is described in [3] as the scripted condition, the male confederates followed the script explicitly, which often meant disregarding questions and comments by the subjects, causing the dialogue to become rather unnatural, al- though confederates were still permitted to use the same kinds of gestures and backchannel cues</page><page sequence="23">TESTING THE INTERACTIVITY MODEL 55 (e.g., head nods) used in the other FtF condition. In the contingent condition (labeled as "unscripted" in the other report), confederates were allowed to use their own words and adapt to subjects' questions, while still trying to convey the same information contained in the script. 2. Where variances for dependent measures were not equal across all groups, unequal vari- ance r-tests were employed. 3. The low reliability on receptivity would normally warrant eliminating it from analyses, as measures with low reliabilities typically fail to produce significant results, but it was retained here for purposes of parallelism with Study 1 . References 1 . Aron, A.; Aron, E.N.; and Smollan, D. Inclusion of other in the self scale and the structure of interpersonal closeness. Journal of Personality and Social Psychology, 63 ( 1 992), 596-6 1 2. 2. Bales, R. F. Personality and Interpersonal Behavior. New York: Holt, Rinehart, &amp; Win- ston, 1970. 3. Bengtsson, B.; Burgoon, J.K.; Cederberg, C; Bonito, J.; and Lundberg, M. Virtual com- munication and the impact of anthropomorphic interfaces. Paper presented to the Second Swedish Symposium on Multimodal Communication, Lund, 1998. 4. Bengtsson, B.; Burgoon, J.K.; Cederberg, C; Bonito, J.; and Lundberg, M. The impact of anthromorphic interfaces on influence, understanding, and credibility. Proceedings of the Thirty- Second Hawaii International Conference on Computer Systems Sciences, Maui, 1 999. 5. Beskow, J. Rule-based audiovisual speech. Master s thesis, Royal Institute ot Technology, Stockholm, Sweden, 1995. 6. Bonito, J.A. Collecting free-response data via computers: effects of technology on re- sponses to hypothetical scenarios. Computers in Human Behavior, 15, 2 (1999), 195-21 1. 7. Burgoon, J.K. Nonverbal signals. In M.L. Knapp and G.R. Miller (eds.), Handbook of Interpersonal Communication. 2d ed. Beverly Hills, CA: Sage, 1994, pp. 344-390. 8. Burgoon, J.K.; Bengtsson, B.; Bonito, J.; Ramirez, A.; and Dunbar, N.E. Designing interfaces to maximize the quality of collaborative work. Proceedings of the Hawaii International Conference on Computer and Systems Sciences, Maui, 1999. 9. Burgoon, J.K.; Birk, T.; and Pfau, M. Nonverbal behaviors, persuasion, and credibility. Human Communication Research, 77(1990), 140-169. 10. Burgoon, J.K.; Buller, D.B.; Floyd, K.; and Viprakasit, R. Does participation affect decep- tion success? Paper presented to the annual meeting of the International Communication Associa- tion, Jerusalem, 1998. 1 1 . Burgoon, J.K., and Hale, J.L. Validation and measurement of the fundamental themes of relational communication. Communication Monographs, 54, 1 (1987), 19-41. 12. Burgoon, J.K.; Johnson, M.L.; and Koch, P.T. The nature and measurement of interper- sonal dominance. Communication Monographs, 65 (1998), 308-335. 13. Burgoon, J.K.; Walther, J.B.; and Baesler, E.J. Interpretations, evaluations, and conse- quences of interpersonal touch. Human Communication Research, 19, 2 (1992), 237-263. 14. Cahn, D.D., and Shulman, G.M. The perceived understanding instrument. Communication Research Reports, 1 (1984), 122-125. 1 5. Coker, D.A., and Burgoon, J.K. The nature of conversational involvement and nonverbal encoding patterns. Human Communication Research, 13, 4 (1987), pp. 463-494. 16. Daft, R.L., and Lengel, R.H. Organizational information, media richness and structural design. Management Science, 32 (1986), 554-57 1 . 17. Dennis, A., and Valacich, J.S. Rethinking media richness: toward a theory of synchronicity. Proceedings of the Hawaii International Conference on Computer and Systems Sciences, Maui, 1999. 18. Dertouzos, M. L. What Will Be: How the New World of Information Will Change Our Lives. San Francisco: Harper-Edge, 1997. 19. Hallowell, E. M. The human moment at work. Harvard Business Review, 77(1999), 58-64. 20. Hart, R.P. Seducing America: How Television Charms the Modern Voter. New York: Oxford University Press, 1994.</page><page sequence="24">56 BURGOONETAL. 21. Kashy, D. A., and Kenny, D.A. The analysis of data from dyads and groups. In H.T. Reis and CM. Judd (eds.), Handbook of Research Methods in Social Psychology. New York: Cam- bridge University Press, in press. 22. Kenny, D.A. Models of nomndependence in dyadic research. Journal of Social and Per- sonal Relationshins. 13('996' 279-294. 23. Kiesler, S.; Sproull, L.; and Waters, K. A prisoner's dilemma experiment on cooperation with people and human-like computers. Journal of Personality and Social Psychology, 70 ( 1 996), 47-65. 24. Krauss, R.M., and Fussell, S.R. Mutual knowledge and communication effectiveness. In R. Galegher, R. Kraut, and C. Egido (eds.), Intellectual Teamwork. Hillsdale, NJ: Erlbaum, 1 990, pp. 111-145. 25. Lombard, M., and Ditton, T.B. At the heart of it all: the concept of presence. Journal of Computer Mediated Communication. 3 (1997). 26. Markova, I.C.; Graumann, CF., and Foppa, K. Mutualities in Dialogue. Cambridge: Cambridge University Press, 1995. 27. McCroskey, J.C, and McCain, T.A. The measurement of interpersonal attraction. Speech Monographs, 41 (1974), 261-266. 28. Moon, Y., and Nass, C How "real" are computer personalities? Psychological responses to personality types in human-computer interaction. Communication Research, 23, 6 (1996), 651- 674. 29. Nass, C; Fogg, B.J.; and Moon, Y. Can computers be teammates? International Journal of Human-Computer Studies, 45 (1996), 669-678. 30. Nohria, N., and Eccles, R.G. Networks in Organizations: Structure, Form and Action. Boston: Harvard Business School Press, 1992. 31 . Perrolle, J. Computers and Social Exchange: Information, Property, and Power. Belmont, CA: Wadsworth, 1987. 32. Suchman, L. Plans and Situated Actions: The Problem of Human-Machine Communica- tion. Cambridge: Cambridge University Press, 1987. 33. Valacich, J.S.; Paranka, D.; and Nunamaker, J.F. Communication concurrency and the new media: a new dimension for media richness. Communication Research, 20, 2 (1993), 249-276. 34. Walther, J.B. Computer-mediated communication: impersonal, interpersonal, and hyperpersonal interaction. Communication Research, 23, 1 (February 1996), 3-43. 35. Walther, J.B., and Burgoon, J.K. Relational communication in computer-mediated interac- tion. Human Communication Research, 19, 1 (September 1992), 50-88. 36. Williams, F.; Rice, R.; and Rodgers, E. Research Methods and the New Media. New York: Free Press, 1988.</page></plain_text>
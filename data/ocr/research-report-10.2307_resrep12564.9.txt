<plain_text> <page sequence="1"> 4 DEFENSE –    YESTERDAY,TODAY   AND TOMORROW 4�1        Epochs and Technologies  4�2        Layers of ‘Defense’  4�3        AI in Other Armed Forces Today  4�4        Use Cases  HCSS REPORT 60 </page> <page sequence="2"> 4� Defense – Yesterday, Today  and Tomorrow Having identified a number of different ‘layers’ (and generations) of AI, we will now  propose to also differentiate between a number of different ‘layers’ (and maybe again  also evolutionary mutations) of defense and armed force. HCSS has already emphasized  in previous work195 that many of the terms that we use in a contemporary defense and  security context are deeply (and – in our opinion – increasingly counterproductively)  embedded in the industrial age.196 When most of us think about the concept of ‘armed  force’ today, we conjure up highly hierarchically organized mobile formations of  uniformed soldiers equipped with a wide range of industrial-age physical technologies  based (mostly) on steel, engines and firepower (tanks, frigates, jet-fighters, etc.), that are  employed by national political leaders to control and secure their territory and to defend  and/or advance their national goals through the application of (often lethal) industrial- kinetic197 violence. Their primary raison d’être is thought to be to successfully achieve  certain operational mission goals against various opponents. In this prevailing view of  defense and armed force, AI is typically seen as a new technology that, very much along  the lines of previous technological enhancements like stealth or precision strike, might  195   Stephan De Spiegeleire and Peter Essens, “C2 That! Command and Control over Post-Industrial Armed  Forces” (15th International Command and Control Research and Technology Symposium: “The Evolution of C2: Where Have  We Been? Where Are We Going?,” Santa Monica CA, 2010). 196  We use the term ‘industrial-age’ fairly loosely here – metals had been used since the Bronze Age, and even  firearms go back to at least the Renaissance period and became quite common already in the 18th century. For  those interested, see Kenneth Chase, Firearms : A Global History to 1700 (Cambridge UK; New York NY: Cambridge  University Press, 2003); Brenda Buchanan, Gunpowder, Explosives and the State : A Technological History (Aldershot  England ; Burlington VT: Ashgate, 2006). But the argument here is that Industrial warfare saw nation-states creating  and equipping large armies and navies (and in the 20th century also air forces) based on mass conscription, rapid  transportation (first on railroads, then by sea and air) and unprecedented communication (from telegraph to wireless  communications). In terms of physical technology, this era saw the rise of rifled breech-loading infantry weapons  capable of massive amounts of fire, high-velocity breech-loading artillery, metal warships, submarines, aircraft,  rockets and missiles, etc. 197   Since the 1990s the word ‘kinetic’ has been used (often loosely) by military analysts and practitioners as a  particular form of application of military force: in ‘kinetic’ and ‘non-kinetic’ ways. This closely corresponds to what  some are now calling ‘right of bang’ vs ‘left of bang’: kinetic force (‘right of bang’) is thought to be the lethal application  of (usually physical, explosive and destructive) military force; and non-kinetic force is everything else. The actual roots  of the word ‘kinetic’, however, merely refer to something that moves. The word comes from the Greek verb kinein  (“to move”), which in turn goes back to a proto-Indo-European root *kie-neu-, the suffixed form of the root *keie- (“to  set in motion“). When looked at more broadly, therefore, kinetic force or kinetic strike can probably best be defined  more generally as the application of ‘force’ (the ability to make somebody else do something that s/he may not want  to do out of their own volition) through some kinetic vector carrying a payload (the ‘effector’) that is applied to the  target. Currently the kinetic capabilities that our armed forces possess combine explosive payloads (firepower) with  various typically metal-based vectors with an intent to destroy or kill. In our own work, we prefer to use the term  ‘industrial-kinetic’ to differentiate that particular industrial-age type of ‘kinetic’ force from potential new kinetic  vectors and payloads (cyber, biometric, behavioral, informational, etc.) to achieve similar or new types of effects (e.g. to  incapacitate or detain rather than kill). 61 ArtificiAl intelligence And the future of defense </page> <page sequence="3"> augment the ability of our current industrial-age military capability bundle. The same  industrial-age actors, doing the same industrial-age things with the same industrial- age – but AI-enhanced – instruments. While this particular image is by now deeply ingrained in our consciousness, ‘armed  forces’ have not always looked like their current industrial-age incarnations.198 Before the  nation-state became the primary actor in the international system (a point in history often  traced back by political scientists to the Treaties of Westphalia of 1648), ‘armed force’ was  exercized by a far more heterogeneous set of actors than just the nation-states (tribes,  clans, religious or ethnic groupings, etc.). And the physical incarnation of this force –  the defense capability bundle they used – looked quite differently prior to the industrial  revolution than it did afterwards. There are many signs that we once again find us at a  new epochal tipping point. Our suggestion in this section is that ‘armed force’ is likely to  go through another epochal transformation in which AI’s impact is likely to be far more  revolutionary than stealth or precision strike. This chapter will start by taking a closer look at how technologies – both physical and  social – have affected the most fundamental – epochal – shifts in human history. It will  then apply some of those insights to defense and armed force, in order to come up with a  4-tiered layering of what defense may be morphing into today. 4�1� Epochs and Technologies We have just argued that our current way of thinking about defense and armed force is  still very much anchored in the industrial age which followed the most recent epochal  revolution in the history of homo sapiens about two centuries ago. We have all learned  in our history books how various physical technologies sparked the industrial revolution:  water mills, the cotton gin, steam engines, etc. These ‘artificial’ machines did indeed  dramatically change our polities, societies, economies, individual employment patterns,  demography, and even our cultures. But one of the under-appreciated ‘revolutionary’  aspects of the industrial revolution was the amount of socio-technological innovation  that co-evolved around the new physical technological innovations that irrupted into our  societies.199 The new physical technologies (machines) of the industrial revolution were  198   Nor do the etymological roots of this word preordain such a narrow definition. The original root of the word  ‘arm’ is thought to derive from the Proto-Indo-European (she hypothetical reconstructed ancestral language of the  Indo-European language family whose time scale is much debated, but thought to be about 7,000 years ago, see J. P.  Mallory and Douglas Q. Adams, The Oxford Introduction to Proto Indo European and the Proto Indo European World (New  York: Oxford University Press, 2006).) base ‘*ar-‘, meaning ‘to fit, to join together. The notion thus seems to be that  ‘arms’ implied ‘that which is fitted together’ (Harper, “Online Etymology Dictionary: Arm.”). This suggests that ‘armed  force’ merely represents what we today would call ‘capability packages’ (that what could be fitted together) for the  purpose of imposing one’s will on others (‘force’). And the precise instantiation of these capability packages typically  reflects the Age in which they are used. In pre-historical times, ‘what was fitted together’ was essentially wood, a few  primitive ropes and some stones (for clubs, spears, bows, slings). In the Bronze Age, bronze was added to the mix to  yield edged metal weapons; the Iron Age added the much more commonly available iron to the mix – and so on until we  reach the current industrial-age ‘armed force’ that we now take as the standard. 199   Richard R. Nelson, “Physical and Social Technologies and Their Evolution,” Économie Appliquée 56, no. 3  HCSS RepoRt 62 </page> <page sequence="4"> powerful engines of change in their own right. But what really turned everything upside- down were the social ways in which we humans re-organized ourselves to creatively  leverage the opportunities embedded in them. Both of these drivers (physical and social technologies) were powered by human  intelligence. Just as in the (individual – but even more so – social – see also the  introduction) ‘intelligence explosion’ that accompanied homo sapiens’ march to the top  intelligence played the key role, so too did the social technologies of the industrial age  arguably prove more consequential than the physical ones. ‘Division of labor’, for instance,  was a social technology that revolutionized first manufacturing, and thence all walks of  (human) life. Similarly, the modern ‘firm’ is a social technology that only emerged in  this very same period (and that has kept evolving ever since): first in Britain as a (manu) factory; then by the 1920s as the large modern business enterprise.200 The ‘nation-states’  as a social technology co-emerged alongside these other social innovations, as did the  accompanying social technologies to manage them, like governments, ministries, civil  services, educational systems, armed forces, etc. It may seem counter-intuitive to call  these ‘technologies’, but just like their physical counterparts, social technologies had to  be ‘invented’ by (groups of) humans and were also constantly tinkered with, refined and  adjusted.201  Many of these industrial-age social technologies still drive and define our everyday  lives. Most of us now work for governments or companies. Nation states still shape our  economic, political and social activities, our interests (arguably even our values) and our  very identities. Many of us think that all of these are ‘normal’ immutable aspects of the  human condition. By doing so we forget that they are essentially little more than transient  (human-invented) social technologies202 that have only existed for a few generations and  are highly likely to be as subject to disruptive change as the physical – let alone digital –  technologies around us.  (2003): 13–32; Carlota Perez, Technological Revolutions and Financial Capital: The Dynamics of Bubbles and Golden  Ages (Cheltenham UK; Northampton MA USA: Edward Elgar Publishing, 2002); Eric Beinhocker, The Origin of Wealth:  Evolution, Complexity, and the Radical Remaking of Economics (Boston Mass.: Harvard Business School Press, 2006). 200   Judit Kapás, “Industrial Revolutions and the Evolution of the Firm’s Organization: An Historical Perspective,”  Journal of Innovation Economics &amp; Management, no. 2 (2008): 15–33; Joel Mokyr, The Gifts of Athena: Historical Origins  of the Knowledge Economy (Princeton, [N.J.]: Princeton University Press, 2002); Chris Freeman and Francisco Louçã,  As Time Goes by: From the Industrial Revolutions to the Information Revolution (Oxford: Oxford University Press, 2002);  Alfred D. Chandler, “How High Technology Industries Transformed Work and Life Worldwide from the 1880s to the  1990s,” Capitalism and Society 1, no. 2 (January 7, 2006), doi:10.2202/1932-0213.1004.. And since the Third Industrial  (ICT) revolution it keeps evolving to flatter and more decentralized companies that are increasingly organized in semi- autonomous project-based teams. 201  In this context, it may be useful to point out that even the very word ‘technology’ had a very different meaning  prior to the industrial revolution, when it referred principally to a field of study concerned with the practical arts Eric  Schatzberg, “Technik Comes to America: Changing Meanings of Technology before 1930,” Technology and Culture 47,  no. 3 (2006): 486–512.. “Oldenziel and Marx in fact argue that it attained the status of “keyword” only in the 1930s, and  that before this time, issues that historians now discuss in terms of technology were framed in such terms as useful  arts, manufacturing, industry, invention, applied science, and the machine... George Crabb’s Universal Technological  Dictionary of 1823 defined technology as “a description of the arts, especially those which are mechanical.”” 202  Here too etymology proves revealing: the Greek root tekhne («art, skill, craft in work; method, system, an art, a  system or method of making or doing) comes from the Proto-Indo-European root *teks, meaning «to weave, fabricate,  make». The original sense thus seem to refers to human’s skillfully creative activities. 63 ArtificiAl intelligence And the future of defense </page> <page sequence="5"> Many authors claim that we are currently moving into a post-industrial age.203 And here,  the lines between physical, digital and social technologies seem to be blurring. Engineers  today are moving from the atom-based (physical) world into the bit-based (digital) world:  in the US, the ratio of software to hardware engineers is 53% and growing.204 That means  that the current-day equivalents of the physical technologies that shaped the industrial  age are no longer purely physical but an increasingly physical-digital hybrid. At the same  time, however, we are also – once again – witnessing the emergence of a whole range  of new social technologie: the ways in which we as humans try to leverage these new  hybrid digital-physical technologies to pursue our needs and desires205. Social networks  (Facebook, LinkedIn, Whatsapp, Instagram, Snapchat; but also Airbnb, Avvo, Behance,  Doximity, Github, GrabCad, Researchgate, Rizzoma, StackOverflow, Quora, Rallypoint (for  the military), Uber, Upwork and many other new – increasingly web-based – software  programs and/or apps etc.), for instance, represent a fundamental change in the way in  which many of us interact socially and professionally.  In contrast to the industrial age, those new social technological changes have not just  been triggered by new physical technologies. This time around, it is developments in both  203   The seminal work on this remains the 1976 classic Daniel Bell, The Coming of Post-Industrial Society: As Venture  in Social Forecasting, Peregrine Books (Harmondsworth: Penguin Books, 1976)., which was popularized in Alvin Toffler,  The Third Wave, A Bantam Book (New York: Bantam Books, 1990) and - applied to the defense realm - in Alvin Toffler  and Heidi Toffler, War and Anti-War Survival at the Dawn of the 21st Century (New York: Little Brown, 1993). Another  important milestone in this discussion was Manuel Castells’ work on the ‘network society’ (Manuel Castells, The Rise  of the Network Society, 2nd ed., with a new pref, The Information Age : Economy, Society, and Culture, v. 1 (Chichester,  West Sussex ; Malden, MA: Wiley-Blackwell, 2010). Overall, we continue to prefer to characterize what is happening  around us now as a ‘post-industrial’ revolution rather than (merely) a ‘fourth industrial’ one (or Industry 4.0), even  though the ‘fourth industrial revolution’ meme has been gaining quite a bit of traction since it became the main theme  of the 2016 World Economic Forum in Davos. See Klaus Schwab, “The Fourth Industrial Revolution” (World Economic  Forum Geneva, 2016), https://foreignaffairs.org/articles/2015-12-12/fourth-industrial-revolution; Klaus Schwab, The  Fourth Industrial Revolution (World Economic Forum, 2016). Here is how Klaus Schwab describes ‘his’ 4 industrial  revolutions: “The First Industrial Revolution used water and steam power to mechanize production. The Second  used electric power to create mass production. The Third used electronics and information technology to automate  production. Now a Fourth Industrial Revolution is building on the Third, the digital revolution that has been occurring  since the middle of the last century. It is characterized by a fusion of technologies that is blurring the lines between  the physical, digital, and biological spheres.” Different experts and scholars use different periodizations for these  ‘industrial revolutions’ (for another one, see Perez, Technological Revolutions and Financial Capital. ). We agree that what  is going on now is a genuine revolution, but our reasons for not lumping this new revolution together with the first two  (or even with the third one - which we see as far from completed but already carrying in itself the germs of even more  fundamental changes that the fourth is likely to bring to fruition) are twofold. First of all, we see the main agents of  change behind the more general, canonical industrial revolution as lying not so much in the physical technologies that  triggered it (steam, coal, iron production) but in the social ones (‘the ‘modern’ enterprise; ‘modern’ government; the  ‘modern’ (Weberian) state; ‘division of labor’, etc.). So too do we surmise that the new ‘social’ technologies (between  people and - to a smaller extent - machines) that Schwab’s third revolution is starting to engender, and the increasingly  more AI (and not machine-)-centric ones that his fourth one is likely to spawn are likely to be dramatically different  from the first two. Secondly, we feel that whereas the main organizing principle behind the ‘industrial age’ was the  ‘line’, the post-industrial age is much more likely to become the age of the ‘network’ or even the ‘ecosystem’. Taking  these two arguments together, we feel that calling what is going on now just a fourth installment of a recurring pattern  underestimates its far more disruptive nature. We do want to point out, however, that Schwab too sees this ‘fourth’  installment as a quite different one: “When compared with previous industrial revolutions, the Fourth is evolving at an  exponential rather than a linear pace. Moreover, it is disrupting almost every industry in every country. And the breadth  and depth of these changes herald the transformation of entire systems of production, management, and governance.” 204  Another interesting aspect here is that the typical desired attributes of these engineers is also changing, in  the sense that creativity is becoming a more important part in the mix. See also Adam Grant, Originals: How Non- Conformists Move the World (Penguin, 2016). 205  McKinsey Global Institute et al., The Social Economy: Unlocking Value and Productivity Through Social Technologies  (McKinsey Global Institute, 2012). HCSS RepoRt 64 </page> <page sequence="6"> hardware and software – primarily, but not only in the ICT-sector – that are the key drivers  behind emerging new social technologies. But if we still try to differentiate between – on  the one hand – what scientists are developing in terms of hard- and software and – on  the other hand – how we as members of society are starting to use these scientific- technological developments to reorganize the way in which we create ‘value’ , we see that  the interaction between these two elements is leading to truly disruptive change – just  like it did during the industrial revolution. In the private sector, we see that this change is leading to some fundamental changes  of the main interacting agents and the way in which they interact. The (industrial-age)  ‘company’ is being reimagined into a set of new social technologies. What some have  called the ‘platform’ revolution, for instance, see the industrial-age firm morph into a new  business model that uses technology to connect people, organizations, and resources in  an interactive ecosystem in which unprecedented amounts of value can be created and  exchanged206  This has already occurred in the telecom and media sectors. We are witnessing it in  the retail, mobility and hospitality sectors. Is it prudent to assume that ‘defense’ will  prove immune against these trends?207 Or should we start anticipating that the ongoing  technological acceleration – including, maybe even relatively soon, an upcoming new  intelligence explosion – is likely to engender fundamental changes in both physical and –  maybe even more importantly – social ‘defense’ technologies? Changes that may not  merely change the capability bundle our armed forces currently use to execute their  operations, but that may end up changing the very essence of who they are, what they do,  and how they do it. In the next section, we will explore what these changes might mean  for defense and security organizations. 4�2� Layers of ‘Defense’ Virtually all of the literature on the nexus between AI and defense that we have perused in  preparing this think-piece focuses on one particular incarnation of ‘defense’ and ‘armed  force’: one that is primarily based on industrial-age physical technologies (/violence) as  206   Geoffrey Parker, Marshall Van Alstyne, and Sangeet Paul Choudary, Platform Revolution: How Networked  Markets Are Transforming the Economy and How to Make Them Work for You, 2016, https://www.overdrive.com/ search?q=747D962F-32B3-4F05-9126-A09E659AB96C 207   In their ‘Platform Revolution’, Parker et al. (2016) point to four attributes that make an industry ready for  ‘platform’ disruption: being information-intensive; having non-scalable gate-keepers ; being highly fragmented ()  and being characterized by extreme information asymmetries Ibid.. Many might argue that defense is different: that  it is physical rather than informational; that the ‘gate’ is effectively kept by the nation states’ pre-digital monopoly on  legitimate violence; that the defense industry is oligo-polistic and -psonistic and that existing information asymmetries  (supported by ‘secrecy’) are desirable and sustainable. Our counter-argument would be that this is an industrial- age interpretation of what defense really is; a mental association that is quite analogous to those in the mobility  sector who thought ‘Detroit’ was safe; only to be upended by Silicon Valley. We see defense as increasingly becoming  informational; with - poorly scalable - national armed forces as gate-keepers that have an increasingly hard time in  ‘holding’ the gate; with a plethora of currently poorly connected potential ‘(security and defense) value providers; and  with an increasingly level informational playing field. 65 ArtificiAl intelligence And the future of defense </page> <page sequence="7"> the main sources of actionable power. Most of these writings accept that we have now  crossed a ‘tipping point’ in AI and look – logically consistently within that paradigm – for  ways to embed this new ‘(fourth) industrial-age’ technology into – essentially – the same  types of ‘armed force’ executing the same types of ‘operations’ with very similar, but now  AI-enhanced ‘weapons’ and concepts of operations. The main argument of this think piece  is that this prevailing logic – the paradigm within which we think about security, defense  and armed force – may be increasingly incongruous with the disruptive transformations  that are afoot. We have already referred in the beginning of this report to a temporally distant era and  form of ‘defense’ in which the relatively vulnerable and seemingly weak homo sapiens  managed to climb to the top of the food chain over many physically far more potent  adversaries. It did so, by the looks of it, much more through a combination of cognitive  and social technologies than through purely physical ones. Despite our species’ historical  ‘defense’ experience over these past few millennia (or even centuries208), we still tend  to think that the actor with stronger physical vigor, with superior (industrial) firepower,  with more potent protection against that firepower, etc. is likely to gain the upper hand  in the contests of will of the future. It is based on that extrapolation that we pour ever  more money into those attributes of power for defensive and/or offensive purposes. In  this paradigm AI is seen to augment our current weapon systems by giving them ever  more physically potent and destructive – and increasingly autonomous – capabilities. Our predilection for (industrial-age) physical forms of ‘defense’ is even visible in the ways  in which we try to imagine the future of our species’ defense efforts in science fiction209.  These authors often portray curiously anthropomorphic alien creatures organized  along mostly human social technological lines (with governments, separate ‘warrior’  castes, etc.) moving around the universe in suspiciously – some might say comically –  human-like steel vessels (‘alien spaceships’) and ‘shooting’ at each other or at us with  suspiciously recognizable weapons like missiles or – in the more imaginative cases –  photon torpedoes. In projecting such futures, we essentially deny our very own basal  human evolutionary trajectory, in which none of these attributes proved either dominant  or decisive. Are we cognitively doomed to only ‘remember’ the future instead of creatively  dream it up?210 Is it conceivable that we are ‘stuck’ in a particular mental frame that  prevents us from thinking about truly different ways of achieving our aspirational defense  and security goals? Is it not more likely, for instance, that (benevolent or malevolent or  208   Most analysts would probably also agree that the West’s ‘victory’ over the Soviet Union had less to do with its  ‘brute-force’ physical military superiority (where the Soviet Union may even have had superior capabilities in quite a  few areas) than with its vibrant economy and society that was able to navigate the shift to a technologically far more  advanced service economy far more elegantly than the much more industrial-age Soviet Union. 209   For some recent exemplars of science fiction writers imagining the future of warfare, see NATO Allied  Command Transformation, Visions of Warfare 2036, ed. Trina Marie Phillips and August Cole (Norfolk VA: NATO  Allied Command Transformation, 2017); United States Marine Corps, Science Fiction Futures; Marine Corps Security  Environment Forecast: Futures 2030-2045 (Quantico, VA: United States Marine Corps, 2016), http://www.mcwl.marines. mil/Portals/34/Documents/FuturesAssessment/Marine%20Corps%20Science%20Fiction%20Futures%202016_12_9. pdf?ver=2016-12-09-105855-733.  210   See Stephan De De Spiegeleire and Tim Sweijs, Volatility and Friction in the Age of Disintermediation. HCSS  StratMon 2016-2017 Yearly Report, 2017. for how humans primarily ‘remember’ the future HCSS RepoRt 66 </page> <page sequence="8"> even neutral) alien species would have myriad other ways to achieve their ‘policy’ goals  than by just ‘shooting’ at us the way we have historically done at one another?  Staying closer to the current day and age – could it be that the current Russian leadership’s  use of (mostly non-physical) behavioral influencing technologies (primarily targeted at  their own population, but also at ‘vulnerable’ segments in our midst) heralds a more  novel – and more (also cost-) effective – approach to defense planning than the West,  in all of its (undisputed) technological superiority, has been able to muster? And are  we so satisfied with our own attempts over these past few decades to use (increasingly  expensive) industrial-kinetic military capabilities to ‘stabilize’ various parts of the world  where we thought our interests and/or values jeopardized? We have suggested in previous HCSS work that ‘defense’ and ‘armed force’ might very  well start looking very differently again from what we have grown accustomed to over  the past few ‘modern’ centuries.211 If the security returns on our industrial-age defense  and security investments and efforts seem to be diminishing and if ‘power’ is becoming  increasingly dematerialized, does it still make sense to focus so overwhelmingly on  robotic forms of actualizing ‘AI-power’ to achieve our defense and security aims? Will  intelligent algorithms that are as intelligent as or even more intelligent than humans  still need industrial-age machines to make us behave in ways that their masters (or  increasingly maybe even they themselves) consider optimal from the point of view of  their own values?212  Our own intuition is that the advent of AI (and its co-emerging technologies) requires  us to to look more broadly, probably quite differently, but above all more creatively – at  ‘defense’ and ‘armed force’ and at the role AI is likely to play in those. Sheer cognitive (and  social) intelligence has proved to be far more evolutionarily powerful than brute human  or human-invented physical force. As we find ourselves on the cusp of what is likely to  become a new intelligence explosion, does it really still make sense to restrict ourselves  to presentist or recentist views of what defense and/or armed force really represent? With this health warning in mind, this study proposes the following four-tiered  classification of ‘defense’ as a social technology: • ‘Defense’ as military operators (‘warfighters’ in the parlance of some nations) –  e.g. the Netherlands Defense Force (NDF); • Defense as an organization that supports these operators but also interacts with  its counterparts  – e.g. the Netherlands Defense Organization (NDO); • Defense as a player in an increasingly more whole-of-government security- oriented approach – e.g. the Netherlands Defense and Security Organizations  (NDSO); and 211   Stephan De Spiegeleire and Peter Essens, “C2 That! Command and Control over Post-Industrial Armed  Forces,” in The Evolution of C2 (15th International Command and Control Research and Technology Symposium, Santa  Monica CA, 2010). 212  On the issue of ‘values’ for/of AI, see Bostrom, Superintelligence. 67 ArtificiAl intelligence And the future of defense </page> <page sequence="9"> • Defense as the (potential) catalyst of a broader defense and security ecosystem  of sensors and effectors – e.g. the Netherlands Defense and Security Ecosystem  (NDSE) Netherlands Defense Force (NDF) Netherlands Defense Organization (NDO) Netherlands Defense and Security Organizations (NDSO) Netherlands Defense and Security Ecosystem (NDSE) Figure 9: 4 LAYerS OF DeFeNSe  Most of our defense efforts are currently focused on the heart of this bull’s eye: our armed  forces, and especially their operational (warfighting) ‘edge’, which is widely thought  to embody the core competency of ‘defense’. The various supporting elements of the  armed forces and the broader organization around them are primarily seen as supporting  this hard core. The third, ‘whole of government’ layer includes all elements of national  government that bear some responsibility for national security writ large. This layer  tends to remain quite stovepiped in most countries, and therefore relatively embryonic as  a cohesive layer – although we can definitely discern a notable (if glacially slow) trend in  that direction. In the Netherlands, for instance, this layer has manifested itself in efforts  like the ‘3D’ approach around expeditionary operations; on topics like water security,  cybersecurity, counterterrorism; or in the whole-of-government efforts around national  risk assessment. The fourth, defense and security ‘ecosystem’ layer remains mostly a concept, even if it is  gaining significant traction in the Netherlands.213 This layer contains all actors that have  some direct or indirect affinity with the Netherlands and its security and that might be able  to be ‘mobilized’ in any defense or security effort. In relatively stable and secure security  environments, like the one the Netherlands has by and large enjoyed since the end of  the Cold War, this ecosystem remains mostly latent and therefore invisible. But when  the security environment becomes more threatening or threatened, the elements of that  213  The defense and Security Ecosystem was the central theme of the major 2017 ‘Future Force Conference’,  organized by the Dutch Chief of defense, which brought together some 1200 representatives of the NDSE to think about  how to turn this idea into an actionable reality. Ministry of Defence, The Netherlands, The Hague Centre for Strategic  STudies, and Future Force Conference 2017, “From Partnerships to Ecosystems: Combining Our Efforts for a More  Secure World,” Future Force Conference, accessed January 29, 2017, https://futureforceconference.com/theme/. HCSS RepoRt 68 </page> <page sequence="10"> ecosystem become more perceptible as they start ‘rallying around the flag’ domestically  or start expressing sympathy for the country from abroad – whether in words or in deeds.  These different layers of ‘defense’ of course interact with each other – both within a  country and across (friendly and not-so-friendly) countries.  All of this is quite comparable to the business world, where we also have different layers  that interact with each other. These interactions have come to be known by some widely  used acronyms like B2B (business-to-business) or B2G (business-to-government) or B2C  (business-to-customer). Businesses interact with other businesses (B2B) throughout  their value chain: the companies they buy things (or – increasingly – services) from, the  companies they sell things (or – increasingly – services) to, etc. Many of them also interact  with governments (B2G), which continue to represent 40-50% of our GDP in developed  countries: they lobby them, they are subject to their regulatory authority, but they also  ‘sell’ to them. And finally, and probably most importantly, businesses interact with their  end-customers (B2C): they monitor their consumption preferences (increasingly also  through AI – see Amazon, Google, etc.), they bombard them with behavioral influence  strikes (advertisements for their products), they sell to them as customers, etc.  Individual B2I Customer B2C Business B2B Business B2G Government Figure 10: LAYerS OF iNTerACTiON iN THe BuSiNeSS WOrLD  Recently, IBM’s CEO Ginni Rometty has added a new acronym to this group: B2I – business- to-individual. This goes beyond the more narrowly transactional B2C interaction between  a business and an individual. Rometty argues that businesses increasingly have to realize  that any individual, beyond being a mere transactional ‘customer’ of their products, is  also somebody the company should (and increasingly can) understand and engage with  as a broader individual.  She sees IBM making a new dramatic pivot toward what IBM now calls cognitive  computing – they prefer calling these new technologies ‘cognitive’ instead of ‘artificial’214 –  214  Cognitive computing refers to systems that learn at scale, reason with purpose and interact with humans  naturally. Rather than being explicitly programmed, they learn and reason from their interactions with us and from  their experiences with their environment.” Kelly, “Computing, Cognition and the Future of Knowing.” 69 ArtificiAl intelligence And the future of defense </page> <page sequence="11"> in which a much more ‘intimate’ relationship between machines/algorithms and humans  as full-fledged individuals creates new business opportunities. This line of reasoning  comes from the mouth of one company’s (IBM) CEO, but we suggest that this thinking  is increasingly permeating the thinking and acting of many leading-edge companies,  most of which tend to be platform businesses215 increasingly with AI at their very cores  (including Amazon, Apple, Baidu, Facebook, Google, Microsoft, etc). The argument that we will be developing here is analogous to what Ginny Rometti is now  arguing for the business world, but then applied to the defense and security realm. For  a long time – throughout the industrial age really – ‘defense’ has been about A2A: ‘our’  armed force against ‘their’ armed force. One ‘order of battle’ against another (or multiple  other) one(s). We now arguably see a trend towards defense (and security) increasingly  becoming about one (or a few allied) ‘whole-of-government(s)’ (or even – societies)  against another (or multiple other) ‘whole-of-government(s)’ (or even whole-of-society(/ ies)): D2G and/or D2S. The ‘comprehensive approach’ (and/or hybrid warfare) is a good  example of this trend in various countries. Recent problems with the public acceptance  of the value proposition of our armed forces have also triggered a renewed focus on D2P  (politics) and D2C (citizen).  But is it possible that, just as business is becoming more and more about B2I, defense  might be becoming more about D2I? That we can bypass many of the institutional middle  men,216 most purely transactional relations (the citizen as a ‘customer’ of defense and  security) in order to to drill down to the actual (complex) individual human being with a  unique utility function that polities’ primary role would be to foster (human flourishing)  and that should become the primary target of our purposive actions? Armed Force A2A Armed Force A2D D2A G2A E2A I2A Defense organization D2D Defense organization A2G D2G G2D E2D I2D Government G2G Government A2E D2E G2E E2G I2G Ecosystem E2E Ecosystem A2I D2I G2I E2I I2E Individual I2I Individual Figure 11: DeFeNSe AND SeCuriTY eCOSYSTeM 215   Parker, Van Alstyne, and Choudary, Platform Revolution. 216   On the trend towards disintermediation, see our 2016-2017 HCSS Strategic Monitor. De Spiegeleire and Sweijs,  Volatility and Friction in the Age of Disintermediation. HCSS StratMon 2016-2017 Yearly Report. HCSS RepoRt 70 </page> <page sequence="12"> 4.2.1. Armed Force: AI and A2A Most of our current discussions about ‘defense’ (and – consequently – also about the role  of AI in defense) are focused on this first – in the current military mindset ‘core’ – layer  of Figure 11. From this vantage point ‘defense’ is seen as an assembly of individuals that  are given a set of of extraordinary rights (also in terms of the tools they are ‘allowed’  to use) and responsibilities in order to defend our societies against other ‘militaries’:  A2A. The focus in this contest between (or cooperation amongst) armed forces is on  ‘operations’ and ‘operators’ (in US parlance – ‘warfighters’).  They embody the sharp, bleeding edge of a broader bureaucratic institutional setup  that was created to support it. In line with some of the influential thinking in the  business management literature about how companies should just focus on their  ‘core competencies’,217 the view here is that ‘fighting (and winning) wars’ is the core  competence of our armed forces – under the political control and strategic guidance of  their political leaders. In a nicely linear fashion, this view delineates our militaries as  implementation agencies to which the conduct of politically mandated and (hopefully  also legally) legitimated military operations is insourced. Consequently, their attention  should be squarely and solely focused on the (order of battle of the) ‘enemy’ and his  capability bundle that has to be defeated (preferably decisively) by ‘our’ order of battle  with our capability bundle. Western defense analytical and political thinking has over the past few decades focused  on how to optimally empower the edge of the defense effort under the catchphrase  “Power to the Edge”218. In the operational sense, this implied relying on ever more  sophisticated information technologies to better link sensors and effectors (‘network- enabled capabilities’ in NATO parlance). In the political sense, the implication was that the  frontline operators had to be as ring-fenced as possible from the various cutbacks that  were being inflicted on our defense organizations. Not inconsequentially, this focus on  the operators as the leading edge also jibed nicely with the increasingly dominant ruling  market-ideology that was supposed to (rightfully – in the eyes of these authors) replace  the suffocating bureaucratic administrative-control approach to defense planning219.  In this new philosophy, the the real ‘customer’ that should be at the heart of a more  market-driven approach to defense and security was not the political-military  decisionmakers in our ministries, but the operator who was supposed to better know  what ‘the market’ required and who had to be better supported by a leaner and more  efficient public administration based on better (and more transparent) market incentives. 217   C. K. Prahalad and Gary Hamel, The Core Competence of the Corporation (Harvard Business Review, 2001). 218   David S. Alberts and Richard E. Hayes, Power to the Edge: Command, Control in the Information Age, Information  Age Transformation Series (Washington, DC: CCRP Publication Series, 2003). 219   For an analogous view on the suffocating role of bureaucracy in the private sector, see Gary Hamel and  Michele Zanini, “Excess Management Is Costing the U.S. $3 Trillion Per Year,” Harvard Business Review, September 5,  2016, https://hbr.org/2016/09/excess-management-is-costing-the-us-3-trillion-per-year. 71 ArtificiAl intelligence And the future of defense </page> <page sequence="13"> Public New Public  Table (after Harlye 2005) Design Thinking Administration Management Population Homogeneous Atomizer Complex Straightforward,   Needs/problems defined by’ profes- Wants/express by ‘the Complex, volatile,  sionals’ /’experts’ market’ prone to risk Strategy State- and Market - and consum- Service- and consum-producercenter er centered er centred Governance throught Hierarchies, public Markets, purchasers Networks and part- actors servants and providers nersship Key concepts Public goods Public choice Public value Role of policy markers Commanders Announcers / Leaders and inter-commissioners preters Role of public managers Clerks and martyrs Effeciency and market maximizers Explorers Role of population Clients Customers Co-producers Figure 12: SHiFTS iN THe DOMiNANT MODeLS OF THiNKiNg ABOuT PurPOSiVe PuBLiC ACTiON Based on this line of thinking, which has remained dominant throughout most of the  industrial age to this date, new technological breakthroughs should be primarily focused  on the operational exigencies of military operations. Given the still predominantly  industrial-kinetic nature of those operations, this means that the focus should be on our  operators and their weapon systems, which are still seen as the most powerful effectors.  Based on this premise the logical implication is that AI should be used to improve the  (mostly) kinetic capabilities that ‘win wars’: target detection and acquisition; autonomous  weapon systems; planning and support tools, etc. 4.2.2. Defense Organizations: AI and A2D (/D2D) The second layer of the current defense model is essentially the (bureaucratic) derivative  of the first one. The ‘sharp edge’ (the armed ‘operators’ or ‘warfighters’) can only be  effective if it is supported by a modern, competent governmental bureaucracy. Even if the  ‘teeth’ are ultimately more important, so goes this line of reasoning, they can only exist  by the grace of an efficiently organized supportive ‘tail’ in turn supported by an efficient  Weberian bureaucracy. The focus therefore shifts from the ‘(operational) edge’ to the  broader ‘defense enterprise’. This approach is surprisingly popular and deeply embedded  in our current way of thinking, planning and doing. Part of this is understandable given  the large amount of people who are involved in the ‘defense enterprise’. Also many other  public and private actors see this ‘layer’ as the interface with (and the gatekeeper of)  the ‘operators’ who have to be protected against, buffered against the ‘impurities’ of the  outside world. From this perspective, it is this more bureaucratic layer that is the real  customer. They have the best interest of the operators in mind, but are (presumably)  better equipped to deal with all of the other commercial, political, ideological etc. vectors  that try to influence them. HCSS RepoRt 72 </page> <page sequence="14"> It can be expected that this second layer of defense will also start leveraging ever more  elements of AI in its everyday practices and procedures. Many of these have become of  such byzantine complexity, that various more rule-based software tools have already  been introduced over the past few decades – to decidedly mixed effect even within the  confines of this layer – to help manage them. Examples here include the introduction  of various 100s of legacy software systems that have been rolled out over the past few  decades and have recently started being integrated into all-encompassing enterprise  resource planning (ERP) systems like SAS. Most of these (often proprietary) systems  were still based on the pre-cognitive programming model of human software: engineers  writing millions of lines of code that often proved buggy, were not particualrly secure and  then had to be iteratively ‘fixed’ at great (financial and non-financial) expense.  As more efficient learning algorithms – first still ANI-based, but presumably also  increasingly AGI-based – gradually start to taking over from programmed algorithms,  it stands to reason that the D2D and D2G layers will represent great opportunities for  AI applications. Some low-hanging fruit ANI applications might include recruitment;  acquisition; budget management, human resource management, knowledge  management, and so on. As in other non-defense-related walks of life, the more large- scale roll-out of such algorithms is likely to have significant effects on the defense  enterprise workforce. 4.2.3. Defense and Security Organizations: D2G (/G2G) The third defense layer extends beyond our defense organizations proper. It includes  the entire public sector’s purposive effort to safeguard our societies’ security. A2A  experiences over the past two ‘expeditionary’ decades have demonstrated fairly  persuasively that it has now become virtually impossible – if ever it even was possible –  to achieve one’s defense and security goals through exclusively or even predominantly  (industrial-kinetic) military means. To their credit, our armed forces have been amongst  the most vocal advocates of this humbling recognition. This has led to a glacially slow  but still discernable trend towards more ‘comprehensive’ approaches to defense and  security solutions, in which many of the axioms of the previous age had to be – and still  are being – rethought.  Our governments (including our defense and security organizations) are still based on  various linear industrial-age social technologies that proved extremely useful when the  main challenge was to ‘mass’-produce various physical products and to enforce law and  order in a (mostly) top-down way. Various digital technologies are exerting increasing  pressure on these linear structures and mindsets. If (and it is an ‘if’) it was possible to  by and large divorce economic planning from defense planning, for instance, in the past;  then today it increasingly is not. This requires our governments to re-invent themselves  to reflect the requisite variety of the national and international world that they are trying  to affect. 73 ArtificiAl intelligence And the future of defense </page> <page sequence="15"> This third layer has two important sub-layers: a more bureaucratic one, where the  different agencies within our governments have to arrive at better coordinated purposive  actions; and a more political layer, where the various diverging political interests in our  societies also have to find ways to better align themselves in ways that enhance ‘public  value’ – also in the defense and security realm. We submit that the potential of AI to  intelligently rationalize and align the various inputs, throughputs and outputs of these  various processes is enormous. The amount of (increasingly electronic) paperwork that  our governments produce is mind-boggling. Most of this is produced in a stovepiped way,  with certain government departments producing policy that may be in direct conflict with  policy being produced in another government department – without either of them even  knowing about the other. AI’s deep learning algorithms offer unprecedented opportunities  for improved situational awareness and understanding as well as ‘deep learning’ across  these different silos.  The promise of AI for the more political (and thus emotional) D2G/G2G layer is less  straightforward. AI is likely to provide our politicians as well as our citizens with uniquely  deep insights in both the drivers of various types of human endeavors and their outcomes. The extent to which wily politicians will prove amenable to conform their behavior with  these insights remains an open question.  4.2.4. Defense and Security Ecosystem: E2I (/E2E) The fourth layer (which exists only latently in most developed societies) is much broader  than the previous three, but it is in our view also potentially far more potent – also from  the point of view of the applicability of AI. This layer includes both the level beyond  government (the defense and security ecosystem) and how it interacts with the layer  underneath all of these institutions (the individual). We have noted in previous work how  the increased technology-driven empowerment of this most human of layers is one of  the most powerful mega-trends in this day and age220 – and one that some of the West’s  opponents appear to have been more adroit and adept at embracing/exploiting than we  have. Since the dawn of the industrial age our nation states have confided the legitimate use  of (increasingly awesome) physical power to a uniformed corps of defense and security  professionals, equipped with the requisite ‘arms’ to maintain their dominant position as  the ultimate agents of power with the ability of physical escalation dominance. Just like  the physical technologies that the industrial revolution spawned and that so radically  transformed the manifestations of violence and war, so too did these industrial-age  social technologies. Many recent authoritative long-term histories of political violence221  220   Stephan De Spiegeleire et al., Si Vis Pacem, Para Utique Pacem. Individual Empowerment, Societal Resilience  and the Armed Forces (The Hague, The Netherlands: The Hague Centre for Strategic Studies, 2015), http://www. literatuurplein.nl/boekdetail.jsp?boekId=1078494 221   Francis Fukuyama, The Origins of Political Order: From Prehuman Times to the French Revolution (Farrar, Straus  and Giroux, 2011); Francis Fukuyama, Political Order and Political Decay: From the Industrial Revolution to the Globalization  of Democracy (Farrar, Straus and Giroux, 2014); Azar Gat, War in Human Civilization (OUP Oxford, 2008); Yuval Noah  HCSS RepoRt 74 </page> <page sequence="16"> have documented how this monopolization of violence has greatly reduced the overall  incidence of different types of violence, even though there clearly still remains ample  room for improvement. We see all around us, however, how new technologies are starting to transform our  economies, societies and polities – in many cases quite disruptively. Our militaries will  not remain unaffected. Like all purposive actors (public and private) they will have to  start redesigning the way they interact with others in order to achieve the defense and  security objectives of which they remain the legitimate custodians. If we look at how this process is unfolding in the private sector, we observe the emergence  of truly novel ways of organizing purposive action. Companies still exist; they still  compete; they still want to prevail in their markets; they still want to make money. But  they are starting to do all of this in radically different ways. The astonishing success of  these new models may portend analogous changes in the military world. In The Platform  Revolution, a popular recent book on this phenomenon, three influential authors describe  how disruptors like Airbnb, Amazon, Alibaba, Facebook, Google, Uber, and many others  have found new ways to leverage technology to connect people, organizations, and  resources around themselves into interactive ecosystems in which “amazing amounts of  value can be created and exchanged. Even incumbent giants from Walmart and Nike to  John Deere, GE, and Disney are all scrambling to adopt similar models”.222 In some sense, this is a Copernican revolution in the way in which these private actors  organize and position themselves in their environment to achieve their goals. The way  they generate value is still through their own selfishly purposive efforts, but these efforts  now increasingly put their ecosystem partners, and not themselves or their traditional  supply chains, center stage. Rather than seeing themselves at the center of their business  universe – doing innovation mostly on the inside; selecting and controlling supply chain  partners; shielding themselves off from competitors – they are starting to see themselves  as much less central (but therefore not less profitable) players who increasingly get to  generate even more private value by piggy-backing on the efforts of outsiders – global  innovative players that they do not choose, but that choose them. Harari, Homo Deus: A Brief History of Tomorrow (Random House, 2016); Yuval Noah Harari, Sapiens: A Brief History of  Humankind (Random House, 2014); Steven Pinker, The Better Angels of Our Nature: Why Violence Has Declined (Penguin,  2011); Ian Morris, Why The West Rules - For Now: The Patterns of History and What They Reveal about the Future  (Profile Books, 2010); Johan Norberg, Progress: Ten Reasons to Look Forward to the Future (Oneworld Publications,  2017) 222  Parker, Van Alstyne, and Choudary, Platform Revolution.. On the emergence of new forms of organizing  purposive action (what we called here ‘new social technologies’) outside of the military realm, see also Sangeet  Paul Choudary, Platform Scale: How an Emerging Business Model Helps Startups Build Large Empires with Minimum  Investment, First edition (S.L.: Platform Thinking Labs Pte. Ltd, 2015); David S. Evans and Richard Schmalensee,  Matchmakers: The New Economics of Platform Businesses: How One of the Oldest Business Models on Earth Powers  the Most Incredible Companies in the World (Boston, Massachusetts: Harvard Business Review Press, 2016); The Zero  Marginal Cost Society: The Internet of Things, the Collaborative Commons, and the Eclipse of Capitalism, 2014; Salim Ismail  and Michael S. Malone, Exponential Organizations: Why New Organizations Are Ten Times Better, Faster, and Cheaper than  Yours (and What to Do about It), 1. ed, A Singularity University Book (New York, NY: Diversion Books, 2014). 75 ArtificiAl intelligence And the future of defense </page> <page sequence="17"> Unlike companies, defense organizations are not in the business of producing private  financial value. They are, however, there to produce public security value. Recent  developments in geodynamics (Russia, ISIS, terrorism, etc.) suggest that the demand for  that defense security value is increasing – both by preventing and dealing with security  threats, and by jumping on security opportunities223. The en-vogue term ‘hybrid warfare’  suggests that also some of our adversaries are experimenting with such new, less linear  and more ‘piggybacking’ models for organizing their defense efforts.  The ‘platform ecosystem’ model might offer some lessons for a different way in which  our defense organizations might provide defense and security value for their taxpayers’  money – re-actively against traditional and ‘new’ challenges, but also pro-actively to new  reap new opportunities for prevention and building resilience-building. Many of the key  trends that have enabled the platform ecosystem revolution in the private sector are  equally relevant and visible in the security realm. Most of the emerging physical and,  increasingly, digital technologies that connect and empower business ecosystems are  organically intertwined with the security dynamics in our societies. Social networks  connect both the agents of conflict and the agents of resilience; the agents of progress  and the agents of regress. Just like companies can now increasingly leverage available  market intelligence about individuals’ preferences ‘from the source’ – the (big) data that  is being generated and collected – but also the individual creativity and drive of individual  and networked entrepreneurs, so too could (legitimate and responsible) defense and  security professionals find ways to leverage the mega-trend of global personal and inter- personal empowerment in order to achieve our defense and security objectives. Our current myopic focus on the first three layers of ‘defense and security’ may have  obscured the existence of an increasingly vibrant defense and security ecosystem ‘out  there’. With many diverse actors – some known, many more unknown – that could help  our defense and security organizations in achieving their goals, both as sensors and as  effectors. This ecosystem may include app developers that are currently using big data  to develop apps for ‘our’ daily needs, but that could also be incentivized to dream up  apps that could address defense and security challenges in fragile, conflict-ridden or  propaganda-afflicted regions. It may include individual youngsters, farmers, fishermen,  mothers with smartphones living in those same regions, who could be empowered as  agents of stability or resilience. It includes the rapidly exploding global deep learning and  AI community that is coming up with new ways to diagnose and address various problems  (in terms of economy, education, health, but also security) much earlier in the process. It  certainly includes companies that benefit from stability in developing their markets, but  that also contribute to the same through their investments. Could our defense organizations start using big data and AI to become the catalysts and  custodians of these broader defense and security ecosystems – not by trying to ‘command  &amp; control’ the ecosystem actors, but by stimulating, facilitating and leveraging them? Can  223  See the recent HCSS Strategic Monitors for more details De Spiegeleire and Sweijs, Volatility and Friction in the  Age of Disintermediation. HCSS StratMon 2016-2017 Yearly Report; De Spiegeleire et al., Si Vis Pacem, Para Utique Pacem.  Individual Empowerment, Societal Resilience and the Armed Forces. HCSS RepoRt 76 </page> <page sequence="18"> we imagine defense capability planning processes that try to include not only their ‘own’  capabilities, but that start looking for a better balance between those ‘own’ capabilities  and capabilities to empower various ecosystem players? Whereby ‘defense‘ is no longer  just the operator who intervenes heavily, physically, lately in a conflict dynamic (and we  still foresee a need for that security function as well) ; but the more strategic custodian  who looks for ways to intervene, digitally and early in the process? A thoughtful curator  that advocates a better balance between conflict-centric and resilience-centric efforts in  order to maximize the defense value proposition? 4�3� AI in Other Armed Forces Today The armed forces of the world’s leading military powers all recognize the qualitative  edge AI systems are likely to give them today and tomorrow – soldiers who often “face  problems of scale, complexity, pace and resilience that outpace unaided human decision  making.”224 Whether for commanders faced with unconventional adversaries in high- speed engagements; intelligence analysts faced with drawing the correct conclusions  from petabytes of noisy data; or frontline soldiers; AI promises to augment analysis and  decision-making capabilities and reaction times both, speed up learning, and improve  their ability to act with discretion, accuracy, and care under uncertain and changing  conditions. It is therefore little surprise that many of world’s leading militaries are  running active AI development and deployment programs; however, it is the way these AI  systems are tailored to underlying needs, which reveals a lot about the evolving strategic  and tactical doctrines of these powers – and the changing nature of deterrence and  warfare in the decades to come.  In this section, we present some evidence that can be gleaned from open sources on the  military AI efforts made by four particularly active countries, which will be surveyed in  purely alphabetic order. 4.3.1. China As the second biggest ‘player’ in general-purpose AI China is increasingly showing  that it is more than capable of keeping pace with the US in this field. While in terms  of fundamental breakthroughs, China is still lagging behind the US, there has been a  massive increase in growth in terms of cited (machine learning) research.225 To spur this,  in February 2017, China’s National Development and Reform Commission approved a  plan to establish an online ‘national laboratory for deep learning’, commissioning Baidu  to set up the research effort which will focus on seven areas of research including  machine learning-based visual recognition, voice recognition, new types of human  224  Artificial Intelligence · Lockheed Martin,” accessed September 21, 2016, http://www.lockheedmartin.com/us/ atl/research/artificial-intelligence.html. 225  Zhang, “China’s Artificial-Intelligence Boom.”. Cf. Niu et al., “Global Research on Artificial Intelligence from  1990–2014.” 77 ArtificiAl intelligence And the future of defense </page> <page sequence="19"> machine interaction and deep learning intellectual property. The overarching goal, it  stated, is to “boost China’s overall competence in artificial intelligence”.226 Meanwhile,  major Chinese companies such as Baidu, Alibaba and Tencent have proven remarkably  adept at rapidly iterating over breakthroughs to develop – and deploy – applications of this  technology,227 as well as making remarkable home-grown breakthroughs in fields such as  speech recognition228 or self-driving cars.229 These developments are catalyzed by a high-performance computing (HPC) industry  which is increasingly self-reliant: after the US government banned the sale of powerful  Intel Xeon processors to Chinese supercomputing initiatives in April 2015,230 China was  able to substitute its own, native-build processors in the design of the Sunway TaihuLight,  since 2016 the world’s fastest supercomputer.231  Moreover, this drive towards AI is spurred on by strong links between private actors and  civilian applications on the one hand, and government agencies (specifically the People’s  Liberation Army - PLA) on the other. Such government support goes all the way to the  top: in 2016, China’s 13th 5-year plan (2016-20) highlighted the importance of further  breakthroughs in AI, as did the 13th 5-year National Science and Technology Innovation  Plan.232 In 2016, the Chinese government announced plans to develop a 100 billion RMB  ($15 billion) AI market by 2018.233 These initiatives have been characterized as part of the  “China Brain Plan” (中国脑计划),234 an ambitious effort to develop artificial intelligence  and deploy it in unmanned systems, in cyber security and for social governance – and for  military supremacy – under the umbrella of President Xi Jinping’s national strategy of  “military-civil fusion” (军民融合).235 At present, the Chinese military’s initial approach to artificial intelligence is still strongly  informed by its examination of US developments and initiatives. This echoes historical  context: in the wake of the 1st Gulf War, as US forces demonstrated the supremacy of  226   Meng Jing, “China’s First ‘deep Learning Lab’ Intensifies Challenge to US in Artificial Intelligence Race,” South  China Morning Post, February 21, 2017, http://www.scmp.com/tech/china-tech/article/2072692/chinas-first-deep- learning-lab-intensifies-challenge-us-artificial. 227   Zhang, “China’s Artificial-Intelligence Boom.” 228   Will Knight, “Baidu System Rivals People at Speech Recognition,” MIT Technology Review, 2015, https://www. technologyreview.com/s/544651/baidus-deep-learning-system-rivals-people-at-speech-recognition/. 229  Aaron Mamiit, “China’s Baidu Unveils New All-Electric, Self-Driving Car: Testing Begins For Modified Chery  EQ,” Tech Times, August 28, 2016, http://www.techtimes.com/articles/175317/20160828/chinas-baidu-unveils-new-all- electric-self-driving-car-testing-begins-for-modified-chery-eq.htm 230   Don Clark, “U.S. Agencies Block Technology Exports for Supercomputer in China,” Wall Street Journal, April  9, 2015, sec. Tech, http://www.wsj.com/articles/u-s-agencies-block-technology-exports-for-supercomputer-in- china-1428561987 231  Zhang, “China’s Artificial-Intelligence Boom.” 232   People’s Republic of China, “The People’s Republic of China National Economic and Social Development of  the Thirteenth Five-Year Plan,” 2016, http://www.gov.cn/xinwen/2016-03/17/content_5054992.htm.; People’s Republic  of China, “13th Five-Year National Science and Technology Innovation Plan,” 2016, http://www.gov.cn/zhengce/ content/2016-08/08/content_5098072.htm 233   Xiao, “The Chinese Government Wants A 100 Billion RMB AI Market By 2018.” 234  Xinhua News Agency, “中国‘脑计划’纳入规划全面展开 坚持‘一体两翼,’” Xinhua News Agency, 2016, http://news. xinhuanet.com/politics/2016-08/18/c_129238381.htm.; Elsa Kania, “China May Soon Surpass America on the Artificial  Intelligence Battlefield,” Text, The National Interest, (February 21, 2017), http://nationalinterest.org/feature/china-may- soon-surpass-america-the-artificial-intelligence-19524 235   Kania, “China May Soon Surpass America on the Artificial Intelligence Battlefield.” HCSS RepoRt 78 </page> <page sequence="20"> network-centric warfare, the PLA embarked on an ambitious agenda of ‘informatization’  (信息化).236 While it has made great strides in this space, the PLA ultimately has not yet  caught up to evolving US integration of information technologies. As such, being faced with  the US’s ‘Third Offset Strategy’, the PLA has identified a great need – and opportunity –  to use the disruptive potential of AI to match or even leapfrog US capabilities, seeking  what it calls a “military revolution of intelligentization”: moving beyond “digitalization”  (数字化) and “networkization” (网络化), to achieve the transition from ‘informatized’ to  ‘intelligentized’ (智能化) warfare.237 Concretely, as part of this effort the PLA has established an Intelligent Unmanned Systems  and Systems of Systems Science and Technology Domain Expert Group (军委智能无人系 统及体系科学技术领域专家组), and has invested in and field-tested intelligent unmanned  vessels for reconnaissance missions and to reinforce the PLA Navy’s ability to monitor  and establish a presence in disputed waters.238 The PLA has also made breakthroughs  in UAV swarming and command and control, and even – inspired by AlphaGo’s victory  over Lee Sedol in the ancient Chinese game of go –  explored the role of intelligentized  command and control within a joint operations command system.239 Another area of Chinese interest is missile technology: in order to counter the US’s  ‘semi-autonomous’ Long Range Anti-Ship Missile (LRASM) – a replacement for the  Harpoon missile, capable of autonomously following waypoints, avoiding engagement  range of non-target ships, and optimizing strike location for maximum lethality240 –  China has expressed interest in utilizing AI to empower the flight guidance and target  recognition systems in new generations of its own cruise missiles. This could enhance  their operational versatility, allowing commanders to tailor missiles to specific and  rapidly altering battlefield conditions.241 Wang Changqing, director of the General Design  Department of the China Aerospace Science and Industry Corp’s 3rd Academy, told China  Daily that Chinese engineers have researched such applications for AI for many years,  and they are leading the world, adding that “our future cruise missiles will have a very  high level of artificial intelligence and automation. They will allow commanders to control  them in a real-time manner, or to use a fire-and-forget mode, or even to add more tasks  to in-flight missiles.”242 This, Chinese officials hope, may enable and strengthen a doctrine  236   Elsa Kania, “The Next U.S.-China Arms Race: Artificial Intelligence?,” The National Interest, 2017, http:// nationalinterest.org/feature/the-next-us-china-arms-race-artificial-intelligence-19729 237   Ministry of National Defense of the People’s Republic of China, “The Dawn of the Intelligent Military  Revolution” (People’s Liberation Army Daily, January 28, 2016), http://www.mod.gov.cn/wqzb/2016-01/28/ content_4637961.htm.; Kania, “The Next U.S.-China Arms Race.” 238   Kania, “China May Soon Surpass America on the Artificial Intelligence Battlefield.” 239   Ibid.; Kania, “The Next U.S.-China Arms Race.” 240   Lockheed Martin, “LRASM: Overview,” Lockheed Martin, 2016, http://www.lockheedmartin.com/us/products/ LRASM/overview.html 241   Zhao Lei, “Nation’s next Generation of Missiles to Be Highly Flexible,” China Daily, 2016, http://www.chinadaily. com.cn/china/2016-08/19/content_26530461.htm.; Ben Blanchard, “China Eyes Artificial Intelligence for New Cruise  Missiles,” Reuters, August 19, 2016, http://www.reuters.com/article/us-china-defence-missiles-idUSKCN10U0EM.;  Abhijit Singh, “Is China Really Building Missiles With Artificial Intelligence?,” The Diplomat, 2016, http://thediplomat. com/2016/09/is-china-really-building-missiles-with-artificial-intelligence/ 242   Lei, “Nation’s next Generation of Missiles to Be Highly Flexible.”;Blanchard, “China Eyes Artificial Intelligence  for New Cruise Missiles.” 79 ArtificiAl intelligence And the future of defense </page> <page sequence="21"> known as ‘remote warfare’, whereby large fleets of small vessels are able to successfully  attack, and evade or overwhelm the point defense systems of larger capital ships such as  US aircraft carriers.243 Significantly, given that the PLA conventionally approaches military innovation through a  lens of ‘technology determines tactics’,244 they may be more inclined to rely upon artificial  intelligence than the US – and may be more willing to relinquish ‘meaningful human  control’ in order to achieve ever-greater cognitive speed in battlefield decisions. 4.3.2. Israel Israel was one of the first countries to reveal that it has deployed fully automated robots:  self-driving military vehicles to patrol the border with the Palestinian-governed Gaza Strip.  Next in the IDF’s plans is to equip the vehicles with weapons, and deploy them in stages to  Israel’s frontiers with Egypt, Jordan, Syria, and Lebanon. Meanwhile, the Israeli ‘Harpy’  anti-radiation unmanned aerial vehicle is claimed to already able to detect, target, and  engage enemy radar installations without any human oversight or supervision.245 Further  in the future, the military is looking to form mixed combat units of robotic vehicles and  human soldiers.246 Various Israeli companies also claim to apply AI in a number of their defense systems.  The former chief of the Israel Defense Forces’ (IDF’s) Central Command and current head  of land systems at Israel Aerospace Industries (IAI), Major General (retd) Gadi Shamni, for  instance, told IHS Jane’s that the company has spent enormous sums on research and  development (R&amp;D) aimed at developing new products to enable the IDF and overseas  clients detect and accurately strike time-critical targets. “In an age of big data, this  requires a system that can handle such heavy information loads so IAI has developed  an automated system, called Automated Decision Making (ADM), that employs artificial  intelligence and robotics to sift through the data and respond to it instantly.”247 Israeli contractor Aeronautics Ltd has also produced a range of UAV control systems  which allegedly contain AI-algorithms. One of those systems, Aeronautics’ Unmanned  243   Cf. John Markoff and Matthew Rosenberg, “China’s Intelligent Weaponry Gets Smarter,” The New York  Times, February 3, 2017, https://www.nytimes.com/2017/02/03/technology/artificial- intelligence-china-united-states.html 244   Cf. Dennis J. Blasko, “‘Technology Determines Tactics’: The Relationship between Technology and Doctrine in  Chinese Military Thinking,” Journal of Strategic Studies 34, no. 3 (June 1, 2011): 355–81, doi:10.1080/01402390.2011.574 979 245  Paul Scharre, “Robotics on the Battlefield, Part I: Range, Persistence and Daring,” 20YY Series: Preparing  for War in the Robotic Age. (Center for a New American Security, May 2014), http://www.cnas.org/sites/default/files/ publications-pdf/CNAS_RoboticsOnTheBattlefield_Scharre.pdf., footnote 50 246   The Future of War: Israel First to Deploy Fully Automated Military Robots,” The Mainichi, August 24, 2016,  http://global.factiva.com/redir/default.aspx?P=sa&amp;an=AIWMDM0020160824ec8o00105&amp;cat=a&amp;ep=ASE.; Israel Today,  “Israel First to Deploy Autonomous Military Robots,” Israel Today, August 25, 2016, http://www.israeltoday.co.il/ NewsItem/tabid/178/nid/29924/Default.aspx. 247   Yaakov Lappin, “Interview: Gadi Shamni, Head of Land Systems, Israel Aerospace Industries,” Jane’s Defence  Weekly, September 7, 2016, http://janes.ihs.com.proxy1.athensams.net/Janes/Display/1782846 HCSS RepoRt 80 </page> <page sequence="22"> Multi-Application SystemTM (UMAS), is “a software-based package that is designed to  provide ‘advanced’ control of a ‘variety’ of manned and unmanned applications. As such,  it is described as incorporating proprietary artificial intelligence and ‘unique’ interfaces  and as offering ‘unrivalled’ levels of system reliability and performance. System  functions include artificial intelligence-based electronic/mechanical failure prediction;  real-time decision making support; the facilitating of data transfer between systems;  and hierarchical handling of fixed/variable order data strings as a function of tool safety  (using an integral time domain camouflage interface).”248 Also in the field of combat simulation, Israeli defense electronics company Elbit  Systems Ltd produces a Command and Staff Trainer (CST) that simulates a range of  joint operations. The system is purported to include advanced simulation models (full  spectrum of conflict, mounted operations in urban terrain, out-of-the-window homeland  security) that contain a scenario with thousands of entities and large training areas and  include artificial intelligence for aggregate behaviors.249 The system was delivered to the  Royal Netherlands Army (RNLA) in 2012 for use in command and staff exercises, for  concept development and experimentation (CD&amp;E), as well as mission rehearsal events  to simulate complex battlefield operations in both low and high-intensity conflicts as well  a broad spectrum of non-military settings, such as operations other than war (OOTW) and  civil-military cooperation (CIMIC), including operation of military forces with municipal  authorities, police and medical organization.250 As is increasingly the case in the civilian world, AI is often used as a sales pitch. It is  virtually impossible to independently verify the various claims made by these companies.  Israel’s prowess in AI is widely acknowledged, however, also stimulated by the many  startups that emerge in the IDF’s ecosystem.251 4.3.3. Russia While still somewhat lagging behind on its great power rivals in terms of deep machine  learning capabilities, the Russian Federation has displayed a steady commitment to  developing and deploying a wide range of robotic military platforms, including unmanned  ground vehicles (UGVs), with the full backing of its MoD and domestic industries: in  January 2017, President Putin called for the creation of “autonomous robotic complexes”  248   Jane’s, “Aeronautics Control Systems,” Jane’s Unmanned Aerial Vehicles and Targets, 22-Mar-17, http://janes. ihs.com.proxy1.athensams.net/Janes/Display/1318450 249   Jane’s, “Elbit Systems Ltd - Command and Staff Training Systems,” Jane’s Simulation and Training Systems,  March 23, 2017, http://janes.ihs.com.proxy1.athensams.net/Janes/Display/1592554. 250   army-technology.com, “Elbit Delivers Command and Staff Trainer to Royal Netherlands Army - Army  Technology,” November 23, 2012, http://www.army-technology.com/news/newselbit-delivers-command-staff-trainer- royal-netherlands-army 251   Ariel Felner, “The Israeli AI Community,” AI Magazine 37, no. 3 (October 7, 2016): 118–22; Eze Vidra, “30  Machine Intelligence Startups to Watch in Israel,” Medium, February 15, 2017, https://medium.com/@ediggs/30- machine-intelligence-startups-to-watch-in-israel-a05b6597c4a5.. For more on the Israeli start-up culture See also  Dan Senor and Saul Singer, Start-up Nation: The Story of Israel’s Economic Miracle, Reprint edition (New York: Twelve,  2011). 81 ArtificiAl intelligence And the future of defense </page> <page sequence="23"> for use by the military,252 previously entrusting the Advanced Research Foundation with  the new ‘National Center for the Development of Robotic Technologies and Basic Robotic  Components’, in order to consolidate so far uncoordinated efforts for the creation of  advanced robotic equipment. Andrey Grigoryev, General Director of the Foundation, has  noted that “the centre will allow for efficiently sharing information about already available  developments and achievements, will lead to their unification, to making the world’s best  military-use and special-purpose robots from the best components, including control  systems, visual equipment complexes, special sensors, and much more. We have  many rather interesting domestic achievements in the most advanced sectors.”253 In an  interview by the official Russian newspaper Rossiyskaya Gazeta in August 2016, Grigoryev  detailed an exercise in the Nizhniy Tagil training range in which an unmanned helicopter  quickly detected a concealed ‘enemy’, issued a command to a tracked ‘terminator-robot’  armored vehicle named ‘Nerekhta’ armed with missiles and machine guns that deployed  to a firing position, made its own decisions about what would be best to use in a given  situation to destroy the targets, and accomplished the mission of destroying the ‘enemy’  successfully.254 More critically, while most Russian robotic UGVs are still in development and testing  stages, a number of them have actually seen active combat service: the Uran-6 demining  robot saw use by Russian forces operating in Syria, amongst others for clearing Palmyra  of booby traps and IEDs left behind by ISIS forces in the wake of the March 2016 regime  offensive against the city.255 Already, Russian defense experts have suggested that the  robot’s larger cousin, the heavily armed and armored Uran-9, may be deployed in Syria in  support of Russian or Syrian regime ground operations,256 although there are indications  that to present this has not yet taken place.257 Similarly, the ‘Platforma-M’ reconnaissance  UGV, developed by the ‘Progress’ Science and Technical Institute, is currently deployed  with the Russian Pacific Fleet.258 The heavy ‘Udar’ UGV, unveiled in 2015, comes in combat,  engineering support, and transportation versions, and has been built on the existing  frame of the BMP-3 armored vehicle, in order to ease the maintenance and repair of the  system.259 252   ФБА «Экономика сегодня», “Назад В Будущее: Путин Объявил Эру Боевых Роботов,” Рамблер/Новости,  January 26, 2017, https://news.rambler.ru/politics/35932393-nazad-v-buduschee-putin-obyavil-eru-boevyh-robotov/. 253   Сергей Птичкин, “Умная пуля видит цель,” Российская Газета, July 19, 2016, sec. СОБЫТИЯ И  КОММЕНТАРИИ; Арсенал 254   Russian Pundit Interviewed on Latest Combat Equipment,” BBC Monitoring Former Soviet Union, August 4, 2016,  http://global.factiva.com/redir/default.aspx?P=sa&amp;an=BBCSUP0020160804ec84000m9&amp;cat=a&amp;ep=ASE 255   Russia Today, “Russia’s Mine-Clearing Uran-6 Robots to Help Get Rid of Hidden Explosives in Palmyra  (VIDEOS),” RT International, March 30, 2016, https://www.rt.com/news/337810-russia-palmyra-demine-robot/.; cf.  Samuel Bendett, “Get Ready, NATO: Russia’s New Killer Robots Are Nearly Ready for War,” Text, The National Interest,  (March 7, 2017), http://nationalinterest.org/blog/the-buzz/russias-new-killer-robots-are-nearly-ready-war-19698. 256   Эксперт Не Исключил, Что Новейший комплекс ‘Уран-9’ испытают В Сирии,” РИА Новости, January 9,  2017, https://ria.ru/arms/20170109/1485307092.html; Ян Грогман, “Российский Робот-Танк «Уран-9»: Бесполезная  Игрушка Или Революция?,” ИноСМИ.Ru, April 13, 2016, http://inosmi.ru/military/20160413/236108861.html 257   Арик Толер, “Использовала Ли Россия Боевых Роботов В Сирии?,” ИноСМИ.Ru, January 17, 2016, http:// inosmi.ru/military/20160117/235078297.html 258   nortwolf_sam, “Роботизированный Комплекс «Платформа-М» На Вооружении Тихоокеанского Флота,”  Nortwolf_sam, October 11, 2015, http://nortwolf-sam.livejournal.com/1054499.html 259   Bendett, “Get Ready, NATO.” HCSS RepoRt 82 </page> <page sequence="24"> Notably, at present most of these Russian military bots are still designed (or deployed)  to be controlled by remote operator, as the Russian defense establishment remains  somewhat uncomfortable with the notion of fully autonomous military systems:260 in  2015, the Russian daily Komsomolskaya Pravda still argued that “such [fully autonomous]  weapons are of an offensive nature, while our military doctrine is defensive [...] If there  is an artificial brain in such a system, you never know what may happen, since ‘friend or  foe’ computer and signal mechanics can be easily suppressed by means of electronic  warfare, which is one of Russia’s key military strengths.”261  However, while Russia might put some faith in its electronic warfare abilities to try and  scramble or nullify the autonomous weapons deployed by its adversaries, it is possible  this attitude will change should the Russian military face increasing numbers of fully  autonomous, and highly responsive combat systems.262 Finally, Russia’s United Instrument Manufacturing Corporation (OPK) is working on  using AI systems for border protection, developing a system which will automatically  interact with video cameras, infrared and seismic sensors, radars and drones, in order  to monitor and observe any type of violations. In addition, the new system, to be deployed  on Russia’s Eastern and Southern borders, is intended not only to collect different types  of information, but also contains elements of artificial intelligence which will allow for  analysis and forecasting of the situation and work out proposals for the protection of  borders, by calculating steps and routes that offenders may take, as well as the necessary  measures to prevent malicious acts, including the assessment of possible risks.263 4.3.4. US As of yet the most prominent actor in the field of military AI, the United States has been  actively involved in AI-related R&amp;D since its very emergence of the field (see chapter 2  page 26). However, having overseen and driven much of the early breakthroughs in  AI research (and computer science broadly) during the Cold War, the bulk of the US’s  efforts have now shifted towards deploying these technologies with a clear focus on  increasing its armed forces’ operational effectiveness as well as standoff force projection  capabilities (A2A in our terminology). One well-known driver of the US’s commitment to developing these systems is their  extensive military experience, over the last two decades, with drone systems. As a result  of this experience, notably in Iraq and Afghanistan, US spending on Unmanned Aircraft  Systems (UAS) grew tenfold, from $283 million in 2000 to $2.9bn in 2016. At the same  time, the US inventory of UAS exploded a staggering 65x (from 167 to 11,000) between  260   Samuel Bendett, “Can Russia’s Military Bots Keep Pace?,” RealClearWorld, August 27, 2015, http://www. realclearworld.com/blog/2015/08/robots_military_russia_hopes.html.; Bendett, “Get Ready, NATO.” 261   Михаил ТИМОШЕНКО | Сайт «Комсомольской правды», “Война Под Микроскопом,” KP.RU - Сайт  «Комсомольской Правды», August 6, 2015, http://www.kp.ru/daily/26415/3289072/. 262   Bendett, “Get Ready, NATO.” 263   Sputnik, “Robots on Patrol: Russian Borders to Be Guarded by Artificial Intelligence,” 2016, https:// sputniknews.com/military/201606301042223143-russian-borders-guarded-robots/. 83 ArtificiAl intelligence And the future of defense </page> <page sequence="25"> 2002 and 2013, even in the face of multi-year downturns in overall US defense spending.264  The patent success of these systems has as such led to the formulation of the ‘Unmanned  Systems Integrated Roadmap’, setting out an ambitious roadmap for further developing  all Unmanned Autonomous Systems (airborne, ground and maritime) in the period up to  2038.265 However, US ambitions in the field of ‘intelligent weaponry’ go far beyond this; in 2015,  the Pentagon’s fiscal 2017 budget request included $12-15 billion to fund war gaming and  the demonstration of new technologies – including wearable electronics, exoskeletons,  autonomous weapons and unmanned aircraft; drone mother ships and deep-learning  machines – which could ensure a continued military edge over great powers such as  China and Russia.266 These investments, and the major role they reserve for AI in future  military force projection, reflect the core logic of the Pentagon’s so-called ‘Third Offset  Strategy’.267 This doctrine, in development since 2012, was first announced in November 2014 by  Chuck Hagel,268 and later pursued and implemented by Ashton B. Carter, both successive  US Secretaries of Defense under President Obama.269 Aiming at a geostrategic doctrine  that can preserve a qualitative military advantage in the face of rising rivals,270 the ‘Third  Offset’ strategy is intended to be the successor to the First Offset Strategy of the 1950s –  in which President Dwight D. Eisenhower sought to develop nuclear-warhead and missile  technologies to counter and deter Soviet conventional numerical superiority – and the  Second Offset Strategy of the 1970s – in which Secretary of Defense Harold Brown  shepherded the development of precision-guided munitions, stealth, and intelligence,  surveillance, and reconnaissance (ISR) systems to counter the nuclear parity and  numerical superiority and improving technical capability of Warsaw Pact forces along the  Central Front in Europe.271 264   Bank of America Merrill Lynch, “Robot Revolution - Global Robot &amp; AI Primer.”, pg. 7 265   Department of Defense, “Unmanned Systems Integrated Roadmap: FY2013-2038,” 2013, http://archive. defense.gov/pubs/DOD-USRM-2013.pdf. 266   Shalal, “Pentagon Eyes $12-15 Billion for Early Work on New Technologies.” ; cf. also Mackenzie, “The  Future Military-Artificial Intelligence Complex? | FT Alphaville,” Financial Times - Alphaville, 2015, http://ftalphaville. ft.com/2015/12/15/2147846/the-future-military-artificial-intelligence-complex/. 267   Joshua Pavluk and August Cole, “From Strategy to Execution: Accelerating the Third Offset,” War on the Rocks,  June 9, 2016, http://warontherocks.com/2016/06/from-strategy-to-execution-accelerating-the-third-offset/., John  Markoff, “Pentagon Turns to Silicon Valley for Edge in Artificial Intelligence,” The New York Times, May 11, 2016, http:// www.nytimes.com/2016/05/12/technology/artificial-intelligence-as-the-pentagons-latest-weapon.html. 268   Cf. Robert Martinage, “Toward a New Offset Strategy: Exploiting U.s. Long-Term Advantages to Restore U.s.  Global Power Projection Capability” (Center for Strategic and Budgetary Assessments, 2014), http://csbaonline.org/ uploads/documents/Offset-Strategy-Web.pdf. 269   Ashton Carter, “Keynote Address: The Path to the Innovative Future of Defense,” Center for Strategic and  International Studies, October 28, 2016, https://csis-prod.s3.amazonaws.com/s3fs-public/event/161028_Secretary_ Ashton_Carter_Keynote_Address_The_Path_to_the_Innovative_Future_of_Defense.pdf.. The authors of this report  recognize that the change in administration which has occurred since the articulation of the Third Offset has re-opened  many settled strategic assumptions, and may lead to major changes in the US force posture, operational doctrine, and  procurement policies. Nonetheless while some modest structural changes may occur, there is at present no reason  to suppose a drastic change in the role of AI within the doctrine. Cf. also Theodore R. Johnson, “Donald Trump’s  Pentagon and the Future of the Third Offset Strategy: Will the Department of Defense Invest in People or Technology?,”  The Atlantic, November 29, 2016, https://www.theatlantic.com/politics/archive/2016/11/trump-military-third-offset- strategy/508964/ 270   Markoff and Rosenberg, “China’s Intelligent Weaponry Gets Smarter.” 271   Timothy A. Walton, “Securing The Third Offset Strategy: Priorities For Next US Secretary Of Defense – Analysis  HCSS RepoRt 84 </page> <page sequence="26"> What does that look like in practice? Speaking in 2015, Robert Work, the then-US deputy  secretary of defense, emphasized “human-machine collaboration combat teaming”,  arguing that: “Early adoption will be a key competitive advantage, while those that lag  in investment will see their competitiveness slip”.272 In this speech to the Defense One  National Security Forum conference, Work identified five pillars to the military future:273 1� Autonomous deep learning machine systems which are able to see the patterns  through the chaff of hybrid warfare, to give early warning that something is  happening in gray zone conflict areas (such as the Ukraine), and which are able  to respond at extreme speed, and under rapidly shrinking engagement windows.  Such learning systems might, he argues, fill the gap in those fields – such as  air defense or cyber defense – where human operators alone cannot achieve  sufficient speed to stop or degrade a determined attack. 2� Human machine collaboration, which will include the promotion of so-called  ‘Centaur’ warfighting,274 going from the observation that teams combining the  strategic analysis of a human with the tactical acuity of a computer, reliably  defeat either human-only or computer-only teams across many games. 3� Assisted human operations, whereat wearable electronics, uploadable combat  apps; heads up displays, exoskeletons, and other systems, can enable humans  on the front line to perform better in combat. 4� Advanced human-machine combat teaming where a human working with  unmanned systems is able to take better decisions and undertake cooperative  operations. Examples of these are the Army’s Apache and Gray Eagle UAV  systems, which are designed to operate in conjunction. Other examples are  drone ‘motherships’; electronic warfare networks, or swarming systems which  will help transform operations by enabling one mission commander to direct a  full swarm of micro-UAVs. 5� Network-enabled semi-autonomous weapons, where systems are both linked,  and hardened to survive cyberattack.275 All of these systems would be networked together through learning systems, enabling  a form of ‘algorithmic warfare’ and a machine-learning approach to targeting.276 In this  | CSBA,” CSBA | Center for Strategic and Budgetary Assessments, July 27, 2016, http://csbaonline.org/2016/07/27/ securing-the-third-offset-strategy-priorities-for-next-us-secretary-of-defense-analysis/.. For a view on what this  means for Europe, see Daniel Fiott, “Europe and the Pentagon’s Third Offset Strategy,” The RUSI Journal 161, no. 1  (January 2, 2016): 26–31, doi:10.1080/03071847.2016.1152118. 272   Mackenzie, “The Future Military-Artificial Intelligence Complex? | FT Alphaville.” 273   Ibid 274   Sydney J. Freedberg, “Centaur Army: Bob Work, Robotics, &amp; The Third Offset Strategy,” Breaking Defense,  November 9, 2015, http://breakingdefense.com/2015/11/centaur-army-bob-work-robotics-the-third-offset-strategy/ 275   Mackenzie, “The Future Military-Artificial Intelligence Complex? | FT Alphaville.” 276   Cf. Charlie Lewis, “Capturing Flying Insects: A Machine Learning Approach to Targeting,” War on the Rocks,  September 6, 2016, http://warontherocks.com/2016/09/capturing-flying-insects-a-machine-learning-approach- to-targeting/.. Note that such ‘algorithmic warfare’ also may call for oversight and accountability within the chain  of command Cf. Dustin A. Lewis, Gabriella Blum, and Naz K. Modirzadeh, “War-Algorithm Accountability,” SSRN  Scholarly Paper (Rochester, NY: Social Science Research Network, August 31, 2016), http://papers.ssrn.com/ abstract=2832734. 85 ArtificiAl intelligence And the future of defense </page> <page sequence="27"> way, military operations can increase in accuracy and pace, and learning ability, all the  while being guided by intelligence operations which are, through deep learning-enabled  ‘anticipatory intelligence’, increasingly able to anticipate the development of social unrest  and societal instability several days in advance.277 What is the doctrine backing up this strategic interest and investment? In terms of  strategic emphasis, one of the best articulations of current US thinking can probably be  found back in the 2015 study on Autonomy that was recently published (after a one-year  delay) in June 2016 by the DOD’s Defense Science Board (DSB)278, a committee of civilian  experts that provides the Secretary of Defense with independent advice on scientific  and technical matters279. The study focuses on “institutional and enterprise strategies  to widen the use of autonomy; approaches to strengthening the operational pull for  autonomous systems; and an approach accelerate the advancement of the technology for  autonomy applications and capabilities”.280 The officially commissioned but independent  study concluded that “action is needed in all three areas to build trust and enable the  most effective use of autonomy for the defense of the nation”. The focus of the study in terms of the areas where the DSB feels that autonomy can  deliver value by mitigating operational challenges lies on: rapid decision-making; high  heterogeneity and/or volume of data; intermittent communications; high complexity of  coordinated action; danger of mission and High persistence and endurance. All of these  challenges are quite (sensibly) generic, and might just as well be applied to preventing  conflict (as opposed to fighting it) or to strengthening resilience. Yet the way in which  they are operationalized in the study puts them all within the current focus on (mostly  industrial-kinetic, but increasingly also cyber) operations that are predominantly focused  on combatting the enemy. The heart of the study lies in its chapter 4 page 61, which  focuses on ‘operational pull’.281 Most of the concrete actions they endorse lie in the  traditional realm – with a few cyber exceptions interspersed. In essence, this is an agenda  to ‘insert’ AI into the currently dominant mode of thinking about armed force. The study concludes with the observations that advances in artificial intelligence  have ensured autonomy has now crossed a ‘tipping point’, and that such autonomous  capabilities are increasingly and readily available to allies and adversaries, on the basis of  277   Frank Konkel, “The CIA Says It Can Predict Social Unrest as Early as 3 to 5 Days Out,” Defense One, 2016, http:// www.defenseone.com/technology/2016/10/cia-says-it-can-predict-social-unrest-early-3-5-days-out/132121/ 278   Defense Science Board, “Autonomy.” 279   Defense Science Board, “Defense Science Board - Charter,” May 6, 2016, http://www.acq.osd.mil/dsb/charter. htm 280   Defense Science Board, “Defense Science Board Summer Study on Autonomy,” 2016, https://www.hsdl. org/?abstract&amp;did=794641., i. 281   The key passage here, from our point of view, is the following: “Because the DoD mission is so broad, it  was beyond the scope of this study to conduct an exhaustive review of, and search for, all of the beneficial roles for  autonomy. Rather, the study chose to select representative system and mission applications to illustrate the potential  value of autonomy. The study investigated four areas in depth–protection, battlespace awareness, force application,  and logistics. These are joint capability areas that could immediately adopt existing autonomous technologies.” This  illustrates nicely what we see as the profoundly disruptive nature of AI on the one hand and the current mode of  operating in defense. The DSB study, while clearly sympathizing with the former, ends up on the side of the latter. This  study advocates starting from the former. HCSS RepoRt 86 </page> <page sequence="28"> which it recommends that the DoD “take immediate action to accelerate its exploitation  of autonomy while also preparing to counter autonomy employed by adversaries.”282 The authors of this study have no quarrel with most of the recommendations of this DSB  study. We do, however, feel that the study misses an important part of what AI can mean  for defense and security from a strategic – and not merely operational – point of view.  Our own hunch is that AI (and a number of attendant technological developments that are  co-emerging around big data) may have a much more disruptive impact on the essence  ‘defense’ than the focus on AI-enhanced physical robotics and how they might affect our  current way of safeguarding defense suggest. This is what we want to focus on in the  subsequent chapters. 4�4� Use Cases This section provides a number of concrete use cases for AI in defense organizations.  This list illustrates applications of AI useful to military purposes are not limited to  solely enhancing ‘kinetic’ or ‘hard power’ functions in a tactical context, but also include  supportive, logistical, and strategic applications providing forces with a qualitative edge,  information, and staying power. The list reflects the current literature’s – as well as the  leading nations’ defense (see section 4.3) – focus on what we have called the A2A layer,  but also includes a number of use cases from the other layers where HCSS suspects  better investement opportunities. As such, this overview is intended to be illustrative  rather than exhaustive, and to spark debate and exploration, rather than settle it. 4.4.1. Automating Cyber Operations (G2G, D2D) In the first place, AI systems can play a powerful role in their ‘native’ environment –  cyberspace. There are indications that AI’s ability to sift through prohibitively large  quantities of data, and pick up on vague cues can strengthen security: for instance,  Distil Networks uses machine learning algorithms to begin to defend against Advanced  Persistent Threat bots, whose interactions are normally difficult to discern from real  human users;283 likewise, Google284 and the behavior analytics company Gurucul285 each  separately have developed artificial intelligence-based approaches to cybersecurity  based on user and risk profiles instead of human-defined rules. Scientists at Arizona  State University have developed machine learning algorithms for identifying zero-day  282   Defense Science Board, “Autonomy.”, pg. Iii; (cf. pg. 99-101) 283   Connor Forrest, “How Distil Networks Uses Machine Learning to Hunt down ‘Bad Bots’ - TechRepublic,”  TechRepublic, August 3, 2016, http://www.techrepublic.com/article/how-distil-networks-uses-machine-learning-to- hunts-down-bad-bots/. 284   Cage Metz, “Google’s Training Its AI to Be Android’s Security Guard | WIRED,” WIRED, May 2, 2016, http://www. wired.com/2016/06/googles-android-security-team-turns-machine-learning/. 285   Mark Cox, “Machine-Learning Based Risk Analytics Vendor Gurucul Launches First Channel Program,”  ChannelBuzz.ca, June 1, 2016, http://www.channelbuzz.ca/2016/06/machine-learning-based-risk-analytics-vendor- gurucul-launches-first-channel-program-17747/. 87 ArtificiAl intelligence And the future of defense </page> <page sequence="29"> security exploits, and tracing them as they spread around the hacker community;286 and  researchers at MIT’s Computer Science and Artificial intelligence Laboratory have worked  with startup PatternEx to construct a ML system that can review more than 3.6 billion  lines of log files each day, to detect 85% of attacks, autonomously learning from- and  countering cyberattacks as they evolve in real time.287 Nonetheless, such systems can also  be a double-edged sword, as they can facilitate the automation of vulnerability-detection  and exploitation software. This was shown by the victory of MAYHEM, an AI developed by  Carnegie Mellon University, in the 2016 Cyber Grand Challenge, a competition started by  DARPA to spur the development of automatic cyber defense systems which can discover,  prove and (if used defensively) correct software flaws and vulnerabilities in real time.288 4.4.2. Algorithmic Targeting (A2A) Another major use case for AI, of particular value in a tactical context, is the use of AI in  developing rapid and accurate automatic target recognition (ATR) systems: start-up Deep  Learning Analytics, for instance, has developed a machine-learning based ATR program  prototype for DARPA, to trial systems assisting pilots in finding and engaging targets.289  This is part of DARPA’s Target Recognition and Adaptation in Contested Environments  (TRACE) research program, which seeks to deliver an accurate, real-time, and energy- efficient target recognition system that can work with existing radar systems, to provide  long-range targeting capabilities for tactical airborne surveillance. This is useful since visual identification of targets by human pilots requires flying at close  approach, putting aircraft at risk from anti-aircraft systems; conversely, although radar in  principle enables the identification and engaging of ground targets at a standoff distance,  this comes at the cost of unacceptably high false-alarm rates or collateral damage. ATR  systems can thus combine the best of both worlds: highly accurate aircraft fire support  from a standoff distance.290 Key tactical requirements for such a capability are that it can  offer low false-alarm rates in complex environments – ensuring it is not easily thrown of  by decoys, or mistakes – and can rapidly improve its learning capabilities on the basis of  sparse or limited training data.291  286   Eric Nunes et al., “Darknet and Deepnet Mining for Proactive Cybersecurity Threat Intelligence,” arXiv Preprint  arXiv:1607.08583, 2016, http://arxiv.org/abs/1607.08583 287   Kalyan Veeramachaneni and Ignacio Arnaldo, “AI2: Training a Big Data Machine to Defend,” accessed August  20, 2016, http://people.csail.mit.edu/kalyan/AI2_Paper.pdf.. For a shallow overview of startups and actors developing  AI cybersecurity solutions, see AI.Business, “Artificial Intelligence in Defence and Security Industry,” AI Business, 2016,  http://ai.business/2016/06/21/artificial-intelligence-in-defence-and-security-industry/ 288   DARPA, “‘Mayhem’ Declared Preliminary Winner of Historic Cyber Grand Challenge,” 2016, http://www.darpa. mil/news-events/2016-08-04.; Coldewey, “Carnegie Mellon’s Mayhem AI Takes Home $2 Million from DARPA’s Cyber  Grand Challenge.” 289   Deep Learning Analytics,” Deep Learning Analytics, 2016, http://www.deeplearninganalytics.com/single- post/2016/05/15/Deep-Learning-Analytics-Develops-DARPA-Deep-Machine-Learning-Prototype 290   John Keller, “DARPA TRACE Program Using Advanced Algorithms, Embedded Computing for Radar Target  Recognition,” Military &amp; Aerospace Electronics, July 24, 2015, http://www.militaryaerospace.com/articles/2015/07/hpec- radar-target-recognition.html. 291   Ibid. HCSS RepoRt 88 </page> <page sequence="30"> A more extreme version of these systems could also see the increasing combat  competitiveness of UAVs acting as ‘wingmen’ to human fighter pilots: in the spring of 2016,  Psibernetix’s artificially intelligent fighter pilot ALPHA soundly defeated US Air Force  Colonel (ret.) Gene Lee in a series of simulated dogfights. The ‘fuzzy logic’ based system  was able to process sensor data and plan combat moves in less than a millisecond (more  than 250 times faster than the eye can blink), while using no more computing power than  that supplied by a $29 Raspberry Pi.292 Reflecting on the exercise, the experienced air  instructor argued that it was “the most aggressive, responsive, dynamic and credible AI  I’ve seen to date.”293 Algorithmic targeting could also increase versatility and accuracy at a theatre level. In  the US, the joint targeting cycle currently consists of six major steps – ”(1) end state  and commander’s objectives, (2) target development and prioritizing, (3) capabilities analysis,  (4) commander’s decision and force assignment, (5) mission planning and force execution,  and (6) assessment”294. Each of this steps contains its own feedback mechanisms and  time lags. Yet while this approach works well in traditional wars, in complex combat  environments, where insurgent networks could reform or quickly adapt to dominant  institutional tactics, the amounts of data available on which decisions could be based,  can overwhelm traditional analysts, at times actually inhibiting effective, accurate  or informed decisionmaking. In this context, integrating machine learning systems to  process diverse information can allow for faster, more effective – and more accurate –  targeting decisions.  As noted by one analyst, “[t]he computer can identify a targeted building as a hospital  instead of an insurgent stronghold by querying a non-governmental organization (NGO)  database instead of hoping a commander is aware of that information.”295 If applied with  care, such systems could make battlefield decisionmaking not only more rapid and  responsive in complex or vague environments, but also actually reduce the risk of civilian  casualties – although such ‘war-algorithms’ may again raise their own quandaries in  terms of accountability.296 4.4.3. Mission Handoff (A2A; A2D) Sustaining military efforts for longer periods of time requires regularly rotating units.  This may be required by reasons of time (optimizing the operational tempo of the units)  or context (changes in the operational environment that require different force bundles;  292   Coby McDonald, “A.I. Downs Expert Human Fighter Pilot In Dogfight Simulation | Popular Science,” Popular  Science, June 27, 2016, http://www.popsci.com/ai-pilot-beats-air-combat-expert-in-dogfight?src=SOC&amp;dom=tw.. For  the study, see also Nicholas Ernest et al., “Genetic Fuzzy Based Artificial Intelligence for Unmanned Combat Aerial  Vehicle Control in Simulated Air Combat Missions,” Journal of Defense Management 06, no. 01 (2016), doi:10.4172/2167- 0374.1000144 293   M.B. Reilly, “Beyond Video Games: New Artificial Intelligence Beats Tactical Experts in Combat Simulation,”  University of Cincinnati Magazine, June 27, 2016, http://magazine.uc.edu/editors_picks/recent_features/alpha 294   Lewis, “Capturing Flying Insects.” 295   Ibid. 296   Cf. Lewis, Blum, and Modirzadeh, “War-Algorithm Accountability.” 89 ArtificiAl intelligence And the future of defense </page> <page sequence="31"> new equipment entering the force that an outgoing unit lacks; etc.). The United States’  Armed Forces define mission handoff as “[T]he process of passing an ongoing mission  from one unit to another with no discernible loss of continuity” (e.g. situational awareness,  adversary composition, allies, host nation forces, civilian populace, other USG, etc.)”. 297  Mission handoff has proved a major challenge to many Western militaries, especially in  high-threat environments where operational security is of paramount importance. Some  of the problems include: • The short timeframe available for handoff while in theater, combined with the  difficulties of sharing information afterward; • The dynamic nature of the operational environment, creating uncertainty over  what information will be relevant; • Unwillingness of combat-weary outgoing units – eager to return home – to  spend much time on handoff; • Mismatch in the information or capabilities offered by the outgoing unit, and  those needed by the incoming unit; • Format mismatch as Information (e.g. AARs, intel reporting) is often stored on  laptops in un- or poorly structured formats. In the current situation, outgoing units typically meet face-to-face with incoming units  and transfer a select number of documents they deem relevant and important. In the  short run, AI may offer the incoming unit with an opportunity to have the system ingest all  unstructured text generated by the departing unit during its deployment (including After  Action Reports, intelligence reports, briefing materials, etc.). Throughout their rotation,  they could then query the AI-enhanced knowledge base for insights. 4.4.4. Situational Awareness and Understanding (A2A) While greatly supporting force projection in asymmetric conflicts, UAVs at present still  know a number of operational limitations, such as a low flying speed and vulnerability to  air defense systems. Increasing the autonomy of unmanned systems will strengthen their  survivability, enable more higher-end performance, and improve their effectiveness at  patrolling or monitoring areas. This feeds into an increased ability for militaries or states  to cover far greater areas with sensors, at greater cost-effectiveness than human troops.  The enhanced situational awareness enabled by more autonomous and survivable drones  can strengthen the security of bases and, experts have suggested, could potentially  lead to greater stability between states (such as North- and South Korea) by enhancing  monitoring of contested areas, reducing the viability of covert or ‘hybrid’ operations.298 297   United States, Joint Chiefs of Staff, Foreign Internal Defense, Joint Publication, JP 3-22 (Washington, D.C.: Joint  Chiefs of Staff, 2010), http://purl.fdlp.gov/GPO/gpo29282 298   Michael C. Horowitz, Sarah E. Kreps, and Matthew Fuhrmann, “The Consequences of Drone Proliferation:  Separating Fact from Fiction,” SSRN Scholarly Paper (Rochester, NY: Social Science Research Network, January 25,  2016), https://papers.ssrn.com/abstract=2722311. HCSS RepoRt 90 </page> <page sequence="32"> Conversely, such innovations can also destabilize deterrence. In the spring of 2016,  DARPA also trialled the Sea Hunter, the first full-scale prototype of its Anti-Submarine  Warfare (ASW) Continuous Trail Unmanned Vessel (ACTUV).299 On the principle that the  hardest aspect about countering enemy submarines is not so much tracking them once  found, but finding them in the first place, these cost-effective ships are designed to  scour the seas for quiet (missile) submarines, and once found automatically trail their  quarry globally and for months. The resulting accurate, cost-effective and up-to-date  ASW intelligence could have revolutionary – and potentially destabilizing – implications  for the (perceived) survivability of the traditionally near-invulnerable seaborne leg of the  nuclear triad.300 In a completely different battlefield context, AI systems could greatly increase the safety  and efficacy of forces (or indeed non-military government personnel) operating in-the- field, in foreign environments or unfamiliar cultures: systems such as the improved  Google Translate or IBM Watson, when combined with natural-language processing and  natural voice synthesis capabilities, will be fluent in hundreds of languages, making  shortages of interpreters a thing of the past. Moreover, improvements in facial- and  emotional recognition systems could improve the ability of soldiers equipped with  persistent-stare surveillance modules to gauge a situation, and to ascertain the intent –  hostile or peaceful – of many dozens of individuals on crowded streets at a glance.301  Applied with care, this could simultaneously support early threat identification, and  could reduce the risk of intercultural miscommunications or misperceptions leading to  unnecessary or unwitting escalation of interactions with local actors or civilians. 4.4.5. Automated Planning and Manpower Allocation (A2A) While full-fledged ‘automated planning’ is currently still proving a bottleneck on AI  development,302 machine learning systems working from datasets of soldiers’ capacity  tests and their past mission performance (individually and in different constellations  of teammates) on different types of missions, could formulate elaborate models.  On the basis of these, commanders could gain a comprehensive assessment of an  individual’s skills, experience, personality, strengths, weaknesses or psychological  condition. Machine learning systems could also help them align human talent to mission  requirements, and optimize team composition for specific missions, based on expertise  &amp; personality, or past unit performance under different conditions. Finally, such systems  could draw up force rosters which balance different constraints (e.g. training schedules,  299   Rachel Courtland, “DARPA’s Self-Driving Submarine Hunter Steers Like a Human,” IEEE Spectrum:  Technology, Engineering, and Science News, April 7, 2016, http://spectrum.ieee.org/automaton/robotics/military-robots/ darpa-actuv-self-driving-submarine-hunter-steers-like-a-human.. For project overview, see Scott Littlefield, “Anti- Submarine Warfare (ASW) Continuous Trail Unmanned Vessel (ACTUV),” DARPA, accessed September 19, 2016, http:// www.darpa.mil/program/anti-submarine-warfare-continuous-trail-unmanned-vessel 300   James R. Holmes, “Sea Changes: The Future of Nuclear Deterrence,” Bulletin of the Atomic Scientists 72, no.  4 (July 3, 2016): 228–33, doi:10.1080/00963402.2016.1194060.; Cf. The Economist, “Anti-Submarine Warfare: Seek, but  Shall Ye Find?,” The Economist, August 6, 2016, http://www.economist.com/news/science-and-technology/21703360- proliferation-quieter-submarines-pushing-navies-concoct-better-ways 301   Cf. Anthony Cruz, “The Robot General: Implications of Watson on Military Operations,” Armed Forces Journal,  2011, http://armedforcesjournal.com/the-robot-general/. 302  Geist, “(Automated) Planning for Tomorrow: Will Artificial Intelligence Get Smarter?” 91 ArtificiAl intelligence And the future of defense </page> <page sequence="33"> scheduled downtime, priority missions), ensuring efficient use of service members’ time,  and indirectly improving morale.hat optimize force time-efficiency and, indirectly, morale. Figure 13: AuTOMATeD PLANNiNg AND MANPOWer ALLOCATiON 4.4.6. Target Systems Analysis/Target Audience Analysis (A2A, G2G, D2P) Target Systems Analysis (TSA) and Target Audience Analysis (TAA) are intelligence- related methods used to develop deep understanding of potential areas for operations.  They involve the analysis of reports, documents, newsfeeds and other forms unstructured  information. Further afield, AI systems could provide probabilistic forecasts of enemy  behavior, anticipate and flag bottlenecks or vulnerabilities in supply lines before they  occur, and suggest mitigation strategies; draw on data (e.g. weather conditions collected  by drones), to examine factors affecting operations and assess the viability of different  mission approaches. Natural language processing programs can filter social media  and news to identify strategically salient themes303 – or, conversely, can text-mine the  mission reports of own and allied forces in order to identify common themes or patterns  in engagements. For instance, an influential 2015 paper assessed 2,200 military combat incidents involving  ISIS, mining these incidents to derive relationships and rules for ISIS vehicle-borne  improvized explosive device attacks, as well as indirect fire. By modelling ISIS’s behavior,  the researchers were able to identify priority targets for the movement, and find strong,  previously unrecognized correlations between tactics, such as the fact that spikes in  car bombs in Baghdad were often the prelude to ISIS attacks on Northern Iraqi cities,  suggesting that ISIS used the bombings as a diversion to draw Iraqi security forces away  from prospective targets.304  303  Benjamin Jensen and Ryan Kendall, “Waze for War: How the Army Can Integrate Artificial Intelligence,” War  on the Rocks, September 2, 2016, https://warontherocks.com/2016/09/waze-for-war-how-the-army-can-integrate- artificial-intelligence/. 304   Andrew Stanton et al., “Mining for Causal Relationships: A Data-Driven Study of the Islamic State,”  arXiv:1508.01192 [Cs], August 5, 2015, http://arxiv.org/abs/1508.01192.. Cf. Alex Lockie, “This Algorithm Could Help  Predict ISIS’ Future Moves,” Business Insider, 2015, http://www.businessinsider.com/machine-learning-used-to- HCSS RepoRt 92 </page> <page sequence="34"> Similarly, by drawing on a mix of classified and open-source data, and analyzing these  using machine learning algorithms, the CIA in 2016 claimed to have achieved an  impressive level of ‘anticipatory intelligence’, being able to anticipate the rise of social  unrest and societal instability up to three to five days in advance.305 In this way, the product of the analysis is a sophisticated knowledge of the key individuals  and organizations that operate in the economic, cultural, political, tribal, religious  spheres of a society. This in turn informs operational planning and deployment, and may  also involve the active shaping of public opinion through the careful crafting of messages  for specific audiences. 4.4.7. Lessons Learned – Operational and Non-Operational (A2A, A2D) During and after operations and exercises, defense organizations collect information  in order to enable lessons to be developed, shared and learned to help continuous  improvement. Intelligent systems (such as IBM’s Watson) could curate repositories  and support intelligent query analysis (not unlike many current Google services) enable  military personnel to find applicable lessons and apply them to their situation.  Already today, so-called ‘Intelligent Tutoring Systems’ (ITS) are used in the military  to develop, cost-effectively deploy responsive, scalable teaching programs that can  tailor themselves to the learning needs of each individual.306 For instance, an ITS  called SHERLOCK is being used to teach Air Force technicians to run electrical system  diagnostics on aircraft,307 and the Information Sciences Institute at the University of  Southern California has developed an avatar-based training program to prepare military  personnel in appropriate intercultural communication when posted abroad.308 4.4.8. Options Analysis for Capability Development (A2A, A2D) Options analysis is a key early step in the capability development process.Some  governments require that the option set in the initial stages of the acquisition process  includes at least one Off-the-Shelf (OTS) solution, where available, as a benchmark.  Options that move beyond the requirements of an OTS solution must include a rigorous  cost-benefit analysis of the additional capability sought so that the full resource risks  and other impacts are understood by governments. As defense must be able to effectively  implement any option presented, each option must be achievable in financial, technical,  logistics, workforce and schedule terms. The time, effort and expense of examining each  predict-and-model-isis-2015-9 305   Konkel, “The CIA Says It Can Predict Social Unrest as Early as 3 to 5 Days Out.” 306   Stanford University, “Artificial Intelligence and Life in 2030 One Hundred Year Study on Artificial Intelligence |  Report of the 2015 Study Pane.”; p.32. 307   Alan Lesgold et al., “SHERLOCK: A Coached Practice Environment for an Electronics Troubleshooting Job,” in  Computer-Assisted Instruction and Intelligent Tutoring Systems: Shared Goals and Complementary Approaches (Hillsdale,  New Jersey: Lawrence Erlbaum Associates, 1988). 308   Michael V. Yudelson, Kenneth R. Koedinger, and Geoffrey J. Gordon, “Individualized Bayesian Knowledge  Tracing Models,” Artificial Intelligence in Education, 2013, 171–80. 93 ArtificiAl intelligence And the future of defense </page> <page sequence="35"> option in detail makes it essential to concentrate on investigating usually no more than  three or four options. Even then that is likely to take 12–18 months to develop the required  level of detail. The use of AI may improve the rigour of the analysis and employ trade off  analytics to expedite the process 4.4.9. Electronic Medical Records Analysis &amp; Optimizing Medevac (A2A, D2G) In partnership with the US Veterans Administration IBM’s Watson Research team has  developed a clinical reasoning prototype called the Electronic Medical Record Analyzer  (EMRA). This preliminary technology is designed to ingest a patient’s electronic medical  record and, using machine-learning techniques, automatically identify and rank the most  important health problems for which the patient should be seen. The system is trained  to identify symptoms, triggers and risk factors in patient vitals, physician notes, and  lab reports. It compares this patient information with the latest medical knowledge in  textbooks, medical journals and pharmaceutical information to alert the physician to the  patient’s most serious health problems. In a tactical context, narrow AI agents could also aid in the medevac of injured personnel  from insecure areas: such systems can query up-to-date databases and cross-reference  these against live intelligence from other forces in the area. Combining information on the  severity of injuries, the length and security of available exfiltration routes, landing sites  and weather conditions, and the projected rate of medical emergencies in the coming  days, such a system can perform a preliminary triage and determine the optimal means  of evacuating casualties, increasing the efficiency and safety of medical evacuations –  and saving lives.309 4.4.10. Documents Classification and ‘Crypto-Preserving’ Intelligence Sharing (D2G,  G2G) During and after operations and exercises, defense organizations have a need to move  information between security domains. This requires the careful checking of the content  to ensure no highly classified data or information will be moved or revealed to a less  highly classified user or system. While aspects can be automated, the checking often  requires a human to conduct the check. This can be very time consuming and is prone  to inaccuracy. Watson may be able to more accurately read, understand and verify the  content is safe to send from one domain to another, and also help to minimize data  aggregation risks – and reduce the risk of inadvertent leaks. Perhaps more importantly,  Google has recently conducted research into ‘privacy-preserving deep learning’,310 which  could enable multiple organizations (such as hospitals) to share and combine sensitive  data (e.g. patient information) on which to train overarching machine learning systems,  without actually divulging the underlying information.311  309   Jensen and Kendall, “Waze for War.” 310   Reza Shokri and Vitaly Shmatikov, “Privacy-Preserving Deep Learning” (ACM Press, 2015), 1310–21,  doi:10.1145/2810103.2813687 311   Cf. H. Brendan McMahan et al., “Communication-Efficient Learning of Deep Networks from Decentralized  HCSS RepoRt 94 </page> <page sequence="36"> Likewise, using a technique called homomorphic encryption, Microsoft has developed  what it calls ‘CryptoNets’, which are trained deep-learning systems which can  take encrypted data and spit out encrypted (but accurate) answers.312 The potential  applications of such a system for intelligence sharing could be revolutionary – enabling  allied intelligence services to enjoy most of the strategic and operational benefits of  freely pooling their information and data (e.g. allowing the analysis of global patterns  in terrorist communications, tactics or strategy), without the fear that leaks or double  agents in their allies’ services might compromize that information or its sources. 4.4.11. ‘P4’ Conflict Prevention – Predictive, Preventive, Personalized and Participatory  (X2I) Critically, whereas most of the previous use cases fall within the more traditional  industrial-age ‘defense’ box the authors of this report suspect that AI’s most fundamental  (and disruptive) impact may lie elsewhere. The first one we offer resides in the area  of prevention. Many defense efforts are currently still predominantly focused on the  response stage of the conflict cycle. Armed forces, so goes the argument, are there to  wage and win wars or to prevail in conflicts short of war.  Many – also military – voices are increasingly suggesting that we may have to start  focusing more on prevention. In many ways, this trend closely mirrors an analogous  development in the medical field which is slowly but steadily shifting its focus from  punctual interventions to ‘fight disease’ to more systemic approaches to prevent disease  and stimulate healthy lifestyle choices.  One strand of this new thinking has gained some popularity under the acronym ‘P4’:  Predictive, Preventive, Personalized and Participatory medicine’. Big data sets – from  molecular and cellular data, over conventional medical data, to vast amounts of new  imaging, demographic and environmental data – that are constantly analyzed by  machine learning algorithms are expected to allow a radically different, more proactive  and ‘systemic’ approaches to health care that may reverse the ever escalating costs of  healthcare and lead to better health outcomes.313 Could we imagine a similar trend in defense and security whereby the combination of big  data, ever more powerful computational and AI-algorithmic capabilities leads to deeper  insights into the (even individual) drivers of conflict and whereby AI can then also be used  to nudge potential agents of conflict away from realizing their malign intentions?  Data,” arXiv:1602.05629 [Cs], February 17, 2016, http://arxiv.org/abs/1602.05629 312  Nathan Dowlin et al., “CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and  Accuracy,” Microsoft Research, February 8, 2016, https://www.microsoft.com/en-us/research/publication/cryptonets- applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy/.; cf. Tom Simonite, “Microsoft  and Google Want to Let Artificial Intelligence Loose on Our Most Private Data,” MIT Technology Review, 2016, https:// www.technologyreview.com/s/601294/microsoft-and-google-want-to-let-artificial-intelligence-loose-on-our-most- private-data/; Tom Simonite, “A Cloud That Can’t Leak,” MIT Technology Review, 2011, https://www.technologyreview. com/s/424942/a-cloud-that-cant-leak/. 313   Walhout, et al., 2013; Flores, et al., 2013; Tian, et al., 2012; Hood, &amp; Friend, 2011 95 ArtificiAl intelligence And the future of defense </page> <page sequence="37"> Figure 13 describes the example of Alphabet (Google) Jigsaw’s Redirect Method that is  already putting this idea in practice, as described by Wired magazine. Google has built a half-trillion-dollar business out of divining what people want  based on a few words they type into a search field. In the process, it’s stumbled  on a powerful tool for getting inside the minds of some of the least understood  and most dangerous people on the Internet: potential ISIS recruits. Now one  subsidiary of Google is trying not just to understand those would-be jihadis’  intentions, but to change them. Jigsaw, the Google-owned tech incubator and think tank—until recently known  as Google Ideas—has been working over the past year to develop a new program  it hopes can use a combination of Google’s search advertising algorithms and  YouTube’s video platform to target aspiring ISIS recruits and ultimately dissuade  them from joining the group’s cult of apocalyptic violence. The program, which  Jigsaw calls the Redirect Method and plans to launch in a new phase this month,  places advertising alongside results for any keywords and phrases that Jigsaw  has determined people attracted to ISIS commonly search for. Those ads link to  Arabic- and English-language YouTube channels that pull together preexisting  videos Jigsaw believes can effectively undo ISIS’s brainwashing—clips like  testimonials from former extremists, imams denouncing ISIS’s corruption of  Islam, and surreptitiously filmed clips inside the group’s dysfunctional caliphate  in Northern Syria and Iraq. “This came out of an observation that there’s a lot of online demand for ISIS  material, but there are also a lot of credible organic voices online debunking their  narratives,” says Yasmin Green, Jigsaw’s head of research and development.  “The Redirect Method is at its heart a targeted advertising campaign: Let’s take  these individuals who are vulnerable to ISIS’ recruitment messaging and instead  show them information that refutes it.” The results, in a pilot project Jigsaw ran early this year, were surprisingly effective:  Over the course of about two months, more than 300,000 people were drawn to  the anti-ISIS YouTube channels. Searchers actually clicked on Jigsaw’s three or  four times more often than a typical ad campaign. Those who clicked spent more  than twice as long viewing the most effective playlists than the best estimates of  how long people view YouTube as a whole. And this month, along with the London- based startup Moonshot Countering Violent Extremism and the US-based Gen  Next Foundation, Jigsaw plans to relaunch the program in a second phase that  will focus its method on North American extremists, applying the method to both  potential ISIS recruits and violent white supremacists... But Green says that the Redirect Method, beyond guiding ISIS admirers to its  videos, doesn’t seek to track them further or identify them, and isn’t designed to  lead to arrests or surveillance, so much as education. “These are people making  HCSS RepoRt 96 </page> <page sequence="38"> decisions based on partial, bad information,” says Green. “We can affect the  problem of foreign fighters joining the Islamic State by arming individuals with  more and better information.” She describes the campaign’s work as a kind of  extension of Google’s core mission “to make the world’s information accessible  and useful.” Perhaps one of world’s most dangerous problems of ignorance and  indoctrination can be solved in part by doing what Google does best: Helping  people find what they most need to see.314” 4.4.12. Empowering Societal Resilience (G2I, E2I) In previous work,315 HCSS has introduced the notion that there are two flip-sides to the  security coin: the (highly mediatized) side of the ‘agents of conflict’, and the (surprisingly  far less mediatized) side of the ‘agents of (societal) resilience’. We have argued that  societal resilience to conflict – the healthy fibers in today’s societies that contain organic  antibodies to any excesses of violence – has increased over time and in many senses only  continues to strengthen.316 We have also submitted that any strategic net assessment of  our current security environment and of the available options portfolio that would allow  us to achieve our defense and security objectives in a more sustainable way should strive  to strike a better balance between the realm of conflict on the one hand (preventing and  stopping conflict), and on the other hand the realm of resilience (stimulating both ‘home’  and ‘forward’ resilience). We want to stress that in our usage of the term ‘resilience’, it applies to both our own  societies and to other societies that may be on their way to erupting in violent conflict or  to pose a threat to international stability. Resilience is – maybe surprisingly – a relative  newcomer in the defence realm. During the Cold War (or before that – e.g. ) our own  societal resilience did play a significant role in our defense planning efforts. In recent  decades it did much less so, although recent security events like terrorism, refugees  and populism are once again raising its visibility. As Europe is increasingly concerned  about the security effects that radiate inwards from its neighborhood, more (also cost-) effective actionable options to strengthen the security resilience in our neighbors are  once again gaining political visibility. 314   Andy Greenberg, “Google’s Clever Plan to Stop Aspiring ISIS Recruits,” WIRED, September 7, 2016, https:// www.wired.com/2016/09/googles-clever-plan-stop-aspiring-isis-recruits/. 315   De Spiegeire, et al., 2016; De Spiegeleire, &amp; Sweijs, 2017; De Spiegeleire, et al., 2015 316   Diamandis, &amp; Kotler, 2012; Oosterveld, et al., 2015; Pinker, 2011; Nordberg, 2016 97 ArtificiAl intelligence And the future of defense </page> <page sequence="39"> The Conflict Model The Resilience Model Agents Agents of conflict Agents of resilience Goals of main agents Disruption Normalcy ‘Glue’ between agents Strong Weak Organizational form (Mostly) Organized group (Maybe networked) Individuals Efforts by ‘us’  (Responsive) Ops/PsyOps (Preventive) Resilience/nurturing efforts Action by ‘us’ Force Nudge (‘Our’) Desired effects Stop conflict/’win’ Nurture conflict immunity Figure 14: CHArACTeriSTiCS OF THe CONFLiCT MODeL VS THe reSiLieNCe MODeL  If we connect this idea of focusing more of our public defense and security efforts on  resilience as opposed to conflict to the different layers(/generations) of AI we have  described in this think piece, an entirely new options horizon opens up. As we described  in the previous use case, our ability to track and understand the dynamics that lead to  either strengthened or weakened societal resilience based on a combination of big data,  ever more powerful computational and AI-algorithmic capabilities is likely to increase  exponentially. Can we imagine our armed forces catalyzing a broader network of sensors  and effectors within the defense and security ecosystem that might be able to stimulate  both our own and others’ ‘immune system’ against destructive conflict? Would we not  want to make sure that our defense (and capability) planning efforts can better adjudicate  the claims over scarce resources coming from the more traditional ‘conflict- and war- centric’ constituencies within our armed forces and defense organizations vs from these  more ‘resilience-centric’ ones? As we noted in our section about the caveats surrounding AI, there are various legal,  ethical and other (even existential) issues that our societies and our polities will have  to think through before embarking upon any large-scale efforts to apply AI to ’defense  and security’. Many of these caveats apply to both the more traditional defense areas  as well as to the prevention and the resilience aspects of ‘defense AI’. We would still  submit, however, that these last two use cases may prove to be far more palatable to  our societies (and polities) than the applications of AI that aim for ‘autonomous’ lethal  strike. The current campaign against ‘killer drones’ already heralds fundamental and  comprehensible societal apprehensions about applying AI to the ‘kill-chain’. We suggest  that re-focusing that debate on how AI could be used in a more positive way for both  prevention and resilience capabilities might prove far more productive. HCSS RepoRt 98 </page> </plain_text> 
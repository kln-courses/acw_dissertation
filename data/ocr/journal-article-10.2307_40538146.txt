<plain_text><page sequence="1">PHILOSOPHICAL TRANSACTIONS OF T^ THE ROYAL ï% PhiL Trans- R- Soc- B (2009) 364, 3527-3538 SOCIETY MJ doi:10.1098/rstb.2009.0157 Role of expressive behaviour for robots that learn from people Cynthia Breazeal* The MIT Media Lab, 20 Ames Street, El 5 room 149, Cambridge, MA 02139, USA Robotics has traditionally focused on developing intelligent machines that can manipulate and inter- act with objects. The promise of personal robots, however, challenges researchers to develop socially intelligent robots that can collaborate with people to do things. In the future, robots are envisioned to assist people with a wide range of activities such as domestic chores, helping elders to live inde- pendently longer, serving a therapeutic role to help children with autism, assisting people undergoing physical rehabilitation and much more. Many of these activities shall require robots to learn new tasks, skills and individual preferences while 'on the job' from people with little exper- tise in the underlying technology. This paper identifies four key challenges in developing social robots that can learn from natural interpersonal interaction. The author highlights the important role that expressive behaviour plays in this process, drawing on examples from the past 8 years of her research group, the Personal Robots Group at the MIT Media Lab. Keywords: social robotics; human robot interaction; robot learning; expressive behaviour; affective computing 1. INTRODUCTION Studies by the United Nations Economic Commission and International Federation of Robotics forecast a dramatic increase in consumer demand for robots that assist, protect, educate and entertain over the next 20-30 years. In the future, personal robots will be able to help people as capable assistants in their daily activities. Consider cooperative activities such as preparing a meal together, building a structure with teammates or teaching someone a new skill. Through sophisticated forms of social interaction and learning, people are able to accomplish more than they could alone. Socially intelligent robots could have a significant positive impact on real-world challenges, such as helping elders to live independently at home longer, serving as learning companions for children and enriching learning experiences through play, serving a therapeutic role to help children with autism learn communication skills, or functioning as effective members of human -robot teams for disaster response missions, construction tasks and more. Many of these applications require robots to engage humans in sophisticated forms of social interaction, including human-centred multi-modal communi- cation, teamwork and social forms of learning such as tutelage. Over the past several years, my research has focused on endowing autonomous robots with social intelligence to enable them to engage in the powerful, social forms of interaction and learning that people readily participate. This vision is motivated * cynthiab @media . mit . edu Electronic supplementary material is available at http://dx.doi.org/ 10.1098/rstb.2009.0157 or via http://rstb.royalsocietypublishing.org. One contribution of 17 to a Discussion Meeting Issue 'Computation of emotions in man and machines'. by the observation that humans are ready-made experts in social interaction; the challenge is to design robots to participate in what comes naturally to people. By doing so, socially interactive robots could help not only specialists, but anyone. Today, however, autonomous and semi-autonomous robots are widely regarded as tools that trained oper- ators command and monitor to perform tasks. Beyond robustness and proficiency in the physical world, how- ever, the promise of personal robots that can partake in the daily lives of people is pushing robotics and AI research in new directions. Whereas robotics has tra- ditionally focused on developing machines that can manipulate and interact with things, the promise of per- sonal robots challenges us to develop robots that are adept in their interactions with people. Further, in con- trast to the traditional view of robots as sophisticated tools that we use to do things for us, this new generation of socially intelligent robots is envisioned as partners that collaborate to do things with us. Over the past several years, new research fields have emerged (i.e. human-robot interaction and social robotics) to address challenges in building robots that are skilful in their interactions with people (Dautenhahn 1995; Fong et al 2003; Breazeal 20046; Duffy 2008). Given that social robots are designed to interact with people in human-centric terms within human environments, many are humanoid (e.g. Tanaka et al. 2004; Ogura et al. 2006) or animal-like (e.g. Fujita 2004; Wada et al. 2005) in form, and even the more mechanical-looking robots tend to have anthropo- morphic movement or physical features (e.g. Kozima 2006; Tanaka et al. 2006). A unifying characteristic is that social robots com- municate and coordinate their behaviour with humans through verbal, non-verbal or affective modalities. For instance, these might include whole-body motion 3527 This journal is © 2009 The Royal Society</page><page sequence="2">3528 C. Breazeal Expression in social robots (e.g. dancing, Duffy 2003; walking hand-in-hand, lim et al 2004), proxemics (i.e. how a robot should approach a person, Walters et al 2008; follow a person, Gockley et al 2007; or maintain appropriate interpersonal distance, Brooks &amp; Arkin 2007), gestures (e.g. pointing, shrugging shoulders or shaking hands, Miwa et al 2004a,¿&gt;; Roccella et al 2004), facial expressions (e.g. lida et al 1998; DiSalvo et al 2002; Berns &amp; Hirth 2006; Hayashi et al 2006), gaze behaviour (e.g. Kikuchi et al 1998; Sakita et al 2004; Sidner et al 2005), head orientation and shared attention (e.g. Imai et al 2001; Fujie et al 2004), linguistic and paralinguistic cues (e.g. Matsusaka et al 2003; Fujie et al 2005) or emotive vocalization (e.g. Cahn 1990; Abadjieva et al 1993), social touch-based communication (e.g. Stiehl et al 2005) and how these cues complement verbal communication (e.g. Cassell et al 2000). Progress continues in building robots that can learn from people, through observation, imitation or direct tutelage (for reviews see Schaal 1999; Argall et al 2009). For instance, impressive strides have been made in designing robots that learn new skills (e.g. pen- dulum swing-up, Atkeson &amp; Schaal 1997 'b; body schema, Hersch et al 2008; peg insertion, Hovland et al 1996; dance gestures, Mataric et al 1998; com- munication skills and protocols, Billard et al 1998; Roy &amp; Pentland 1998; Scassellati 1998) as well as tasks (e.g. stacking objects, Kuniyoshi et al 1994; Calinon &amp; Billard 2007; fetch and carry, Nicolescu &amp; Mataric 2003; setting a table, Pardowitz et al 2007 or sorting objects into bins, Saunders et al 2006; Chernova &amp; Veloso 2008). Modern robots are beginning to participate as members of heterogeneous teams that cooperate with people in order to achieve shared goals. For instance, a remote human might supervise a distributed team of robots to perform a task (e.g. disaster response or search and rescue, Bluethmann et al 2004; Murphy et al 2008). In addition, co-located teamwork has been explored such as a human and a robot working side by side (Adams et al 2009), or a team of humans and robots working in the same area to assemble a structure (Fong et al 2005). Furthermore, as people begin to interact with robots more closely, it is important that robots' behav- iour, rationale and motives be easily understood. The more these mirror natural human analogues, the more intuitive it becomes for us to communicate and coordinate our behaviour with robots. Researchers have begun to explore the role of affect (e.g. Picard 2000; Fellous &amp; Arbib 2005; Duffy 2008; Cañamero), perspective taking and theory of other minds (e.g. Scassellati 2001; Johnson &amp; Demiris 2005; Trafton et al 2005), and even simple forms of empathy (Dautenhahn 1997; Breazeal et al 2005a) and models of attachment (Cañamero et al 2006) in generating a robot's behaviour. A relevant issue underlying these different kinds of interactions is how people form social judgements of robots - are robots perceived as trustworthy, persua- sive, reliable, likeable, etc. (e.g. Kidd &amp; Breazeal 2008; Siegel 2008)? A number of groups have also explored how people's social judgements of robots compare to animated agents and even mixed-reality Phil. Trans. R. Soc. B (2009) agents (Holz et al 2009). It is intriguing that the phys- ical presence of robots seems to matter to people as robots often score higher than their virtual counter- parts on measures of engagement, social presence, working alliance as well as social influence on human behaviour (e.g. Kidd &amp; Breazeal 2004; Powers et al 2007; Bainbridge et al 2008). Researchers have started delving into functional magnetic resonance imaging studies to try to understand these differences and to what extent people attribute human character- istics to robots, including theory of mind (Krach et al 2008). 2. ROBOTS THAT LEARN FROM PEOPLE Within this broader context of human-robot interaction (HRI) and social robotics, this paper sum- marizes the past 8 years of research from my group (the Personal Robots Group at the MIT Media Lab; http://www.media.mit.edu/~cynthiab; http://robotic. media.mit.edu; Breazeal 2002) with respect to signifi- cant lessons we have learned in our quest to build robots that can learn from anyone. My group is recog- nized for pioneering HRI and social robotics through the development of expressive autonomous robots that socially interact with people in a natural manner (Breazeal 2002). Figure 1 presents the three 'flagship' social robots we have developed, starting with Kismet in the late 1990s, Leonardo spanning the early-mid 2000s and our new robot Nexi. Each design is con- sidered state-of-the-art (building upon lessons and technologies of its predecessor) and supports a different set of highly related scientific questions at the intersection of emotion and HRI, social learn- ing, sophisticated forms of social cognition and human-robot teamwork. One of my main research interests has been to develop robots that can learn from natural interpersonal interactions. Personal robots of the future will need to quickly learn new tasks and skills from people who are not specialists in robotics or machine learning tech- niques but possess a lifetime of experience in teaching and learning from one another. A major technical goal is to engineer robots that can leverage social gui- dance to efficiently and robustly acquire new capabilities from natural human instruction and to do so dramatically faster than it could alone. As an integral part of this endeavour, my group has contributed new knowledge and findings towards how humans teach social robots, and the important role that the robot's expressive behaviour plays in this interpersonal process. In contrast to traditional statistical machine learn- ing approaches that require human expertise to craft a successful large-scale search problem that uses little or no real-time human input, my group's approach recognizes the advantage of designing robots that can leverage from the same rich forms of social interaction that people readily use to teach or learn from one another. Human teachers verbally and non-verbally guide the exploration of learners by directing atten- tion, providing feedback, structuring experiences, supporting learning attempts, and regulating the com- plexity and difficulty of information to push learners a little beyond their current abilities in order to help</page><page sequence="3">Expression in social robots C. Breazeal 3529 Figure 1 . Three examples of social robots used in this research: (a) Kismet, (b) Leonardo and (c) Nexi. them acquire new skills and concepts. In turn, learners tune their teachers' instruction and shape subsequent guidance by expressing their current understanding through demonstration and a rich variety of communi- cative acts. Through this interaction, learner and teacher form mental models of each other that they use to support the learning- teaching process as a richly collaborative activity. It is actually very difficult to build robotic systems that can successfully learn in real time from the general public. Human teaching behaviour is highly variable and complex, and different people bring different styles of interaction to the table. Today, it is common practice for robots to be taught and evaluated by the same researchers who developed it. Not surprisingly, if the teacher has special technical expertise and knowledge of the underlying learning algorithms that the robot uses, this leads to a strongly machine-centric style of interaction that is neither natural nor intuitive to someone who lacks such expertise. In fact, although there exists quite substantial work in developing robots that learn from people, it is still uncommon to conduct human participant studies with members of the gen- eral public to assess the learning performance of a robot when taught by someone who is not an expert in robotics, machine learning or otherwise. My research group is unusual for a robotics group, having conducted over a dozen controlled, in-lab human participant studies with hundreds of partici- pants in order to gain greater qualitative and quantitative understanding on how people approach the task of teaching a socially responsive machine. Often, we begin an investigation with a human study to learn more details about how people teach each other. Then, computationally modelling this process allows us to identify and explore the use of a variety of social cues, expressive behaviours, skills and cogni- tive capabilities that support social learning in robots. In this way, we use social robots as a scientific tool for measuring and quantifying human behaviour in new ways. This in turn has allowed us to generate new findings and discover new knowledge that can even inform how people teach and learn from one another. Figure 2 contrasts (a) the traditional machine-centric approach with (b) our human-centric approach. 3. CHALLENGES IN BUILDING TEACHABLE ROBOTS Applying these results, my group has developed and evaluated how these social behaviours and expressive Phil. Trans. R. Soc. B (2009) capabilities enable robots to learn interactively with human participants, as well as how the same social skills address several key challenges in learning from natural human instruction. I highlight several chal- lenges below together with research highlights of my research group's contributions towards their solution. (a) Challenge 1 Robots face the situation that there is a fundamental mismatch in their social and communicative sophisti- cation relative to humans. For effective learning, however, it is important that learners are slightly chal- lenged to push themselves towards new abilities that are within reach, while avoiding situations where they are too overwhelmed to make sense of things. Fortu- nately, teachers and learners can work together to establish to a suitable level of difficulty and to regulate the complexity of the interaction to be suitable for both. (i) Example: envelope displays To address this challenge, our research has contributed evidence for the importance of paralinguistic com- munication cues in HRI, and how they can be used to successfully manage this imbalance in a natural and intuitive manner. Through HRI studies with our robot, Kismet, we found that humans readily entrain to a robot's non-verbal social cues (e.g. envelope dis- plays that regulate the exchange of speaking turns in human conversation) to improve the efficiency and robustness of 'conversational' flow by intuitively slow- ing the rate of turn exchanges to a level that the robot can handle well. For instance, humans tend to make eye contact and raise their eyebrows when ready to relinquish their speaking turn, and tend to break gaze and blink when starting their speaking turn. When these same facial displays are implemented on a robot, we found that they are effective in smoothing and synchronizing the exchange of speaking turns with human subjects, resulting in fewer interruptions and awkward long pauses between turns (Breazeal 20036). (ii) Example: coordination behaviours Through another series of HRI studies, we examined the use of a number of coordination behaviours where participants guided our robot, Leonardo, using speech and gesture to perform a physical task involving pressing a sequence of coloured buttons ON. Leonardo communicates through gaze (visual attention) and facial expressions (affective state) or</page><page sequence="4">3530 C. Breazeal Expression in social robots Figure 2. (a) The traditional, machine-centric approach to teaching robots where the teacher is often has expertise in the robot's learning algorithms, (b) Our new, human-centric approach that supports how 'ordinary' people approach the task of teaching robots new skills or knowledge. explicitly through gestural cues (i.e. pointing). The robot's coordination behaviours include visually attending to the human's actions (e.g. pointing to or pressing a button) to acknowledge their contributions, issuing a short nod to acknowledge the success and completion of the task or subtask (i.e. turning the but- tons ON), visually attending to the person's attention directing cues such as to where the human looks or points, looking back to the human once the robot presses a button to make sure its contribution is acknowledged, and pointing to buttons in the work- space to direct the human's attention towards them. Both self-report via questionnaire and behavioural analysis of video support the hypothesis that these non-verbal communication cues positively impact human-robot task performance with respect to under- standability of the robot, efficiency of task performance and robustness to errors that arise from miscommunication (Breazeal et al. 2005Ò). (iii) Example: emotive displays In addition, we found that emotive expressions (as governed by the robot's emotion-based models) are interpreted by humans as natural analogues, and thereby can be used by the robot to regulate its interaction with the human - to keep the complexity of the interaction within the robot's perceptual limits and even to help the robot to achieve its goals (Breazeal &amp; Scassellati 2000). Many of these results were first observed with our robot. Kismet, the first robot designed to explore socio-emotive face-to-face interactions with people explicitly (Breazeal 2002). Our research with Kismet was strongly inspired by the origins of social interaction and communication in people, namely that which occurs between carer and infant, through extensive computational model- ling guided by insights from developmental psychology and behavioural models from ethology (Breazeal 2003a). It is well established that early infant-carer exchanges are grounded in the regulation of emotion and its expression. Inspired by these interactions, Kismet's cognitive - affective architecture was designed to implement core proto-social responses exhibited by infants given their Phil. Trans. R. Soc. B (2009) critical role in normal social development. Internally, Kismet's models of emotion interacted intimately with its cognitive systems to influence behaviour and goal arbitration. Through a process of behavioural homeo- stasis, these emotive responses served to restore the robot's internal affective state to a mildly aroused, slightly positive state - corresponding to a state of inter- est and engagement in people and its surroundings that fosters learning. One purpose of Kismet's emotive responses was to reflect the degree to which its drives and goals were being successfully met. A second pur- pose was to use emotive communication signals to regulate and negotiate its interactions with people. Specifically, Kismet utilized emotive displays to regulate the intensity of playful interactions with people, ensur- ing that the complexity of the perceptual stimulus was within a range the that robot could handle and poten- tially learn from. In effect, Kismet socially negotiated its interaction with people via its emotive responses to have humans help it achieve its goals, satiate its drives and maintain a suitable learning environment (Breazeal 2004a). (iv) Summary: joint action While more established approaches to instructing robots view the interaction as a one-way flow of infor- mation from human to machine, this body of work challenges the paradigm by illustrating the myriad of ways in which humans participate in the teaching- learning process as tightly coupled joint action. Humans do not simply provide training inputs as a one-sided interaction to which the learner must react. Rather, people are constantly reading and interpreting numer- ous behavioural cues of the robot as indicators of its internal state, and are continually adapting and tuning their teaching behaviour to be suitable for the robot learner. This interaction dynamic has significant impli- cations for the design of robots that learn from people. The robot is not restricted to learning in a complex environment that does not care whether the robot succeeds or fails - a common assumption in robot learning systems. Rather, people view teaching and learning as a partnership with shared goals.</page><page sequence="5">Expression in social robots C. Breazeal 3531 Because of this, the robot can proactively improve the quality of its learning environment, tuning the teach- ing acts of the human to be more suitable, through using communication acts that reveal its learning process to the human teacher. (b) Challenge 2 Faced with an incoming stream of sensory data, a robot must figure out which of its myriad of percep- tions are relevant to the task at hand. This is an important capability for generating coherent behaviour as well as for learning given that the search over state space becomes enormous as perceptual abilities and complexity of the environment increase. (i) Example: saliency and shared attention To address this challenge we have identified a set of socially embodied cues and socio-cognitive abilities that assist the robot's determination of saliency when learning a task. These cues and abilities make the robot's underlying attention mechanisms responsive to a human teacher's efforts to highlight a distinct environmental context or change that is relevant to the learning task. In a series of human studies we have identified a grow- ing set of social cues and socio-cognitive skills that play an effective role in addressing the saliency question. For instance, we have implemented a multi-modal attention system to enable the robot to leverage the human teacher's desire to direct its visual attention by following the human's pointing gestures or gaze (esti- mated by head pose). To compute our robot's attentional focus, the attentional system computes the level of saliency (a measure of 'interest') per feature channel for objects and events in the robot's perceivable space (Breazeal &amp; Scassellati 1999; Breazeal et al 2000). For Leonardo, the contributing factors to an object's overall saliency fall into three categories: its per- ceptual properties (i.e. its proximity to the robot, its colour, whether it is moving, etc.), the internal state of the robot (i.e. whether this is a familiar object, what the robot is currently searching for and other goals) and social reference (if something is pointed to, looked at, talked about or is the referential focus). For each item in the perceivable space, the overall saliency at each time step is the result of the weighted sum for each of these factors. The item with the highest saliency becomes the current attentional focus of the robot, and also determines where the robot's gaze is directed. The gaze direction of the robot is an important communi- cation device to the human, verifying for the human partner what the robot is attending to and thinking about. The human's attentional focus is determined by what he or she is currently looking at. Leonardo calculates this using the head pose tracking data, assuming that the person's head orientation is a good estimate of his or her gaze direction. By following the person's gaze, the shared attention system determines which (if any) object is the attentional focus of the human's gaze. The mechanism by which infants track the referential focus of communication is still an open question, but a number of sources indicate that looking time is a key Phil Trans. R. Soc. B (2009) factor, such as word learning studies. For example, when a child is playing with one object and hears an adult say 'It's a modi', the child does not attach the label to the object the child happens to be looking at (which is often the adult's face!) . Instead the child redir- ects his or her attention to look at what the adult is looking at, and attaches the label to that object. For our robot, we use a simple voting mechanism to track a relative-looking-time for each of the objects in the robot's and human's shared environment. The object with the highest accumulated relative-looking-time is identified as the referent of the communication between the human and the robot (Thomaz et al. 2005). Using these models, we have found that active monitoring of shared visual attention between the human teacher and the robot learner is important in order to achieve robustness in the learning interaction. In a series of human participant studies where human teachers guide a robot to perform a simple task (learn- ing to operate a control panel with a lever, toggle and button), we have found that humans readily coordi- nate their teaching behaviour with the robot's gaze behaviour - waiting until the robot re-establishes eye contact before offering their next guidance cue, adap- tively re-orienting their guidance cue to be in alignment with the robot's current visual focus, actively trying to re-direct the robot's gaze through deictic cues or offering more guidance if the robot's gaze behaviour conveys uncertainty in what to do next (e.g. looking back and forth among several possible alternatives) (Breazeal &amp; Thomaz 2008a; Thomaz &amp; Breazeal 2008). These findings suggest that people read the robot's gaze as an indicator of its internal state of attention as well as solicitations for help, and intuitively coordinate their teaching acts to support the robot's learning process. (ii) Example: perspective taking In another series of human and HRI studies, we ident- ified, verified and evaluated mental perspective taking as an important socio-cognitive skill that helps either human or robot learners to focus attention on the subset of the problem space that is important to the teacher by actively considering the teacher's experi- ence such as visual perspective, attentional focus or resource considerations (Berlin et al. 2006). This con- strained attention enables the robot learner to overcome the ambiguity and incompleteness that is often present in human demonstrations. To endow Leonardo with perspective taking abilities, our cognitive -affective architecture incorporates simulation-theoretic mechanisms as a foundational and organizational principle. Simulation theory holds that cer- tain parts of the brain have dual use; they are used not only to generate our own behaviour and mental states, but also to predict and infer the same in others. To try to recognize or infer another person's mental process, the robot uses its own cognitive processes and body struc- ture to simulate the mental states of the other person - in effect, taking the mental perspective of another. In figure 3, the two concentric bands denote two different modes of operation. In the generation mode (the light band) the robot constructs its own mental</page><page sequence="6">3532 C. Breazeal Expression in social robots Figure 3. The self-as-simulator architecture. states to behave intelligently in the world. In the simu- lation mode (the dark band) the robot constructs and represents the mental states of its human collaborator based on observing his or her behaviour and taking their mental perspective. By doing so, the mental states of the human and the robot are represented in the same terms so that they can be readily compared and related to one another. For instance, within the perception system, the robot performs a transform- ation to estimate what the human partner can see from his or her vantage point. Within the motor system, mirror-neuron inspired mechanisms are used to map and represent perceived body positions of the human into the robot's own joint space to conduct action recognition. Within the belief system, belief construction is used in conjunction with adopting the visual perspective of the human partner in order to estimate the beliefs the human is likely to hold given what he or she can visually observe. Finally, within the intention system where goal-directed beha- viours are generated, schémas relate preconditions and actions with desired outcomes and are organized to represent hierarchical tasks. Within this system, motor information is used along with perceptual and other contextual clues (i.e. task knowledge) to infer the human's goals and how he or she might be trying to achieve them (i.e. plan recognition). In a learning situation, the robot can take the per- spective of the teacher in order to model the task from their perspective. In effect, the robot runs a par- allel copy of its task-learning engine that operates on its simulated representation of the human's beliefs. In essence, this focuses the hypothesis generation mechanism on the subset of the input space that mat- ters to the human teacher. This enables the robot to learn what the teacher intends to teach even if the demonstrations are ambiguous. Phil. Trans. R. Soc. B (2009) To investigate this, we conducted a human partici- pant study where the participants were asked to engage in four different learning tasks involving foam building blocks. We gathered data from 4 1 participants, divided into two groups: 20 participants observed dem- onstrations provided by a human teacher sitting opposite them (the social condition), while 21 partici- pants were shown static images of the same demonstrations, with the teacher absent from the scene (the non-social condition). Participants were asked to show their understanding of the presented skill either by re-performing the skill on a novel set of blocks (in the social context) or by selecting the best matching image from a set of possible images (in the non-social context). Figure 4 (left) illustrates sample demonstrations of each of the four tasks. The tasks were designed to be highly ambiguous, providing the opportunity to investigate how different types of per- spective taking might be used to resolve these ambiguities. The subjects' demonstrated rules can be divided into three categories: perspective taking (PT) rules, non-perspective taking (NPT) rules and rules that did not clearly support either hypothesis (other). For instance, task 1 focused on visual perspective taking during the demonstration. Participants were shown two demonstrations with blocks in different con- figurations. In both demonstrations, the teacher attempted to fill all of the holes in the square blocks with the available pegs. Critically, in both demon- strations, a blue block lay within clear view of the participant but was occluded from the view of the tea- cher by a barrier. The hole of this blue block was never filled by the teacher. Thus, an appropriate (NPT) rule might be 'fill all but blue' or 'fill all but this one,' but if the teacher's perspective is taken into account, a more parsimonious (PT) rule might be 'fill all of the holes' (see figure 4).</page><page sequence="7">Expression in social robots C. Breazeal 3533 Figure 4. The four tasks presented to human participants. In task 1, subjects were asked to infer the rule for which blocks received a yellow peg. A visual occlusion presents a different viewpoint of the demonstration between teacher and learner (the teacher cannot see the hidden blue block). In task 2, subjects were asked to infer the rule for which blocks get a bead where proximity and gaze were used to denote which blocks the teacher intended to use for the demonstration. Tasks 3 and 4 were figure assembly tasks. (Right) Shows different sets of blocks that could be considered when learn- ing the rule if perspective taking (PT) is used, or not (NPT). The tasks from our human study were used to create a benchmark suite for our architecture. In our simulation environment, the robot was presented with the same task demonstrations as were provided to the study participants. The learning performance of the robot was analysed in two conditions: with the perspective taking mechanisms intact and with them disabled. Table 1 (left) shows the hypotheses enter- tained by the robot in the various task conditions at the conclusion of the demonstrations. The hypotheses favoured by the learning mechanism are highlighted in italic. For comparison, table 1 (right) displays the rules selected by study participants, with the most popular rules for each task highlighted in italic. For every task and condition, the rule learned by the robot matches the most popular rule selected by humans. These results support our hypothesis that the robot's perspective taking mechanisms focus its atten- tion on a region of the input space similar to that attended to by study participants in the presence of a human teacher. It should also be noted, as evident in table 1, that participants generally seemed to entertain a more varied set of hypotheses than the robot. In par- ticular, participants often demonstrated rules based on spatial or numeric relationships between the objects - relationships that are currently not yet represented by the robot. Thus, the differences in behaviour between humans and the robot can largely be understood as a difference in the scope of the relationships considered Phil Trans. R. Soc. B (2009) between the objects in the example space rather than as a difference in this underlying space. The robot's perspective taking mechanisms seem to be successful at bringing the robot's focus of attention into align- ment with the humans' focus of attention in the presence of a social teacher. (iii) Example: spatial scaffolding In other human participant and HRI experiments, we have identified, verified and evaluated a set of simple, prevalent and highly reliable spatial scaffolding cues by which human teachers interactively structure and organize the physical workspace to help direct the attention of the learner (e.g. moving objects nearer or farther from the learner's body to signify their relevance) (Breazeal &amp; Berlin 2008). For example, we designed a set of tasks to examine how teachers emphasize and de-emphasize objects in a learning environment with their bodies, and how this emphasis and de-emphasis guides the exploration of a learner and ultimately the learning that occurs. In our human study, we gathered data from 72 individual participants, combined into 36 pairs. For each pair, one participant was randomly assigned to play the role of teacher and the other participant was assigned the role of learner for the duration of the study. For all the tasks, participants were asked not to talk, but were told that they could communicate in any way other than speech. The teacher and learner stood on opposite sides of a tall table, with 24 colourful foam building blocks (four different colours and six different shapes) arranged between them on the tabletop. The study tasks were interactive 'secret constraint' tasks where one person (the learner) knows the task goal (construct a tangram-like figure out of the blocks) but does not know that there is a secret constraint to accomplish the task successfully. The other person (the teacher) does not know the task goal (the figure) but knows the constraint (e.g. 'the figure must be con- structed using only blue and red blocks, and no other blocks.'). Hence, both people must work together to complete the task successfully. To record high-resolution data of the study inter- actions, we developed a data-gathering system that incorporated multiple, synchronized streams of infor- mation about the study participants and their environment. For all the tasks, we tracked the positions and orientations of the heads and hands of both partici- pants, recorded video of both participants and tracked all the objects with which the participants interacted such as the positions and orientations of all the foam blocks. To identify the emphasis and de-emphasis cues provided by the teachers in these tasks, an important piece of 'ground-truth' information was exploited: for these tasks, some of the blocks were 'good' and others were 'bad.' In order to complete the task successfully, the teacher needed to encourage the learner to use some of the blocks in the construction of the figure and to steer clear of some of the other blocks. We observed a wide range of embodied cues pro- vided by the teachers in the interactions for these two tasks as well as a range of different teaching styles. Positive emphasis cues included simple hand</page><page sequence="8">3534 C. Breazeal Expression in social robots Table 1. (Left) Rules learned by the robot with perspective taking enabled (PT) or disabled. (Right) The corresponding rules learned by people for the same tasks. The difference in rule choice by subjects between social and non-social condition is highly significant (p &lt; 0.001). task condition high-likelihood hypotheses task condition hyphotheses selected task 1 with PT all; all but blue task 1 social all; number; spatial arrangement without PT all but blue non-social all but blue; spatial arrangement; all but one task 2 with PT all red and green; shape task 2 social all red and green; shape preference preference; spatial arrangement without PT shape preference non-social shape preference; all red and green tasks 3 with PT rotate figure; mirror figure tasks 3 social rotate figure; mirror figure and 4 without PT mirror figure and 4 nonsocial mirror figure gestures such as tapping, touching and pointing at blocks with the index finger. These cues were often accompanied by gaze targeting, or looking back and forth between the learner and the target blocks. Other positive gestures included head nodding, the 'thumbs up' gesture and even shrugging. Teachers nodded in accompaniment to their own pointing ges- tures, and also in response to actions taken by the learners. Negative cues included covering up blocks, holding blocks in place or maintaining prolonged contact despite the proximity of the learner's hands. Teachers would occasionally interrupt reaching motions directly by blocking the trajectory of the motion or even by touching or (rarely) lightly slapping the learner's hand. Other negative gestures included head shaking, finger or hand wagging, or the 'thumbs down' gesture. However, by far the most important set of cues used related to block movement and the use of space. To emphasize blocks positively, teachers would move them towards the learner's body or hands, towards the centre of the table, or align them along the edge of the table closest to the learner. Conversely, to emphasize blocks negatively, teachers would move them away from the learner, away from the centre of the table, or line them up along the edge of the table closest to them- selves. Teachers often devoted significant attention to clustering the blocks on the table, spatially grouping the bad blocks with other bad blocks and the good blocks with other good blocks. These spatial scaffolding cues were the most prevalent cues in the observed interactions (Breazeal &amp; Berlin 2008). To verify the prevalence and usefulness of these spatial scaffolding cues for a robot, we substituted our robot Leonardo for the role of the learner (Berlin et al. 2008). The robot's attention system was designed to pay attention to block movement towards and away from its body. In order to give the robot the ability to learn from these embodied cues, we developed a simple, Bayesian learning algorithm. The algorithm was designed to learn rules pertaining to the colour and shape of the foam blocks and maintained a set of classification functions that tracked the relative odds that the various block attributes were 'good' or 'bad' according to the teacher's secret constraints. Each time the robot observed a salient teaching cue, these Phil Trans. R. Soc. B (2009) classification functions were updated using the pos- terior probabilities presented in the previous section - the odds of the target block being 'good' or 'bad' given the observed cue. For example, if the teacher moved a green triangle away from the robot, the rela- tive odds of green and triangular being good block attributes would decrease. Similarly, if the teacher then moved a red triangle towards the robot, the odds of red and triangular being good would increase. These simple spatial scaffolding cues proved to be highly effective. We invited 18 participants to teach Leonardo the identical secret constraint tasks as our human learners. The robot successfully learned the task in 33 of the 36 interactions (92%). These results support the conclusion that the spatial scaffolding cues observed in human-human teaching interactions do indeed transfer to HRIs, and can be effectively taken advantage of by robot learners (Berlin et al. 2008). (iv) Summary: social filters Whereas traditional approaches to teaching robots do not model social -cognitive skills and abilities as inte- gral to the learning process, this body of work has identified and verified a number of ways that internal and external social factors play an important role in how a robot learner filters the incoming perceptual stream to attend to what matters, that human teachers bring many of these same social cues and skills to bear when teaching either humans or robots, and that these * social filters' can be effectively used by a robot to help it identify the most relevant items to consider, thereby making the learning problem significantly more manageable. (c) Challenge 3 Once the robot has identified salient aspects of the scene, how does it determine what actions it should take? If the robot had a way of focusing on potentially successful actions, its exploration would be more effec- tive. This can be addressed in a number of ways, such as by experimenting on its own as in reinforcement learn- ing (RL). However, for large state-action spaces this typically requires a prohibitively large number of trials.</page><page sequence="9">Expression in social robots C. Breazeal 3535 (i) Example: tutelage-style interaction To address this issue, we have explored how social skills such as turn-taking enable a human teacher to play an important and flexible role in guiding the robot's exploration. This focuses the robot's selection of the most promising actions in specific contexts to discover solutions more quickly. By participating in a 'dialogue' of demonstration followed by feedback and refinement, the human helps the robot to determine what action to try through a communicative and itera- tive process. We evaluated this approach by comparing it to learning the same task using traditional RL and achieved significant improvements in efficiency with- out loss of accuracy and with decreased sensitivity to noise (e.g. errors introduced by miscommunication are quickly repaired, which leads to greater robustness) (Breazeal et al 2004). (ii) Example: socially guided exploration Unfortunately, a common limitation of human teach- able robots is that the robot only learns when being explicitly taught. Personal robots, however, will need to learn while 'on the job' even when a person is not pre- sent or willing to teach it. To address this, we have developed and evaluated a learning system whereby learning opportunities for the robot's hierarchical RL mechanism arise from a combination of intrinsically motivated self-exploration and social scaffolding pro- vided by a human teacher, such as suggesting actions for the robot to try, drawing the robot's attention to rel- evant contexts and highlighting interesting outcomes (Breazeal &amp; Thomaz 2008Ò). We have systematically identified and verified our set of social scaffolding mechanisms through a series of HRI studies where a human teacher guides Leonardo's exploration as it dis- covers a set of behaviours (e.g. opening or closing, playing music, changing colors of lights) of a 'smart box' through pressing buttons, pushing levers and slid- ing toggles. Over time, Leonardo learns a set of task policies for bringing about each of these behaviours from different starting conditions to 'master' the 'smart box'. We analysed the learning performance of the robot both with and without human teachers and found that learning performance via self-exploration is slower but more serendipitous resulting in a broader task suite, whereas learning with a human teacher makes learning more efficient and robust but tends to result in a smaller, more specialized task suite that reflects what the person wanted the robot to learn (Breazeal &amp; Thomaz 2008a,¿&gt;). (iii) Summary: intrinsically motivated but guidable learning Personal robots will need to adapt their learning style to suit the dynamics of a changing learning environ- ment. Sometimes the robot will have to explore on its own, while at other times a teacher might be present to help guide the robot's exploration. Through our studies, we have found that each style of learning has its respective advantages and produces learning pro- ducts that are synergistic. For instance, what is learned more slowly but serendipitously through intrinsically motivated exploration yields a broader Phil Trans. R. Soc. B (2009) task suite that can come in handy at a later date - especially when the robot encounters a human teacher who helps the robot to rapidly hone and build on its growing skill set through socially guided exploration. Importantly, the mechanisms by which the robot's learning can be guided by the human should be informed by how people are naturally inclined to teach robots. (d) Challenge 4 Once the robot attempts to perform an action, how can it determine whether it has been successful? How does it assign credit for that success? Further, if the robot has been unsuccessful, how does it deter- mine which parts of its performance were inadequate? It is important that the robot be able to diagnose its errors in order to improve performance. (i) Example: multi-modal feedback To address this challenge, our approach recognizes that the teacher can readily help the robot do this given that he or she has a good understanding of the task and knows how to evaluate the robot's success and progress. One way in which a human facilitates a learner's evaluation process is by providing feedback through various communication channels. For instance, we demonstrated the capability of a robot to interpret and appropriately respond to the affective intent in human speech, such as praising or scolding tones of voice (Breazeal &amp; Aryananda 2002). In HRI studies we showed that people refer to the robot's expressive cues to confirm that the robot understood them as well as the strength of the affective intent. We have applied verbal feedback in teaching scenarios to help the robot correct its task model as soon as mistakes are made. Furthermore, the robot provides the human with communicative feedback so that mis- understandings can be detected quickly. Both forms of feedback help to prevent errors from persisting for multiple steps, which could make them more awkward to correct later on. In recent HRI studies, our data suggest that these various forms of feedback contribute to a more fluid, efficient, accurate and robust teaching/ learning interaction (Breazeal et al. 2004; Breazeal &amp; Thomaz 2008a,¿&gt;). (ii) Example: guidance and understanding intent Note that for any given feedback channel, it is impor- tant to understand what people are trying to communicate through it and how they are trying to make use of it. Our HRI studies with an interactive RL agent revealed that people use the reward signal not only to provide feedback on past actions (what is commonly assumed in the design of RL algorithms) but also to guide future action (Thomaz &amp; Breazeal 2008). Further, we discovered a strong bias of positive over negative feedback over the entire duration of the training, even in the beginning when the agent was doing many things wrong (Thomaz &amp; Breazeal 2008). This suggests that people were using the feed- back channel to motivate and encourage the robot. In short, people were naturally inclined to use the reward signal in many ways that the traditional RL</page><page sequence="10">3536 C. Breazeal Expression in social robots framework was not designed to handle. Given our findings, we were then able to adapt the RL agent algorithm and teaching interface to accommodate how and what people were trying to communicate to the learner. As a result, our modified RL agent learned much more efficiently and robustly in a subsequent series of HRI experiments (Thomaz &amp; Breazeal 2008). (iii) Summary: transparency While traditional approaches to robot training do not consider how a robot can proactively communicate and reveal its learning process to the human teacher, the findings generated by this body of work argue for the importance of transparency in designing interactive robot learners. People are willing and able to help robots address the difficult task of assigning value to its past actions. People are also willing to help guide the robot to select good future actions, to motivate the robot and more. However, human teachers cannot do this well if they lack a good mental model of the robot's learning process or if they are not pro- vided with the right set of communication channels. The robot's behaviour, both its expressive cues and instrumental actions, can play a significant role in shaping the mental model that the human has for the robot. These readily observable expressive and performance-based cues make the robot's learning process transparent to the teacher. Much of our work to date has emphasized the role of the robot's non- verbal cues, such as facial expressions, gestures and use of gaze, in supporting this process. And conversely, our HRI studies have helped us to identify what kinds of intents people want to communicate to the robot through both verbal and non-verbal channels - to help the robot learn by influencing its evaluation process and more. 4. CONCLUSION While it might be tempting to compare our outcomes with those of statistical machine learning techniques, my research vision and the challenges I wish to solve are ultimately different. My students and I have built and evaluated autonomous robotic systems that are able to leverage from the interplay of social guidance with statistical inference algorithms to learn new tasks and concepts from humans from natural social inter- actions. For task learning, our robots are able to quickly infer the critical preconditions and desired out- come for each step of the learned task, as well as how these steps relate to one another in the overall task struc- ture, with improved efficiency and robustness to noise without loss of accuracy over traditional statistical machine learning methods (e.g. traditional RL). For concept learning, our robots are able to learn the cor- rect concept from natural interactions by exploiting natural scaffolding cues such as how the teacher uses space to highlight the concept to be learned, or by applying socio-cognitive skills to consider the teachers' perspective in order to learn the appropriate concept in the face of ambiguous demonstrations. The underlying machine learning algorithm can be simple because the robot appropriately leverages the social structure inherent in the teacher's behaviour or the modified Phil. Trans. R. Soc. B (2009) workspace to attend to what matters and learn the right thing. Furthermore, the same social cues can be repurposed to support other social capabilities such as multi-modal communication and our research on human-robot teamwork. To conclude, the field of social robotics is very young but growing rapidly - motivated by the vision of personal robots that help anyone in their daily activities. My dream is to enable machines to engage in the powerful, social forms of interaction, collabor- ation, understanding and learning that people readily participate in. This vision is motivated by the obser- vation that humans are ready-made experts in social interaction; the challenge is to design robots to partici- pate in what comes naturally to people. By doing so, socially interactive robots could help a wide demo- graphic of people in a broad range of applications and real-world challenges from health, therapy, education, communication, security, entertainment, or physical assistance. In this article, I have tried to illustrate the myriad of ways in which designing social robots that successfully interact with and learn from ordinary people presents new challenges and opportunities, and have highlighted some of the key lessons and findings learned along the way. We live in an exciting time where so much is possible at the intersection of science and technology. Social robots promise to be not only helpful to us in the future but also a lot of fun. And in the process of building them, we may learn even more about ourselves. REFERENCES Abadjieva, E.3 Murray, I. R. &amp; Arnott, J. L. 1 993 Applying analy- sis of human emotional speech to enhance synthetic speech. Proc. Eurospeech '93, Berlin, Germany, pp. 909-912. Adams, J. A., Humphrey, C. M., Goodrich, M. A., Cooper, J. L, Morse, B. S., Engh, C. &amp; Rasmussen, N. 2009 Cognitive task analysis for developing UAV wilderness search support. J. Cogn. Eng. Dec. Mak. 3, 1-26. (doi:10.1518/155534309X431926) Argali, B., Chernova, S. &amp; Veloso, M. 2009 A survey of robot learning from demonstration. Robot. Autonomous Syst. 57, 469-483. (doi: 10. 10 167j.robot.2008. 10.024) Atkeson, C. G. &amp; Schaal, S. 19976 Robot learning from dem- onstration. In Int. Conf. on Machine Learning, pp. 1 1-73. Bainbridge, W., Hart, J., Kim, E. &amp; Scassellati, B. 2008 The effect of presence on human-robot interaction. IEEE Int. Symp. on Robot and Human Interactive Communication, Munich, Germany. Berlin, M., Gray, J., Thomaz, A. L. &amp; Breazeal, C. 2006 Per- spective taking: an organizing principle for learning in human-robot interaction. Proc. 21st Nati. Conf. on Artificial Intelligence (AAAI-06), Boston, MA. Berlin, M., Breazeal, C. &amp; Chao, C. 2008 Spatial scaffolding cues for interactive robot learning. Proc. 2008 IEEEIRSJ Int. Conf. on Intelligent Robots and Systems (IROS 2008), Nice, France. Berns, K. &amp; Hirth, J. 2006 Control of facial expressions of the humanoid robot head ROMAN. Proc. 2006 IEEE/ RSJ Int. Conf. on Intelligent Robots and Systems, Beijing, China, pp. 3119-3124. Billard, A., Dautenhahn, K. &amp; Hayes, G. 1998 Proceedings of the Socially Situated Intelligence Workshop, Zurich, Switzerland. As part of the Int. Conf. on Simulation of Adaptive Behavior.</page><page sequence="11">Expression in social robots C. Breazeal 3537 Bluethmann, W. et al. 2004 Building an Autonomous Humanoid Tool User. Proc. IEEEIRAS Fourth Int. Conf. on Humanoid Robots (Humanoids 2004), Santa Monica, CA5pp. 402-421. Breazeal, C. 2002 Designing sociable robots. Cambridge, AIA, USA: MIT Press. Breazeal, C. 2003a Emotion and sociable humanoid robots. Int. J. Hum. Comput. Interact. 59, 119-155. Breazeal, C. 2003Ò Regulation and entrainment for human- robot interaction. Int. J. Exp. Robot. 21, 883-902. Breazeal, C. 2004a Function meets style: insights from emotion theory applied to HRI. IEEE Trans. Syst. Man Cybernet. Part C 34, 187-194. (doi:10.1109/TSMCC. 2004.826270) Breazeal, C. 2004b Social interactions in HRI: the robot view. IEEE Trans. Syst. Man Cybernet. Part C 34, 181-186. (doi: 10. 1109/TSMCC.2004. 826268) Breazeal, C. &amp; Aryananda, L. 2002 Recognizing affective intent in robot directed speech. Autonomous Robots 12, 85-104. (doi: 10. 1023/A: 10 132 1501 0749) Breazeal, C. &amp; Berlin, M. 2008 Spatial scaffolding for soci- able robot learning. Proc. 23rd Conf. on Artificial Intelligence (AAAI-08), Chicago, IL. Breazeal, C. &amp; Scassellati, B. 1999 A context-dependent attention system for a social robot. Proc. 16th Int. Joint Conf. on Artifical Intelligence (IJCAI 99), Stockholm, Sweden, pp. 1146-1151. Breazeal, C. &amp; Scassellati, B. 2000 Infant-like social inter- actions between a robot and a human caregiver. Adap. Behav. 8, 47-72. Breazeal, C. &amp; Thomaz, A. 2008a Experiments in socially guided exploration: lessons learned in building robots that learn with and without human teachers. Connection Sci. 20, 91-100. Breazeal, C. &amp; Thomaz, A. L. 20086 Learning from human teachers with socially guided exploration. Proc. 2008 IEEE Int. Conf. on Robotics and Automation (ICRA-08), Pasadena, CA. Breazeal, C, Edsinger, A., Fitzpatrick, P., Scassellati, B. &amp; Varchavskaia, P. 2000 Social constraints on animate vision. IEEE Intell. Syst. Special Issue on Humanoid Robotics 15, 32-37. Breazeal, C, Hoffman, G. &amp; Lockerd, A. 2004 Teaching and working with robots as a collaboration. Proc. Third Int. Joint Conf. on Autonomous Agents and Multi Agent Systems (AAMAS), pp. 1030-1037. Breazeal, C, Buchsbaum, D., Gray, J., Gatenby, D. &amp; Blumberg, B. 2005a Learning from and about others: towards using imitation to bootstrap the social under- standing of others by robots. Artif Life 11, 1-32. Breazeal, C, Kidd, C, Thomaz, A. L., Hoffman, G. &amp; Berlin, M. 20056 Effects of nonverbal communication on efficiency and robustness in human- robot teamwork. Proc. Int. Conf. on Intelligent Robotics and Systems. Brooks, A. G. &amp; Arkin, R. C. 2007 Behavioral overlays for non-verbal communication expression on a humanoid robot. Autonmous Robots 22, 55-74. (doi: 10. 1007/ S10514-006-9005-8) Cahn, J. E. 1990 The generation of affect in synthesized speech. J. Am. Voice Inputl Output Soc. 8, 1-19. Calinon, S. &amp; Billard, A. 2007 What is the teacher's role in robot programming by demonstration? - toward bench- marks for improved learning. Interaction Stud. Special Issue on psychological benchmarks in human-robot interaction 8, 441-464. Cañamero, L. Animating affective robots for social inter- action. In Animating expressive characters for social interaction (eds L. Cañamero &amp; R. Aylett), pp. 103- 122. Advances in Consciousness Research Series. John Benjamins Publishing Co. Phil. Trans. R. Soc. B (2009) Cañamero, L., Blanchard, A. &amp; Nadel, J. 2006 Attachment bonds for human-like robots. Int. J. Humanoid Robot. 3, 301-320. Cassell, J., Sullivan, J., Prévost, S. &amp; Churchill, E. (eds) 2000 Embodied conversational agents. Boston, MA, USA: MIT Press. Chernova, S. &amp; Veloso, M. 2008 Teaching collaborative multi- robot tasks through demonstration. IEEE-RAS Int. Conf. on Humanoid Robots, Daejeon, Korea, December 2008. Dautenhahn, K. 1995 Getting to know each other - artificial social intelligence for autonomous robots. Robot. Autonomous Syst. 16, 333-356. (doi: 10. 101 6/0921- 8890(95)00054-2) Dautenhahn, K. 1997 I could be you: the phenomenological dimension of social understanding. Cybernet. Syst. 28, 417-453. (doi:10.1080/019697297126074) DiSalvo, C, Gemperle, F., Forlizzi, J. &amp; Kiesler, S. 2002 All robots are not created equal: the design and perception of humanoid robot heads. Designing interactive systems. Proc. Fourth Conf. on Designing Interactive Systems: Processes, Practices, Methods, and Techniques, pp. 321-326. Duffy, B. 2003 Anthropomorphism and the social robot. Robot. Autonomous Syst. 42, 177-190. Duffy, B. R. 2008 Fundamental issues in affective intelligent social machines. Open Artif. Intell. J. 2, 21-34. Fellous, J.-M. &amp; Arbib, M. A. (eds) 2005 Who needs emotions?: The brain meets the robot. Oxford, UK: Oxford University Press. Fong, T, Nourbakshsh, I. &amp; Dautenhahn, K. 2003 A survey of social robots. Robot. Autonomous Syst. 42, 143-166. (doi: 10.101 6/S092 l-8890(02)00372-X) Fong, T, Nourbakhsh, I., Ambrose, R., Simmons, R., Schultz, A. &amp; Scholtz, J. 2005 The peer-to-peer human-robot interaction project. Proc. AIAA Space 2005, September, 2005. Fujita, M. 2004 On activating human communications with pet-type robot AIBO. Proc. of IEEE 92, pp. 1804-1813. Fujie, S., Ejiri, Y, Nakajima, K., Matsusaka, Y. &amp; Kobaya- shi, T 2004 A conversation robot using head gesture recognition as paralinguistic information. Proc. IEEE RO-MAN 2004, September 2004, pp. 158-164. Fujie, S., Fukushima, K. &amp; Kobayashi, T. 2005 Back- channel feedback generation using linguistic and nonlin- guistic information and its application to spoken dialogue system. Proc. Interspeech 2005, September 2005, pp. 889-892. Gockley, R., Forlizzi, J. &amp; Simmons, R. 2007 Natural person-following behavior for social robots. Proc. of Human-Robot Interaction, March, 2007, pp. 17-24. Hayashi, K., Onishi, Y, Itoh, K., Miwa, H. &amp; Takanishi, A. 2006 Development and evaluation of face robot to express various face shape. Proc. of IEEE Int. Conf. on Robotics and Automation, pp. 481-486. Hersch, M., Sauser, E. &amp; Billard, A. 2008 Online learning of the body schema. Int. J. Humanoid Robot. 5, 161-181. (doi:10.1142/S0219843608001376) Holz, T., Dragone, M. &amp; O'Hare, G. M. P. 2009 Where robots and virtual agents meet: a survey of social interaction across milgram's reality-virtuality continuum. Int. J. Soc. Robot. 1, 83-93. Hovland, G. E., Sikka, P. &amp; McCarragher, B. J. 1996 Skill acquisition from human demonstration using a hidden Markov model, IEEE Int. Conf. on Robotics and Auto- mation, Minneapolis, MN, pp. 2706-2711. Minneapolis, MN: IEEE Press. Iida, F., Tabata, M. &amp; Hara, F. 1998 Generating personality character in a Face Robot through interaction with human. Proc. of Seventh IEEE Int. Workshop on Robot and Human Communication, pp. 481-486.</page><page sequence="12">3538 C. Breazeal Expression in social robots Imai, M., Ono, T. &amp; Ishiguro, H. 2001 Physical relation and expression: joint attention for human-robot interaction. Proc. RO-MAN2001, pp. 512-517. Johnson, M. &amp; Demiris, Y. 2005 Perceptual perspective taking and action recognition. Int. J. Adv. Robot. Syst. 2, 301-308. Kidd, C. &amp; Breazeal, C. 2004 Effect of a robot on user perceptions. Proc. 2004 IEEEIRSJ Int. Conf. on Intelligent Robots and Systems (IROS), Sendai, Japan, vol. 4. pp. 3559-3564. Kidd, C. &amp; Breazeal, C. 2008 Robots at home: understand- ing long-term human -robot interaction. Proc. 2008 IEEEIRSJ Int. Conf. on Intelligent Robots and Systems (IROS 2008), Nice, France. Kikuchi, H., Yokoyama, M., Hoashi, K., Hidaki, Y, Kobayashi, T. &amp; Shirai, K. 1998 Controlling gaze of humanoid in communication with human. Proc. IROS, October 1998, pp. 255-260. Kozima, H. 2006 An anthropologist in the children's world: a field study of children's everyday interaction with an interactive robot. Proc. Int. Conf. on Development and Learning, ICDL-2006, Bloomington, IN, USA. Krach, S., Hegel, F., Wrede, B., Sagerer, G., Binkofski, E &amp; Kircher, T. 2008 Can machines think? Interaction and perspective taking with robots investigated via fMRI. PLoS ONE 3. Kuniyoshi, Y, Inaba, M. &amp; Inoue, H. 1994 Learning by watching: extracting reuseable task knowledge from visual observation of human performance. IEEE Trans. Robot. Automat. 10, 799-822. (doi:10.1 109/70.338535) Lim, H., Ishii, A. &amp; Takanishi, A. 2004 Emotion-based biped walking. Int. J. Inform., Educ. Res. Robot. Artif. Intell. 22, 577-586. Mataric, M. J., Zordan, V. B. &amp; Mason, Z. 1998 Movement control methods for complex, dynamically simulated agents: Adonis dance the Macarena. Proc. Agents 1998, pp. 317-324 Matsusaka, Y, Tojo, T. &amp; Kobayashi, T. 2003 Conversation robot participating in group conversation. Trans. IEICE E86-D, 26-36. Miwa, H., Itoh, K., Matsumoto, M., Zecca, M., Takanobu, H., Roccella, S., Carrozza, M. C, Dario, P. &amp; Takanishi, A. 2004&lt;2 Effective emotional expressions with emotion expression humanoid robot WE-4RII. Proc. 2004 IEEEIRSJ Int. Conf. on Intelligent Robots and Systems, pp. 2203-2208. Miwa, H., Itoh, K., Takanobu, H. &amp; Takanishi, A. 2004Ò Design and control of 9-DOFs emotion expression huma- noid arm. IEEE Int. Conf. on Robotics and Automation, New Orleans, pp. 128-133. Murphy, R. R., Tadokoro, S., Nardi, D., Jacoff, A., Fiorini, P., Choset, H. &amp; Erkmen, A. M. 2008 Search and rescue robotics. In Handbook of robotics (eds A. Zelinkski &amp; B. Sciliano), pp. 1151-1173. Nicolescu, M. N. &amp; Mataric, M. J. 2003 Natural methods for robot task learning: instructive demonstrations, generaliz- ation and practice. AAMAS 241-248. Ogura, Y, Aikawa, H., Shimomura, K., Kondo, H., Morishima, A., Lim, H. &amp; Takanishi, A. 2006 Develop- ment of a new humanoid robot WABIAN-2. Proc. IEEE Int. Conf. on Robotics and Automation, pp. 76-81. Pardowitz, M., Zoeliner, R., Knoop, S. &amp; Dilmann, R. 2007 Incremental learning of tasks from user demonstrations, past experiences and vocal comments. IEEE Trans. Syst., Man Cybernet., Part B 37, 322-332. Picard, R. 2000 Affective computing. Cambridge, MA: MIT Press. Powers, A., Kiesler, S., Torrey, C. &amp; Fussell, S. 2007 Comparing a computer agent with a humanoid robot. Second AC M I IEEE Int. Conf. on Human- Robot Interaction (HRI 2007). Phil Trans. R. Soc. B (2009) Roccella, S.A. et al. 2004 Design, fabrication and preliminary results of a novel anthropomorphic hand for humanoid robotics: RCH-1. Proc. of 2 004 IEEEIRSJ Int. Conf. unintel- ligent Robots and Systems, Sendai, pp. 266-271 . Roy, D. &amp; Pentland, A. 1 998 Learning audio-visually grounded words from natural input. AAAI Workshop on the Grounding of Word Meaning: Data and Models, Madison, WI. Sakita, K., Ogawara, K., Murakami, S., Kawamura, K. &amp; Ikeuchi, K. 2004 Flexible cooperation between human and robot by interpreting human intention from gaze information. Proc. Int. Conf. on Intelligent Robot and Sys- tems, pp. 846-851. Saunders, J., Nehaniv, C. &amp; Dautenhahn, K. 2006 Teaching robots by moulding behavior and scaffolding the environment. Proc. ACM SIGCHIISIGART Conf. on Human -Robot Interaction (HRI), pp. 118-125. Scassellati, B. 1998 Imitation and mechanisms of joint atten- tion: a developmental structure for building social skills on a humanoid robot. Computation for metaphors, analogy and agents, vol. 1562 (ed. C. Nehaniv). Springer Lecture Notes in Artificial Intelligence. Berlin, Germany: Springer- Verlag. Scassellati, B. 2001 Theory of mind for a humanoid robot. Autonomous Robots 12, 13-24. Schaal, S. 1999 Is imitation learning the route to humanoid robots? Trends Cogn. Sci. 3, 233-242. (doi:10.1016/ S1364-6613(99)01327-3) Sidner, C. L., Lee, C, Kidd, C. D., Lesh, N. &amp; Rich, C. 2005 Explorations in engagement for humans and robots. Artif. Intell. 166, 140-164. (doi:10.1016/j.artint. 2005.03.005) Siegel, M. 2008 Persuasive robotics: towards understanding the influence of a mobile humanoid robot over human belief and behavior. September 2008, S. M. Media Arts and Sciences. Cambridge, MA: MIT Press. Stiehl, W., Lieberman, J., Breazeal, C, Basel, L., Lalla, L. &amp; Wolf, M. 2005 Design of a therapeutic robotic compa- nion for relational, affective touch. Proc. of 14th IEEE Workshop on Robot and Human Interactive Communication, pp. 408-415. Tanaka, F., Noda, K., Sawada, T &amp; Fujita, M. 2004 Associ- ated emotion and its expression in an entertainment robot QRIO. Proc. of the Third Int. Conf. on Entertainment Com- puting, Eindhoven, pp. 499-504. Tanaka, F., Movellan, J. R., Fortenberry, B. &amp; Aisaka, K. 2006 Daily HRI evaluation at a classroom environment: reports from dance interaction experiments. Proc. of the First Annual Conf. on Human-Robot Interaction (HRI 2006), Salt Lake City, USA, March 2006, pp. 3-9. Thomaz, A. L. &amp; Breazeal, C. 2008 Teachable robots: understanding human teaching behavior to build more effective robot learners. Artif. Intell. (AIJ) 172, 716- 737. (doi:10.1016/j.artint.2007.09.009) Thomaz, A. L., Berlin, M. &amp; Breazeal, C. 2005 An embo- died computational model of social referencing. Proc. 14th IEEE Workshop on Robot and Human Interactive Communication, Nashville, TN. Trafton, J. G., Cassimatis, N. L., Bugajska, M. D., Brock, D. P., Mintz, F. E. &amp; Schultz, A. C. 2005 Enabling effec- tive human- robot interaction using perspective-taking in robots. IEEE Trans. Syst. Man Cybernet. Part A: Syst. Hum. 35, 460-470. Wada, K., Shibata, T, Sakamoto, K. &amp; Tanie, K. 2005 Long-term interaction between seal robots and elderly people - robot assisted activity at a health service facility for the aged. Proc. of the Third Int. Symp. on Autonomous Minirobots for Research and Edutainment, pp. 325-330. Walters, M. L., Dautenhahn, K., Woods, S. N. &amp; Koay, K. L. 2008 Robotic etiquette: results from user studies involving a fetch and carry task. Proc. of the Second ACMIIEEE Int. Conf. on Human- Robot Interaction, pp. 317-342.</page></plain_text>
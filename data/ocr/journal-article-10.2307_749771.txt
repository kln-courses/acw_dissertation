<plain_text><page sequence="1">Journal for Research in Mathematics Education 1999, Vol. 30, No. 5, 487-519 Students' Probabilistic Thinking in Instruction Graham A. Jones, Cynthia W. Langrall, Carol A. Thornton, and A. Timothy Mogill Illinois State University In this study we evaluated the thinking of 3rd-grade students in relation to an instruc- tional program in probability. The instructional program was informed by a research- based framework that included a description of students' probabilistic thinking. Both an early- and a delayed-instruction group participated in the program. Qualitative evidence from 4 target students revealed that overcoming a misconception in sample space, applying both part-part and part-whole reasoning, and using invented language to describe probabilities were key patterns in producing growth in probabilistic thinking. Moreover, 51% of the students exhibited the latter 2 learning patterns by the end of instruction, and both groups displayed significant growth in probabilistic thinking following the intervention. Key Words: Cognitive development; Curriculum; Elementary, K-8; Instructional assessment; Instructional intervention; Learning; Probability; Reasoning In recent recommendations the importance of having all students develop an awareness of probability concepts and applications has been recognized (National Council of Teachers of Mathematics, 1989). Because of this emphasis on proba- bility in the school curriculum, there is a need for further, ongoing research into the learning and teaching of probability (Shaughnessy, 1992). Although there has been considerable research into students' probabilistic thinking (e.g., Fischbein, Nello, &amp; Marino, 1991; Fischbein &amp; Schnarch, 1997; Jones, Langrall, Thornton, &amp; Mogill, 1997; Piaget &amp; Inhelder, 1951/1975; Shaughnessy, 1992), there has been almost no research on the development and evaluation of instructional programs in probability. More recently a number of researchers (e.g., Fennema et al., 1996) have suggested ways to bridge the gap between learning and teaching. In particular, these researchers advocated the use of a general instructional model in which research-based knowledge of students' thinking is used to inform classroom instruction. In this study we extended research on this general instructional model by using research-based knowledge of students' probabilistic thinking to develop and evaluate an instructional program in probability. More specifically, we sought to (a) use a framework that describes and predicts students' thinking about probability to construct a third-grade instructional program and (b) evaluate the effect of the instructional program on students' learning in two classes, one of which partici- pated in the instructional program in the fall (early group) and the other in the spring</page><page sequence="2">488 Students' Probabilistic Thinking (delayed group) of the same school year. It should be emphasized that although the pedagogical features of the instructional program had a clearly developed theoretical rationale, the major focus of the evaluation was on student learning, not on instruc- tional practice. THEORETICAL CONSIDERATIONS In the conceptualization of the instructional program examined in this study we draw on two theoretical perspectives. The first is a cognitive framework (Jones et al., 1997) used to describe and predict students' thinking across four key prob- ability constructs. The second is an instructional model (e.g., Fennema et al., 1996) that is predicated on the use of research-based knowledge of students' thinking to inform instruction. In making the connection between these two theoretical posi- tions, we use the cognitive framework as the research base that informs the instructional program. Framework for Students' Probabilistic Thinking On the basis of the cognitive framework (Figure 1), we assume that proba- bilistic thinking is multifaceted and develops slowly over time. To capture the manifold nature of probabilistic thinking and its interconnections, in our frame- work (Jones et al., 1997) we incorporate four key constructs: sample space, prob- ability of an event, probability comparisons, and conditional probability, as they relate to one-stage (e.g., tossing a coin) or two-stage (e.g., tossing two coins) probability situations. In this study a probability situation, or a situation involving uncertainty, refers to an activity or random experiment for which multiple outcomes are possible; that is, the actual outcome cannot be predeter- mined exactly. However, the set of possible outcomes for the probability situ- ation can be determined as can the long-term distribution of these outcomes (Hogg &amp; Tanis, 1997). It should also be noted that in this study the term prob- abilistic thinking will be used to describe children's thinking in response to any probability situation.1 The framework was initially constructed from our 2-year study of students' probabilistic thinking and from a synthesis of previous probability research in sample space (e.g., Borovcnik &amp; Bentz, 1991; English, 1993), in probability of an event (e.g., Acredolo, O'Connor, Banks, &amp; Horobin, 1989; Fischbein et al., 1991), in probability comparisons (e.g., Falk, 1987; Fischbein et al., 1991), and in conditional probability (e.g., Borovcnik &amp; Bentz, 1991). lWe recognize that students may not always use probabilistic thinking when responding to a prob- ability situation. In fact neither deterministic thinking nor subjective reasoning is strictly proba- bilistic thinking even though each is used by students in this study. We incorporate all student thinking about probability situations as evidence of development toward probabilistic thinking.</page><page sequence="3">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 489 _ )- _ 70 cz ec c 3 C" ) - a c oC -C &gt; Uo= - S 0 - -0U)) _ c co- S.. C *?- '0p cz-0) c C. ) c'CE ~ CD O C O C 0) CZ U)D 2 -+CU).5-- CE),_ , "?D?c -c = - x a"0 0 ,0..e 7 0 0 - Cz a a).C) co C : C:o cCCoc aCCdE2 E oarr . . .- -.. , , U 0UC 0Cc a C CzE0a U)- C 0 " " -Fz oE -- 0 pCE:3 CzCE U) E U C 10 C 0- : 2 C C a, Q-e 0(oCD - CZ t CZ E&gt; C U_0E&gt; - '1U0E) EU)Q 0 0 C:E Ec cz cO o0-, 0) a,, _ _: ' ou -C0 C - CD.- CZU C1 c " : C ) CTE c a) "--&gt; E:3"0 CZ U) C+&gt; C:C &gt;o0 e o o c o c- _ OCDcC 0 _ C - U2 C? DU)C.-D * ~ tEC: ): )00Ec )&gt;C:C z U) 0 - a )" c ,-,-,-,,-"+._:0- - o 0oCoxCZ - C ,-.&gt; a Zcc, 0oU oo = - o -0 ooo 0 C._o C o-o C '--C: "" "U)o -- c .O rz " 0) )0 Q ) ) ._ . wE 5 --c c o &gt;z QC C CC &gt;. : O 3&gt;" _ C . D .o C L 0co ) :p CZ 0) 0 " .- -? -- c.,-, &gt;,c .--&gt; .&lt; -" co C 0C" C: a, -o &gt; :0)C a) o SC:D:3 f -0C: C00 0 )C + c aC -CaCZ' n E0Ec: cz -00 CD O~c- 0 cz a) c: EC - &gt;cCEP CD -C: O~ C :a C E a :o _b :_ " *-. .-. .. 0 cZ CZ &gt;, o ', C :o --Co o o -C " Co o oc CI C:r oC : U CZ E z U), +o C,3 70 r -0 o &gt;.+_. cz coo, ,-, 0-  _-, , r n,,_ o~~C~jn ~xl~ a . o z a) cz r , +o :3 --- _&gt; n" zra n: +-r a)E C: C a) E c 0)- 0 CLr Q?-c 0 -r-?? :t- - c _r ?, 0 co a) u) a) S&lt;  co u) +2 0 / C, : m -o:? a) 0a):no n :t-- o C5 o U) 0 0 D CZ -0 2 2 LD 0 c CD E~~~S~~I a. ) -- 0OOE Cd V o 0 c &gt; C 0CZ0 c +? CZ CZ z _Q : C: CZ c: E c: 0 czct: 0 0 C: ) cz c 0 0 E n 0 E c cn C: o &gt;, CD 0 cz ?c CD 0 +- a) .- C: C Q n-P n - C: Et-'Z C -0 C: &gt; a) c) 0 U) J V) cu E.E E cn ()C 0()00a) U t-U r C E -c (3 E --p u) -o (3 8U)c " + r -0 C) :t--Oc~c :3 C: -0 0 C: _7 70 Cn 70 a, u) a I C:&gt; ) 0 C:&gt; Z &gt;C:75 ~n c z3:- a C -o () 3 t 7 z )0 : C 0 x + :3 z o &gt; -0 " (3.(3 1 C0- C:C 0 +!, E 0 cz u (3) a)a U) _0 cnV L r Y (3) = :3 ) cz CZ t c &gt; 0) C: cz CZ U) +- CZ 0 0 C)- :3t C) a)+? - 4-- ) U)a) o0 U)0) C a) +?cncnD ). U 05 3 3 3 U) U) cz C: C: QL0 C6"- 0)- cQ 3) C a) E u a&gt;) &gt; :3 c: c C) C: 0 c) + L cz 00 0 M 0 Q) 0 o a, E ?c 0) c a On - U) a) C:0 )`7 ()a) U)U)1- - 3C) &gt;C &gt; -+-U :: . C: 3 0:-O x ) + 0 c -i c a ) ? - 3 ,(3 Za)- o-0 C)a a)?5 C:&gt; QC:+-U)(3 ---0 u)E 9 (3</page><page sequence="4">490 Students' Probabilistic Thinking Through validation of the initial framework (Jones et al., 1997), conducted in conjunction with this study,2 we confirmed the existence of four levels of proba- bilistic thinking across each of the four constructs. Level 1 is associated with subjec- tive thinking; Level 2 is transitional between subjective and naive quantitative thinking; Level 3 involves the use of informal quantitative thinking; and Level 4 incorporates numerical reasoning. These levels of probabilistic thinking appear to be consistent with a neo-Piagetian general developmental model developed by Biggs and Collis (1991; Collis &amp; Biggs, 1991). Incorporated in this developmental model arefive modes offunctioning (senso- rimotor-from birth, ikonic-from around 18 months, concrete-symbolic-from around 6 years, formal-from around 14 years, and postformal-from around 20 years) and four cognitive levels (prestructural, unistructural, multistructural, and relational) that recycle during each mode and represent shifts in the complexity of students' reasoning. According to Biggs and Collis (1991), each of the five modes of functioning emerges and develops in a way that incorporates the continuing development of earlier modes. The modes that are most applicable to the students in our research are the ikonic and the concrete-symbolic, although such students will also use some sensorimotor functioning. We claim that the four levels of probabilistic thinking described in our frame- work (subjective, transitional, quantitative, and numerical) correspond to the four levels of cognitive thinking identified by Biggs and Collis (1991). Students exhibiting Level 1 thinking are narrowly and consistently bound to subjective reasoning, that is, reasoning like "Red, because it is my favorite color." As such, these students appear to reflect what Biggs and Collis describe as the prestructural thinking level of the learning cycle; that is, the learner is engaged in the task but is then distracted or misled by an irrelevant aspect. According to Biggs and Collis, although the prestructural level is associated with the concrete-symbolic mode, prestructural responses really belong in the ikonic mode. In this latter mode students' intuitive thinking often involves myths and mental imaging and as such is consistent with reasoning that is subjective or focused on irrelevant aspects. 2 In this study we use the same broad database used in the validation study (Jones et al., 1997); however, the data used in this study are more extensive than those used for the validation study. In the validation study we focused only on students' probabilistic thinking at each of the three assess- ment points and used these data to refine the framework and illuminate the probability-thinking characteristics at each level. Even though in this study we used the same data at the three assessment points, our major purpose was to examine students' probabilistic thinking during each of the 16 instructional sessions-with a view to tracing changes in their probabilistic thinking. These instruc- tional data were analyzed after we had completed the data analysis in the validation study and had made refinements to the framework. In fact, all the data for both studies were reanalyzed after we made refinements to the framework, and therefore all probabilistic thinking levels were established according to the validated framework. It is true that the instructional program was implemented using the unrefined framework. However, reference to our validation study (Jones et al., 1997) will reveal that minimal changes were made to the framework during the refinement process. The constructs and levels were the same, but there were changes to the descriptors in 5 of 16 cells. In fact, it was the strong correspondence between the initial and the refined frameworks that acted as a catalyst for the present study.</page><page sequence="5">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 491 In contrast to students at Level 1, students exhibiting Level 2 thinking, when faced with probability situations, demonstrate a readiness to recognize the significance of quantitative measures. Consequently, Level 2 appears to be a period of transi- tion that is characterized by students' naive and often inflexible attempts to quan- tify probabilities. Their thinking is more indicative of what Biggs and Collis (1991) termed the unistructural level in the sense that the task engages the students in a relevant way, but generally only one aspect is pursued. Biggs and Collis claimed that these students are beginning to function in the concrete-symbolic mode and, as such, have the potential to represent their thinking using mathematical language and symbols. However, there is potential for conflict when such students try to reconcile ikonic intuitions and concrete-symbolic reasoning (Watson, Collis, &amp; Moritz, 1997), and this conflict appears to manifest itself through reversions to subjective judgments. Students exhibiting Level 3 thinking typically use quantitative reasoning when dealing with probability tasks. Thinking at this level is manifested through students' use of more generative strategies in listing the outcomes of two-stage experiments and through the ability to coordinate and quantify thinking about sample space and probability. Students assessed at Level 3 appear to exhibit characteristics of both the multistructural and relational levels within the concrete-symbolic mode (Biggs &amp; Collis, 1991) in the sense that they recognize more than one relevant feature of a task and tend to integrate features such as changing sample spaces and proba- bilities in without-replacement situations. Students exhibiting Level 4 thinking make precise connections between sample-space outcomes and their probabilities, and they are able to use valid numerical measures to describe the probabilities of events and conditional events. Our observations indicate that their thinking is consistent with the characteristics of the relational level within the concrete- symbolic mode. That is, they now integrate relevant aspects of the task into a mean- ingful structure and generate abstractions in probability as long as these abstrac- tions are related to their "experienced world" (p. 63). Notwithstanding the capabilities of students who exhibit Level 4 thinking, they may be limited by the scope of their mathematical experiences, which generally do not include fractions and combinatorics. In formulating and refining the framework (Figure 1), we attempted to achieve stability for a student's thinking across the four constructs; that is, when a student's probabilistic thinking was at Level 2 in sample space, it was also expected to be at Level 2 for probability of an event, probability comparisons, and conditional prob- ability. Stability was important because we wanted each level in the framework to represent a consistent picture of probabilistic thinking across all four constructs. From a practical perspective this feature was intended to make the framework more "user-friendly" for teachers when monitoring a student's probabilistic thinking. Although in the validation study (Jones et al., 1997) we demonstrated that the frame- work provided a coherent picture of probabilistic thinking at each of the four levels of the framework, there was "static in the system" in that each student's thinking levels were not always uniform. We concluded that this static resulted from</page><page sequence="6">492 Students' Probabilistic Thinking students' unpredictable tendencies to regress to subjective judgments and from task- related factors associated with the assessment of sample space and conditional prob- ability. Given the present study's focus on instruction, it was also noteworthy that the lack of stability was more pronounced in assessments following instruction (pp. 120-121). Instructional Model Research-based knowledge of students' thinking is increasingly being identified as an important component of instruction because it has been shown that this kind of knowledge is useful to teachers as they plan and implement instruction (Fennema et al., 1996; Fennema, Franke, Carpenter, &amp; Carey, 1993). In particular, an expanding body of research on students' thinking about whole numbers (e.g., Carpenter, Fennema, Peterson, Chiang, &amp; Loef, 1989), geometry (e.g., Fuys, Geddes, &amp; Tischler, 1988), fractions (e.g., Mack, 1995), and ratio and proportion (e.g., Lamon, 1993) has been used to guide instruction. Just as frameworks have been used to assess students' thinking and to build problems in whole number and geometry instruction, the Probabilistic Thinking Framework (Jones et al., 1997) was used in this study to inform the planning and implementation of probability instruction. In essence, instruction was expected to be driven by teachers' knowl- edge of the framework as it related to individual children. The design of this probability instructional program was also consistent with a socioconstructivist orientation to learning. Such a view, grounded in the work of Piaget (1968/1970) and extended by other researchers (e.g., Cobb, Yackel, &amp; Wood, 1993), holds that mathematics learning is a process in which students reor- ganize their mathematical thinking to resolve situations that are problematic for them. Additionally, we adopt the view that mathematical learning is an interactive as well as a constructive process (Cobb et al., 1993). Hence, we have taken the posi- tion that opportunities to construct probability knowledge arise from students' attempts to solve problems, to build on and reorganize their informal knowledge, and to resolve conflicting points of view. This perspective is consistent with an inquiry approach, which requires frequent opportunities for students to "discuss, critique, explain, and when necessary, justify their interpretations and solutions" (Cobb et al., 1991, p. 6). METHOD The instructional program was presented to two Grade 3 classes: to one class in the fall (early-instruction group) and to one in the spring (delayed-instruction group). The probabilistic thinking of all students in both classes was assessed three times during the study: prior to the fall instructional program (September), at the conclusion of the fall instructional program (December), and after the spring instructional program (April). Because neither group had received any previous instruction in probability, the study was designed so that the deferral of the instruc-</page><page sequence="7">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 493 tional program for the delayed-instruction group allowed us to use it as a control group for measuring the performance of the early-instruction group during the fall semester. By using this design, we could also compare the performance of the delayed-instruction group with that of the early-instruction group at the end of the spring instructional program. In establishing this repeated measures design, we were also cognizant of the fact that the delayed-instruction group might benefit from addi- tional mathematical experiences before commencing the instructional program. These experiences included more extensive work on whole numbers but did not include fractions. Participants The sample for this study consisted of 37 Grade 3 students from two classes at an elementary school in central Illinois. One class (early-instruction group, n = 18; mean age of 8 years 8 months; range of 8 years 3 months to 9 years 5 months at the beginning of instruction) participated in the instructional program during the fall semester, whereas the other class (delayed-instruction group, n = 19; mean age of 9 years; range of 8 years 5 months to 9 years 5 months at the beginning of instruc- tion) participated during the spring semester. In addition to completing the overall analysis involving the early- and delayed- instruction groups, we selected four target students identified by pseudonyms (Jana and Kerry [early-instruction group] and Corey and Deidra [delayed-instruction group]), from their respective classes for more detailed case-study analysis.3 Immediately prior to receiving the instructional program, each target student's modal level of probabilistic thinking was 2. Teacher ratings of the mathematical achievement of these students were Jana, average; Kerry, low; Corey, average; and Deidra, high. Procedure Each semester's instructional program comprised sixteen 40-minute sessions with two sessions occurring each week over a period of 8 weeks. Sessions typically opened with a whole-class exploration posed by one of the researchers. Twelve teacher education student-mentors then worked with pairs of students to solve prob- ability problems. Each mentor worked with the same pair of students throughout the instructional program and also acted as a participant observer, collecting and organizing data on the probabilistic thinking of his or her students. Not only was 3In the validation study, eight target students were randomly selected. However, because only two researchers were available each semester to observe target students during the entire instructional program, data for onlyfour of the eight target students, two per semester, were used in this study. During the random selection process for the validation study, the first two students selected from each instructional group (early and delayed) were designated as target students for this study.</page><page sequence="8">494 Students' Probabilistic Thinking the content of the instructional program the same for both the early- and the delayed-instruction groups but also the same 12 mentors worked with each group of students. Instructional Program The probability instructional program developed by two of the researchers (Jones &amp; Thornton, 1992) is outlined in Table 1. About 43% of the program focused on sample space, about 45% on probability of an event and probability comparisons, and the rest on conditional probability. Key elements of this program are described below. Table 1 Outline of the Probability Instructional Program Session Probability problem task Constructs 1 Which Color Now? SS , PE 2 Modeling Which Color Now? SS , PE 3 The Animal Snap Game SS , PE, CP 4 Model the Bear Game; Make It Fair SS , PE 5 The Gumball Comes Out SS , CP 6 Race Home Game SS , PE, PC 7 Spinner Sums SS2 , PE 8 Pick a Sum SS29 PE 9 Which Baseball Card? (with replacement) SSI, PE, CP 10 Which League? Which Team? SS2, PE 11 Candy Rolls SS29 PE, CP 12 Same Chance for Two Red Candies? SS29 PC 13 Are the Chips Fair? SS , PE, PC 14 A Double Choice: Is It Fair? SS 2 PE, PC 15 Pizza Combinations SS29 PE 16 Pizza Topping Survey SS , PE Note. SS1 = sample space, one-stage; SS2 = sample space, two-stage; PE = probability of an event; PC = probability comparisons; CP = conditional probability. Probability problem tasks. One or two related probability problem tasks provided the focus for each instructional session. Each of these problem tasks was based on one or more of the key constructs: sample space, probability of an event, proba- bility comparisons, and conditional probability. For example, in Session 6, the Race Home Game (Figure 2) incorporated problem tasks that involved spinners and focused on the first three constructs. The problems were chosen so they would be accessible to students functioning at different levels of the framework. With respect to the Race Home Game, Table 2 illustrates typical student responses to questions on sample space, probability of an event, and probability comparisons. Notice how students' responses to the probability-comparison question "Which spinner is better for the red chip?" became more sophisticated both in terms of quantitative reasoning and use of numerical symbols. Similar changes were evident in responses to the probability-of-an-event</page><page sequence="9">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 495 Session 6: Race Home Game Whole-Class Opener Two basketball teams are playing tonight, the Red Hots and the Cyclones. The Red Hots have won 3 out of 7 games, and the Cyclones have won 6 out of 7 games. Who do you think will win tonight? Why ? Activity Sheet Which Spinner? Problem Task: Each player picks one chip, either red or white. Put your chip in the start box of the Race Home Game Board. Which spinner is better for your color? Race Home Game Pick red or white. Put chips on start. Take turns with Spinner 1. If red, move one space. If white, move one space. Play again. Use Spinner 2. z Spinner 1 Spinner 2 Talk About It: Did the game turn out as you said? Think and Tell: What spinner is better for the red chip? The white chip? Why? Sample Questions: * What colors could come up on the spinner? (sample space) * Why does red have the better chance on Spinner 1? (probability of an event) * Which spinner is better for the red chip? (probability comparisons) Parallel Task: * Have students make up a similar game and play it. Extensions: "* What if the parts on the spinner were not equal? Could you have three parts red and one part white and still have a better chance of winning with the white? "* Can you make a fair spinner with three colors? Why is it fair? Figure 2. Race Home Game.</page><page sequence="10">496 Students' Probabilistic Thinking question. With respect to the sample-space question "What colors could come up on the spinner?" the change in sophistication was most apparent between the Level 1 and Level 2 responses. Although the sample-space responses given under Levels 3 and 4 are not sufficient to meet the criteria for these levels (such criteria depend on students' responses to two-stage experiments), they are indicative of the greater confidence and consistency that students at higher levels demonstrated in such sample-space tasks. Table 2 Examples of Students' Thinking Levels on the Race Home Game Construct/ Level 1 Level 2 Level 3 Level 4 question Subjective Transitional Informal Numerical quantitative Sample space What colors "Red. It's going "Red and white." "Red and white, "Red and white, could come up to win." of course." but they don't on the spinner? have the same chance." Probability of an event Why does red have "It's my favorite "There's more "Red; there's "Red's chance a better chance on color." red [than white]; three red pieces is three out of Spinner 1? it's also where to one white." four and white's I'd start the is only one out spinner." of four." Probability comparisons Which spinner "It doesn't matter "Spinner 1; it's "Spinner 1; there "Spinner 1 is is better for the because I always got more red. are three sections best for red; it red chip? spin red; it's my It's my lucky of red compared has three out of favorite color." color." to one section of four chances of white." winning. Spin- ner 2 has only one out of four chances of winning." As the instructional program progressed, greater integration of probability constructs occurred. For example, sample space was normally linked with proba- bility-of-an-event or probability-comparisons tasks, and conditional-probability tasks typically arose out of probability-of-an-event tasks involving both with- and without-replacement situations. To establish a context for conditional probability, we asked students whether the probabilities had changed; that is, they were asked to compare each new probability with the original probability. A typical instructional session. Session 6 (Figure 2) exemplifies the instructional approach. It began with a whole-class opener that was designed to focus students' thinking on the probability-comparisons construct and was rich enough to generate</page><page sequence="11">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 497 a range of probabilistic thinking. Following this opener, students worked with their mentor on the Race Home Game problem task that also focused largely on the prob- ability-comparisons construct. The task was designed to have students predict the better spinner to use for each color chip, then experiment to compare the two spin- ners, and, finally, determine the better spinner on the basis of their analysis of data and spinners. Through the use of questions like "Did the game turn out as you said?" and "Which spinner is better for the red chip? Why?" students were encouraged to share their thinking either verbally or in writing. If mentors assessed that students needed more experience with the construct(s) associated with a task, parallel tasks involving different game settings and different spinners were used to foster growth in their probabilistic thinking. Similarly, extension problems for this activity went beyond spinners with equal sections (Figure 2). The session closed with a whole-class wrap-up in which students discussed how the Race Home Game was similar to the basketball game situation introduced at the beginning of the session. Pedagogicalfocus. The pedagogical orientation for implementing the instructional program was grounded in research-based knowledge of students' probabilistic thinking (Fennema et al., 1993) and was consistent with a socioconstructivist approach to learning (Cobb et al., 1991; Cobb et al., 1993). To foster this kind of instruction, mentors participated in 11 one-hour seminars each semester: 3 hours prior to the instructional program and 1 hour each week during the 8 weeks of instruction. In these seminars, which we conducted, the mentors explored strategies for using the Probabilistic Thinking Framework to monitor and nurture students' thinking. During these sessions mentors learned how to (a) use the framework to assess and build on students' understanding, (b) pose problems and questions rather than model solutions, (c) encourage students to construct their own solutions, (d) maxi- mize opportunities for pairs of students to engage in collaborative problem solving, and (e) guide students in negotiating conflicts between alternative interpretations or solutions to a problem. More specifically, to learn to use these strategies, mentors regularly observed and discussed video vignettes that focused on such activities as "guiding students to construct their own solutions" and "challenging students to negotiate meanings and multiple solutions." They also discussed questioning strate- gies and the value of appropriate questions (e.g., How is your solution the same as or different from your partner's? Is it possible for both answers to be correct? Find another way to model the problem. Why do you think the data you collected are different from the set of class data? Can you use numbers to tell me?). In addition, during the seminars mentors examined the content of the probability problems and the instructional materials for the following sessions. While consid- ering the instruction materials, mentors worked in pairs to construct multiple solu- tions to the problem tasks and to identify possible student strategies. Through these discussions and experiential sessions, we attempted to ensure that mentors' content knowledge and knowledge of students' thinking vis-A-vis the framework were as uniform as possible. We also attempted to ensure that mentors fostered learning</page><page sequence="12">498 Students' Probabilistic Thinking in similar ways, albeit recognizing that student responses should drive instruction. Each week we shared our overall perceptions of previous sessions and addressed areas of concern, especially with respect to the pedagogical focus. When neces- sary, we worked individually with mentors to produce an instructional approach to elicit students' thinking rather than to reflect mentors' telling. In summary, we observed mentors each session and attempted to maintain an approach that was consistent with the pedagogical focus of the instructional program. Data Collection Interview and observational data were gathered from three sources: (a) researcher- generated assessments conducted at the beginning (September), middle (December), and end (April) of the school year; (b) mentor evaluations and notes on each of their two students for each instructional session (although only data on target students were used in this study); and (c) researcher narratives of observations on each of the four target students and their mentors. The assessment data listed under (a) are described in the next section. The data in (b) were collected on Mentor Summary Evaluations (MSEs). These forms, comprising three to five questions that were virtually the same for each session, were designed to help mentors capture students' probabilistic thinking in relation to the problem tasks. More specifically, mentors were expected to respond to questions designed to obtain information on students' solution strategies, visual representations, special insights, and difficulties. In essence, they built up an ongoing profile of each student's probabilistic thinking. With respect to the data in (c), the two target students in the early-instruction group were observed throughout the 16 instructional sessions by two of the four researchers, and the two target students in the delayed-instruction group were observed by the other two researchers. On the basis of field notes, each researcher constructed a Researcher Narrative Summary (RNS) for his or her target student every session. Over the 16 sessions, each target student was also videotaped four times. These video observations were used only to augment the respective RNSs. In summary, the RNSs described target students' thinking on the mathematical tasks involved in the instructional program and also contained the ongoing annotations we made in an attempt to identify trends in the students' thinking. Instrumentation The interview assessment protocol based on the Probabilistic Thinking Framework comprised 20 tasks (see selected items, Figure 3). Five items were asso- ciated with sample space, 4 with probability of an event, 7 with probability compar- isons, and 4 with conditional probability. In designing items for the interview assess- ment protocol, we used probability generators such as spinners (continuous models) and groups of objects (discrete models) that were often set in the contexts of gumball machines, race settings, and games. Both the probability generators and the contexts were consistent with these students' experiences. Linking assessment tasks to the key constructs of the framework enabled us to explore students'</page><page sequence="13">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 499 Interview Assessment: Selected Items Sample Space Probability of Probability Conditional an Event Comparisons Probability SS1 PE1 PC2 CP1 I will shake this box. This is a gumball Red R BR (Using the same box (Allow the student to machine. (Allow the Blue R as SS1) Close your observe that this box students to see that Yelow RB eyes and draw a contains 4 green, 3 the cup contains 1 A B bear. What color is red, and 2 yellow red and 4 green chips.) You're going to play it? Put the bear bears.) If you close If you close your eyes the penny game again back. If you were to your eyes and draw and draw 1 gumball, (see PE3). Which close your eyes and a bear from the box, what color are you spinner would be the pick again, what what colors could most likely to get? best for you? Why? colors could your your bear be? Why? Why? What's the (If student prefers one bear be? Why? chance of getting spinner over the other, this color? ask, "Does it really matter which spinner you use?") Use num- bers to tell me about the chances of getting a red. SS2 PE2 PC4 CP2* (Continuing (Same gumball (Place the Race from PE4) 12 4 machine) Suppose Home Game mat (A red bear is drawn I I/ you got a red gumball. before the student. and the student is A B (Remove red chip.) Show the spinners.) asked to observe Spin both spinners. Now if you draw Your color is red. that the red bear is What numbers did again with your eyes Which spinner would not replaced.) I will you get? What num- closed, what color be better for you if shake the box again. bers could you get are you most likely you wanted to win? If you draw another if you spin both spin- to get? Why? What Why? Can you use bear without looking, ners again and again? is the chance of numbers to explain what color will you Is that all? How do getting this color? your choice or com- have the BEST you know? pare the chances on chance of getting? the two spinners? SS3 PE3 PC5 CP3t (Continuing (OMRed (For the game in PC4) from CP2) Blue How would you (Another red bear is Yellow change each spinner drawn and not re- (Let the student ob- This spinner is used so that both players placed.) I will shake serve the colors of to play the penny would have the same the box again. If the four-section spin- game. You and a chance? Show me. you draw another ner: red, green, blue, friend pick a color Can you use numbers bear without looking, and yellow. Spin the and then take turns to explain what you what color would spinner in front of the spinning. If the have done? you have the LEAST student.) What color pointer lands on chance of getting? came up on the spin- the color you picked, ner? What colors you get a penny. If could you get by spin- not, you lose a penny. ning the spinner? Which color would you choose? Why? Figure 3. Selected items from the interview assessment. (continues on next page)</page><page sequence="14">500 Students' Probabilistic Thinking SS4 PE4 PC7 CP4 (Continuing Pretend that your wall I will shake this box. from CP3) is divided into two (Allow the student to 4Has the chance of sections. Use the red observe that the box A B c getting a red and blue crayons to contains 4 green, 3 (For the game in PC4) changed? Why or paint each section a red, and 2 yellow Would any of these why not? Has the different color. Show bears.) If you draw a spinners make the chance of getting a me how many different bear without looking, game fair? green changed? ways you could paint which color do you Why or why not? the wall. Is that all? have the LEAST Has the chance of How do you know? chance of getting? getting a yellow changed? Why or why not? Can you use numbers to explain? *In CP2, additional probes like "Has the chance of getting a red changed? Why or why not?" were asked because they were critical in capturing students' understanding of conditional probability. tin CP3, the probe "Why has the chance of getting a red changed?" was used to assess conditional- probability understanding. Figure 3 (cont.). Selected items from the interview assessment. thinking in terms of the four levels of the framework. Tasks were framed so that students would respond orally, but they could also write or use available materials to demonstrate their thinking. Two procedures were utilized to code the interview assessments. The first proce- dure involved double coding (Miles &amp; Huberman, 1994) and was used to generate performance scores (maximum = 20) for all students in the early- and delayed- instruction groups at each of the three assessment points. Each item was scored 1 or 0 according to a 2-point rubric: 1 for responses that were correct and validly justi- fied; 0 for responses that were incorrect or correct but not validly justified. Working independently, two of the authors scored students' responses. Agreement was achieved in scoring 92% of the assessments of the 37 students over the three time periods, that is, on 102 of 111 assessments. Variations were clarified until consensus was reached. The second procedure was also used with all students. It involved double coding (Miles &amp; Huberman, 1994) to establish each student's probabilistic thinking level on each of the four constructs over the three assessment points. Details of this proce- dure were presented by Jones et al. (1997). In this case, three researchers inde- pendently coded students' thinking levels and reached agreement on 129 of 148 levels, that is, 87%. Variations were clarified until consensus was reached. Data Analysis A "within-case displays" approach (Miles &amp; Huberman, 1994) guided the analysis of mentor and researcher observational data on the four target students. For each target student, we assigned multiple codes to their 16 MSEs and 16 RNSs. These codes were</page><page sequence="15">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 501 based on the four constructs and four thinking levels associated with the framework. Subsequently, a time-ordered matrix was generated for each target student over the 16 instructional sessions to display changes and trends in thinking across the four prob- ability constructs. These matrices were further analyzed and synthesized to discern patterns and relationships in the learning exhibited by each student. Triangulation was used to carefully scrutinize mentor data (MSEs) and researcher data (RNSs) not only for consistency and commonality but also for alternative inter- pretations of the data. Although it was not possible to videotape each target student every session, the sample of four videos on each target student proved to be a valu- able means of corroborating mentor and researcher observations. The video sampling indicated a high degree of consistency between mentors and researchers in their reports of observations but also revealed that mentors and researchers noticed different aspects of students' learning. Data from mentors and researchers were further triangulated with assessment data to generate as rich a perspective as possible on each target student. We also carried out a quantitative analysis using the performance data on all students as the dependent variable. This repeated measures analysis of variance was used to test for differences between the early-instruction and delayed-instruction groups at all assessment points. RESULTS The Effect of the Intervention Program: Case-Study Analysis We have presented, as a preface to the analysis of case-study data, the frequen- cies of the modal4 probabilistic thinking levels for all students in both instructional groups at the three assessment points (see Table 3). For the early-instruction group, the intervention occurred between the first assessment and the midassess- ment, whereas that for the delayed-instruction group occurred between the midassessment and the final assessment. Immediately prior to instruction, the delayed-instruction group showed fewer students at Level 1 and more students at the higher bimodal Levels 2 and 3 than the early-instruction group. The fact that this difference was not as apparent at the first assessment point when students in both groups were almost evenly distributed across Levels 1 and 2 indicates that there were students in the delayed-instruction group who increased their probabilistic thinking levels even without the benefit of instruction. The most salient feature of the data in Table 3 is the number of students in both groups who increased their modal level of probabilistic thinking to 3 following instruction. There were no students with a modal level of 3 prior to instruction, even though 5 students were exhibiting bimodal Level 2-3 thinking, that is, Level 3 thinking on two constructs. Immediately following instruction there were 19 4The modal level was used to summarize each student's probabilistic thinking because our intent was to capture a student's dominant level of thinking on the four constructs.</page><page sequence="16">502 Students' Probabilistic Thinking Table 3 Frequency of Modal Probabilistic Thinking Levels for Each Instruction Group at the Three Assessment Points Early-instruction group (n = 18) First assessment Midassessment Modal level (Preinstructiona) (Postinstructiona) Final assessment 1 9 4 2 2 8 4 8 3 0 7 7 Bimodal 1-2 0 1 0 Bimodal 2-3 1 2 1 Delayed-instruction group (n = 19) Midassessment Final assessment Modal level First assessment (Preinstructiona) (Postinstructiona) 1 7 5 1 2 9 10 4 3 0 0 12 Bimodal 1-2 1 0 0 Bimodal 2-3 2 4 2 aAssessment levels immediately prior to and following instruction. students (7 in the early-instruction group and 12 in the delayed-instruction group), or 51% of those in the study, exhibiting a modal level of 3. Notwithstanding these gains, there were 5, or 14% of the students, mostly from the early-instruction group, still at modal Level 1 following instruction. In our qualitative analysis we will attempt to explicate and illuminate some of these trends. Case-Study Analysis We discerned a number of learning patterns by analyzing mentor MSEs, researcher RNSs, and videotaped observations of the thinking of target students during the intervention program. We augmented these patterns by examining the relationship between target students' learning during instruction and their thinking at the three assessment points, especially their thinking at assessment points that immediately preceded and followed instruction. Figure 4 shows a profile of each target student's thinking levels at the three assessment points and also indicates when the instructional intervention occurred for each target student. The findings about learning patterns that emerged from this analysis of instruc- tion and assessment were (a) misconceptions in sample space, when they exist, can be deep-seated and appear to be fueled by subjective judgments; (b) the applica- tion of part-part reasoning is crucial to students' quantifying probability situations in any meaningful way; (c) the application of both part-part and part-whole rela- tionships in probability situations is the key to producing growth in probabilistic thinking; and (d) the use of invented or conventional language to describe part- whole relationships provides scaffolding for coherent probabilistic thinking.</page><page sequence="17">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 503 Early-Instruction Group Jana Kerry 4 4 I ii IE P P ISP CC SP CC II IIP PS EPCC SP CC Delayed-Instruction Group Corey Dierdra 4 W 0SS PEPC CP SS PEPC CP SS PEPC CP 0SS PEPC CP SS PEPC CP SS PEPC CP D First Assessment September SS: Sample Space 2- ,f-83,2 STiming of Instructional mMiddle Assessment December PE: Probability of an Event ? 2 ',2 0 SS PE PC CP SS PE PC CP SS PE PC CP SS PE PC CP SS PE PC CP SS PE PC CP Delayed-Instruction GrouIntervention PC: Probability Comparisons Corey Final Assessment April P: Conditional Probabilityerdra U4 ,4- &gt;3 "&gt;31 2 .2 i 2 0 0-SS PE PC CP SS PE PC CP SS PE PC CP 0 SS PE PC CP SS PE PC CP SS PE PC CP E3First Assessment September SS: Sample Space 'Timing of Instructional MdlAsemntDcbr PE: Probability of an Event ,Intervention EMdl sesetDcme PC: Probability Comparisons SmFinal Assessment April CP: Conditional Probability Figure 4. Profiles of case study students' probabilistic thinking patterns. In the descriptions above and in the case-study analyses that follow, the term growth in probabilistic thinking is used to indicate progression to a higher level of thinking as measured by the framework descriptors. Part-part reasoning refers to thinking that involves the relationship of two parts to each other and part-whole reasoning refers to thinking that represents the relationship of a part to a whole. For example, when one is trying to determine the most likely event in the protocol task PE1 (Figure 3), examining the relationship of four green gumballs (part) to one red gumball (part) represents part-part reasoning; comparing four green gumballs (part) to all five (whole) represents part-whole reasoning (Singer &amp; Resnick, 1992). Invented language is used in the sense that one or more students suggested their own ways of describing probabilities and others then adopted their language. This language was used in both oral and written forms. An example of such invented language is the use of "one out of three" to describe a probability rather than the more conventional use of one third. Target Student 1. Jana, who was in the early-instruction group, was typical of students who exhibited enduring misconceptions in sample-space thinking (Figure 4). She exhibited Level 1 thinking about sample space prior to instruction and was still at that level following instruction. Although her thinking about probability of an event remained at Level 2 before and after instruction, her thinking about prob- ability comparisons and conditional probability was inconsistent in that thinking about probability comparisons increased from Level 2 to Level 3 and in conditional probability decreased from Level 2 to Level 1. She was a typical example of</page><page sequence="18">504 Students' Probabilistic Thinking students whose thinking levels across the four constructs were more unstable following instruction than prior to it. Interestingly, at the final assessment point, following a period of no instruction, Jana exhibited Level 3 thinking about sample space and also showed higher levels of thinking about probability of an event and conditional probability than she had immediately after instruction. Reflecting this growth in sample-space thinking, Jana's profile at the final assessment indicates a stronger and more coherent understanding of probability. In the narrative below, we trace Jana's development during the intervention and illustrate and explicate her thinking. Prior to instruction, Jana did not list all the outcomes in a one-stage experiment whether the outcomes were associated with a box of discrete objects or a spinner. For example, when asked what colors could be drawn from a box of bears of different colors (Figure 3, SS1), she identified only one outcome, "Red, it's on the top." Similarly, when asked what colors you could get on a spinner (Figure 3, SS3), she again said, "Red [because] it's my favorite color." Even when probed, she was reluctant to give the complete set of outcomes. Although some researchers (e.g., Piaget &amp; Inhelder, 1951/1975) have attributed this phenomenon to task factors, such as the meaning of could, our results indicate the presence of a genuine miscon- ception in that students like Jana place a degree of certainty in a situation in which certainty does not exist. During the intervention Jana responded to tasks involving sample space in diverse ways. For example, when she experimented with a bag containing two red squares and one blue square in Session 1, she not only listed all the outcomes of this one-stage experiment but also stated, "Red won't always be drawn; sometimes blue will be drawn." Given this spontaneous response, Jana's mentor felt that she was now taking cognizance of all outcomes in one-stage sample spaces and was beginning to move beyond Level 1 thinking about sample space. However, during Session 5 when presented with a gumball task, Jana again insisted that not all the gumball colors were possible: "They must be close to the bottom." In the 6th session she did recognize that there were two outcomes on a red-white spinner, but in the 9th session she again gave an incomplete set of outcomes for a bag containing chips of different colors. More explicitly, in the 13th session, she said, "Six [is the only chance on the die because] it will win for me." This last response is especially significant because it was made in response to a probability generator that was not composed of discrete objects like a gumball machine or a box of bears. Her response exemplified the same misconception, but this time she supported her thinking by appealing to the anthropomorphic power of the die rather than appealing, as she had previously, to spatial considerations. Although she appeared less prone to exhibit this misconception with continuous probability generators (e.g., spinners) than with discrete probability generators (e.g., gumball machines), we claim that her misconception is conceptual rather than task- driven. This claim is further supported by the fact that no amount of experimen- tation and discussion on certain, possible, and impossible outcomes and random mixing seemed to move Jana's thinking beyond Level 1 in sample-space situations.</page><page sequence="19">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 505 Given that Jana's thinking about sample space was consistently at Level 1 prior to and during the instructional program, we would have expected, on the basis of the Framework, that her thinking in probability-of-an-event, probability-compar- isons, and conditional-probability situations would also be at approximately Level 1. In fact, it was generally higher but unstable. For example, in Lesson 6 during the Race Home Game, Jana easily identified the better spinner for the red token saying, "It [the spinner with 3/4 red] will have a better chance because there's more red than white." She used this same kind of quantitative reasoning in Lessons 3, 4, 8, and 14, usually limiting her response to a comparative judgment (Level 2) in the form "more of" or "less of" the target event. Jana's mentor noted that Jana's partner often used numerical probabilities (e.g., "3 out of 4" for the Race Home Game spinner), but there was no instance of Jana's using such a numerical prob- ability until Lesson 12, and this use was an isolated instance. Jana's responses were mostly based on comparative judgments in spite of mentor probes [Can you use numbers to tell me?] and discussions between Jana and her partner. More impor- tant, in Lessons 1, 2, 9, and 13, Jana sometimes reverted to subjective judgments or ignored part of an event when two outcomes were not contiguous on a spinner. This instability with respect to the three probability constructs was captured by Jana's mentor, who wrote, "It is difficult to see trends in her thinking. She is so inconsistent. She has difficulty listing outcomes, but then she seems to be able to determine which spinner is best for a given event. On the other hand, she had diffi- culty recognizing that a coin toss was fair because she believed 'heads' was best." Interpretive analysis ofJana's thinking. In our view Jana' s probabilistic thinking is strongly but not completely limited by her tendency to use a deterministic approach in thinking about sample space, that is, to posit a degree of certainty in random situations in which such certainty does not exist. This misconception in sample-space thinking is puzzling, but we claim that the pervasiveness of her subjec- tive judgments essentially conflicts with her other judgments about whether all outcomes could occur. This interpretation appears to be consistent with Biggs and Collis's (1991) char- acterization of thinking at the prestructural level. According to this view, taking cognizance of all outcomes is irrelevant for Jana because her ikonic functioning, manifest through subjective judgments, has served her well in the past; she is not motivated to make the move to a different way of conceptualizing this probability situation even though she has the mental capability to perform such a task and does indeed demonstrate this capability when dealing with probability-of-an-event and probability-comparison tasks. More specifically, when she is faced with tasks that require her to make comparisons between two or more probabilities, she generally uses quantitative judgments that seem to be based on the presence of a part-part schema. This schema, however, lacks potency because within a probability context her part-part thinking is also prone to subjectivity. In essence, there appeared to be very little linkage between Jana' s thinking about sample space and her thinking about the three probability constructs in spite of efforts during instruction to make</page><page sequence="20">506 Students' Probabilistic Thinking such mathematical connections more visible. Subjective judgments dominated her thinking in situations related to all constructs, although the effect was more persistent for sample space than for the other three constructs. On the basis of our analysis of all students' assessment data, we suggest that Jana' s sample-space misconception is not unique. Fifteen of the 37 students in this study, or 41%, exhibited this misconception immediately before their intervention (at the first assessment for the early-instruction group and at the middle assessment point for the delayed-instruction group). Although results for these 15 students cannot be directly located in Table 3 because it does not list thinking levels for indi- vidual constructs, the number of students who exhibit modal Level 1 thinking prior to instruction is a useful indicator of the extent of the sample-space misconception prior to instruction. By the end of instruction 10, or 27%, of the students in the study had overcome the misconception, but 5, or 14%, still exhibited the misconception immediately after instruction. Of the 5 for whom the misconception persisted, only 1 was in the delayed-instruction group. Target Student 2. Kerry was in the early-instruction group and exemplified students who experienced difficulty in quantifying probabilities. At the first assess- ment point, prior to instruction, Kerry exhibited Level 1 thinking about sample space and Level 2 thinking about each of the other three constructs (Figure 4). Like Jana, she had difficulty listing the outcomes of a one-stage experiment and was prone to subjectivity. However, she was beginning to use quantitative reasoning when comparing the probabilities of events, albeit she did not always use valid quan- tifications. Like Jana's, Kerry's profile at the middle assessment point was more unstable following instruction than prior to it. She exhibited Level 3 thinking in sample-space tasks, Level 1 in probability-of-an-event and conditional-proba- bility tasks, and Level 2 in probability-comparisons tasks. It appears that her growth in sample-space thinking during the intervention was not accompanied by measurable growth of thinking about the other three constructs; in fact, her thinking levels actually decreased for probability of an event and conditional probability. We trace Kerry's development during the instructional intervention and interpret the changes in her thinking. Unlike Jana, who experienced protracted difficulty with one-stage sample-space tasks, Kerry seemed to grasp this concept during the first and second sessions of the intervention and was quite spontaneous in listing outcomes for one-stage experiments during Sessions 4, 6, and 9. There was no evidence that Kerry used subjective thinking after the first two sessions of the intervention, and this absence was maintained in the middle and final assessments. Although Kerry struggled when trying to list the outcomes of two-stage experiments for much of the intervention, mentor and researcher documentation indicated that during Sessions 14 and 15 Kerry had begun to move beyond Level 2 thinking about sample-space situations and had adopted more efficient strategies for two-stage experiments. For example, in Session 14, when she was asked to list the outcomes in a game when two chips (red on one side and white on the other) were tossed, Kerry wrote RR, RW, WR,</page><page sequence="21">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 507 and WW and said, "I started with red and kept matching." In response to the mentor's request for a demonstration using the chips, Kerry showed her construc- tion using just two chips, which she flipped back and forth to produce the same listing she had written. When asked by the mentor to distinguish between RW and WR, she used chips to produce the two different outcomes. The strategy used by Kerry to list the four outcomes in the game with red-white chips exemplifies what English (1993) termed the "odometer" strategy and represents one of the more complex strategies English documented in relation to young children's responses to two- and three-stage combinatorial problems. Kerry's thinking in Session 14 was further reflected in the midassessment in which she was able to systematically list the outcomes in both one-stage and two-stage sample-space tasks. Notwithstanding this growth in her understanding of sample space, Kerry's thinking relative to the three probability constructs was severely inhibited by her inability to quantify probabilistic situations in any meaningful way. She could iden- tify the outcomes and she was no longer prone to subjective reasoning, but she had difficulty recognizing quantitative relationships between events. For example, in the midassessment, when asked which color is more likely to be drawn from a gumball machine containing 1 red chip and 4 green chips (Figure 3, PE1), Kerry answered, "They are the same; it's 50-50." For Kerry it seems that the presence of two outcomes is synonymous with "equally likely" because she made the same response for a two-outcome spinner (75%-25%) in the Race Home Game (Session 6) and for 1 white and 2 red chips in Are the Chips Fair? (Session 13). Moreover, this thinking persisted even though the mentor had Kerry perform experiments that generated data that were counter to her 50-50 predictions. Kerry was not always consistent with respect to the 50-50 misconception, but it was never far removed from her immediate thinking. In Session 1, she correctly stated that red had a better chance of being drawn from a bag with two red squares and one blue. However in Session 2, she was not able to color a three- or six-section spinner so that each represented a probability model that was equivalent to the prob- ability model associated with the squares in the bag. In the case of the three-section spinner, she said, "It can't be done," whereas in the case of the six-section spinner she made the two colors equally likely. In essence the misconception was merely delayed. Although modeling tasks recurred in Sessions 4, 5, 6, 9, and 15, researcher documentation indicated that Kerry's difficulties in recognizing and representing equivalent probability models persisted except in cases for which the outcomes were equally likely. In a conditional-probability situation, when faced with a nonreplacement task involving a pack of two red and two white candies (Session 11), Kerry was unable to recognize that the probability of selecting a red had changed as a result of having already drawn a white. This thinking was typical of the kind she had previously displayed in conditional-probability tasks in Sessions 3 and 9 and seemed to be a further manifestation of her thinking that two outcomes were always equally likely. That is, because there were still some red and some white remaining, she thought that each color had a "50-50 chance."</page><page sequence="22">508 Students' Probabilistic Thinking Interpretive analysis of Kerry's thinking. In contrast to Jana, Kerry showed rapid growth in sample-space thinking, at least in one-stage experiments, and appeared to overcome the tendency to use subjective reasoning. Although her thinking about sample space indicates that she recognized the "parts" operating in a probability situation, there was little evidence of her using valid part-part rela- tionships in situations involving the three probability constructs and certainly no evidence of her using part-whole thinking. One strong manifestation of this lack of ability to use part-part relationships recurred whenever she encountered prob- ability situations with two outcomes. Kerry grouped all such situations under the rubric "equally likely" even though her mentor regularly had her carry out exper- iments that were intended to challenge such thinking. Further examples of her inability to apply part-part reasoning were evident whenever she attempted to construct probability generators that were equivalent to other probability genera- tors. She faithfully represented the parts but did not quantify the parts in a way that maintained equivalence between the two probability generators even though, in the case of the spinners, the sections were already drawn and the mathematical rela- tionships were therefore somewhat transparent. The fact that Kerry used part-part relationships, albeit weakly, in the assessment prior to instruction but did not apply them in probability situations during instruc- tion is perplexing. It may well be that, during classroom instruction, we prematurely followed the lead of those students who were describing probabilities quantitatively. For some students, invented language like "one out of three" or "50-50" supported their part-part or part-whole probabilistic thinking. For students like Kerry, however, it may have produced conflict that tended to override her more intuitive thinking- thinking that had initially enabled her to recognize a difference between the parts. Alternatively, Kerry's inability or reluctance to use valid part-part relationships may be indicative of the more subtle and even mystical images that probability contexts and experiences generate for young children who exhibit Level 1 thinking. This latter interpretation is consistent with Biggs and Collis's (1991) description of prestructural thinking in that Kerry's ikonic functioning has not been embellished by concrete-symbolic functioning. In essence, relationships that are transparent in one context may become translucent or even opaque in a mystical context like prob- ability. On the basis of our analysis of all the student assessment data, we suggest that there were 3 students who demonstrated probabilistic thinking similar to Kerry's. Kerry and 9 other students from the 15 (referred to earlier in the section on interpretive analysis of Jana's thinking on page 505) who initially exhibited the sample-space misconception were able to overcome it and increase their sample-space thinking beyond Level 1 by the end of the instructional program. Seven of these 10 students, or 19% of all students, also increased their thinking on the three probability constructs to at least Level 2; however, 3 students, including Kerry, exhibited the same or decreased thinking levels in some probability constructs. Kerry typifies these 3 in that she showed little evidence of using part-part thinking and no evidence of using part- whole thinking in situations involving the three probability constructs.</page><page sequence="23">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 509 Target Student 3. Corey was in the delayed-instruction group and was typical of students who showed growth in probabilistic thinking during the intervention. Although Corey's thinking was only at Level 2 across all four constructs at the midassessment point, prior to instruction (see Figure 4), he had exhibited higher level thinking at the first assessment point. However, his early conceptions appeared to be rather unstable, and we were not surprised that his thinking levels dropped on two constructs in the period prior to instruction. His early thinking was char- acterized by part-part reasoning. For example, in the midassessment, when faced with the gumball machine holding 1 red and 4 green chips (Figure 3, PE 1), Corey said, "Green is more likely-it's four and red is one." By the final assessment following the intervention, Corey exhibited stronger probabilistic thinking-being at Level 3 for all constructs except conditional probability, for which he remained at Level 2. In the descriptions and analysis below, we trace Corey's development during the intervention and interpret changes in his thinking. During the intervention, Corey's mentor reported that he had no trouble listing the outcomes in one-stage sample-space tasks and that he quickly developed systematic strategies for listing outcomes of the two-stage tasks during Sessions 7, 8, 10, and 11. We also observed that he could readily recognize and construct equivalent models of probability situations. For example, in Session 2 he was able to select a three-section spinner and correctly designate the events to represent a situation that involved drawing a square from a bag containing 1 blue and 2 red squares. He was also able to use a red-white chip in Session 4 to model the bear game, which involved two equally likely outcomes and a discrete probability generator. Corey could identify the component "parts" of a probability situation, that is, the set of outcomes and their probabilities. This ability enabled him to recog- nize when two probability generators were equivalent. For Corey, a key learning opportunity relating to the three probability constructs occurred during the Animal Snap Game (Session 3). Corey was trying to find the chance of getting a match for the lion when he suddenly asked his mentor what was meant by chance. At the time, we wondered about the reason for this ques- tion because the word had been used during the two assessments and the two previous lessons. However, in previous probability tasks, Corey had been able to respond to questions about chance by comparing probabilities using part-part rela- tionships. In this task that route was less obvious, even though he could have compared the event of a match to its complement. At any rate, the mentor grasped the opportunity to focus Corey's thinking on part-whole probability relations, first with respect to a spinner and then in the context of the Animal Snap Game. She used the three-sector spinner (from Session 2) in which one sector represented the blue square and two sectors represented the red square and asked, "What do you think is the chance of getting red?" After Corey answered, "Two chances," the mentor asked, "Out of how many?" Picking up on this prompt, Corey replied, "Two chances out of three." The mentor indicated that this was one way of describing chance and reminded Corey that one of the students had used similar language in the whole-class opening session that day. This experience seemed to</page><page sequence="24">510 Students' Probabilistic Thinking have a twofold effect on Corey's probabilistic thinking: Part-whole as well as part- part relationships became part of his probabilistic thinking, and invented language of the form "two chances out of three" seemed to provide a scaffolding for his thinking. In fact, later in the same session, when looking at the chance of a match in the Animal Snap Game, Corey abstracted his thinking further when he said, "The chance for a match is the number of matches [match cards left in the pack] out of the total number of cards left [in the pack]." Corey's enhanced thinking was further evident in Session 4 when he recognized that two spinners, one with two reds out of six and the other with one red out of three, represented equivalent probability models. However, he was puzzled as to why "two out of six" was the same as "one out of three." This situation may have been more easily resolved had Corey understood equivalent fractions, but he did not, so the mentor suggested that he cut the spinner with three sectors into six equal parts. This activity enabled Corey to match up the various parts, and he later demonstrated that a spinner with two reds out of four gave one the same chance as a spinner with one red out of two. Moreover, he described the equivalency as "two out of four is the same [chance] as one out of two." During the rest of the instructional program, Corey consistently expressed his thinking in precise numerical terms and, according to his mentor, acted as a peer tutor for his partner. In this role he showed his partner strategies for listing outcomes, drew diagrams to show the equivalence of probability generators, encouraged his partner to use the "out of" notation for expressing chance, and generally took the initiative when he and his partner reached an impasse on a problem. For example, in Lesson 6, when the mentor asked Corey and his partner to construct a spinner that had more red sections than white sections but for which white had a better chance of winning, Corey was the one who showed leadership. Although both students initially felt that such a spinner could not be constructed and were unsuccessful on their first attempt to create one, Corey then created a spinner that had one section of white filling three fourths of the spinner and three sections of red filling the remaining quarter of the spinner. Corey explained to his partner how he had drawn the spinner: "I made the white piece bigger than the red, then I broke the red into three." As might have been expected, Corey's thinking levels at the final assessment were at Level 3 except for conditional probability. His strength at identifying the outcomes in the sample space, his increased fluency with part-whole relationships, and his use of invented language like "one out of three" drove his thinking about probability of an event and probability comparisons. Interestingly, in the assess- ment item on conditional probability (Figure 3, CP4), he did not recognize that the probability of drawing yellow had changed as a consequence of two red bears' having been drawn. He maintained that the number of yellow had not changed, ignoring the fact that the total number of bears had dropped from nine to seven. Interpretive analysis of Corey's thinking. Corey appeared to be the only target student who showed no evidence of subjective judgments immediately prior to instruction. At that point his thinking was stable across the four constructs even though it had dropped on two constructs in the noninstructional period between the</page><page sequence="25">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 511 first two assessments (see Figure 4). In contrast to Kerry, Corey not only identi- fied all the outcomes in the sample space, he also realized that the number of outcomes in an event is linked to the probability of that event. As a result, Corey started the intervention relying almost entirely on a part-part schema to compare and quantify probabilities. Corey's growth to Level 3 thinking (except for conditional probability) during instruction seemed to be consistent with a move from the unistructural to the multistructural level or possibly even the relational level of the concrete-symbolic mode (Collis &amp; Biggs, 1991). In essence, his experiences during instruction enabled him to automate his part-part thinking so that he had the capacity to accommodate a part-whole schema and consequently to integrate his knowledge at a higher level of the concrete-symbolic mode. The catalyst for his growth in prob- abilistic thinking appeared to be the mentor's response to Corey's question about the meaning of chance. The researcher observing the scenario felt that the mentor's probe "out of how many?" may have been too directive. However, the evidence indicates that the mentor's question prompted Corey to reconceptualize his thinking because after that exchange he consistently used part-whole thinking and adopted the "out of" language as if he had invented it himself. Surprisingly this combina- tion of part-whole thinking and its associated symbolic representation, used so successfully by Corey in probability-of-an-event and probability-comparisons situations, was not adopted by him when he was faced with the conditional-prob- ability task in the final assessment (Figure 3, CP4). In conditional-probability tasks, he appeared to limit his thinking to part-part reasoning and ignored the fact that the total number of outcomes had changed. Even though a part-part comparison of the event to its changing complement would have sufficed, the notion of comple- ment did not seem to be accessible to Corey and other students in this study unless there were only two events. Analysis of all the student assessment data indicates that there were 19 students, or 51%, who exhibited modal thinking levels of 3 following instruction (see Table 3). Seven of these were in the early-instruction group and 12 were in the delayed- instruction group. Although 5 of the 19 had started the intervention at levels slightly higher than Corey's (bimodal Level 2-3), they all showed growth similar to Corey's. Assessment data revealed that all 19 of these students were consistently using part-part and part-whole thinking by the end of the instructional program. In addition, all the students except Deidra, who will be discussed below, used the "out of" notation, albeit to varying degrees. Target Student 4. Deidra was in the delayed-instruction group and was one of two students who consistently used fractions. Immediately prior to the interven- tion, at the midassessment point, her probabilistic thinking was at Level 1 on sample-space tasks, at Level 3 on probability-of-an-event tasks, and at Level 2 on probability-comparisons and conditional-probability tasks (see Figure 4). Deidra's Level 1 thinking for sample space at the midassessment point was puzzling because she had exhibited Level 2 thinking for sample space at the first assessment point. She suddenly reverted to subjective judgments in the one-stage sample-space</page><page sequence="26">512 Students' Probabilistic Thinking tasks even though subjectivity was not characteristic of her thinking for the other three constructs. By the final assessment Deidra exhibited a stronger and more consistent profile of probabilistic thinking-Level 4 for sample space and at least Level 3 for each of the three probability constructs. We trace Deidra's develop- ment during the instructional intervention and interpret some of the changes in her thinking. Deidra's Level 1 thinking on sample space prior to instruction seemed to be a temporary lapse because she had no further difficulty in listing the outcomes of a one-stage experiment, even in the early instructional sessions. Her mentor reported, "Deidra had no trouble listing the two outcomes in the game with blue and red squares (Session 1), the two outcomes in the red and white spinner (Session 2), and the several outcomes in the Animal Snap Game (Session 3)." Moreover, there was no evidence that subjectivity was induced by either the discrete or continuous probability generators. Our field notes also indicated that by Session 11 she had become more systematic in listing the outcomes of two- stage experiments, an observation that is supported by her thinking in sample-space tasks at the final assessment. Even though Deidra used fractions in a meaningful way within the context of probability, her flexibility in using part-part and part-whole relationships and her fluency in using conventional or invented language to reason about probabilities were more remarkable. This flexibility and fluency were evident in her responses prior to instruction, and this reasoning grew even stronger during instruction. In our researcher summary for Session 4, we stated, "Deidra noted that the target event in a four-section spinner represented two out of four equal parts, and she actually wrote the probability using the fractional notation 2/4." Although she did not always use fractional notation, preferring at times the invented form "2 out of 4," her use of fractions to describe probabilities did distinguish her thinking from Corey's. Her integration of part-whole relationships and numerical symbolization was even more evident in probability-of-an-event and probability-comparisons tasks in Sessions 6, 9, and 11 when she used invented language and fractions inter- changeably to represent probabilities she determined by using part-whole reasoning. For example, in Session 11 after listing the six outcomes for a pack of candy in which two red and two white candies are randomly mixed, Deidra reasoned, "The chance of getting two reds at the start of the pack is one out of six or one sixth because there is only one out of six that starts with RR [she points to the outcome RRWW]." In Session 6, she used a percentage to represent a "50% chance" for a fair spinner with two outcomes. Not surprisingly, Deidra's level of thinking on the final assessment for probability of an event and probability comparisons was Level 3 or above and was indicative of her growing tendency to connect proba- bility relationships with the ways she represented them. Deidra's overall growth in probabilistic reasoning was further exemplified in her thinking on conditional probability. Her use of part-part relationships to represent probabilities in the Animal Snap Game of Session 3 was the forerunner of her use of part-whole reasoning and corresponding numerical representations in later</page><page sequence="27">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 513 sessions. For example, in Session 3, when asked about the chance of getting a match given that she had drawn a koala, she stated, "There's only two [wild cards] that will match and there's nine that won't." Later, in Session 11, in the "without- replacement" candy problem, Deidra recognized that the colors left were depen- dent on the colors already drawn: "If you get a red first [two red and two white candies in the pack], then you only have a one out of three chance of getting red again." In the postintervention assessment, Deidra was the only student in the study who exhibited conditional thinking at Level 3. She alone recognized that all the probabilities changed in a without-replacement task (Figure 3, CP4). For example, even though red bears were drawn on the first two trials, she realized that the prob- ability of all colors had changed and, in the case of yellow, stated, "The chance of yellow starts at two ninths, .. . it's two sevenths at the end because there's still two and there's only seven altogether." Interpretive analysis ofDeidra's thinking. In contrast to the deep-seated miscon- ceptions Jana exhibited in sample-space tasks, Deidra's preinstructional Level 1 thinking for sample space seemed to be an aberration that was rapidly overcome during instruction. Notwithstanding this apparent aberration, Deidra's reversion to subjectivity in sample space illustrated the powerful and continuing influence subjectivity can have on students' probabilistic thinking. As such, this scenario appears to be a further exemplar of the conflict that students have when they are trying to reconcile ikonic intuitions and concrete-symbolic reasoning in probability contexts (Watson et al., 1997). The key features that reflected both Corey's and Deidra's probabilistic thinking were their abilities to use part-whole thinking and to describe their part-whole thinking with appropriate language or symbolic representations. Although there was little difference in the thinking of the two students, Deidra's reasoning seemed more refined and more adaptive, enabling her to integrate several relational ideas. In the sense of Collis and Biggs (1991), Deidra's probabilistic thinking seemed to be more reflective of the relational level of the concrete-symbolic mode in that she had "inte- grated what is known into a coherent system" (p. 196) so that when she tackled a probability problem, she was able to identify the sample-space outcomes, relate each of these outcomes to the whole, and then use invented language or fractions to record her thinking about the probability of events. This ability to integrate, record, and compare relations was especially helpful in probability-comparisons and conditional-probability tasks in which she had to compare the probabilities of a target event with respect to two different sample spaces. In the case of probability comparisons both sample spaces were available, whereas in the case of conditional probability a "new" sample space had to be compared with an "old" sample space. It is this latter type of thinking that sets Deidra apart from other students in this study. Although 19 students including Corey and Deidra exhibited modal thinking levels of 3 after instruction (see Table 3), only Deidra demonstrated Level 3 thinking in conditional-probability situations.</page><page sequence="28">514 Students' Probabilistic Thinking The Effect of the Intervention Program: Analysis of the Two Instructional Groups The students' probability performances on the interview assessment items were analyzed for each of the three assessment points: the beginning (September), middle (December), and end (April) of the school year. The relevant means and standard deviations for both the early-instruction group and the delayed-instruc- tion group are presented in Table 4. Table 4 Mean Scores and Standard Deviations for First, Middle, and Final Assessments of Early- and Delayed-Instruction Groups Group n First Middle Final Early instruction 18 M 12.44 15.39 15.00 SD 2.56 2.70 2.47 Delayed instruction 19 M 13.11 13.95 16.63 SD 2.77 2.32 1.54 Note. The highest possible score for each assessment was 20. A repeated measures analysis of variance revealed significant differences for the three assessment points (F(2, 70) = 12.88, p &lt; .001) and a significant groups by assessment points interaction (F(2, 70) = 6.38, p &lt;.01). Further analysis using the Tukey-HSD test showed that the interaction was disordinal, being produced by significant (in each case p &lt; .05) but reversed differences in the means of the two instructional groups at the middle and final assessment points (see Figure 5). 20 19 - S18- o 17 - C 16 - , E14- o 13- _(D 12 - C 11 - ) 10Early Instruction Group 10-------Delayed Instruction Group 2 111 0I iI 0 First Middle Final Assessment Points Figure 5. Early- and delayed-instruction groups' performance at first, middle, and final assessments.</page><page sequence="29">G. A. Jones, C. W. Langrall, C. A. Thornton, and A. T. Mogill 515 DISCUSSION Although there has been a call for the development and evaluation of instruc- tion that is informed by research-based knowledge of students' thinking, virtually all the researchers responding to this call have focused on whole number opera- tions and fractions (Carpenter et al., 1989; Mack, 1995). Significantly, in this study we investigated the effect of instruction that was informed by a framework describing students' thinking about probability, an emerging content area for the elementary school. The instructional program was also based on a socioconstruc- tivist orientation to learning (Cobb et al., 1993). Notwithstanding this carefully developed instructional design, the focus of the evaluation was on student learning rather than on instructor actions. Analysis of the target students' learning during the instructional program revealed a number of patterns that appear to have critical ramifications for children's under- standing of probability. These patterns are related to children's conceptions of sample space, their use of part-part and part-whole relationships in comparing and representing probabilities, and their use of invented or conventional language to describe their probability thinking. For 5 (14%) of the 37 students in this study, the concept of sample space in its most basic one-dimensional form was problematic, and even after the intervention their thinking remained at Level 1 according to the framework. Exemplified by Jana, these students did not recognize the possibility that all outcomes could occur; their impo- sition of a degree of certainty on random situations we have characterized as "the sample-space misconception." In accord with the developmental model of Biggs and Collis (1991), we claim that the Level 1 thinking of these students reflects the preptructural level of the concrete-symbolic learning cycle; that is, the learner is engaged in the task but is distracted or misled by an irrelevant aspect. With respect to the sample-space misconception, the irrelevancy is manifest in the form of subjec- tive judgments that are extremely pervasive for these students. In essence, the students are functioning within the ikonic mode rather than the concrete-symbolic mode, and they use intuitions that to an adult seem almost mythical (Watson et al., 1997). In spite of the severity of this misconception, 10 of the 15 students who held it prior to instruction revealed higher level sample-space thinking following instruc- tion. That is, ongoing experiences with experimental activities with continuous and discrete probability generators seemed to be successful in enabling the majority of such students to recognize that no one outcome was certain in probability situations. Although Jana and two others of the remaining 5 students eventually overcame the misconception after instruction, there remain concerns about any probability program that does not enable children to overcome a misconception as fundamental as this. As Collis and Biggs (1991) stated in relation to moving students' thinking from the prestructural to the unistructural level, "The [goal] is to get the students to 'join the game' with its new rules and its different way of conceptualizing reality" (p. 193). In that sense our instructional program was found wanting. Whether instruction spread over a longer period of time would produce better results than the intensive 8-week</page><page sequence="30">516 Students' Probabilistic Thinking program used in this study is a question that needs to be addressed by researchers who might also seek to identify tasks that challenge the sample-space misconcep- tion in a more potent way than the tasks used in this study. A further conclusion of this study is that the use of part-part reasoning provides a threshold level for dealing with probability situations that incorporate some need for quantitative reasoning. In addition to those students who exhibited the sample- space misconception, three other students failed to reach this threshold after the inter- vention. We had anticipated from previous research (Jones et al., 1997) that students who reached Level 2 in sample-space thinking, that is, could list the outcomes of a one-stage situation, would be able to quantify probabilities in a minimal way. However, three students, or 8% of those in this study, who exhibited at least Level 2 in sample-space thinking did not quantify probabilities in a valid way even after instruction. Kerry exemplified these students in that she recognized the events (parts) in a probability situation but then failed to quantify them or quantified them as if they were equally likely whether that was the case or not. The failure to discriminate between parts is in accord with Vygotsky's (1934/1986) claim that when students are confronted with a new situation, they often use low-level generaliza- tions that are characterized by vague discrimination between mathematically rele- vant and irrelevant features. Kerry's thinking may also be another instance of her functioning in the ikonic mode on one task and in the concrete-symbolic mode on another (Watson et al., 1997). In fact, such dual use of modes is consistent with the findings of Watson et al. in that they identified students who could recognize uncer- tainty in probability situations but were unable to quantify the situation even in a minimal way. Watson et al. hypothesized that the reasoning of these students was based on concrete experiences with probability generators instead of solely on subjective feelings linked to the ikonic mode. In essence, Watson et al. seemed to be saying that experiences with probability generators develop intuitive notions of uncertainty and the possibility of multiple outcomes; however, these intuitive notions are only weakly linked to the concrete-symbolic mode and do not incorpo- rate the use of quantification in responding to probability situations. The fact that 51% of the students began instruction below modal Level 3 (Table 3) and reached modal Level 3 after instruction is an important finding in this study. Even more consequential is the evolution of these students' thinking, which is exem- plified by Corey and Deidra. Consistent with students in previous studies (e.g., Singer &amp; Resnick, 1992), Corey and Deidra began the instructional program using only part-part reasoning, and we maintain that they were operating at the unistruc- tural level within the concrete-symbolic mode (Biggs &amp; Collis, 1991). We claim that by the end of instruction their part-part and part-whole schemas had been inte- grated and that this integration resulted in their operating at the multistructural level or even the relational level (Biggs &amp; Collis, 1991). For both Corey and Deidra, the critical moment in this change came when they began to use part-whole relation- ships as well as part-part relationships to represent probabilities. This increased usage of part-whole relationships was generally accompanied and supported by symbolic representations or invented language like "one out of three." Because</page><page sequence="31">G. A. Jones, C W. Langrall, C. A. Thornton, and A. T. Mogill 517 Deidra was one of only two students who used fractions, we believe that the use of a part-whole schema instead of the use of fractions is the critical element in driving valid quantitative probabilistic thinking. The use of fractions may have helped Deidra in some conditional-probability tasks, but even in these cases the fractions may have been merely a vehicle to convey her part-whole thinking. A repeated measures analysis of variance was used to evaluate the overall effect of the instructional program on student learning. This analysis demonstrated that both the early- and delayed-instruction groups showed significant growth in perfor- mance following instruction. Moreover, because the delayed-instruction group essentially acted as a control group between the first and middle assessment points, the significant difference in favor of the early-instruction group at the midassess- ment supports evidence from case-study analysis that learning was not due solely to maturation. There is also evidence that although the early-instruction sequence produced significant initial growth in performance, it was not as effective by the final assessment point as the delayed-instruction sequence (Figure 5). This differ- ence may be because the delayed-instruction group had a greater readiness for learning when they began their instructional program (see Table 3), or it may be the result of a short-term versus long-term instructional effect. Because it was not possible to assess the delayed-instruction group 4 months after they had completed their instructional program, the short- versus long-term issue could not be addressed. Consistent with the direction advocated by Fennema et al. (1993), the results of this study show that the probabilistic-thinking framework can be used to develop an effective instructional program in probability. Although it was not our intent in this study to make claims about specific aspects of the instructional program, the use of the framework, or the role of the mentors, the results provide preliminary evidence that the framework can be used by novice teachers in a way that enhances students' probabilistic thinking. Notwithstanding this claim, we acknowledge that students in this study benefited from working in pairs with an adult mentor. In essence, they received almost individualized instruction of the kind that is not gener- ally possible in a classroom. Accordingly, further research is needed to evaluate the viability of using the frame- work for informing probability instruction in regular classroom situations, that is, to assess the ease with which classroom teachers are able to use the probabilistic- thinking framework to enhance student learning. Such research would also provide opportunities for fine-tuning the framework and making it more effective for gener- ating instructional programs that build on students' prior knowledge, foster their thinking through problem-focused experiences, and monitor their understanding. REFERENCES Acredolo, C., O'Connor, J., Banks, L., &amp; Horobin, K. (1989). Children's ability to make probability estimates: Skills revealed through application of Anderson's functional measurement methodology. Child Development, 60, 933-945. Biggs, J. B., &amp; Collis, K. F. (1991). Multimodal learning and the quality of intelligent behavior. In H. A. H. Rowe (Ed.), Intelligence: Reconceptualization and measurement (pp. 57-76). Hillsdale, NJ: Erlbaum.</page><page sequence="32">518 Students' Probabilistic Thinking Borovcnik, M. G., &amp; Bentz, H. J. (1991). Empirical research in understanding probability. In R. Kapadia &amp; M. Borovcnik (Eds.), Chance encounters: Probability in education (pp. 73-105). Dordrecht, The Netherlands: Kluwer. Carpenter, T. P., Fennema, E., Peterson, P. L., Chiang, C. -P., &amp; Loef, M. (1989). Using knowledge of children's mathematics thinking in classroom teaching: An experimental study. American Educational Research Journal, 26, 499-531. Cobb, P., Wood, T., Yackel, E., Nicholls, J., Wheatley, G., Trigatti, B., &amp; Perlwitz, M. (1991). Assessment of a problem-centered second-grade mathematics project. Journal for Research in Mathematics Education, 22, 3-29. Cobb, P., Yackel, E., &amp; Wood, T. (1993). Theoretical orientation. In T. Wood, P. Cobb, E. Yackel, &amp; D. Dillon (Eds.), Rethinking elementary school mathematics: Insights and issues. Journal for Research in Mathematics Education Monograph Series, Number 6 (pp. 21-32). Reston, VA: National Council of Teachers of Mathematics. Collis, K. F., &amp; Biggs, J. B. (1991). Developmental determinants of qualitative aspects of school learning. In G. Evans (Ed.), Learning and teaching cognitive skills (pp. 185-207). Melbourne: Australian Council for Educational Research. English, L. D. (1993). Children's strategies for solving two- and three-dimensional combinatorial prob- lems. Journal for Research in Mathematics Education, 24, 255-273. Falk, R. (1987). Conditional probabilities: Insights and difficulties. In R. Davidson &amp; J. Swift (Eds.), Proceedings: The Second International Conference on Teaching Statistics (pp. 195-221). Victoria, Canada: University of Victoria. Fennema, E., Carpenter, T. P., Franke, M. L., Levi, L., Jacobs, V. R., &amp; Empson, S. B. (1996). A longi- tudinal study of learning to use children's thinking in mathematics instruction. Journal for Research in Mathematics Education, 27, 403-434. Fennema, E., Franke, M. L., Carpenter, T. P., &amp; Carey, D. A. (1993). Using children's mathematical knowledge in instruction. American Educational Research Journal, 30, 555-583. Fischbein, E., Nello, M. S., &amp; Marino, M. S. (1991). Factors affecting probabilistic judgements in chil- dren and adolescents. Educational Studies in Mathematics, 22, 523-549. Fischbein, E., &amp; Schnarch, D. (1997). The evolution with age of probabilistic, intuitively based miscon- ceptions. Journal for Research in Mathematics Education, 28, 96-105. Fuys, D., Geddes, D., &amp; Tischler, R. (1988). The van Hiele model of thinking in geometry among adoles- cents. Journal for Research in Mathematics Education Monograph Series, Number 3. Reston, VA: National Council of Teachers of Mathematics. Hogg, R. V., &amp; Tanis, E. A. (1997). Probability and statistical inference. Upper Saddle River, NJ: Prentice Hall. Jones, G. A., Langrall, C. W., Thornton, C. A., &amp; Mogill, A. T. (1997). A framework for assessing and nurturing young children's thinking in probability. Educational Studies in Mathematics, 32, 101-125. Jones, G. A., &amp; Thornton, C. A. (1992). Data, chance &amp; probability: Grades 1-3. Lincolnshire, IL: Learning Resources. Lamon, S. J. (1993). Ratio and proportion: Connecting content and children's thinking. Journal for Research in Mathematics Education, 24, 41-61. Mack, N. K. (1995). Confounding whole-number and fraction concepts when building on informal knowledge. Journal for Research in Mathematics Education, 26, 422-441. Miles, M. B., &amp; Huberman, A. M. (1994). Qualitative data analysis: An expanded sourcebook (2nd ed.). London: Sage. National Council of Teachers of Mathematics. (1989). Curriculum and evaluation standards for school mathematics. Reston, VA: Author. Piaget, J. (1970). Structuralism (C. Maschler, Trans.). New York: Basic Books. (Original work published 1968) Piaget, J., &amp; Inhelder, B. (1975). The origin of the idea of chance in children (L. Leake, Jr., P. Burrell, &amp; H. D. Fischbein, Trans.). New York: W. W. Norton. (Original work published 1951)</page><page sequence="33">G. A. Jones, C. W. Langrall, C A. Thornton, and A. T. Mogill 519 Shaughnessy, J. M. (1992). Research in probability and statistics: Reflections and directions. In D. A. Grouws (Ed.), Handbook of research on mathematics teaching and learning (pp. 465-494). New York: Macmillan. Singer, J. A., &amp; Resnick, L. B. (1992). Representations of proportional relationships: Are children part- part or part-whole reasoners? Educational Studies in Mathematics, 23, 231-246. Vygotsky, L. S. (1986). Thought and language (E. Hanfmann &amp; G. Vakar, Eds. and Trans.). Cambridge, MA: MIT Press. (Original work published 1934) Watson, J. M., Collis, K. F., &amp; Moritz, J. B. (1997). The development of chance measurement. Mathematics Education Research Journal, 9, 60-82. Authors Graham A. Jones, Professor, Illinois State University Mathematics Department, Campus Box 4520, Normal, IL 61790-4520; jones@ilstu.edu Cynthia W. Langrall, Associate Professor, Illinois State University Mathematics Department, Campus Box 4520, Normal, IL 61790-4520 Carol A. Thornton, Distinguished Professor, Illinois State University Mathematics Department, Campus Box 4520, Normal, IL 61790-4520 A. Timothy Mogill, Doctoral Student, Illinois State University Mathematics Department, Campus Box 4520, Normal, IL 61790-4520</page></plain_text>
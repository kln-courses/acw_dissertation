<plain_text><page sequence="1">Causation Upside Down? GENNARO AULETTA* Resumo Este artigo centra-se na relevância metodológica da causalidade de tipo top-down. É fornecida uma análise do alcance e dos limites da metodologia reducionista tradicional. São distinguidos cinco tipos de concepções reducionistas: um requisito metodológico geral, o conselho pragmático de se seguir metodologias bem estabelecidas, um reducionismo inter-teórico, uma forma intra-teórica e, finalmente, um reducionismo ontológico. Subsequentemente, salienta-se a existência de domínios (nomeadamente a biologia e as neurociências) onde uma abordagem diferente, mas complementar, centrada em explicações etiológicas de tipo top-down, pode ser útil para melhorar o nosso conhecimento dos organismos. Também é evidenciado que a causalidade de tipo top-down não pode ser separada de mecanismos de controle exibindo, numa estrutura biológica, a capacidade básica da homeostase. Palavras-chave : causalidade de tipo top-down, controlo de informação, explicação etiológica, explicação genética, reducionismo Abstract This paper focuses on the methodological relevance of top-down causation. An analysis of the scope and limits of the traditional reductionist methodology is provided. Five kinds of reductionist conceptions are distinguished: a general methodological requirement, the pragmatic advice to follow well-established methodologies, an inter-theoretic reductionism, an intra-theoretic form and finally an ontological reductionism. Thereafter, it is pointed out that there are domains (namely biology and neuroscience) where a different but complementary approach centred on top-down etiological explanations could be helpful for improving our knowledge of organisms. It is also shown that top-down causation cannot be separated from control-mechanisms displaying, in a biological framework, the basic ability to keep homeostasis. Keywords : etiological explanation, genetical explanation, information control, reductionism, top-down causation 1. Introduction A recent top-down agreement issue (or about of downward) Interface the relevance Focus causation (# of 2.1, this shows February concept how 2012) far in the we devoted are scientific from to top-down (or downward) causation shows how far we are from agreement about the relevance of this concept in the scientific (and philosophical) community. On the one hand, we have those who tenaciously hold reductionism as the only admissible methodology in * Pontificia Università Gregoriana, auletta@unigre.it Vol. 68 I Fase 1-2 Q RPF 2012 ļ &lt;^32</page><page sequence="2">1° I Gennaro Auletta science, on the other we have those who believe that top-down causation is already a well established methodology and even assume that it is a general methodology of universal applicability. It is likely that the truth is somehow in between and a certain caution is demanded. Nevertheless, such a cautious behaviour should not be detrimental to the necessity of exploring new ways to deal with scientific problems that are not easily manageable with received methodologies. This is a fundamental tenet of scientific research itself. It is not by chance, al least so seems to me, that scientists show in general a more open attitude than philosophers towards new possible developments. Therefore, I would also suggest to shift the question from "believing or not believing in irreducibility" (i.e. the problem of how far are we authorized to support the point of view of top-down causation given the current state of our knowledge), as cast by Butterfield,1 to the following issue: is this proposed methodology of explanation helpful to the further progress of science (and philosophy)? Indeed, scientific knowledge has to do with problems and the possible solutions to those problems and not with beliefs, at least at a primary level. It is at a higher, philosophical level of inquiry that we may rise the fundamental issue of the rational justification of certain beliefs, but this cannot be done if not starting from the primary need for giving a scientific answer to empirical questions, otherwise we would completely turn upside down the basic requirement to begin our enquiry always from what is best known to us. This is even more important when we have to decide whether a new methodology of investigation is worth introducing or not. 2. The issue of reductionism The very appreciable paper of J. Butterfield2 points out several potential problems and open questions with the concept of top-down causation to be taken seriously into account in order to make some progress in the concerned topics. His starting point is the defence of the reductionist methodology. There is no doubt that science could not exist at all without such a methodology. However, I remark a basic ambiguity in the concept of reductionism. In a first approximation, it can mean - Either the requirement to isolate the minimal factors that are necessary to the development of a certain inquiry by excluding all 1. Butterfield, Jeremy - "Laws, Causation and Dynamics at Different Levels". Interface Focus 2(2012): 101-114. 2. Ibid. Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="3">Causation Upside Down? ļļ other elements that for different reasons do not contribute to our model; - Or the necessity to consider any kind of explanation as not sufficiently scientific if not ultimately led back to the minimal, basic and certainly well grounded explanations of physics. Surely, the first meaning represents a fundamental requirement of any scientific (and even philosophical) inquiry. It is indeed impossible to proceed in any investigation without introducing simplified models and therefore excluding what, for a certain goal, in the framework of a certain field and at a certain stage of the development of our knowledge, is taken to be irrelevant or inessential. However, this methodological requirement gives a priori no particular criteria for judging what is irrelevant or not. Moreover, taking into account the high-specialized character of science in general (but especially today), it even suggests that different fields or kinds of investigation may consider irrelevant (or relevant) very different aspects, problems, or questions. For instance, we are certainly not interested in the macroscopic properties of water when studying the details of the specific quantum-chemical molecular bonds, but certainly we are if our problems is situated in the field of fluid dynamics. To take another example, when studying the polarization currents in single neurons, we certainly avoid any consideration about the architecture of the brain, but when studying the way in which sensory information of the multimodal areas is exchanged with information coming from the motor areas for building visual- motor representations,3 we certainly need to take this architecture into consideration and can even dismiss any minute analysis of single neurons. We think that no scientist or philosopher could disagree with this. Another kind of problems is raised by the second understanding of the term. Actually, in the history of modern science this has been often mixed with the previous one, for a particular and therefore ultimately historical reason. The first science to be built and certainly the most firmly established was classical mechanics. This was in a sense necessary, since science needs to start with the easiest problems and models, and nothing is easier than classical-mechanical systems. Since this represented a very successful instance of reductionism in the first sense, then, it was also quite obvious that most scientists tried to apply to other fields of 3. Jeannerod, Marc - Motor Cognition: What Actions Tell the Self. Oxford: Oxford University Press, 2006; Auletta, Gennaro - Cognitive Biology: Dealing with Information from Bacteria to Minds. Oxford: Oxford University Press, 201 1: Chaps. 4-5, 13-14 and 18. Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="4">12 Gennaro Auletta investigation the same rigorous methodological requirements already employed by classical mechanics. The easiest and most assured way to do this was simply to lead any problem back to classical-mechanical terms. It is undeniable that science has progressed a lot in its different kinds of inquiry thanks to such a methodological approach. We may recall here the advancements in chemistry until its actual form as quantum chemistry (where again the source is a physical discipline: quantum instead of classical mechanics), and even in molecular biology, which relies both on physics and chemistry. The successful application of classical-mechanical methods to several kinds of problem shows how precious may be the pragmatic/heuristic rule to follow a reductionist approach in science whenever possible. It is indeed mandatory to apply a successful method as long as it produces interesting or important results. With Einsteins words: "the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience".4 Nevertheless, this broad pragmatic/heuristic rule does not indicate which is the one and only admissible specific method of inquiry, nor it implies that any question is to be considered as non-scientific if not put in basic physical terms. The latter claim has to do with the second meaning of reductionism stated above, and let me point out that it may, in turn, take at least two different forms. The first one is to suppose that any scientific question needs to be expressed in physical- chemical terms, which is a form of the so-called inter-theoretic reduction,5 aiming at reducing postulated entities of a secondary theory to collections of entities of a primary theory (and so to eliminate some concepts of the former). The second one is to suppose that any physical problem needs to be expressed in terms of what we assume to be the basic physical theory (a kind of intra-theoretic but also weaker reduction that does not necessarily implies the accomplishment of the previous step). Now, I think that no scientist or philosopher could elevate this particular (either inter- theoretic or intra-theoretic) understanding of reductionism to a dogma. We would be justified in doing this only if we were to basically maintain a kind of ontological (and no longer methodological) reductionism, that is, the belief that nature is in fact built out of elementary bricks that sum or aggregate in pure linear ways, so that any complex system can 4. Einstein, Albert - "On the Method of Theoretical Physics". Philosophy of Science 1 (1934): 163-169. 5. Friedman, Kenneth - "Is Intertheoretic Reduction Feasible?". British Journal for Philosophy of Science 33 (1982): 17-40. Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="5">Causation Upside Down? 13 be in principle reduced to its components without any appreciable loss in our knowledge. Unfortunately, this ontological reductionism is today fully unwarranted and even obsolete, and this can be shown by starting, I would say, from both the bottom and the top: from the bottom, since quantum mechanics does not allow such an understanding of nature due to its well known non-local interdependences,6 and from the top, due to the growing body of evidence that linear phenomena are relative rare in nature and that non-linear process and phenomena (which are therefore indecomposable in the previous sense) are, instead, very abundant, even in physics.7 Nevertheless, the question remains whether or not, as a matter of fact, a reductionist methodology aiming at reducing a certain discipline to basic physics has really worked well in some domains or fields that raised problems that at a first glance seemed difficult to account for in a traditional classical-mechanical framework. It is almost unavoidable for the scholar who is interested in this kind of problems to discuss the issue of the reduction of thermodynamics to statistical mechanics, a kind of heterogeneous inter-theoretic reduction. Indeed, this is also the preferred example of J. Butterfield,8 who explicitly quotes the success of "statistical mechanics in explaining irreversible macroscopic processes". I would like to point out a general problem with this view and then deal with more specific issues. A complete, non-statistical description of the phenomena that are object of statistical mechanics does not exist-as also remarked by Friedman.9 Now, this description is necessary for a reductionist methodology aiming at providing a true explanation of the problems that are object of the science one wishes to reduce (thermodynamics, in this case). Clearly, it is assumed that this non-statistical description is in principle possible and that the difficulties in calculations are only due to the large number of the involved systems; a problem that further advancements in science and technology should, sooner or later, allow to deal with. However, the point is not trivial. A well-known classical problem is that of three bodies:10 we are not able to provide an analytical deterministic description already of three interacting bodies, so that both in classical physics (like for the description of the orbits in our 6. Auletta, G., Fortunato, M. &amp; Parisi, G. - Quantum Mechanics. Cambridge: Cambridge University Press, 2009. Chap. 16. Auletta, Gennaro - "Correlations and Hyper- Correlations". Journal of Modern Physics 2 (201 1): 958-961. 7. Auletta - Cognitive Biology, 201 1, Chap. 6. 8. Butterfield - "Laws, Causation and Dynamics at Different Levels" (2012). 9. Friedman - "Is Intertheoretic Reduction Feasible?" (1982). 10. Poincaré, Henri -Leçons de mécanique celeste. Paris: Gauthier- Villars, 1905-1909. Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="6">14 Gennaro Auletta planetary system) and in quantum mechanics (like for the descriptions of the hydrogen molecular ion or the helium atom) we are forced to make use of approximation and/or factorization methods.11 Obviously, these kinds of problems are magnified when the number of interacting atoms and molecules is exceedingly large as it happens for current problems of thermodynamics and statistical mechanics. So, the main assumption here remains still unproved. Le us now deal with the specific problems. As is well known, Boltzmann originally introduced the concept of entropy as a consequence of a deterministic equation. In fact, the concept of entropy was initially deduced from the H theorem, which is in turn a consequence of the Boltzmann equation for molecules collisions. If f(x, p, t ) represents now a distribution (whose specific form is here irrelevant) telling us the number of actual particles in various cells of the phase space, then the number N of particles in a 6-dimensional region R is given by N = i /(x,p, t)d3xd?p Jr The Boltzmann collision equation has the general form: % + E (s + F&gt;lļ) = / ' *V / ' (//' - if) &lt;M, where F.=dp./dt represents the j-th component of an external force on the particle, 6sc is the scattering angle, the functions f and f are determined by the scattering in an scattering out processes, where the scattering happens into the solid angle dQsc&gt; and o(v, 6sc) is the differential scattering cross-section of a single scattering centre. Since, as a consequence of the previous equation, it can be shown that the quantity H = j f log fd3xd3p can only decrease, Boltzmann assumed that the entropy is given by: S = -kH. As recalled by both Jaynes and Sklar,12 Zermelo and Loschmidt pointed out that there is no a priori reason why the mechanical and disordered motion of some molecules will not bring them back from an 11. Auletta, G., Fortunato, M. &amp; Parisi, G. - Quantum Mechanics, Chaps. 1 1-12. 12. Jaynes, Edwin T. - "Foundations of Probability Theory and Statistical Mechanics". In: M. Bunge (Ed.) - The Delaware Seminar in the Foundations of Physics. New York: Springer- Verlag, 1967, pp. 77-101; Sklar, Lawrence - "Statistical Explanation and Ergodic Theory". Philosophy of Science 40 (1973): 194-212. Vol. 68 Fase 1-2 Q RPF 2012</page><page sequence="7">Causation Upside Down? 15 equilibrium state to a non-equilibrium one. Moreover, they produced two counterexamples showing that Boltzmanns collision equation could not be an exact description of the dynamical processes involved in collision. Boltzmann stepped back from his initial deterministic formulation and subsequently interpreted the distribution f not as describing the actual number of particles but an average, speaking, as a consequence, only of a major probability of the involved systems to evolve towards states of larger entropy than to states of lower entropy. However, if we interpret the term f as expressing an average, we have on the left side of the Boltzmann equation an average f whilst for the right hand side we would like to have an average of products ff' and not a product of averages. However, these two quantities cannot be the same at least until we have not clarified over which parameter we are doing the average (time, number of particles, . . .). A related problem, always pointed out by Jaynes and Sklar, is the validity of the ergodic theorem, telling that a system starting in any given microstate eventually passes through every other microstate. As is well known, the ergodic theorem was believed by Boltzmann to provide a basic physical explanation for the irreversibility displayed by thermodynamic entropy (namely, a system spends more time in those regions of a certain measure space that have higher entropy). It can be objected that such a theorem is not valid for some sets of Lebesgue measure zero and that it is also necessary to consider measurement intervals of infinite length. Birkhoff reformulated the theorem in new and weaker terms (which are likely to be less interesting for the issue of reductionism) relative to the previous Boltzmanns attempts, by relaying on the so-called Poincarés recurrence theorem and excluding sets of Lebesgue measure zero: in this way, he succeeded in connecting time averages with "space" averages. This solution is not fully satisfactory, because it can be shown that the dismissal of sets of Lebesgue measure zero is based on statistical assumptions that are not fully justified.13 Jaynes 14 also recalled that the true mathematical apparatus of statistical mechanics was built by Gibbs, who, however, fully avoided the concept of ergodicity. Although Gibbs' work on entropy remained unfinished, he was clear about the fact that irreversibility has nothing to do with coarse or fine graining (coarse graining is the traditional method for removing anomalous sets), since, whatever graining we choose, the macroscopic properties remain the same, and they are the only ones to be relevant for 13. Friedman, Kenneth - "A Partial Vindication of Ergodic Theory". Philosophy of Science 43(1976): 151-162. 14. Jaynes - "Foundations of Probability Theory" (1967). Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="8">16 Gennaro Auletta the issue of irreversibility. Friedman15 pointed out that coarse graining can be questioned on the argument relying on the fact that "the summation of probabilities over phase cells will give the same results as the integration of probability densities over phase points only if the probability of each of the phase cells is correctly calculated. Yet there is an assumption made in calculating the probabilities of phase cells - that the probability density within each cell is constant' - which is clearly a statistical assumption. However, saying that a macroscopic observer is forced to assign a uniform (or, at the very least, a uniformly continuous) probability measure over points among which he/she is unable to distinguish, cannot justify such an assumption. Indeed, the purpose of ergodic theory, according again to Friedman,16 is "to predict the actual behaviour of thermodynamic systems, and the systems themselves can 'know' at what precise point of the phase space they are, even if a macroscopic observer cannot. Thus, systems between which a macroscopic observer cannot distinguish at time tļf may behave quite differently from each other at time t2." Actually, the distributions introduced by Gibbs work very well due to factors like the microscopic constitution of a gas and the initial conditions, which are completely independent of the ergodic theorem.17 Moreover, since Gibbs' equations essentially apply to systems in equilibrium, the presumed reduction of thermodynamics to statistical mechanics for systems not in equilibrium is still an open question.18 Furthermore, as pointed out by Friedman,19 a pertinent and interesting consequence of thermodynamics is the law of perfect gases ( PV=NRT ). However, on this subject statistical mechanics has little to say that could really improve our knowledge. Another problem is the following: when a system becomes very big, it can become thermodynamically insensitive to external perturbations by still remaining mechanically sensitive, a consideration that could represent a threat also to Birkhoff s formulation.20 Up to now we have dealt with heterogeneous inter-theoretic reduction. Friedman21 has pointed out that the so-called homogenous reduction 15. Friedman - "A Partial Vindication of Ergodic Theory" (1976). 16. Ibid. 17. Sklar - "Statistical Explanation and Ergodic Theory" (1973). 18. Sklar, Lawrence - "The Reduction (?) of Thermodynamics to Statistical Mechanics". Philosophical Studies 95 (1999): 187-202. 19. Friedman, Kenneth - "Is Intertheoretic Reduction Feasible?" (1982). 20. Friedman, Kenneth - "A Partial Vindication of Ergodic Theory" (1976).. 21. Friedman, Kenneth - "Is Intertheoretic Reduction Feasible?" (1982). Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="9">Causation Upside Down? 17 (the entities of the secondary and primary theory are of the same kind) has been more successful. However, it mostly consists in intra-theoretic attempts, like the famous passage from quantum to classical mechanics due to the relative smallness of the Planck constant.22 Such reductions are frequently based on ad hoc assumptions and have practical but little theoretical value. Summarizing, the reductionist program both in its inter-theoretic and intra-theoretic form has been far less successful than it is customary assumed and to my knowledge there is no single example of a real success of reduction in these two senses that has brought to new results, new understanding or even to more compact theories able to fully replace previous ones. 3. In which sense we can speak of top-down causation? In order to assess this problem, it is first necessary to clarify some possible misunderstandings. The term "top-down" may induce the reader to assume that there is a cause sitting on the top able to have some effect on the bottom level. The terms top and bottom refer here roughly to a hierarchy of levels in which, for instance, the molecular level is lower than the cellular level. Now, this kind of action is certainly impossible. In order to have any dynamical effect on something, it is necessary that the cause is able to exchange dynamical physical magnitudes like momentum and energy with this something. However, in order to do that it is also necessary that the two involved entities are placed somehow at the same level. It is clear that we are able to do experiments on atoms and even smaller particles, which gives us the feeling that we, in our quality of macroscopic experimenters, are dynamically interacting with microscopic entities. However, this can only happen because there is a chain of causes and effects that starts from our interaction with macroscopic devices and goes through several "descending" (intermediate) steps until a direct effect on microscopic entities becomes possible at that level. It is also obvious that when we turn on a laser pump we generate a beam that can be macroscopically visible and nevertheless have microscopic effects. However, this can happen only due to the physical properties of the laser (and of light in general) that is in principle a quantum phenomenon that can also have (in proportion with the number of involved photons) visible 22. Auletta, G., Fortunato, M. &amp; Parisi, G. - Quantum Mechanics, Subsec. 2.2.4. Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="10">18 Gennaro Auletta effects. Even experiments only allow to exert constraining influences on the lower levels (for instance, in selecting the specific experimental contexts in which certain properties or characters are singled out). For this reason, to act on microphenomena without intermediation of physical agents situated at that level would certainly represent a violation of the closure of the physical laws (at least at that level). This is for what the top-down direction is concerned. What happens bottom up? I think that the situation is here fully symmetric. There can be no cause starting from a lower level able to have effects on a higher level without the intervention of casual factors at that level.23 For instance, it is today obvious that quantum factors are very important for chemical process (actually, as mentioned, chemistry is today growingly a quantum chemistry). However, these factors can have an effect simply because there are other factors of pure chemical kind (like the shape of the involved molecules, their configuration or conformation, and so on) that concur to the final effect, and those chemical factors or properties mostly have no quantum-mechanical significance although may have originated from quantum-mechanical relations. For instance, human vision starts with at least a photon detected by the eye s receptors and goes to different neurons though several brain areas.24 I think that one of the myths of reductionism to challenge is precisely the idea that we can have a pure bottom-up causation without the intervention of factors at the higher levels involved, and this belief may be seen as rooting the mentioned ontological reductionism as well as the inter-theoretic (heterogeneous) one. Perhaps I am wrong but would really be happy if somebody could show me a single case in which we have such bottom up causation without the concourse of some factors at the level in which the dynamical process occurs. Having therefore excluded up to contrary evidence both dynamical top-down and dynamical bottom-up causation in the sense explained, it remains to clarify what top-down causation means at all and whether it can be explanatory relevant or not. The only reasonable answer to the first question seems to me to be the following:25 factors at a higher level must be understood in terms of constraints able to canalize dynamical processes at a lower level. Constraints are for instance those imposed by cellular metabolic network on the chemical reactions that are necessary 23. Auletta - Cognitive Biology, Subsec. 6.3.2. 24. Ibid., Chap. 4. 25. Auletta, G., Ellis, G. &amp; Jaeger, L. - "Top-Down Causation by Information Control: From a Philosophical Problem to a Scientific Research Program". Journal of the Royal Society: Interface 5 (2008): 1159-1172. Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="11">Causation Upside Down? 19 for survival:26 it is indeed well known that the chemical reactions occurring in a cell are a tiny fraction of those that could spontaneously happen given the amount of the involved chemical substances; moreover these reactions occur with a very precise timing. It suffices to think about the complex processes of energy storing and using, for instance the many step-wise processes of oxidation. Indeed, the whole cellular machinery can only work thanks to the massive presence of enzymes and network regulations.27 Constraints do not have any dynamical power in themselves. They ultimately consist in some kind of interdependency among certain parts or constituents of a system. Nevertheless, they can be very effective: if certain spontaneous dynamical processes occurring at a lower level activate them, then they can reciprocally contribute to the final result through their confining action. It may be very easy to understand this kind of effect by considering the action of a piston in a motor: the explosion of a fuel (i.e. the rapid motion of the constituent molecules of the gas) inside of a piston is confined by its walls and the action is directed along a certain predetermined direction (that of the movable cover). Without such a confinement a motor could not work at all. And this may also answer in general terms to the second question above concerning the explanatory relevance of top-down causation, as long as higher-level factors are acknowledged to be really capable of making a difference in the effects dynamically produced at the lower level. Having clarified this, let me turn to some conceptual distinctions in order to avoid an unjustified hyper-generalization of top-down explanations that the previous example may ingenerate. We need first to distinguish top-down causation from what can be called spontaneous convergence . Although the latter could be taken per se as a milder or lower form of top-down causation, its ubiquity in nature suggests that any "mixing" between the two concepts may result in strong ambiguities. Let us consider a very basic chemical reaction like that constituting water molecules. If an oxygen atom comes in contact with two hydrogen atoms, it is very likely that the 2 unpaired electrons in the oxygen s 02p orbitais (py and pz ) give rise to chemical bonds with the two electrons of the hydrogen atoms, and since the two orbitais lie at 90° to each other, the two bonds also lie at 90° to each other. The kind of chemical bonding 26. Barabási, A.-L. &amp; Oltvai, Z. N. - "Network Biology: Understanding the Cells Functional Organisation". Nature Reviews: Genetics 5 (2004): 101-114. 27. Alberts, B., Bray, D., Lewis, J., Raff, M., Roberts, K. &amp; Watson, J. D. (2008) - The Molecular Biology of the Cell, New York: Garland P., 1983 (2nd ed. 1989; 3rd ed. 1994; 4th ed. 2002; 5th ed. 2008), Chap. 2. Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="12">20 Gennaro Auletta coming out is also determined by the high electronegativity of oxygen. Here, the resultant water molecule is the effect of a dynamical process in which several factors are combined in such a way that it could be not otherwise (there are not other ways to make water molecules in nature). What does the term not otherwise mean? It does not mean, of course, that there is something in any of the properties or characters of the oxygen and hydrogen atoms that forces them to constitute a water molecule in any circumstance. As a matter of fact, water molecules are constituted e.g. only in certain pressure and temperature conditions. Moreover, also when bonds between oxygen atoms and couples of hydrogen atoms can be established, the resultant can be a gas, a liquid or a solid according again to the environmental conditions. Rather, the significance of those words is that when the initial conditions are created through which the atoms come appropriately close in a certain environment, then the different facts, relations and properties involved here stick together as pieces of a puzzle (which is an effect of physical and chemical constraints), so to determine a result that could not be different. This is what I call convergence, that is, convergence of different factors into a result that is stable (obviously, another sense of the term convergence is when we speak of phylogenetic convergences, an issue that cannot be treated here). However, although there are constraints present here, we have no particular reason to denote this process as being top-down. Actually, it is even difficult here to understand what level should be considered upper or lower. Another concept that should be distinguished from top-down causation is that of canalization. Actually, canalization and convergence could be taken as synonyms. Here, the only reason why I would like to distinguish between them is that canalization seems to evoke a more complex process in which many interdependent factors play a role (and therefore we have also more constraints of very different kind). So, I assume that canalization is involved in all complex process of adaptation, of building environmental niches and even whole ecosystems, in which several biological systems show mutual adaptation (going from the integration of certain environmental factors in developmental processes of certain organisms up to phenomena like symbiosis and mutualism) thanks to complex causal loops, whose nature may be considered as essentially teleonomic.28 In a first and basic meaning, teleonomic causation can be 28. Auletta, Cognitive Biology, Chaps. 8-11; Auletta, Gennaro - "Teleonomy: The Feedback Circuit involving Information and Thermodynamic Processes". Journal of Modern Physics 2.3 (2011): 136-145. Vol. 68 Fase. 1-2 0 RPF 2012</page><page sequence="13">Causation Upside Down? 21 understood as the internal (genetic) program of the organism29 allowing to start a process through which environmental signals are used as cues for giving rise to structures and functions that are adaptive. As mentioned, this is what actually happens in all developmental processes (in which also many epigenetic constraints are at work). As we shall see, the notion of program will also bring us to further investigation. Nevertheless, although representing a complex form of causation in which very different factors are interconnected, we cannot say that teleonomic processes as such (and therefore canalization) are in general top-down process, since the whole teleonomic network is situated at the same complexity level (cells or organisms and environmental factors able to interact with them). Even if there are molecular processes going on that happen on a smaller scale, they mostly do not possess as such significance for the network if not through the organisms and the other macroscopic factors involved in the network itself. Also when higher-level factors are present (as we shall see), they do not work as sort of supervisors of the network.30 1 could say that molecular or higher-level factors have here only local significance and not a global one. Nevertheless, it is also clear that teleonomic networks bring us beyond a pure reductionist approach in the sense clarified above.31 4. Control versus mechanical determinism Then, what is specific to top-down causation? I think that what is really relevant in this concept is the idea of some form of control , intended as the proper instance through which a causal influence can be exerted downwards at all. When looking at the cell, we find a considerable amount of control mechanisms, for instance: the complex processes (and networks) involved in gene expression and repression (through which many other controls are performed in a sort of cascade-like process and with massive feedback loops), the building of proteins and the control of their activity through phosphorylation and dephosphorylation (adding and removing of phosphate groups, respectively), multisite covalent modification or change of their conformation; or, to take other examples, the different check-points during DNA replication and recombination ensuring that DNA damage is repaired before a cell divides, during transcription where checking and 29. Monod, Jacques -Le hasard et la nécessité. Paris: Seuil, 1970, Chaps. 1 and 3. 30. Auletta, G., Colagè, I. &amp; D'Ambrosio, P. - "The Game of Life Implies both Teleonomy and Teleology". In: G. Auletta et al. - Si può parlare di una finalità nell'evoluzione. Roma: G&amp;B Press, 2012. 31. Barabási, Albert-László - "The Network Takeover". Nature Physics 8 (2012): 14-16. Vol. 68 Fase 1-2 (J RPF 2012</page><page sequence="14">22 Gennaro Auletta rechecking of mRNA sequences before the chemical reaction is allowed to proceed ensures the accuracy of splicing followed by a final check called nonsense-mediated decay, during translation where checking of tRNA through EF-Tu (EF1 in eukaryotes) factors increases the accuracy of the operation in several ways, during the cell cycle ensuring the completion of one step before the next step can begin.32 When we speak of control factors or parameters of any kind, we need necessarily to assume that they are independent of current external conditions (or at least independent of the system to be controlled, which however can be taken here in all its generality to be either the external or the internal environment33). The crucial point is that this is strictly impossible through ordinary mechanical causation, as far as any mechanical process works only in the single way in which it works (this is the quintessence of mechanical determinism). However, this produces effects and not control, which necessarily demands choice between alternatives, i.e. at least the possibility (after appropriate check) to discard some processes or results because not fitting the functional needs of the system. Obviously, all controls happen through ordinary physical-chemical reactions and processes and are even activated through such reactions and processes, but they are activated as higher-level constraints able in turn to influence the latter. As I have explained, we cannot presume that any higher level is able to bypass lower levels in which dynamical processes happen. As I shall say, we can even assume that the first time (at an evolutionary scale) such controls have arisen, this has happened through a spontaneous activation "from below". Moreover, control demands the capability of employing an alternative pathway when the customary one is blocked or inaccessible. Otherwise no control could be exerted if not occasionally, but this in turn would clash with the very notion of control, because it would make the control system immediately dependent on the external and necessarily contingent circumstances, i.e. on the system to be controlled. Then, in order to have an actually operating control we necessarily need an array of possible instantiations of it, meaning precisely that control cannot be exerted in a single way. Now, one of the main confusions when speaking of top-down causation is that between - Multiple realizability (as it is believed to exist when a single thermodynamic macrostate can be realized in many different 32. Alberts, B., Bray, D., Lewis, J., Raff, M., Roberts, K. &amp; Watson, J. D. (2008) - The Molecular Biology of the Cell, Chaps. 3-8, 17. Auletta - Cognitive Biology, Chap. 7. 33. Auletta - Cognitive Biology, Subsec. 5.3.3. Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="15">Causation Upside Down? 23 microstates), which in itself does not require top-down processes and could be considered as ultimately depending on the choice of the observer to single out a certain pattern or regularity;34 and - Functional equivalence classes, which are typical of organisms and depend on the actions and processes of the organisms themselves and not on our choices: such classes respond indeed to vital (functional) needs. For instance, glucose and lactose can to a certain extent be taken as equivalent for the sake of the Escherichia colis survival. In other words, they are both functional to the metabolic processes that keep the internal order of the organism. It is true that E . coli shows a preference for glucose over lactose (and indeed it first consumes the former and subsequently the latter35). However, when there is only lactose available, E. coli feeds lactose and this works quite well for its needs. Therefore, we speak of control when an organism is able to treat several environmental factors as functionally equivalent, that is, satisfying some functional need plus or minus in the same way. This is necessary, since those classes represent the grid that the organism "imposes" on the world in order to be able to exert control at all. We have many further examples of this. When we look at the whole process that brings the E. coli from a certain environment with low concentration of sugars to an environment with very high concentration,36 we may see that it also treats environmental signals in terms of equivalence classes. Indeed, several environments with different concentrations of attractants and repellents induce the same reaction (for instance, tumbling), showing that within a certain window they are treated as equivalent. So, if£. coli exerts in this way a certain control on the whole considered process, one may ask about the biological reasons of such a behaviour. I already gave an answer: it is for the sake of its self-maintenance. This is a vital or functional goal?1 1 am perfectly aware that the term "goal" evokes all 34. As remarked in Butterfield, Laws - "Causation and Dynamics at Different Levels" (2012). 35. Jacob, F. &amp; Monod, J. - "Genetic Regulatory Mechanisms in the Synthesis of Proteins Journal of Molecular Biology 3 (1961): 318-356. 36. Auletta, Gennaro - "Teleonomy: The Feedback Circuit involving Information and Thermodynamic Processes" (2011). Auletta, Gennaro - "A Mathematical Model of Complexity and Its Application to Chemotaxis". British Journal of Mathematics and Computer Science 1 (2011): 204-227. 37. Auletta - Cognitive Biology, Chap. 8; Auletta, G., Colagè, I. &amp; D Ambrosio, P. - The Game of Life Implies both Teleonomy and Teleology" (2012). Vol. 68 -Jjy Fase. 1-2 Q RPF 2012</page><page sequence="16">24 Gennaro Auletta possible spectra of vitalism and anthropomorphism. I am also fully aware that there is no place for this concept in current physics and chemistry. I would add that this is understandable since in physics and chemistry the concept of function makes no sense. On the contrary, biology could barely exist as a science without such a concept: it suffices to think about the different and very specialized or even fine-tuned functions performed by proteins,38 but this can be said virtually of any component or aspect involved in organisms. Perhaps, we can say with Pattee39 that controls are local and conditional whilst physical and chemical laws are global and inexorable (even quantum-mechanical laws are deterministic although ruling probabilities). I do not wish to deal with the issue of how goals (and thereby how living organisms pursuing them) have arisen at all. A very difficult problem, indeed! Below I shall briefly comment on this. By now, recalling Einsteins lesson, I take the existence of goals in the organisms as a fact until somebody is able to show how we can reduce it to some more elementary and well-known mechanism without impairing our ability to understand the processes actually at play. As a matter of fact, a careful analysis of the bacterial Chemotaxis shows that there are two different inputs determining the "choices" of the E. coli : one coming from the exterior through the membrane receptors along a pure feed-forward path and another ultimately depending on the genetic programming and going through a feedback circuit whose effect is to restore the pre-programmed default state independently of what the environmental inputs can be: namely, swimming straight on.40 Therefore, an explanation that would reduce the bacterium to a kind of machine sensitive to environmental inputs only were a simplification unable to account for the real situation. Somebody could point out that also devices like computers or robots are able to exert a kind of control and therefore it is not necessary the sophistication of biological systems and their goals for doing that. Perhaps, mechanical causation can fully account for control. However, strictly speaking a robot or a computer controls nothing. It is only programmed by humans to perform certain operations so that, when inserted in a 38. Alberts, B., Bray, D., Lewis, J., Raff, M., Roberts, K. &amp; Watson, J. D. (2008) - The Molecular Biology of the Cell, Chap. 3. 39. Pattee, Howard H. - "Simulations, Realizations, and Theories of Life". In: C. E. Langton (Ed.) - Artificial Life : Proceedings of an Interdisciplinary Workshop on the Synthesis and Simulation of Living Systems. Redwood City: Addison- Wesley, 1995, pp. 63-78; Pattee, Howard H. - "Evolving Self-reference: Matter, Symbols, and Semantic Closure". Communication and Cognition - Artificial Intelligence 12 (1997): 9-28. 40. Auletta, Teleonomy: "The Feedback Circuit involving Information and Thermo- dynamic Processes" (201 1). Vol. 68 Fase 1-2 Q RPF 2012</page><page sequence="17">Causation Upside Down? 25 certain framework, it results controlled by the human users. Obviously, I cannot foresee the progresses of technology and it is possible that in a certain future autonomous robots able to exert control could be built (whether silicon instead of carbon can provide for the minimal plasticity and complexity required here is still an open question). However, robots or computers of this kind would be kinds of organisms. The consequence would be quite clear: a robot or a computer would become a totally unhelpful (or even dangerous) device, since it would not execute the operations for which it was programmed. So to speak, it would have its own agenda, like a bacterium has. Therefore, I consider control as typical of biological systems and only of them. Now, if controls are local and conditional, which kind of parameters or quantities do they involve? Certainly not quantities like energy, mass, reaction rate, which are typical of physics and chemistry and, although being present in processes on which a control is exerted, are not able per se to explain what control is. When we speak of vital goals, following Monods lesson, we are referring mainly to genetically (or also epigenetically) programmed goals, that is, goals that depend on the information codified in the organism and in the networks it gives rise to. On the other hand, when we speak of the capability of the organism to treat different environmental signals as equivalent, we are referring to the way in which these signals are codified by the sensory receptors. Therefore, in both cases (when something is acquired from the exterior into the interior as well as when an action starts from internal codification towards the exterior), we deal with information. Indeed, information can be very well associated with higher-level constraints since it can be defined in all its generality as correlation (whether classical or quantum-mechanical) among possible events or "choices" and therefore it also implies a reduction (selection) of the space of all possible events in the same way as constraints do.41 Then, since the kind of control that I am considering concern both aspects, let me say in short that any control of this kind is an information control. In other words, what I am saying is that in order that a system be able to exert any kind of control and regulation on another system needs both to have an inbuilt program and a current model of the latter,42 and both elements require information in the way explained. 41. Auletta, Cognitive Biology, Chap. 2; Auletta - "Correlations and Hyper-Correlations" (2011). 42. It is a proved theorem that any regulatory system needs to have a model of the system to be controlled. See Conant, R. C. &amp; Ashby, R. W. - "Every Good Regulator of a System Must be a Model of that System". International Journal of Systems Science Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="18">26 Gennaro Auletta Summarizing, information control may be defined as any procedure through which a system (i) ascertains the functional relevance of a certain signal (where a signal can be understood as any modification of a physical or chemical medium, e.g. the change in concentration of certain chemicals), and (ii) tends to deploy its functions according to its genetic and epigenetic program or also to re-establish a certain steady or default state according to its genetic and epigenetic program (i.e. the programmed homeostasis) whenever certain operations of functional- vital relevance are impaired or perturbed.43 Although the genetic program is the internal source of information control, it is also clear that with the diversification of organisms and especially with the growing relevance of epigenetic processes in higher forms of life, the genome comes itself (in its expression and repression, as mentioned) under the control of more complex circuits.44 It is also clear that information control establishes a new kind of selection, and can even cooperate with, or contribute to the spontaneous work of natural selection, for instance contributing, as a factor among others, to the establishment of teleonomic networks like environmental niches or whole ecosystems.45 An interesting example of information control is the following.46 Organisms need proteins of the family of the selenoproteins. These proteins display a very special feature: the amino acid selenocysteine has 1 (1970): 89-97; Friston, K. J., Thornton, C. &amp; Clark, A. - "Free-Energy Minimization and the Dark-Room Problem". Frontiers in Psychology 3 (2012): 130; doi: 10.3389/fpsyg.2012.00130. 43. For future research paths on the latter issue see Wegscheid, B., Condon, C. &amp; Hartmann, R. - "Type A and B RNase P RNAs are interchangeable in vivo despite substantial biophysical differences". EMBO Reports 1 (2006): 411-417; Auletta, G., Ellis, G. &amp; Jaeger, L. - "Top-Down Causation by Information Control" (2008); Gobert, A., Gutmann, B., Taschner, A., Gössringer, M., Holzmann, J., Hartmann, R. K., Rossmanith, W. &amp; Giegé P. - "A single Arabidopsis organellar protein has RNase P activity". Nature Structural and Molecular Biology 17 (2010): 740-46; Auletta, G., Colagè, I., Cook, G., D'Ambrosio, P., Ramón, M. &amp; Pinsent, A. - "Functional equivalence between plant PRORP1 and bacterial RNase P RNA raises questions on control and recognition mechanisms". Journal of Computational Biology and Bioinformatics Research 3 (2011): 63-64. 44. Alberts, B., Bray, D., Lewis, J., Raff, M., Roberts, K. &amp; Watson, J. D. - The Molecular Biology of the Cell, Chap. 7. Gilbert, Scott F. - Developmental Biology. Sunderland, MA: Sinauer, 2008 (8th ed., 2006); Gilbert, S. F. &amp; Epel, D. - Ecological Developmental Biology: Integrating Epigenetics, Medicine, and Evolution. Sunderland, MA: Sinauer, 2009. See also Auletta - Cognitive Biology, Chap. 1 1 . 45. Auletta, Gennaro - Cognitive Biology, Ch. 10; Auletta, G, Colagè, I. &amp; D'Ambrosio, P. - "The Game of Life Implies both Teleonomy and Teleology" (2012). 46. Ramón-Fuentes, J. Miguel - The Concept of Function in Molecular Biology: A Theoretical Framework and a Case Study, Doctoral Dissertation. Rome: Pontifical Gregorian University, 2012. Vol. 68 -s¡L^ Fase. 1-2 Q RPF 2012</page><page sequence="19">Causation Upside Down? 27 been found in their sequence but this is not among the twenty canonical amino acids of the genetic code. This means that the cell has to somehow bypass the general system of protein synthesis (has to choose an alternative path!) in order to insert selenocysteine in the sequence of selenoproteins. The cell achieves indeed the insertion of selenocysteine through an astonishing and complex control mechanism where many extra partners are involved: secondary structures of RNA and special proteins. Biologists talk about this mechanism as a natural expansion of the genetic code; as if life, after having closed the needed "vocabulary" used by the genetic code, is constrained to insert a new meaning without being allowed to introduce a new "word". The scope of all this machinery is to "recode" the genetic information of the mRNA that codifies for a given selenoprotein. Since there are no triplets left in the genetic code to be assigned to selenocysteine, one of the existing triplets, in particular one of the three triplets that codify for the "stop" signal, is "recoded" into a new meaning (a kind of information falsification). In other words, the organism shows a capability to control its own informational processes (translation in particular) in order to satisfy the vital need of producing selenoproteins. A very high-level and particular form of using "unorthodox" pathways in order to fulfil vital functions. These considerations might give an idea of how top-down information control, as intended here, may be causally relevant for basic biological processes. It is very likely that it will turn out to be even more important for neurological processes, where the issue of dealing with information becomes remarkably more complex. This problem would deserve a specific treatment, and therefore allow me to give here only a couple of hints. Studying the behaviour of rats when exploring a laboratory maze, Kandel and his co-workers47 discovered that dopamine is purposively recruited in a top-down way. Also studies on the olfactory perception of rabbits show that the whole process starts with a certain expectancy.48 Generally speaking, moreover, in the field of neurosciences a large number of studies focussed on motor processes insist on the endogenous top-down contribution that allows to treat different motor segments as alternative 47. Kentros, C. G., Agnihotri, N. T., Streater, S., Hawkins, R. D. &amp; Kandel, E. R. - "Increased Attention to Spatial Context Increases Both Place Field Stability and Spatial Memory". Neuron 42 (2004): 283-295. 48. Freeman, Walter J. - Neurodynamics: An Exploration In Mesoscopic Brain Dynamics. Berlin: Springer, 2000. Vol. 68 ^ Fase 1-2 Q RPF 2012</page><page sequence="20">28 Gennaro Auletta pathways for the execution of a purposeful action and to integrate some disparate segments in a single course of action in a hierarchical way.49 Summing up, we can speak of top-down causation when information control is involved, what implies that we can have top-down processes properly only in the biological (and neurological) domain. It is an open question whether teleonomic processes are possible in non-living matter or not, but, as mentioned, at the global level they do not involve top-down causation as such. The previous example of Chemotaxis also shows that we do not need to abandon the traditional reductionist methodology. On the contrary, this must be used as far as possible (according to the above pragmatic rule) but we are also justified in exploring the possibilities offered by top-down explanations when the previous methodology risks to simplify too much the terms of our scientific problem (I recall Einstein s quotation above). 5. Etiological and phylogenetic explanations Often top-down causation is associated with the issue of emergence and sometimes it is put on the table only in order to account for emergent phenomena in nature. This may be seen as due to a certain basic confusion between phylogenetic (or, more generally, genetical, when non-living physical systems are under consideration) and what I call here for convenience etiological explanations. Phylogenetic (or genetical) explanations deal with the problem of emergence of certain behaviours or properties, an issue that is beyond the scope of the present paper. Most of the phenomena that emerge (like new biological species) happen mainly thanks to teleonomic circuits, and, although some control mechanisms still play a role, the whole process cannot be said in any sense to be under the control of the organism: in general control mechanisms are the result of those emergence processes. This is even truer for the emergence of systems provided with goals (i.e. organism). I would dare to say that this is the result of spontaneous processes (in full absence of control mechanisms) leading to a biomolecule (presumably RNA) having both metabolic and informational-codifying functions isolated by a belt of lipids, a system of such a complexity that a selective fork was consequentially imposed: either having the goal of self-maintenance and therefore exert controls or get 49. Jeannerod - Motor Cognition: What Actions Tell the Self ; Auletta - Cognitive Biology, Chaps. 5 and 14. Vol. 68 Fase. 1-2 Q RPF 2012</page><page sequence="21">Causation Upside Down ? 29 destroyed (what is likely to have in fact happened for many experimented solutions50). Reciprocally, there are many processes in the ordinary life of organisms (like the mentioned Chemotaxis) that involve control and are therefore top-down but have nothing to do with emergence (they have at most emerged billions of year ago). The explanations that deal with this kind of processes can therefore be called etiological explanations. In other words, although both definitively possessing a causal character, etiological explanations deal with ordinary causes of certain phenomena or with causes that are present in many situations of the same kind, whilst genetical explanations deal with long-lasting processes (taking in phylogeny the passing of many generations) and bringing to the first occurrence of a phenomenon or to the establishment of a kind of behaviour or character. Due to this extraordinary character, this occurrence may be well due mainly or exclusively to chance factors (I cannot deal here with quantum random events, whose probabilities are nevertheless ruled by deterministic equations51). At the opposite, every time that we face a regular or recurrent causal process we cannot rely only on chance (although a chance component may be still present) otherwise we would face a perpetual miracle. J. Butterfield,52 in his criticism of top-down causation, postulates that "a system evolves randomly, until it happens to hit its goal - after which it stays in that state". In this way, a pure bottom-up or at least same-level explanation could do the same job (but more economically) as the top-down machinery. However, my feeling is that Butterfield is speaking of genetical explanations, that is, of the important problem of how a particular goal (or a function) has emerged for the first time at all (or even, as mentioned, how goal-directed systems as such have emerged). I agree with him that this is indeed the result of processes that rely ultimately on random variation and natural selection (although intrinsic self-organization and control mechanisms may play an important role). I have indeed mentioned that it is likely that many controls or check-points have arisen through spontaneous and even random dynamical processes occurring at a pure physical-chemical level. However, a little reflection can show that this is not the way in which organisms can deal with the ordinary problem of their self-maintenance. Indeed, all organisms need to feed free energy 50. Pinheiro, V. B., Taylor, A. I., Cozens, C., Abramov, M., Renders, M., Zhang, S., Chaput, J. C., Wengel, J., Peak-Chew, S.-Y., McLaughlin, S. H., Herdewijn, P. &amp; Holliger, P. - "Synthetic Genetic Polymers Capable of Heredity and Evolution". Science 336 (2012): 341-444. 51. Auletta, G., Fortunato, M. &amp; Parisi, G. - Quantum Mechanics, Ch. 3. 52. Butterfield, Jeremy - "Laws, Causation and Dynamics at Different Levels" (2012). Vol. 68 Fase. 1-2 0 RPF 2012</page><page sequence="22">30 I Gennaro Auletta from the environment and to download entropy in it. Only this exchange can keep the necessary order that enables to display vital functionalities. This means that the organism cannot be exposed to the random changes of the environment (otherwise, as explained, we cannot speak of control at all). The probability to remain alive when exposed to random fluctuations is indeed exceedingly low for thermodynamic reasons: the environmental configurations promoting the specific organization needed by the organism are a vanishing subset of all the possible ones. As mentioned, this implies that the organism cannot work as a blind mechanical engine, that is, like a machine that simply maps certain inputs whatsoever into certain corresponding outputs (reactions or actions). In other words, the regularity of the organism cannot depend on physical-chemical factors alone, which would simply lead to the destruction of order; rather it should be rooted in the control mechanisms, which, although phylogenetically arisen through spontaneous or even random processes, once established enable the organism to deal with the environment (and with internal processes) in an appropriate way. Therefore, the organism must be able to look actively for very specific inputs as driving to the appropriate free-energy sources, to select them among many different others (representing noise) and profit from them by favouring the right metabolic exchange with the environment (as noted before with regards to E. colis Chemotaxis). Therefore, when we look for the causes that are at play in the ordinary dealing-with-the- environment performed by organisms (i.e., when we look for etiological explanations) we are forced to take seriously into account the involved control mechanisms displayed (which are of informational kind) and, for this reason, if I am right, we also need to introduce explanations relying on top-down causation. 6. Conclusions It is possible to understand top-down causation in a way that is self-consistent. Although going further than traditional methodologies employed in physical sciences, this kind of explanation does not substitute them completely but need to be integrated with reductionist methods. Of the five different meanings of the term reductionism, I have shown that two (the general methodological requirement to build models as simplified as possible and the pragmatic maxim to apply methods that have been very successful in physics) are necessary for science, one (intra-theoretic reduction) is customary although not very fruitful, one (ontological reductionism) is clearly obsolete, whilst the latter (inter- Vol. 68 Fase 1-2 0 RPF 2012</page><page sequence="23">Causation Upside Down? 31 theoretic reduction) has not shown clear-cut results until now and it is an open question whether it will score better in the future. An adequate treatment of the problems peculiar to biological (and neurological) systems seems to show the need for new kinds of etiological explanations, like the ones based on top-down causation, provided their compatibility with the methodological tenets essential to any fruitful and well-focussed scientific investigation. Surely, it is too early to formulate a clear assessment about the role, the significance and the scope of top-down explanations. However, it seems likely that they might play a major role in the future of biology and neurosciences, where control mechanisms for the fulfilment of certain functions are crucial. It is interest of the scientific and philosophical community to follow these developments with great attention, and try to understand the ways in which they might lead to appreciable results and unexpected knowledge. Acknowledgments I desire to thank P. D'Ambrosio for his extensive comments. I also thank I. Colagè and J. M. Ramón-Fuentes for their suggestions. Vol. 68 Fase. 1-2 Q RPF 2012</page></plain_text>
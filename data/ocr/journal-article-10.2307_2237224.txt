<plain_text><page sequence="1">THE PROBLEM OF ESTIMATION By H. STEINHAUS University of Wroclaw 0. Introduction. A treatment has proved successful in m cases out of n; what is its efficacy? In other words: What will be the frequency of successes if we con- tinue to apply the same treatment in all cases of the disease it was invented for? A lot has been examined by sampling and m items out of n proved defective; what is the best estimate for the fraction defective in the whole lot? This is another example of the same question. A hundred people of a certain tribe have been classified as to their belonging to the blood groups A, B, AB and 0; how are we to estimate the frequencies of the 4 groups in the whole tribe? It is not an over- statement to say that the abundance of applications gives the problem of es- timation an importance sufficient to rank it among the principal problems of science. This is the reason why, for more than a century, it has not ceased to haunt the ingenuity of mathematicians. To make things quite plain let us imagine a statistician (S) compelled by the devil (D) to play the following game: The devil has a collection of coins and he knows for each of them its prob- ability p of showing heads as a result of tossing; he is rich enough to have speci- mens for any p in (0, 1). He chooses a coin suiting his fancy and lets the statis- tician throw it n times; it shows heads m times and it is up to the statistician to give an estimate p' of the value p which is known to D but unknown to him. This being done, S pays to D $(p' - p)2. S tries his best to reduce his loss by an appropriate method of guessing, as far as possible. If he succeeds in finding the best method he will not regret the money lost: his will be the fame of having solved our problem of the best estimate, if "best" is understood as minimizing the expected square error of the estimation; the rules of the game have been fixed by the devil in accordance with such an interpretation of our problem. The following remark may explain the link connecting our game with the problem of point-estimation. The classical method solves this problem assuming that the distribution of coins employed by the devil is known to the statistician. He computes his guess, combining by Bayes' rule this knowledge with the ob- served result of tossing; the guess p' will be equal to the a posteriori value Ep. It can be defined also as the value of p' that minimizes the expected loss E(p' - p)2. Thus the rules of our game correspond to the problem of point- estimation in the case of a known prior distribution; it is not artificial to employ them in the case of an unknown prior distribution. I proposed this problem in 1954 [10] in Prague and in Berlin, calling it "Das statistische Spiel," but it is only in 1956 that I have been informed by L. J. Savage that it has already been solved: J. L. Hodges, Jr., and E. L. Lehmann [4] Received July 30, 1956, revised April 22, 1957. 633</page><page sequence="2">634 H. STEINHAUS attribute the priority to Herman Rubin in their important paper published in 1950. Another paper [3] by M. A. Girshick and L. J. Savage deals thoroughly with the same question; the results have already been included in books [2] and [8]. The generality of the results reached by the American school and their priority make it necessary to explain the reasons for publishing this paper: the first is that my exposition will perhaps be easier to read for some readers who do not feel comfortable when spoken to in the language of consummate specialists; the second is to be found in the last sections, which deal with some cases not covered by the authors quoted above. 1. A statistician who does not believe in probabilities when he is faced with a single game does not even look at the gambling table. He says: "The number m gives me no information whatever about p. My method is to declare p equal to 2. In the worst case the true p will be 0 or 1 and I will lose 25 cents. Any gambler adopting a system different from mine exposes himself to a greater loss than a quarter of a dollar: if his p' is greater than 2 he loses more than 25 cents for a very small p and if his p' surpasses 2 his loss is greater than 25 cents for a p near unity. This is the reason why I abstain from counting heads and tails." The method described above denies the possibility of statisticai estimation, since its estimate is not influenced by the results of experiments. It has, however, the advantage of the certainty it gives to S of never losing more than 25 cents, a guarantee that no other method is capable of. From this point of view we can define 25 cents as the "value of the game." The devil's point of view, however, is different. As he is never sure that S will not guess the exact p, in which case his gain is nil, the "value of the game" is 0 when computed by D. In both cases we consider only the gains of D; nevertheless we get two different values: 25 cents and 0. Such games may be called "open." 2. As is generally known, many mathematical theories were invented to master our problem by the calculus of probability. Laplace did not hesitate to apply to it the so-called inverse probabilities or "probability of causes" derived from the observation of effects. To avoid misunderstandings we will speak of frequencies of different coins instead of the probabilities of their having been chosen by D. Such an approach implies the substitution of a sequence of games for a single game, and of the mean loss for the single loss. Following this principle, we have to imagine S being condemned by D to perpetual gambling. The devil is allowed to choose a new coin in each round of the infinite sequence Q of rounds, but n re- mains unaltered. It is the statistician's business to make his mean loss as small as possible. He could do it easily if he knew the frequency of different coins em- ployed. To be more explicit, let us assume that D adheres to a certain function f(p), the "density," and that S knows this function. In other words, he knows that for any two numbers u, v (0 &lt; u &lt; v &lt; 1) the relative frequency of the coins with u ? p &lt; v is fr f(p) dp. The function f(p) is integrable, nonnegative and f f(p) dp = 1. S puts the following problem to himself: the whole sequence Q of games can be split up into n + 1 subsequences Qm (m = 0, 1, 2, n),</page><page sequence="3">PROBLEM OF ESTIMATION 635 Qm being the subsequence consisting of all rounds showing the same number m of heads. The mean loss in such a subsequence is proportional to the integral (1) I(x, M) f(P) (m) pm qm(p X)2 dp (q = 1 -p), where x is the statistician's answer to m heads. Thus he has to find a function p' = g(m, n) which gives to I(x, m) the least value when substituted for x in the integral (1). Since the (n + 1) values p' takes for m = 0, 1, * , n are inde- pendent, S has to solve the problem I(x, m) = minimum separately for each m. This leads to a function g(m, n) that minimizes the mean loss in the whole se- quence Q. The problem is easily solved, for x is the root of the equation dI(x, m) / dx = 0. Calling it xm we get immediately (2) Xm f f(p)pm+lqn-m dp/ f f(p)pmqn-m dp = g(m, n) Formula (2) is the clue to the problem: S has to declare p' = g(m, n) in every game, g(m, n) being defined by the ratio (2). It is to be noted that the integral (1) is a nonnegative quadratic function of x, which implies that the root of I' = 0 is a perfect minimum of I: for any x different from xm , we get I(x, m) &gt; I(xm, m). A nontrivial case is given by the Bayes hypothesis f(p) = 1. Formula (2) then leads immediately to (3) g(m, n) n + 2 as the best method for S. Laplace employed such a hypothesis and (3), and he has been rebuked for it by his successors. An example of another kind is the favorite method of many naturalists and other scientists, who put p' = m/n. We now have to determine f(p) so as to satisfy (2) identically in m (n is fixed once for all) with g(m, n) replaced by m/n. Putting ni = n we immediately get the condition (4) ff(p)pn+l dp = f f(p)pn dp. The functions integrated being nonnegative and pfn+l less than pn everywhere in (0, 1), (4) implies f(p) 0 (almost everywhere), which contradicts the condi- tion f of(p) dp = 1, essential for any density. Thus the estimate m/n does not correspond to any density f(p) whatever. It is a remarkable fact that some surgeons have reached the same conclusion without being matherhaticians and without knowing how to improve the estimate [7]. 3. The modern theory of games as codified in [5] and extended, for example, in [12], guarantees the existence of a solution of our problem. It proves, for such two-person games as are considered here, the existence of a density f(p) of a sequence { gj(m, n) } of guessing-methods, and of a number V (called the value of the game) such that</page><page sequence="4">636 H. STEINHAUS 10 the statistician applying the guess p' = g()5 (m, n) in thejth round is sure to lose no more than V in the mean whatever the devil does, the mean being taken over the results of the whole sequence Q. 20 the devil who mixes his coins in conformity to the frequency function f(p) is sure to win in the mean at least V regardless of what S does. The use of the frequency function f(p) by D is to be understood as the use of a sequence of coins such that the corresponding sequence {p(j) p has a relative frequency fv f(p) dp of terms belonging to the interval (u, v) whatever this interval may be (O &lt; u &lt; v &lt; 1). It follows immediately from 10 and 20 that 30 the "mixed strategy" defined by Igj) } is the best for S in the minimax sense of "best." It is also clear that V, the "value of the game," is the fixed indemnity which, when paid by D to S before every choice of a coin, makes the play fair; such settlement would not influence our theory. The importance of the theorem of J. von Neumann leading (through its ex- tensions) to the statements mentioned lies, as far as our endeavor is concerned, in the assurance that it is worthwhile to seek an effective formula for the estimate p'. Nevertheless, our reader is neither supposed to know the theory of games nor the somewhat intricate terminology of the books quoted ([5] and [12]). Our argument will be independent of the general theorem, and it will yield in our special problem more than is promised by 10, 20, and 30. The difference between the result of Sec. 1 and the objective of the following sections is also worth notic- ing: we could not guarantee to S a loss less than 25 cents in a single round but we can-as will be shown-reduce his mean loss in a sequence of rounds to a quantity V less than 25 cents by finding a minimax solution which admits no further improvement. It is necessary to explain why we are not entirely satisfied by the promise contained in I, 20, and 30. What we need is an estimate p' = g(m, n) valid for the whole sequence Q of successive rounds; estimates varying from round to round would introduce an indeterminism of a dangerous kind which would make the scientist utter different judgments in identical situations: if gj(m, n) x gh(m, n) for the same couple m, n, he is compelled to estimate differently the efficacy of two antibiotics, although both of them gave m positive results in n experiments; he is compelled to such behavior because the first experiment was scheduled "no, j" and the other "no, h." In Sec. 1 we have seen that no satis- factory estimate can be reached by making it an absolute constant; now we reject estimates which have the drawback of variability, though it is not universally agreed that such estimates are irrational. The case against them is forcibly put by R. A. Fisher, pp. 97-98 of [1]. 4. Let us suppose now that D has chosen once for all a particular coin char- acterized by p, whereas S employs the particular function g(m, n) of (3) as his method of guessing, and let us call E the mean gain of the devil. We get</page><page sequence="5">PROBLEM OF ESTIMATION 637 (5) E = (n)pmqnm (p m+1)2 ( =- m)[ Pn +2 +n+2) To compute E we make use of the trivial equality - (n )pmqnm = 1 and of the following identities: n nQ nn (6) Z (7) mpmqm np, E )m2pmqn p + npq; they are, respectively, familiar formulae for the first and second moments of the binomial distribution. Eqs. (5) and (6) lead immediately to the simple result E (n - 4)pq + 1 (n + 2)2 Let us consider first the case n = 4. Then E ceases to depend on p and becomes equal to 1/36. This circumstance makes the statistician who adopted the method pI = (m + 1)/6 independent of all diabolic cunning: whatever D does, whether he sticks to one coin or changes them as he likes, S will lose in the long run 1/36 as his mean expenditure, never more nor less. It follows therefrom that any method is the best for D as an answer to the method p' = (m + 1)/6. In par- ticular, the method defined by the density f(p) = 1 is such a relatively best method against the statistician's rule p' = (m + 1)/6. What is, on the other hand, the statistician's adequate answer to the devil's rule f(p) _ 1? This answer has already been found in Sec. 2: g(m, n) = (m + 1)/(n + 2), which is equal in our special case n = 4 to (m + 1)/6. Thus we have two antagonistic methods for D and S, each of them being relatively best against the other. We can easily prove that the rule of guessing p' = (m + 1)/6 is not only relatively best but also absolutely best, i.e., that it fulfils the minimax criteria for best strategies. The proof runs as follows: The rule p' = (m + 1)/6 reduces the loss of S to 1/36 whatever D does. On the other hand, the same rule is the best answer against D's employing the system f(p) -1. This last statement implies the im- possibility of S's reducing his loss below 1/36 against the devil's playing as men- tioned. Therefore no method gives a certainty to S of a loss below 1/36; as the rule above gives a guarantee of a loss equal to 1/36, no rule is better in the mini- max sense, Q.E.D. The devil's rule f(p) - 1 is also absolutely best for D, a theorem which can also be proved almost immediately. Both proofs are superflu- ous for a reader knowing the general theorem about games that two methods relatively best against each other are also absolutely best for the opponents em- ploying them. The existence of such a pair of methods shows, in our terminology, that the game is closed. The result of their being constantly applied by both sides is a mean loss equal to the value of the game, which is 1/36 in our case.</page><page sequence="6">638 H. STEINHAUS Thus we have solved our problem of the best estimate for n = 4. The solution is p' = (m + 1)/6. Let us try to free ourselves from the restriction n = 4 by setting more gen- erally, (7) pr = g(m, n) = n+b and assuming the independence of a and b from m but not from n. To compute E in this case we have to write (8) E O- (m)n pmq (nP- n + a instead of (5), and to repeat almost verbally the trivial computations of the special case a = 1, b = 2; they give now (9) E = nPq + (bp-a)' (q= -p). The numerator np(l -p) + (bp - a)2 ceases to depend on p just if we put a = N/n/2, b = ;Z. These values when substituted in (7) for a and b yield the formula (10) p' = g(m, n) = m + Vn/2 - G(m,n) n + N/n- as a guessing method for S. When substituted in (9), they give A -_ ~ 1 4 4(\/n +1)2 as the mean loss of the statistician, whatever the sequence of coins employed by the devil. To follow the path traced in the special case n = 4, we have to find a density f(p) which satisfies (2) when we write for g(m, n) the function G defined by (10). Let us try to this effect f(p) c(pq)8(s &gt; -1) with l/c = f (pq)8 dp. The integrals in (2) now take the form 1 ~~~~~~~~~~~~1 c pS+M+(l - p)s+n-m dp, c p8+m( - p)s+n-m dp, and their respective values are r(s+ m + 2) r(s+ n-m + 1) r(s + m + 1) r(s + n-m + 1) r(2s + n + 3) ' r(2s + n + 2) Their ratio is (s + m + 1)/(2s + n + 2), and condition (2) becomes (12) m + s + 1 m m+ -\n/2 n +2s +2 n?V /-</page><page sequence="7">PROBLEM OF ESTIMATION 639 To satisfy (12), we set s = N/n/2 - 1 and get (13) f(p) (pq)V_I2 r. (V\n/2))2 as the density sought to close the game. Thus the method G defined by (10) is the solution of our problem. It is the best estimate of p because it minimizes the mean square error. The case n = 4 is obviously contained as a special case in (10); it is the only case in which the hypothesis of uniform distribution a priori is consistent, in a certain sense at least, with our theory. It is interesting to note that the classical rules-Bayes' hypothesis of uniform prior distribution and the estimate m/n-can both be saved if (p - p')2/pq is the amount to be paid by S to D. This is easily verified by writing a = 0, b = 0 in (7) and dividing (9) by pq to compute the expected gain of D in the new game; it is 1/n and thus independent of p. On the other hand, if we put f(p) 1 in (1) and replace (p _ x)2 by (p - x)2/pq to satisfy- the new rules of the game, we are led by the same reasoning as employed for the old rule to the formula 1 , 1 Xm = 1 p q dpj f P q dp = m/n, o ~ ~~ o instead of (2). 5. The method of S given by G holds the devil tightly by his horns: he can neither increase nor diminish his mean gain which is equal to A as defined by (11). A is the value of the game and, consequently, the indemnity which, when paid in advance by D to S in every round, makes the whole game fair: this signifies that the mean balance of the sequence of rounds tends to zero with prob- ability 1 if this indemnity is agreed upon and both partners play as well as pos- sible. If S adheres to G the devil's lack of skill does not alter the limit. There are, however, bad methods for D (i.e., bad densities f(p)); if S knew that D has chosen such a method, he could apply a method securing himself a positive mean balance. The expression (14) VA 2= Q +1) may be called the mean error of the estimate (10). We emphasize that it is de- pendent exclusively on n. This enables the scientist to plan his experiments with a desired accuracy: he gets by an adequate choice of n the accuracy desired, neither more nor less, which is very important (e.g., the estimation of a lot by counting good and defective items in a sample of n has to avoid samples too great and too small: the first cost too much, the second give insufficient informa- tion). To appreciate this feature of the estimate (10) we may compare it with the "confidence interval" method where the length of the interval, given the con- fidence level, is known only after the experiment, because it depends on both n and m. Finally, our formulae are extremely simple, and can easily be tabulated for practical purposes.</page><page sequence="8">640 H. STEINHAUS 6. Our estimate G is free from the disadvantage of "mixed strategies" antici- pated at the end of Sec. 3. We may put the question of its uniqueness. Stanislaw Trybula has found the following simple proof [11] that there is no other estimate equivalent to G. It has already been proved here that there is no better estimate; we have the author's consent to repeat here his proof of uniqueness. The proof that there is no other estimate equivalent to G is simple. It is stated, in more general form in [4], where the estimate was first announced. I happened to hear it first from Stanislaw Trybula who rediscovered it in connection with [11]. You have already seen that there is no better estimate; and now here is the proof of uniqueness. We have already stated in Sec. 2 that the solution (2) of the minimum problem for the integral I(x, m) defined in (1) is unique: (15) I(x, m) &gt; I(xm, m) for every x different from xm. Suppose that S adopts any method M, of the form g(m, n) different from G. Let the devil choose the method defined by (13). Since this density has been shown to give G when substituted in (2), we see by (15) that there is at least one subsequence Gm giving to D a greater gain in the mean than the gain he would obtain if S applied the method M: this subsequence is generated by the subscript m for which M differs from G(m, n); there is at least one such value m among 0, 1, * * ,n. For any values m, for which M equals G(m, n) the corresponding subsequences G. give the same gain to D as he would gather if opposed byG(m, n). Thus S will suffer in the mean over all rounds played a loss greater than L, if he applies M and is opposed by (13) as the devil's method. Thus M is not a minimax solution, which proves the uniqueness of our minimax solution G(m, n). The question of uniqueness of the devil's best method has a different answer. It too has been found by Trybula [11], and it is negative. There are densities different from (13) that are equivalent to it as gambling methods in every respect. They are, however, not so simple. We have already seen that there does not exist a single coin po as a "rigid method" for D; the reason is the possibility of S's choosing p' po if D's method is to always use the same coin po . Nevertheless, there are other methods, which correspond neither to densities nor to constants, to speak more generally, which have no distributions. We have omitted taking them into account; because our argument led first to a method G for S which made his mean loss independent of all methods of D, the distributionless methods included, and we had only to find one definite method for D which could never be better answered than by G. Thus we can admit all possible methods of D, having a distribution or not; the theory expounded remains valid without restrictions. As the devil represents nature, we have no reasons to jeopardize his freedom; it is an advantage for S, the human player, that our theory enables him to master the situation in the general case. In all cases, when the existence of limits is asserted, the assertions are true with probability one. There are other points where we have sinned against the</page><page sequence="9">PROBLEM OF ESTIMATION 641 professional vocabulary, e.g., when speakinig about the "mean error"; it is rather a metaphor: we always think of the expression N lim E (P(D) _ p1(i) 2. N-3 xN j=1 For practical purposes this limit is a better measure for the error than any having the disadvantage of being dependent on m and of becoming 0 for m = 0 and for m = n. These disadvantages have shocked practicians and compelled them to leave the hard soil of sound statistics ([7], [9]). Our method may be criticized as leading to a biased estimate. This means, in plain words, that in the case of estimating the same quality p over and over, say r times, we get r values mj (j = 1, - , r) and r estimates p,(j) mj + -\n-/2 n + \/'n- whose mean 1/r = p'(j) does not tend to p for r -* This is, however, ani artificial situation. If we have different lots Lj we are not entitled to suppose pU') the same for all lots and, to be on the safe side, we must give separate esti- mates for each lot. If, however, we have to deal with the same lot r times, we will not compute its quality by taking the mean of the estimates but we will employ the formula (10) with m = EJ1 mj, writing I m + -\IWrl2 nr+ V\r The estimate p' has, obviously, the property that liMr, Pr = P. Our method is essentially based on the measure of the error given by (p _ p,)2. Of course, this measure is by no means the only possible one. In some applica- tions the minimizing of the average error p - p' I would be more realistic; in some cases even some asymmetric function of the difference p - p' could claim to be the best measure of the error in view of the economic consequences of a bad estimate which ought to be minimized. Notwithstanding this objection, we do not see any possibility of covering all the statistical applications by a single formula and must either abstain from giving any general rule or adopt the princi- ple of least squares as being by far the best known and most applied. Its simplicity is inherited by our formula; no tables are necessary to employ it for small n, and there is no distinction between small and large n to be taken care of. 7. The comparison of our estimate (10) and that called the "confidence in- terval" [6] leads to the following remarks. The confidence interval is defined by a "confidence level" and by the postulate of being the shortest one, given m, n and the confidence level. It is not a direct estimate of the unknown p. In many cases, however, such a direct estimate is necessary; let us think, for instance, of selling two kinds of some produce on the basis of a first experience which gave m and n - m buyers respectively for kinds</page><page sequence="10">642 H. STEINHAUS A and B; the producer is compelled to choose a definite p' so that he may include in the next shipment the proper numbers of items A and B. Nevertheless we could consider our estimate as the middle point of an interval of the length 1 / (V/n + 1). This length being the double of the expression (14), we may risk the conjecture that the confidence level for it is 0.6827 * * - for n greater than, let us guess, 30. Thus our estimate would appear as a special case of the classical confidence interval: the case of confidence level 0.6827. This is, however, an illusion, because of the classical confidence interval's having a length depending on m which is not true for the length (14). We have already pointed out in Sec. 5 the importance of this iildependence. The remarks above lead to the problem of modifying the so-called confidence interval by making its length independent of m. To speak again in the language of the theory of games, it would be necessary to let the devil and the statistician fix n and an arbitrary t (0 &lt; t &lt; 1) and let them gamble, the devil choosing the coin to be tossed and the statistician placing an interval J of length t on the real axis after having seen the result of n tossings. The stake would be $1 paid by D to S if p is covered by J and by S to D in the opposite case. The problem for S would consist in placing the middle-point P of J as well as possible. He would have to find a formula P(m, n; t) for the best location of P. This formula would be the statistician's best method of playing and would lead eventually to a value of the game, V(n, t), independent of p. Solving the equation 2V(n, t) = v we would get n = h(t, v); the function h(t, v) would answer the following problem: given the confidence level v and the length t, to determine the number n of experi- ments needed to include the unknown p in an interval of length t with a confidence v. We have not tried to solve this problem; we mention it here to show distinctly the difference between the theory of Neyman's confidence intervals and our line of approach. We pass now to another question; it is the last of the three examples spoken of in the introduction. Instead of the simple alternative, or dichotomy, for which the solution has already been described, we have here four possible results of tossing. Let us more generally suppose that there are k possible outcomes, k &gt; 2. The coin must be replaced by a k-hedron, every face being painted differently from the others; D knows the respective probabilities pi(i = 1, 2, k.., l) for all faces; he has in his collection a model for every set {pt}; obviously k pi = 1. The result of n tossings with a definite k-hedron is a set {mi}; mi (i = 1, 2, * , k) are the respective numbers of tossings rpsulting in the ith face up; obviously D., mi = n. S has to estimate {pi} knowing {mi}; his estimate {pi} has to minimize the expected value of (16) Z=L (P P - He tries to do it by putting (17) m;+a ( = 1, 2, ,k).</page><page sequence="11">PROBLEM OF ESTIMATION 643 We now have, instead of (5), the expression E=E n! pl lp22 . .. pkk _ {m}_ml ! m2 ! * Mk * m! (18) *m)!m2*mk P k ml + a + P nk+a)} the summation being extended over all systems of nonnegative integers mi with D., mi = n. Let us denote by E1 the part of E which is left after cancelling all squares in { } in (18) but the first. If we denote ml by m, pi by p, and i=2 pi by q we get immediately the same expression for E1 that we have called E in (8). This gives, in view of (9) Ei = ( + b)2 (npi(l - pi) + (bpi - a)2). The same applies to each of the k parts Ei of (18) and leads, eventually, to k 1 k (19) '=1 (nI + b) 1 {npi(l -pi) + (bp - a)2} (1) (n + b)2 n + (b2 - n) p2 - 2ab + ka2} This expression becomes independent of the variables pi if and only if we put b = V4-; it then takes the form (20) E = 2 (n-2aV + ka ). (n + VN/)2 To determine a we introduce the condition (21) t = 1, obviously needed in most applications. Thus we get from (17) with the value b=V&gt; (22) 1 M_ = n+ka and, from (22), a = \/1c/k. We note with gratification that this value of a necessary to insure (21) is also just the value needed in (20) to minimize E without regard for (21). The formulae (17) now become (23) Pi = + Vn/ (i = 1, 2, , k). Putting a = V/n/k into (20) we get (24) E= n k-i an expression independent of {pi}.</page><page sequence="12">644 H. STEINHAUS To attain our objective by pursuing the analogy with the case k = 2, we must find a density on the hyperplane (25) ]k i1 (0 ? pi _ 1; i = 1, 2, k), for which the estimates (23) minimize the expected value of Zli=l (P' -p. Let us try the density f(pi P2 ... Pk) = C(Pl P2 P Pk)', where the constants C and s will be deterinined later. Supposing that the statistician knowvs that the frequencies of k-hedra employed successively by the devil are distributed ac- cording to this density (each point on the hyperplane (25) defines a k-hedron and the converse is also true), he will have to determine his guesses {xi}, after having observed the result { mi }, so as to minimize the expected loss that is given by the positive quadratic form F(xi, x2, ..., Xk) (26) n! mli ! L1?. +Pk 1 f (p1. pM) P . I**k E (pi _ Xi)2 The integral in (26) is extended over the domain defined by (25) and dw is the element of the hyperplane (25). The minimum problem is equivalent to the set of equations aF/axi = 0 (i = 1, 2, * , k) which are obviously (27) JP1+. J+Pk=l (pl p2 * * * pk)mpl1 pk22 k - xi) dw = 0 (i 1, 2, ... k) and the method of guessing defined by (23) will be proved best in the minimax sense if the set { xi I solving (27) can be identified with the set { p' } given by (23). This amounts to k conditions of which the first is (28) f..S f p? ml1?S?lp?p2?S ... pk?k dw ml + ... pi p2?S ... pknk+S dw n + / The numerator L and the denominator MI in (28) can be brought into the forms r(ml + s + 2)r(m2 + s + 1) *.. r(mk + S +1) (29) r[n + k(s + 1) + 1] ) r(ml + s + 1)r(m2 + s + 1) *. r(mk + s +1) r[n + k(s + 1)] respectively, if the classical identity [13]</page><page sequence="13">PROBLEM OF ESTIMATION 645 is applied to both of them. (29) immediately yields L ml + s + (31) M +os1 and the condition (28) leads, through (31), to (32) m + s + _ m +Vn/k n + k(s +1) n +V which can be satisfied by settinig s + 1 = Vn/ok; since the same reasoning applies to all k conditions of which (28) is the first, all will be satisfied by the value chosen for s. As to the constant C it can now be found from the condition (33) CfI .j.. f (plp2 . Pk)\nlk-l dw = 1 (k &gt; 2) Pi&gt;=?;Pl+"-'+Pk=l which gives k( I' (Vn//k) and, finally, (35) r(v'/) (plP2 ... pk)lk-1 pk(V\7~k) is the density sought. If it is employed by the devil in an infinite game where the payment (16) in every round is agreed upon, the statistician's best answer is defined by (23), whether or not S is bound to respect the condition (21). This statement has just been proved; it enables us to apply once more the argument employed in the case k = 2 and to recognize the estimates (24) as the best in the minimax sense. The uniqueness of our solution follows by the reasoning already applied (for k = 2) in Sec. 6: as F in (26) shares with I in (1) the property of attaining its minimum at a single point, no modifications of the former reasoning are necessary. 8. If we drop the condition (21) we can write p for pi, q for 1 - p and seek wvith S the best estimate of Pi alone by the theory of the dichotomous case. This leads immediately to the solution (10) which may be written adequately = (ml + Vn/2) (n + Vn) we can, of course, replace the subscript 1 on both sides by i(i = 1, 2, k). We will have for the total loss (16) the mean bA, where A is given by (11). On the other hand, the loss has been computed in (24) under condition (21) as being equal to 4[(k - 1)/k]A; since 4[(k - 1)/k] is less than k for k &gt; 2, we arrive at the paradox that S can reduce his loss in the general case k &gt; 2 by accepting the obligation (21). The explanation lies in the circumstance that the</page><page sequence="14">646 H. STEINHAUS loss A has been computed as minimax, taking into account the possibility of D's playing his best method, which has been found to be the density c(pq)8. In the general case he can not apply the same method for every face of the k-hedron because he would have to choose a density f(pi, P2, *.. , pk) that would have the form cipi(1 - qi) for i = 1, 2, ... , k simultaneously, which is impossible. Thus the plurality of faces hinders the devil from simultaneously playing all the alternative games contained in the general case as well as possible. This obstacle for D opens the way for S to play every alternative game in the general case better than he could do it in the simple alternative k = 2; the in- equality 4[(k - 1)/k] &lt; k is the proof that the advantage thus gained by S is greater than the disadvantage that results from the condition (21). In fact we remarked just after (22) that this disadvantage is purely illusory. 9. The method of this paper applies as well to other distributions as to the binomial. The simplest example is given by the Poisson distribution. The problem is to estimate the mean number of signals per unit time, having observed an arbitrary unit interval and having found k signals in it. To apply the theory of games, we must define the amount to be paid for an erroneous estimate. If, to mention an example of analytical interest, this amount is equal to (c - C,)21C, c being the true mean number and c' the estimate, the problem is easily solved. Let us try the guess c' = k. The expected loss for a given c is X _c - k2 c k (36) E E (c ) = cMo - 2M1 + M2/c, k=-O c the Mi (i = 0, 1 2) being the moments of order i of the Poisson distribution; this leads to (37) E = c-2c + (w + c2)/c=1, w being the variance of the random variable k, which in this instance is c. Thus the loss E does not depend on c. We now have to find a prior distribution which leads to the method c' = k as the relatively best. We will show that the uniform distribution does so. To speak correctly, it will be the distribution of constant density T/(T2 - 1) (T &gt; 1) in (l/T, T) for T -- o. We have to compute x, for a given k so as to minimize the expected loss given by (38) d ec T2- 1 1T ck(c~ c x being the guess we are seeking. The condition for the minimum is evidently T T ecck dc = x T ecck1 dc, 1/T 1/T and becomes, for T- oo, k! = x(k - 1)!, x = k, Q.E.D. It is interesting to note that no minimax solution exists if (c - c')2 is fixed as the amount to be paid by S to D. The reason for this insolubility is to be sought in the freedom of the devil to increase c as far as he likes, putting for</page><page sequence="15">PROBLEM OF ESTIMATION 647 instance cj = j or cj = 1Oj in the jth round. It is easily seen that any guess c' far from k is worse for S than c' = k; on the other hand the expected value of (c - k)2 is c, rising thus with c beyond every limit and increasing indefinitely the gain expected by D, whatever S does. The schedule of payments (c -C)2/c2 is also of practical interest, corresponding as it does to a penalty based on per- centage error. Here again it is easy to see that no minimax solution exists. 10. Different objections to the new estimate have been raised: 10 The loss-function (p - p')2 has been criticized as arbitrary. We have pointed out in the introduction that it is the result of an extrapolation of the estimate Ep of the old school; such a procedure is suggested by the circumstance that the symbol E loses its direct applicability when the prior distribution of p is either unknown or nonexistent. 20 The old estimate m/n has been compared with (10) as giving a better result, especially for n not too small. It has, however, been- rejected not by mathematicians but by men of practice [7], who became aware of the paradox of error 0 for m = 0, m = n. 30 To save the minimax method, the Bayes hypothesis f(p) 1, and the esti- mate m/n, the loss-function (p - p,)2/pq has been proposed, but no examples have been adduced for which this loss function seems realistic. There is also some interest in the loss function (p - p')2/(pq)2-for which no minimax esti- mate exists. There are examples in which this function corresponds to the real situation for p near 0 or for p near 1, but it is difficult to find natural problems in which the function measures the damage caused by bad guessing throughout the whole interval 0 &lt; p &lt; 1. 40 The concept of a mathematically trained and satanically malicious devil has been denounced as leading to unnecessary caution; the estimate (10) is accused of paying too high a tribute to nature, which is incapable of seeking out such sophisticated devices against the mortals as given by (13). This ob- jection may be answered as follows: (a) We are compelled to play a game against nature ("the devil") and we do apply the new theory of games. If we are not allowed to do so we must abandon the new theory of games altogether and return to the old phraseology of "taking into account the psychology of the enemy." It is exactly the indefiniteness of such advice which made the new theory of games the only efficient tool in such problems as pursuit at sea; we need not worry whether the helmsman of the other boat is awake or not-he can just as well be an automaton and can be countered by our automaton. (b) Let us drop the anthropomorphic idea of nature and admit that it acts blindly, without any strategy whatever. Such a view leads us naturally to de- prive the devil of his sequence of coins of various frequencies. But even in such a situation it is difficult to imagine a better method for S against D than the new formulae: they do apply-not as minimax solutions but because of their inde- pendence of the pj-sequence; they give a definite mean-square error, the only light in the total darkness.</page><page sequence="16">648 H. STEINHAUS 50 Mr. A has been the first to investigate the blood-groups of a certain African tribe: he examined n' men and found m' with Rh-plus blood among thein. Mr. B came second and examined another sample; his result was n" and m" respec- tively. Mr. B feels obliged to take into account the information contained in the paper published by A: he considers the result of his predecessor as furnishing a prior distribution and hesitates to apply (10) to his numbers. The sound procedure is, however, for B to publish his own numbers n" and m", to quote the numbers of A, and to estimate the Rh fraction of the tribe by setting n = n' + n", m = m' + m" in formula (10) with the remark: "making use of all available observations." This example illustrates the meaning of our arguments 40(a) and 40(b). REFERENCES [1] R. A. FISHER, Statistical Methods and Scientific Inference, Oliver and Boyd, Edin- burgh, 1956. [2] M. A. GIRSHICK AND D. BLACKWELL, Theory of Games and Statistical Decisions. John Wiley and Sons, New York, 1954. [3] M. A. GIRSHICK AND L. J. SAVAGE, "Bayes and minimax estimates for quadratic loss functions," Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, University of California Press, Berkeley, 1951, pp. 53-74. [4] J. L. HODGES, JR., AND E. L. LEHMANN, "Some problems in minimax point estimation," Ann. Math. Stat., Vol. 21 (1950), pp. 182-197. [5] J. VON NEUMANN AND 0. MORGENSTERN, Theory of Games and Economic Behavior, 2nd ed., Princeton University Press, Princeton, N. J., 1947, pp. 143-168. [6] J. NEYMAN, "On the problem of confidence intervals," Ann. Math. Stat., Vol. 6 (1935), pp. 111-116. [7] A. M. RITALA, "Zur Berechnung des statistischen mittleren Fehlers (standard error)," Acta Societatis Medicorum Fennicae "Duodecim," Ser. B, 19, fasc. 2, Helsinki, 1933. [8] L. J. SAVAGE, The Foundations of Statistics, John Wiley and Sons, New York, 1954, Sec. 13.4. [9] H. STEINHAUS, "Sur l'interpretation des r6sultats statistiques," Colloquium Mathe- maticum, Vol. 1 (1948), pp. 232-238. [10] H. STEINHAUS, "Uber einige prinzipielle Fragen der mathematischen Statistik," Tagung uber Wahrscheinlichkeitsrechnung und mathematische Statistik, Berlin 19-21. X. 1954, Deutscher Verlag der Wissenschaften, V: Das statistische Spiel. [11] S. TRYBULA, "Some problems of simultaneous minimax estimation," submitted for pub- lication in Ann. Math. Stat. [12] A. WALD, Statistical Decision Functions, John Wiley and Sons, New York, 1950. [131 E. T. WHITTAKER AND G. N. WATSON, Modern Analysis, 4th ed., Cambridge University Press, Cambridge, 1940, Sec. 12.5.</page></plain_text>
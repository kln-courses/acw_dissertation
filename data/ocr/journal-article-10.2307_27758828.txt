<plain_text><page sequence="1">Mental States Joseph Margolis Temple University The difference between persons and sentient creatures hangs on a thread. Put in the shortest way possible, to regard an entity as sentient or intelligent is to suppose that predications of belief, perception, intention, and desire may be properly made of it; also, although they do not presuppose the mastery of language on the part of the entity involved, such attributions are conceptually dependent on speech acts nevertheless. For instance, if a dog anticipates his master at the door, as we say, then we must suppose that the dog believes that his master will return soon, or some such thing. The critical consideration is this: we attribute to creates that we regard as sentient and intelligent, mental states of a certain sort, namely, states that have propositional import or proposi tional content or that take propositions as their Intentional objects, whether or not those creatures have been culturally trained in the mastery of a language, whether or not they are persons. This is not to say that Intentional ascriptions of intention, desire, and the like are invariably of the propositional sort only or that all such Intentional ascriptions are completely paraphrasable as ascriptions of the propositional sort. It may or may not be plausible to hold, for instance, that, if Fido wants a bone, what Fido wants is merely that Fido has a bone be true or that Fido wants to make it true or some such thing. But the most perspicuous account of Intentional mental states, as of judging, believing, thinking, is still the one sketched by Geach [1957] and extended and modified by Kenny [1963] for affective psychological states, as of wanting, desiring, wishing, regretting, being pleased: namely, the account in which a report of such mental states is translated into "a report of a mental utterance of a quoted expression." Essentially, the strategy involved is to introduce, as a heuristic device, a speech-act model (Hare [1952]; Searle [1969]; Austin [1962] ), in terms of which the Intentional content of the mental state in question is treated as if it were the oratio obliqua counterpart of some direct speech act. As Kenny summarizes the matter, "Geach draws attention to the possibility of reporting a man's thoughts by the metaphorical use of oratio recta, as in the Biblical expression: 'The fool hath said in his heart "There is no God".' " Kenny himself suggests the following as a specimen extension of Geach's suggestion, for affective states: "The desire to go to Inisfree, for instance, might be reported thus: 'He said in his heart "I will arise and go now, and go to Inisfree".' " Now ?y our theory of certain mental states concedes that such states must be at least minimally interpreted as involving "the metaphorical use of oratio 23</page><page sequence="2">Joseph Margolis recta " then the characterization of sentient and intelligent creatures as such (involving ascriptions of judgment, belief, desire, intention, and the like) must be parasitic on our characterization of persons, that is, of beings literally capable o? oratio recta. This is a very striking conclusion. It explains at a stroke, for instance, why animal psychology is and must be anthropomorphic, regarldess of the care with which our theory of the physiological limits of lower creatures sets constraints on ascriptions of sentience and intelligence, in terms of approximating to, or being altered adjustments of, comparable ascriptions to human persons. Revisions in our picture of human nature by way of attending to animal nature are, inevitably, very complex proposals that cannot them selves be entirely extricated from an initial and ineliminable dependence on our picture of human nature itself; for, even diachronically, we remain unable to eliminate the speech act model. Radical behaviorism, then, is utterly mistaken in thinking that anthropomor phic assumptions, in particular, those regarding the speech model, can be avoided in the scientific description of animals thought to be intelligent and in the initial description of alien human societies {contra Skinner [1953] and Quine [1960] ). And the attempt, as in the interesting study by Bennett [1964], to determine what must be added to the instinctual invariances of honeybee behavior to exhibit a minimal level of rationality is a dramatized reversal of the normal order of speculation, that is, of what may be subtracted from human competences without disallowing ascriptions of rationality to lower crea tures. This is not to say that animals do not behave intelligently or do not do so except as viewed through human eyes; but it appears impossible to provide an analysis of the Intentional states in question without reference to explicit speech. Of course, the entire natural world is interpreted by man. But animals, particularly the higher animals, are not only characterized by men; they're characterized in terms of some metaphorical analogue of that essential attribute that sets human beings apart ? the mastery of language. There are inevitable complications, to be sure. For example, if Fido may be said to be expecting his master at the door, can he be said, assuming that his master = the manager of the First National Bank, to be expecting the manager at the door? Here, one may be inclined to suppose that the usual intensionality of the oratio obliqua constructions holds for animals as it does for men. But that's a mistake. There can be no intensionality regarding linguistic utterances where there are no such utterances and no capacity to make them. We decide, in some manner, that Fido has the concept of his master but not, perhaps, that of manager of the bank; and we formulate the appropriate ? possibly alternative ? metaphorical ascriptions to Fido, on the basis of Fido' s behavior and our theory of Fido' s intelligence. This means that we are never confronted with whether, if Fido believes that p, Fido also believes whatever is equivalent or or entailed by p\ for, if we hold that Fido believes that q, which happens to be equivalent to or entailed by p, our grounds will be independent of the grounds for ascribing the belief that p, unless we have independent evidence that Fido inferred ?7 from p. There is, it may be added, no reason to suppose that inference cannot be ascribed to animals if belief can. What's useful to notice about this constraint is that it obtains, within limits, in human contexts as well. For instance, if we inferred from Sam's non-verbal behavior that Sam believes that/?, we should have made the same kind of metaphorical ascription as before: 24</page><page sequence="3">Mental States in that case, if we wondered whether Sam believes that g, which happens to be equivalent to or entailed by/?, we should have to ask ourselves whether, on our theory of Sam's conceptual capacities and conceptual habits, his behavior justified the ascription. In that sense, questions of intensionality arise regarding Intentional mental states among human beings only where such states are treated as literally involving or actually equivalent to oratio obliqua utterances. This is not an unreasonable concession among human persons, but it is indefensible for animals. And, it may be added, it is a concession among humans. It cannot, fairly, be used to pose or resolve empirical questions about whether, say, there are physically distinct neural processes correlated with the belief that/? and the belief that q. Where linguistic behavior is lacking, either the capacity or the occasion, considera tions of intensionality are pointless and ascriptions of the Intentional content of mental states, metaphorically determined. Consequently, Intentional content or import can only be assigned to neural processes, never, somehow, detected in them {contra Armstrong [1968] and Dennett [1969] ) by correlating neural processes and mental states. Armstrong, in fact, wonders, rightly, why it is, if some mind/body identity thesis obtains, that one may well believe that p without believing that q, where p and q are equivalent and the requisite concepts and inferential abilities, possessed. The answer is a double one: a) because linguistic contexts cannot be reduced to physical contexts; and b) because ascriptions of Intentional content to mental states are metaphorical. It is also true, of course, that, regarding animals, there is simply no basis for construing the syntax of our metaphorical ascriptions as corresponding or not corresponding to that of the local language in which those ascriptions are made. There is no question that we make ascriptions of these sorts to animals and that we would be tempted, under imaginable circumstances, to make them of advanced machines. But we must view them in the right light. First of all, in spite of Brentano's well-known thesis (Brentano [1970]; Chisholm [1957] ) that the Intentional is the mark of the mental, there are phenomena normally regarded as mental, in particular, bodily sensations like pains and aches, that are not Intentional on any of Brentano's criteria. Certainly, though we may describe a pain, we cannot assign it a propositional content in the same way in which we speak of thoughts, beliefs, regrets, desires, or the like (Margolis [1973] ). Again, there are psychological phenomena, in particular, percep tions, such that the relevant perceptual verbs are used non-propositionally as well as propositionally (Chisholm [1966] ). So, for instance, we say boththatSam saw that Fido was in front of him and that Sam saw Fido. What is interesting to notice is that the second but not the first locution behaves extensionally. We would not allow, if Fido = the bank manager's dog, that it follows from the first report that Sam saw that the bank manager's dog was in front of him; but we would allow that Sam saw the bank manager's dog. The differences between Intentional mental states like belief and desire, bodily sensations like pains, and perception need to be sorted further. But what we can see already is that the distinction of Intentional mental states permits us (and obliges us) to reject identity, behaviorist, and epiphenomenalist theories of at least such states, regardless of what may otherwise be required, in admitting bodily sensations and perceptions, or, for that matter, in admitting actions. A second constraint that we must impose on the ascription of Intentional mental states 25</page><page sequence="4">Joseph Margolis concerns the appropriate ontological "fit" between kinds of entities and kinds of attributes. To cite some obvious considerations: a creature cannot be said to intend to do what it does not believe is not yet the case or what it believes it cannot accomplish; and a creature cannot be said to want or desire anything if there is no general congruence between its putative wants and its intentions and the actions it performs; nor can it even be said to know or believe anything if it does not generally act in ways that exhibit a suitable coherence between its putative information and its wants and desires (Rundle [1972] ). It is in this sense that ascriptions of Intentional mental states presuppose an entity of at least a minimally rational sort. In a word, ascriptions of mental states are made only of entities that we assume, however naturally, to behave in accord with certain teleological models that, simplistically, we may characterize as more or less homeostatic. The principal conclusion to stress here is that "an event, state or structure [of the brain or nervous system or the like] can be considered to have [Intentional] content only within a system as a whole" ? hence, that the "fundamental problem [remains] of how the brain uses information intelligently" (Dennett [1969] ). To put the point as a maxim: the brain uses information only if the creature uses information. On the face of it, inanimate physical systems cannot plausibly be ascribed the minimal rationality of sentient crea tures. Living creatures, on the other hand, are said to be sentient insofar as they are also said to be intelligent: they are said to have certain sentient capacities only insofar as whatever putative belief and knowledge may be ascribed them conform, on some theory of their cognitive capabilities and characteristic wants, to what would minimally cohere with putative intentions, desires, and behavior also acri bed to them. To speak of the concepts possessed by an animal, therefore, is simply to speak of the selective capabilities of sentience and intelligence ascribed to it, in virtue of which its putative mental states may be analyzed in the metaphorical manner given. There can, therefore, be no independent access to the concepts of a creature: assuming that it is minimally rational, in the sense sketched, the concepts assigned to it are simply the result of reading back, as potentialities relevant to its own teleological or goal-directed (goal-pursuing) pattern, whatever, on the empirical evidence, may be heuristically reported as the Intentional import of its particular mental states, consequently, we cannot sort the causal role of concepts distinguished either intensionally or extensionally. Armstrong's view [1973] is instructive here: "The concept of red is said to be a certain selective capacity toward members of the class of red things. But are there not other possible concepts under which all and only members of the class of red things fall? And how would we distinguish possession of the concept of red from possession of one of these other concepts? If the class of red things is coextensive with the class of X's, then a selective capacity toward red things is a selective capacity towards things of the sort X . . . [Here is] the solution of our problem. The concept of red is the concept of red because the red object that activates this concept ... has this effect in virtue of the object's redness [sic] . . . And that is the criterion for calling it the concept of red." Nevertheless, Armstrong has difficulty differentiating concepts corresponding to coex tensive classes: in speaking of the causal efficacy of properties [sic], he says that although "two properties are coextensive, . . . they are not both causally operative in the same way in the two [distinct causal] situations," but, in the same context, he admits 26</page><page sequence="5">Mental States that "it seems likely that . . . coextensive properties could not involve different causal powers in relation to anything at all y He wavers again, holding that perhaps the "distinction could be made in situations where the causal chain between object and mind was less direct" (presumably, less direct than otherwise straightforward causal linkages would be), but the claim is ultimately untenable. It is, in fact, unnecessary to speak of the causal efficacy of concepts: concepts are heuristically introduced in just the way in which the propositional content of non-verbalized mental states is introduced; mental states may be assigned a causal role (though precisely how needs to be considered), and distinctions between concepts impose on us no intensional paradoxes, for precisely the same reasons that they do not, in the context in which we report, metaphorically, the Intentional content of mental states. A causal account of concepts is inadequate, then, because it cannot provide for different concepts applying to coextensive properties; and it appears to be self-defeating, because, in order to test whether the alleged causal regularities hold between concepts and instances of certain classes of things that we encounter in certain ways, we must be able to discriminate different concepts whether or not they exhibit the causal regularities in question. So, a causal theory of concepts, even the theory (Armstrong's) that the concept of red "is a second-order capacity ? a capacity to acquire the capacity to react towards the red object when the latter acts upon [one's] mind," is ultimately indefensi ble. The reason is already in our hands: where concepts are ascribed on the basis of linguistic behavior, we are faced with the nonreducibility of language itself; and where concepts are ascribed on the basis of putative mental states, we are faced with the metaphoric dependence of such ascriptions on the very model of language. The bearing of these difficulties on central-state materialism (Armstrong [1968] ) is straightforward. By central-state materialism, Armstrong means essentially the doctinre that "mental states are identified with physical states of the organism that has the mind, in particular, with states of the brain or central nervous system." (Armstrong, it may be noted, fails to distinguish correctly the claims of functional materialism and eliminative materialism [1968]; consequently, he holds that the doctrine is supported not only by Feigl and Smart but also by Putnam and Feyerabend). Against Smart [1962] and Place [1956], Armstrong declares that he wishes to "defend a central-state account of all the mental concepts," whereas these earlier theorists held a behavioristic theory of intentions and the like. Nevertheless, quite apart from functionalist considerations, Armstrong is forced into an impasse in considering the reductive identity of beliefs "with neurophysiological states of the brain." Thus, his theory [1973] leads him to hold that, "Given a belief-state, Bap, we can say that it is also the belief-state Baq if, and only if, 'p' and 'q' are simply different notational expressions of the same organization of Ideas in the one belief-state." But this makes the identity of belief-states depend on the identity of Ideas (that is, adjusting Geach's theory [1957], " 'exercises' of concepts") and concepts themselves; but we have already seen that the ascription of concepts depends on linguistic intensions or the metaphorical description of mental states themselves. Armstrong goes on to say, "Perhaps all would agree that the state of affairs Ba(Fb&amp;Gb) is the very same state of affairs as Ba(Gb&amp;Fb). But what of, say, Ba(if p, then q) and Ba(if-q, then -p)? Have we two beliefs here, or only one? Presumably, we would have to 27</page><page sequence="6">Joseph Margolis look to the future theoretical identification or correlations of neurophysiology to settle such questions with any show of decisiveness." But there are no causal correlations between neural processes and beliefs except where the beliefs in question are already characterized in terms of the speech-act model, and there are no independent causal regularities involving Ideas or concepts. This shows, unmistakably, the sense in which, instead of identifying neural processes and mental states by means of some relevant empirical correlations, we cannot but assign the Intentional content of mental states to neural processes (if we wish) on the basis of correlations between such processes and such states as already Intentionally characterized. A problem rather similar to Armstrong's may be posed for Dennett's account [ 1969]. Dennett asks straightforwardly, "What, if anything, permits us to endow neural events with content?" He sees, rather along the lines already sketched, that ascriptions of mental states having Intentional content are conceptually connected with a teleological model of an organism's life and capabilities and, in particular, following Taylor [1964], that "the question of the elimination of the teleological is intimately bound up with the question of the reducibility of the Intention." He rightly observes that the teleological characteriza tion of the conditions of existence of neural structures "is explicable in terms of the operations of natural selection ? a process that can be given a non-teleological descrip tion;" and he concludes that this itself counts as "a claim in favor of elimination of the teleological." Since the phenomena of natural selection are initially introduced non teleologically, it's a foregone conclusion that a teleological account of such phenomena can be eliminated; in precisely the same sense, a teleological characterization of geologi cal equilibrium can be eliminated. The question remains whether we can reduce teleolog ical and Intentional characterizations for phenomena for which there is no antecedently available non-Intentional or non-teleological alternative, in particular, where sentience and intelligence are ascribed. Dennett himself concedes that, in developing the evolu tionary analogue, "no strict justification has been yet proposed for what must be the crux of any centralist theory: the ascription of content or meaning to particular central states of the brain," but he plainly believes that his extended treatment of evolution provides a basis for the justification. He claims, for instance, that "the principles of evolution" provide not only for the "causes" but also for the "reasons for being" of the particular structures that an animal develops through evolution. He concedes that "the raison d'etre of a neural structure" is not one that the animal or person has, in any sense related to that in which, say a bird picks up twigs in order to make a nest Nor is it a raison d'etre in the sense in which, say, "a can-opener's existence depends on the recognition of its raison d'etre by its maker." No, "the cash value of saying that a neural structure exists for a reason is just this: were the necessary conditions for the survival of a particular animal and the environmental circumstances in general other than they are, such that the neural structure in question would not have the role in survival it has, the structure would not exist." But, precisely, that/s to admit that to assign zraison d'etre to neural structures in terms of evolutionary theory is hardly more than to employ afa?on de parler for handling non-Intentional causal accounts. There is no reason advanced for thinking that the Intentional mental states of sentient creatures could be analyzed analogously. As noted earlier on, Dennett concedes that 28</page><page sequence="7">Mental States mental states are ascribed to creatures or persons and not to brains, which suggests why the ascription of "content" or "significance" to neural events and neural states depends initially on the molar characterization of the behavior and mental states of whole organisms ? as well as why the evolutionary analogue is inapt. In order to make the argument compelling, Dennett would have to show precisely how to reduce the Inten tional mental states that we ascribe to persons and sentient creatures; for, in such circumstances, we appear confronted with an emergent teleology (in Feigl's sense of 'emergent' [1967] ) and not merely an alternative fa?on de parler. Consider what Dennett has to say about a frog's visual discrimination: we might, he says, be inclined to hold that "object reference [say, a fly] is permissible after con vergence of signals from both eyes, or from several sense organs;" still, "the frog will commit itself to a behavioral response on the basis of information from one eye alone . . . Here the shift from a retinal reference to an object reference must depend on what effect a signal has on behavior." But then, "the question facing the centralist is what the organism 'takes the signal to mean' " [italics added], not causal relations between afferent and efferent processes involving the brain. Nothing could be clearer, then, than that Dennett believes that a centralist solution regarding the ascription of Intentional content to neural processes must first concede that such ascriptions cannot but be initially subordinate to Intentional characterizations of the behavior and mental states of the organisms in question. (The frog example, it may b? added, is indecisive in any case since the frog's visual perception is usually characterized in terms of structural/functional invariances that need not even involve ascriptions of intelligence or cognition [Lettvin et. al. (1959)].) Nevertheless, in his central maneuver to overtake the problem favorably, Dennett abandons "the ordinary personal level term 'aware' [and replaces it] by two terms that still take persons (or whole systems) as subjects, but [that] have sub-personal criteria:" thus, "(1) A is aware i that/7 at timer if and only ifp is the content of the input state of A's'speech center' at timer"; and "(2) A is aware 2 thatp at timer if and only ifp is the content of an internal event in A at time r that is effective in directing current behavior." Animals are said to be aware 2 but people are both aware 1 and aware 2 of things. The difficulty, however, is obvious and ineliminable by any maneuver of the sort Dennett proposes; for (1) and (2) max well state empirically necessary and sufficient conditions for awareness 1 and awareness 2, but, if so, they cannot be said to supply "sub-personal" criteria of awareness of either sort. The reason is quite straightforward: nothing could be construed as the propositional content of the input of A' s speech center or the propositional content of an internal event in A except on the basis of an assignment controlled by what Intentional ascriptions are initially made of A, the creature or person involved. Such putative "swb-personal" criteria, therefore, are really elliptical versions of full-blown personal criteria; it is, in fact, only by reference to the latter, that A's "speech center" and the relevant "internal events" in A can even be specified. Given these considerations, it is safe to say (Feigl [1967] ) that no one has yet succeeded in reducing discourse about persons and sentient creatures to non-Intentional discourse about the physical events and states of such systems. Thus, it cannot yet be said, with Dennett, that "the personal story [the ordinary story of a person s mental activities] . . . has a relatively vulnerable and impermanent place [italics added] in our 29</page><page sequence="8">Joseph Margolis conceptual scheme, and could//? principle [italics added] be rendered 'obsolete' if some day we [sic] ceased to treat anything (any mobile body or system or device) as an Intentional system ? by reasoning with it, communicating with it, etc.." There is, at the moment, not the slightest prospect of eliminating persons or the higher animals as emergent entities. It remains to take notice of the respect in which sentient creatures that are not persons may be seen as emergent entities, which, in effect, is to answer a central puzzle in Strawson's account [1959]. Sentient creatures (which Strawson calls "persons") are, as we have seen, ascribed mental states in a way that depends on a metaphorical use of linguistic utterances. They are not actually persons because they lack the mastery of a language; but neither are they merely physical bodies because the specification and explanation of their characteristic properties requires an Intentional and teleological idiom parasitic on the Intentional, rule-governed features of language itself, which properties appear to be irreducible to purely physical phenomena, in the sense em phasized by Lewis [1966], namely, that "physical phenomena have none but purely physical explanations." Nevertheless, since the model of language provides, however ineliminably for the purpose, no more than a heuristic device by which to articulate the nature of the Intentional states of non-language-using creatures, we could conceivably (rather as Descartes seems to have supposed) eliminate such Intentional discourse about animals //we agreed to deny that they were sentient and intelligent. We could treat them as mere physical bodies, in a way in which we could not with ourselves, but we should thereby have lost the most important part of our interest in them. Consequently, we treat animals as entities that have emerged from mere physical bodies in such a way, biologically, that sentience and intelligence may be ascribed to them. Regardless of what may be said of persons, therefore, on the characterization of which their own characteri zation depends, sentient creatures may well be a kind of basic particular, as Strawson claims. They are distinct from physical bodies in that their essential attributes cannot be predicated of mere bodies; but they do not require a form of dualism ? hence, are "primitive" in the sense Strawson emphasizes ? because, on the assumption of their minimal rationality, selected physical phenomena within them and involving them serve as grounds for ascribing functional mental states to them and for construing their molar movements as or as embodying Intentional behavior. In a way, therefore, linguistic ability provides the essential criterion for distinguishing physical bodies, sentient crea tures, and persons: Intentional properties are always, in principle, eliminable for physi cal bodies and scribable to sentient creatures in a way that d?pens metaphorically on the capacity to use language. REFERENCES Armstrong, D.M. [1968], A Materialist Theory of the Mind (London: Routledge and Kegan Paul). Armstrong, D.M. [1973], Belief, Truth and Knowledge (Cambridge: Cambridge University Press). Austin, J.L. [1962], How To Do Things with Words (Oxford: Clarendon). Bennett, Jonathan [1964], Rationality (London: Routledge and Kegan Paul). Brentano, Franz [1970], "The Distinction between Mental and Physical Pehnomena,, (1874), in Harold Morick (ed.), Introduction to the Philosophy of Mind (Glenview: Scott, Foresman). Chisholm, Roderick [1957], Perceiving (Ithaca: Cornell University Press). 30</page><page sequence="9">Mental States Chisholm, Roderick [1966], Theory of Knowledge (Englewood Cliffs: Prentice-Hall). Dennett, Daniel [1969], Content and Consciousness, (London: Routledge and Kegan Paul). Feigl, Herbert [1967], The 'Mentar and the 'Physical': The Essay and a Postscript (Minneapolis: University of Minnesota Press). Geach, P.T. [1957], Mental Acts (London: Routledge and Kegan Paul). Hare, R.M. [1952], The Language of Morals (Oxford: Clarendon). Kenny, Anthony [1963], Action, Emotion and Will (London: Routledge and Kegan Paul). Lettvin, J.Y., H.R. Maturana, Walter Pitts, and W.S. McCulloch [1959], "What the Frog's Eye Tells the Frog's Brain," Proceedings of the Institute of Radio Engineers, XL VII. Lewis, David [1966], "An Argument for the Identity Theory," Journal of Philosophy, LXIII. Margolis, Joseph [1973], Knowledge and Existence (New York: Oxford University Press). Place, U.T. [1956], "Is Consciousness a Brain Process?", British Journal of Psychology, XL VII. Quine, W. V. [1960], Word and Object (Cambridge: M.I.T. Press). Rundle, Bede [1972], Perception, Sensation and Verification (Oxford: Clarendon). Searle, John [1969], Speech Acts (Cambridge: Cambridge University Press). Skinner, B.F. [1953], Science and Human Behavior (New York: Macmillan). Smart, J.J.C. [ 1962], "Sensations and Brain Processes," revised, in V.C. Chappell (ed.), The Philosophy of Mind (Englewood Cliffs: Prentice-Hall). Strawson, P.F. [1959], Individuals (London: Methuen). Taylor, Charles [1964], The Explanation of Behavior (London: Routledge and Kegan Paul). 31</page></plain_text>